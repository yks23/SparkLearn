## 第1部分 技术问题

第一章 测量中的基本问题 3

一、引言 3

二、历史简介 4

1. 早期阶段 5

2. 繁荣阶段 6

3. 第一批判阶段 7

4. 测试组合阶段 7

5. 第二批判阶段 8

6. 问责制时期 8

三、决定的类型 9

四、测试与决定 10

做决定过程中的价值取向 11

五、测量程序的具体步骤 13

1. 特征识别与定性 13

2. 确定隔离和表现特征的操作程序 15

3. 属性的量化 16

4. 测量过程中的问题 18

六、一些测量中的当前问题 19

1. 少数族裔个体测试 20

2. 侵犯隐私 21

3. 使用常模对照组 22

4. 影响测试分数的其他因素 23

vii

5. 受试者的权利和责任 23

总结 24

习题 24

推荐阅读 26

第二章 测量与数字 28

一、如何理解测试分数 28

二、测量量表 31

三、频率分布表的准备 33

1. 分组频率分布 34

2. 累积频率分布 39

3. 图示法 40

四、集中趋势测量 43

1. 众数 43

2. 中值 44

3. 百分位数值 46

4. 算术平均值 47

5. 集中趋势与分布形态 49

五、差异性测量 51

1. 全距 51

2. 半四分位数间全距 51

3. 标准差 52

六、标准差分析 55

七、个体分数分析 57

八、相关性测试 58

九、预测结果 64

确定回归线 66

总结 69

习题 70

推荐阅读 72

第三章 赋予分数意义 73

一、分数的本质 73

1. 参照系 74

2. 标准参照测试和常模参照测试的领域 76

二、标准参照评估 77

三、常模参照评估 80

1. 年级常模 82

2. 年龄常模 86

3. 百分位数常模 88

4. 标准分数常模 94

5. 转换的正态分布 99

6. 九分评分制 101

四、不同类型常模的互换性 103

五、商数 106

六、分数组合 107

七、标准参照分析报告 112

八、学校平均水平常模 115

九、常模使用注意事项 116

十、第三参照系: 项目反应理论 119

总结 126

习题 127

推荐阅读 128

第四章 测量程序应有特性: 信度 130

一、引言 130

二、信度和一致性 131

不一致性的来源 132

三、表示信度的两种方法 133

1. 标准测量误差 133

2. 信度系数 134

\( i\mathbf{x} \)

四、评估信度的方法 135

1. 同材料重复测试 135

2. 平行测试形式 137

3. 单次测量方法 138

4. 方法对比 144

五、信度数据分析 145

1. 标准测量误差 145

2. 信度系数 147

六、影响信度的因素 148

1. 测量对象的差异性 149

2. 测量对象的特征等级 149

3. 测试长度 151

4. 评估信度的方法 152

5. 实际信度和理论信度 153

七、最低信度 154

八、差异分的信度 156

九、不可靠性对变量之间相关系数的影响 159

十、标准参照测试的信度 160

十一、计算机自适应测试的信度 165

总结 169

习题 170

推荐阅读 171

第五章 测量程序应有特性: 效度 172

一、引言 172

二、内容相关效度证据 173

1. 设计命题蓝图 174

2. 测量能力倾向与典型表现的内容效度 181

三、标准相关效度证据 182

1. 表面效度 182

2. 实证效度 182

四、建构相关的效度证据 194

1. 相关性的预测 195

2. 对群体差异的预测 197

3. 对有关实验或干预反应的预测 197

五、效度的统一定义 198

1. 效度验证作为一项科学追求 199

2. 作为整体效度的建构效度 200

3. 梅西克的扩大效度理论 204

4. 对梅西克思想的修正及关注点的变化 208

六、效度理论和测试偏见 210

七、信度和效度的重合 211

八、标准参照测试的效度 212

九、元分析和效度的泛化 213

总结 214

习题 214

推荐阅读 215

第六章 测试的实际应用问题 217

一、例行测试的使用中与实际应用相关的一些因素 217

1. 经济性 217

2. 有助测试实施的因素 219

3. 有助解读和应用测试分数的因素 220

4. 电子化测试 222

二、测试评估指南 223

1. 基本信息 224

2. 关于测试的信息 224

3. 解析测试结果的辅助方法 224

4. 效度 224

5. 信度 225

6. 测试的实施与评分 225

7. 量表和常模 226

\( \mathbf{x}i \)

三、了解具体的测试 226

1. 现存测试有哪些? 227

2. \( X \) 测试到底是什么样的? 229

3. 评审们如何评价 \( X \) 测试? 230

4. 前人对 \( \mathrm{X} \) 测试做过哪些研究? 232

总结 234

习题 234

测试信息参考资料 235

## 第2部分 测试的应用

第七章 教育决策与评估 241

一、引言 241

二、价值观和决策 241

三、《有教无类法案》 242

1. 《有教无类法案》总览 242

2. 标准和评估 244

3. 问责制 245

四、人员安置决策 246

1. 残障学生的主流化问题 247

2. 人员安排决定是如何做出的 248

五、课堂教学决策 249

1. 使用教学目标 250

2. 评估方法的类型 250

六、日常教学决策 253

七、汇报学业进展 254

1. 相对于完美水平的表现 255

2. 相对于同等水平的表现 255

3. 相对于潜能水平的表现 256

4. 评定成绩 257

5. 成绩的重要性 257

八、影响未来教育的决策 258

1. 选拔性决策 259

2. 高风险决策 260

九、其他教育决策 262

1. 有关课程设计的决策 262

2. 公共决策和政治决策 263

总结 264

习题 264

推荐阅读 265

第八章 评估特殊人群: 心理测量、法律及道德问题 267

一、引言 267

二、重大立法与诉讼概览 268

1. 影响重大的立法 268

2. 影响重大的诉讼 269

三、特殊教育评估过程 270

项目实施和评估程序的移交 270

1. 识别和移交 271

2. 资格认定 271

3. 项目计划、实施和评估 272

四、特殊教育评估涉及的主要领域 273

1. 智力和认知能力 273

2. 适应性行为和自理能力 274

3. 行为和社会一情感能力 275

4. 神经心理能力 276

五、评估母语为非英语者 277

1. 简介 277

2. 语言水平评估 278

3. 对母语为非英语者进行学业能力评估 279

4. 对母语为非英语者进行特殊教育评估 280

六、传统学业能力 280

xiii

1. 阅读、数学和书面语评估 280

2. 课程评估 282

3. 生态评估 283

七、专业标准和道德规范 284

简介 284

八、专业训练和专业能力 285

1. 专业训练 285

2. 专业能力 286

九、专业责任和科学责任 286

教育测试与心理测试的标准 286

1. 测试结构、评估和记录 287

2. 测试和公平 287

3. 测试应用 288

十、尊重他人的权利和尊严 288

隐私和保密 288

1. 谁会从收集到的信息中获益? 288

2. 怎么使用这些信息? 289

十一、社会责任 289

1. 公平分配 290

2. 测试的社会效益 290

3. 积极影响的最大化 291

总结 293

习题 294

推荐阅读 294

第九章 测试开发原则 296

一、引言 296

二、编写客观题的一些建议 296

1. 客观题的一般原则 296

2. 编写判断正误题 300

3. 编写多项选择题 305

4. 编写匹配题 318

三、编制可用的客观测试 320

四、客观测试的评分 323

1. 猜题校正 323

五、利用试题分析改进客观测试 325

1. 简化的试题分析程序 326

2. 更多正式试题分析程序 328

六、编写论述题 331

1. 编写论述问题 332

2. 设计论述题测试 334

3. 论述题的评分 335

总结 336

习题 337

推荐阅读 338

第十章 表现评估和作品评估 340

一、引言 340

二、传统认知测试的人为因素 340

三、作品评估 341

四、在认知任务中运用表现评估和作品评估 342

表现评估的评分 343

五、过程评估 345

1. 使用检查表 345

2. 使用定级量表 346

六、评估作品及表现 347

1. 多位观测者的优点 348

2. 多位观测者的可靠性或一致性 348

七、系统观测 350

1. 进行系统观测 351

2. 系统观测的优缺点 354

总结 357

\( \mathbf{X}V \)

习题 357

推荐阅读 358

第十一章 态度及定级量表 359

一、引言 359

二、从他人处了解某人性格 359

1. 推荐信 360

2. 定级量表 362

3. 得出合理定级时存在的问题 363

4. 提高评分效率 370

5. 提高评分准确度 376

6. 用于特殊情况的评分程序 380

三、态度测量 383

1. 累加态度评估量表 385

2. 单项目量表 387

3. 态度评估量表示例 387

4. 其他格式 390

总结 393

习题 394

推荐阅读 395

第十二章 能力倾向测试 397

一、引言 397

二、认知能力理论 397

1. 比奈理论 398

2. 斯皮尔曼的 \( g \) 理论 399

3. 瑟斯通的基本心理能力理论 399

4. 延森理论和韦氏理论 400

5. 卡特尔一霍恩的流动一固定智力理论 402

6. 卡罗尔的三阶层理论 403

7. 斯滕伯格的智力三元理论 403

8. 戴斯-那列里的 PASS 模型 404

9. 加德纳的提议 405

三、个人一般能力测试 406

1. 斯坦福-比奈智力量表第四版 406

2. 斯坦福-比奈智力量表第五版 410

3. 韦氏量表 414

4. 伍德科克-约翰逊心理一教育测试组合第三版 417

5. 戴斯-纳列里认知评估系统 419

6. 认知能力的非语言性测量 420

7. 简易个人测试 423

四、群组一般能力测试 425

五、多能力测试 430

1. 差别能力倾向测试组合 431

2. 一般能力倾向测试组合 433

六、一般认知能力的作用:《钟形曲线》 436

总结 441

习题 441

推荐阅读 443

第十三章 标准化成绩测试 446

一、引言 446

二、标准化成绩测试的特点 446

三、标准化成绩测试的用途 447

四、标准化成绩测试的类别 448

五、群组标准化成绩测试 449

六、个人成绩测试 451

七、中学及大学水平成绩测试 453

八、全国范围内实施成绩测试组合的问题—— “乌比冈湖效应” 456

九、解析标准化成绩测试 459

十、诊断型成绩测试 460

十一、标准参照的标准化成绩测试 462

xvii

1. 标准参照的标准化成绩测试案例 462

2. 标准参照的标准化成绩测试存在的问题 463

总结 464

习题 464

推荐阅读 465

第十四章 兴趣、性格和调整能力 466

一、引言 466

二、兴趣测量. 467

1. 斯特朗兴趣量表 467

2. 职业评估量表 477

3. 自我探索量表 478

三、性格和调整能力评估 479

1. 动态评估法 480

2. 特质研究法 483

3. 人本主义研究法: 性格与自我认知 492

4. 行为研究法 494

四、性格和兴趣测量存在的问题 500

五、计算机评分与解析 502

优点 502

缺点 503

总结 503

习题 503

推荐阅读 504

附录 正态曲线中低于设定值的测试对象所占比例 506

参考文献 508

## 第1部分 技术问题

## 第1章 测量中的基本问题

## 1.1 引 言

无论是社会还是个人都需要不断地做决定, 做决定是每个人每天必不可少的事情之一。从早晨起床,我们就开始不停地做决定,比如早餐吃什么,今天穿什么…… 我们日复一日地做着这样的决定, 以致从来没想过它是怎么发生的。还有一些不常做的决定需要我们仔细思考和分析, 比如将来上哪所大学, 学什么专业, 是否在某企业工作等。做出这类决定需要综合分析是否还有备用的选择, 以及这些选择会产生怎样的结果, 比如我是否对某所大学感兴趣, 毕业后的就业前景怎么样, 我成功的概率有多大, 该企业有什么竞争优势, 以及工作条件怎么样等等。

还有一些是个人为了服务社会所做的决定。每天, 老师们都必须根据学生们当前的知识和能力水平来决定如何为学生们提供对他们来说最佳的教育体验。学校心理咨询教师可能需要做决定, 对于在阅读和数学上有困难的孩子, 是否应该建议其接受特殊教育。学校的、地区的和州教育行政管理人员需要决定相关教育政策, 并且常常还要向州的和地方学校理事会及州议会提供学生优秀表现的证明材料。雇主们需要做决定, 挑选合适的求职者与最适合该求职者的岗位。大学辅导老师需要做决定, 怎样应对学生无法适应相对自由的大学环境的情形。如此看来, 人们需要做的决定和人类的日常交往活动一样多。

一般情况下, 我们假设人越了解影响自己做决定的因素, 做出的决定就越稳妥。 也就是说, 更多更好的信息搜集更有可能使我们做出更好的决定。当然, 仅仅掌握这些信息并不一定就能保证它们被充分且完善地应用。对于所做的决定来说, 这些信息应当是相关且适当的。同时决策者也必须了解如何充分发挥这些信息的作用, 以及与之相行和相悖的推断。我们希望通过本书, 读者可以了解教育和心理学领域的一些基本概念、基本工具和技巧, 以及基础理论等, 对大家在做决定的过程中有所裨益。掌握这些方法技巧, 决策者们今后能更加自如地获取和使用所需信息, 做出合理有效的决定。

## 1.2 历史简介

虽然近几十年来教育测量的发展有目共睹, 尤其是《有教无类法案》的出台和问责制关注度持续上升。正式的教育成果评估及以此为基础来做决定, 这一模式已经沿用几百年。早在公元初年,中国就已经开始实行选拔官员的科举考试制 (DuBois, 1970; Robert M. Thorndike, 1990a)。经过几百年的发展, 中国的科举考试已形成一套制衡机制, 可有效消除测量过程中可能存在的主观偏见, 这些程序与现代制度具有一定的相似性。例如, 隔开应试者们以防止舞弊, 作文由专业抄写员誊抄以避免笔迹的差异性影响打分, 由两位考官共同评阅每一位应试者的考卷, 若有意见不一致的情况则交由第三位评判。测试阶段持续三天, 十分严格, 通过率低, 通常不到应试总人数的 \( {10}\% \) 。 19 世纪初的西欧和美国的公务员选拔考试的发展在许多方面都受到了中国传统科举考试制的影响。

西方教育实践中的正式测试程序萌芽于 19 世纪。过去几百年间, 中学和大学一直通过文章写作和口头测试来评估学生成绩。直到 1897 年, 约瑟夫 - M. 赖斯 (Joseph M. Rice)首次在波士顿公立学校采用统一笔试对学生进行拼写测试。赖斯希望学校开设科学相关的课程, 并认为可以减少部分学生用于拼写训练的时间来学习科学。赖斯指出花在拼写训练上的时间与拼写成绩并不成正比, 因此可以适当减少, 腾出时间来教授科学了。赖斯的研究是利用测试来辅助决定相关课程设置的早期做法之一。

19 世纪后半叶, 心理学这一新兴科学的发展创举主要在于发现了衡量人类行为和经验的新方法。许多测量方面的进步源于实践人员的实验室研究, 诸如赫尔曼 - 艾宾浩斯 (Hermann Ebbinghaus 的研究)。他于 1896 年采用了完形填空测试来测量学生的心理疲劳情况。19 世纪早期的时候, 恩斯特 - 韦伯 (Ernst Weber) 和古斯塔夫・费希纳 (Gustav Fechner) 对感官过程的测量研究, 为心理和教育测试打下了逻辑理论基础。还有一些重要的发展为人类差异性的分布和原因研究奠定了坚实的基础, 比如弗朗西斯 - 高尔顿 (Francis Galton) 爵士和卡尔 - 皮尔森 (Karl Pearson) 爵士有关关联系数的研究。19 世纪初打上了杜布瓦 (DuBois, 1970) 的时代标签, 被称为心理学测试历史上的实验时期。由于常用一些机械装置采集生理和感官特征测量数据, 这一阶段也被称作铜器心理学时代。

19 世纪后半叶, 人类特质测量的关注度不断上升, 主要源自在以下三种情形下做决定的需求。第一, 有关义务教育的立法使得公立学校对评估学生成绩的客观性和问责制的需求不断增强。这些立法的实施使得这些学校第一次迎来了大量社会和经济地位处于中等或中等偏低水平的学生, 而他们此前没有接触过正规教育。其中很多学生学习成绩不佳, 甚至有一些当时的教育工作者认为他们属于 “弱智低能” 者, 无法像正常人一样学习。而精确的测试方法和仪器的发展可以有效地将真正的心智障碍儿童和只是由于家境贫困而造成的学习不佳的儿童区分开来。第二, 医学界也正在完善改进对异常行为的解释和界定。行为和心理测量可以作为划分和诊断相关患者的一种手段。第三, 在招聘中, 企业和政府机构开始以竞争性的选拔考试制替代赞助制, 测试评估潜在职员和公务员的能力。测试逐渐成为员工选拔的基本门槛。

直到 20 世纪头几年, 发展完善的现代心理学和教育学测试原型才开始出现。虽然很难说这期间哪件事情最关键, 但是 1905 年出版的比内一西蒙 (Binet-Simon) 智力量表一直被认为标志着现代心理测试的开端。比内一西蒙智力量表最初以法语出版, 而后很快翻译成了英文和其他语种, 被高度评价为运用一套标准的、复杂程度不一的任务测量复杂的心理过程的首次成功尝试。这些量表可以帮助教育工作者们分辨心智能力跟不上标准统一的公立教育模式的学生。基于心理测试结果, 可以做出是否应将这一类学生编人特殊培养班。在后续 (1908 年和 1911 年) 面世的几个版本中, 比内一西蒙智力量表涵盖了一些测试学龄儿童各方面能力的任务, 可以用来识别处于智力两个极端的学生 (关于这些量表更完整的描述, 请参照罗伯特。M. 桑代克, 1990a.)

与此同时, 比内和西蒙也在研究最早的一些智力测试方法。E. L. 桑代克和他在哥伦比亚大学教师学院的学生正在着手解决学习能力测试中的相关问题。他们的工作内容不仅包括关于测量过程的本质的理论研究, 还包括研究新的评估课堂阅读、算术及书写水平等技能方面的学习能力的测量方法。智力测试时代的序幕由此拉开。

## 1. 早期阶段

早期阶段, 即美国参与第一次世界大战之前的数年间, 是心理学测试理论发展的初探时期。比内一西蒙量表由比内修订了两次之后, 首次被数位测量领域的先驱学者引人美国。其中最有影响力的是斯坦福大学的路易斯・特曼 (Lewis Terman)。特曼于 1916 年首次出版的一种测试或量表, 即斯坦福一比奈智力量表, 仍然是当今许多智力测试的评判标准 (斯坦福-比内智力量表第五版于 2003 年公布)。和特曼一起共事, 亚瑟・奥蒂斯 (Arthur Otis) 与特曼 (Terman) 合作, 也开始探寻测试儿童和成人群组智力的可行性方法。澳大利亚的 S. D. 波蒂厄斯 (S. D. Porteus) 运用一种迷宫测试法对听力或语言障碍患者进行智力测试。

1904 年, 查尔斯・斯皮尔曼 (Charles Spearman) 发表了两套有关人类能力测试的重要理论。一套是描述人类行为测试中的不一致现象的统计学理论。另一套理论解释了不同的认知能力测试方法在排列分级测试者的时候表现出的惊人的一致性。 第一套描述不一致现象的统计学理论发展成为可靠性理论概念, 这一点会在第四章详细讨论。斯皮尔曼的第二套理论提出, 有一种能力维度是绝大多数人类活动表现的基础, 多年以来在决定能力测试的基本方向上起着十分重要的作用, 且在人类认知能力理论中仍然具有极大的影响力。斯皮尔曼指出, 人们在不同能力测试中表现出的一致性取决于其共有的基本智力水平。这一理论的后续发展流派和应用于智力测试的实验方法将在第十二章进一步阐述。

## 2. 繁荣阶段

美国投身第一次世界大战使得扩充军队的需求剧增。心理学这门新兴学科被首次应用于军事领域。也正因为如此, 心理学测试经历了 15 年的繁荣阶段。在此期间, 实验和测试领域出现了许多新方法和巨大的发展进步。为服务于战争, 一组由罗伯特。耶基斯 (Robert Yerkes) 带领的心理学家进一步丰富了奥蒂斯的研究, 发展和实施了第一次大规模的群组能力测试, 分别是阿尔法军队 (Army Alpha) (口头测试) 和贝塔军队 (Army Beta) (使用的是和波蒂厄斯的方法相似的迷宫和谜题测试, 不要求口头或书面语言能力)。阿尔法军队测试是应用多项选择题的大规模群组测试。 第一种较为客观的个性测量方法——伍德沃思 (Woodworth) 个人数据表同样用于该组测试中, 以便区分出太过感性而不适合参军的人员。阿尔法和贝塔测试方法当时被用于筛选见习军官, 同时淘汰有智力障碍的军人。

第一次世界大战后的 12 年间, 可进行测试的行为种类不断扩展。E. K. 斯特朗 (E. K. Strong) 和他的学生开始进行职业兴趣领域的测试, 以助大学生们选择符合自己兴趣的专业和职业。其中性格和能力方面的测试得到了发展和完善, 使用常模测试方法指导教育决策的做法越来越普遍。1929 年, L. L. 瑟斯通 (L. L. Thurstone) 提出了测量和测试人们的态度和价值观的一些方法。很多人认为在此基础上, 只消几年就能够实现对各种人类行为的精确测试和预测。

紧接着第一次世界大战后的这一阶段同时也是智力测试发展的谷点。对测试分数对于测试者能力和性格的说明能力期望过高导致这一测试方法的研究和使用人员过于相信测试分数的准确无误性。正如美国军队测试的结果所示, 美国白人受试者和其他不同种族的受试者的测试分数具有巨大的差异性。测试者分析非裔美国人和南欧、东欧移民的测试分数较低是智力等级不同的表现, 其中北欧族系的移民 (北欧人、日耳曼民族) 智力水平最高。分数最低的种族, 尤其是非洲裔族系的移民群体, 则被贴上了 “弱智低能” 的标签。许多评论家, 比如最著名的瓦尔特。李普曼 (Walter Lippmann), 不但质疑测试本身的科学性, 而且怀疑从这些测试分数得出的结论的可靠性。

## 3. 第一批判阶段

20 世纪 30 年代, 不仅股票市场崩盘了, 人们对心理测量法的期望值和信任度也明显下降了。这一时期是批判和巩固发展阶段。在此期间, 确实也有新的测试方法发表, 最有名的是库德原创 (Kuder) 的职业兴趣测试量表, 即明尼苏达多向性格测量表 (Minnesota Multiphasic Rersonality Inventory)。这也是首次出现能与斯坦福-比奈 (Stanford-Binet) 的韦氏智力量表 (Wechsler-Bellevue Intelligence Scale) 相匹敌的测试。此外, 测试背后所依据的数学理论也取得了重大进展, 尤其是 L. L. 瑟斯通对于称为 “因子分析” 的统计步骤的进一步完善。然而, 并非所有人类行为测试中暴露出来的问题都得到了完满的解决这一事实也日益凸显。而且, 这些问题比想象中更难解决, 尤其是在狂热冒进的 20 世纪 20 年代。

在测试方法的多样化发展日益丰富, 根据测试分数做决策的人群不断增长的现实中以及新闻媒体中对于心理学测试的批判下, 一位年轻的心理学家奥斯卡。布洛斯 (Oscar Buros) 开始呼吁专业心理教育测试学界实行自我监督和管理。布洛斯发现许多测试几乎没有用于支撑使用这些测试方法的客观有力的证据。1935 年, 他首先发起了《心理测试年鉴》(简称 MMY) 以供大家自由地发表有关测试和测试方法的批判评论。其目的在于获取心理学测试领域知名专家们对此的评价和看法, 从而有助于测试研究人员提出更好的测试方法及更多支撑具体用途的测试的证据。在第六章中将会提到, 《心理测试年鉴》上发表的内容仍然是测试相关信息的最佳来源之一。

## 4. 测试组合阶段

20 世纪 40 年代, 心理测试再一次为军事服务。为服务于战争, 成套测试被开发出来用于测量多项不同的能力。基于瑟斯通和其他学者的理论, 能力分为许多不同的类型和方面, 这些测试组合用于军事招募中, 将合适的新兵安排在其最合适的岗位上。这一方法能够有效降低各种军事训练项目的失败率, 也因此促进了心理学测试领域向侧重于测试组合和因子分析的阶段发展。 25 年以来, 大约到 1965 年, 心理学测试研究方向主要在于人类行为的不同方面, 同时关于能力和性格的测试方法不断丰富且多样化。比如布卢姆 (Bloom,1956) 和吉尔福德 (Guilford,1985) 等学者关于能力的分类法阐述了心智功能的范围。

20 世纪 50 年代, 心理学和教育学测试日益发展壮大为一项产业。具有全国规范性和商业适用性的测试用于评估学生成绩已经成为学校生活中必不可少的一部分。学习能力倾向测试 (简称 SAT, 现在又叫学术能力评估考试) 或称美国大学人学考试 (简称 ACT 测评) 几乎成为了所有大学必备的人学测试。工商及行政部门也越来越广泛地使用态度、性格和能力测试方法做出雇用和晋升的相关决策。一般能力倾向测验 (GATB) 是由美国就业服务部开发的。还有一些私有测试公司所开发的其他测试组合, 用于帮助个人或组织做出关于就业或雇用决策。精神病院的患者会进行一系列常规的性格和调节测试。1954 年, 由美国心理学协会主导, 专业测试界发表了一套心理学和教育学测试指导方针, 为良好的测试开发和测试实践提供参照标准。测试成为了美国生活方式的一部分。测试的广泛使用或滥用引发了新一轮的抵制。

## 5. 第二批判阶段

1965 年在一系列国会听证会上, 测试被定性为侵犯隐私, 这标志着第二批判阶段的开端。 20 世纪 60 年代的十年同样是民权运动高涨的时期, 女性合力反抗其所认为的男权社会。由于黑人的能力测试分数普遍低于白人, 在某些地区女性的测试分数低于男性 (尽管在其他一些地区女性的测试分数高于男性), 人们斥责白种人以此为其父权社会的压迫手段。从那时起, 关于在教育和就业领域通过能力与性格测试进行无差别选拔的争论便不绝于耳。人们真正担心的是万一教育和就业领域决策者们以此测试为由歧视女性或有少数民族背景者, 无论有意或无意。因此, 人们详细检查每一项测试是否含有歧视性内容, 调整或舍弃某些测试方式, 同时更加注重受试者的个人权利。心理测试研究领域积极关注这些需求, 并积极作出调整, 以使每一位受试者得到公平的待遇。但这些还不足以说服立法、行政和司法部门改变限制使用这些测试的决定。正如最近颁布的一项行政决定, 建议废除加利福尼亚大学系统以学业能力倾向测验 (SAT) 的成绩作为录取标准的做法。这样的情形不禁令人惋惜, 因为没有最充分的信息基础, 决策者们将无法做出最准确的决定。事实上, 在努力排除测量过程中的偏见时, 我们或许误把最重要的部分也一并舍弃了。第八章将详细讨论有关教育和心理测试使用方面的争议。

## 6. 问责制时期

公众对于测试的批判之声此起彼伏的同时, 政府却日渐相信测试可以协助判断政府资助的项目能否达成目标。1965 年初级和中级教育法案 (ESEA) 的通过使得美国联邦资助的教育机构的态度有所改观, 并规定教育项目须以一定的评估机制为依据,通常为固定形式的测试成绩。乔治 \( \cdot  \mathrm{W} \) . 布什总统于 2002 年签署并通过了《有教无类法案》(NCLB)。该法案的首要目的是确保所有公立学校的学生在阅读一语言以及数学、科学等文理学科均取得优秀成绩。为了达成这一目标, 政府要求每个州制定一套严格的成绩评判标准, 并以此评测学生的学习效率。每个州的学校和学区需对其学生的成绩负责。对于学生平均成绩欠佳的学校, 须无条件接受政府的介入, 对学校提供技术协助或重新规划调整学校结构等。许多州已明确立法, 规定学生须通过固定类型的测试以获得高中毕业文凭。然而这一测试的使用方式风险虽高, 却非首例 (中国早在一千年前就实行过更严格的测试方法并产生了更深远的社会影响), 越来越多的州开始将考试作为毕业的衡量标准之一。以华盛顿学生学习成绩测评为例, 这一分数是 《有教无类法案》的责任要求是否达标的评判标准, 且自 2008 年起, 学生能否取得高中文凭取决于这一测试成绩是否合格。该法案还规定, 全国新进教师须通过固定类型的测试获得资格证书并能出色地完成教学, 这些都是成为“高素质” 教师所必需的。对于测试, 尤其是教育领域固定类型的测试, 批判之声四起, 而与此同时, 由于学校能因此了解和负责其学生的学习成绩, 这些测试也日渐占据越来越重要的位置。

## 1.3 决定的类型

教育和心理评估测试经过发展, 有助于人们针对人做出个人或群体决定。比如, 越来越多的老师、顾问、学校行政人员及工商行业心理学家不断参与到人们的日常决定中, 或为他们做出决定进言献策。测试的作用在于提供信息, 使决策者做出尽可能准确适当的决定。

有些决定具有教学指导意义, 比如老师和学校心理医生的决定。一个具有指导意义的决定可能影响整个班的学生, 比如老师是否应该在课堂上复习课堂内容之外的算术的 “进位”? 或者班上大部分学生是否都会进行这一运算呢? 还有一些决定与具体学生相关, 比如考虑到个人兴趣和阅读水平, 什么样的阅读材料对学生玛丽来说才是最合适的? 对于如上这些情形, 若想做出最明智的决定, 首先应当着重了解该班级学生掌握算术 “进位” 的整体水平, 其次, 应了解学生玛丽的阅读能力及兴趣。

有的决定与课程相关。学校可能考虑引进计算机辅助教学 (CAI) 讲解分数乘法的基本原理, 或是基于网络进行的非洲地理知识教学, 以此来变更课程设置。那么, 该学校应该做出这些改变吗? 决定是否适当取决于, 与传统方法相比, 在采用 CAI 和非洲地理网络教学等新的教学模式下学生在多大程度上取得了进步。学生取得了实质性的进步, 所做决定产生的效果只可能与数学能力或地理知识的测试结果成正比。这些测试结果是我们评估备用教学指导项目的基础。

有些决定是选拔性的, 通常由雇主或教育机构负责人做出。一所好的大学需要决定接受哪些申请者为其来年入校新生。录取标准可能十分复杂, 但有始终不变的一条是每一位合格者都是学校认为能够根据其要求良好地完成学业的学生。心理测试结合其他方法, 如中学的分数及有关学习能力的标准化测试, 如学习能力倾向测验 (SAT) 或美国大学入学考试 (ACT) 测评, 可以为预估学生进入大学后的学习情况提供有效依据。就业领域也需要做选拔性的决定。为了从一群求职者中挑出那些更有潜力的高效员工, 雇主会发现依据比较测试中应聘者们的表现可以提高录用决定中的准确性和客观性, 从而提高生产力和员工满意度。

有时, 决定可以是定性或分级的决定。一所中学需要决定将入学新生归置到进阶数学班或普通班。一位负责军队人事的技术人员需要决定将入伍新兵分配到电子部门还是炊事部门。同样,一位家庭医生诊断由肌肉拉伤或神经受到压迫引起的背部疼痛时也需要做出分类决定。因此, 定性型决定的决策者需要基于一定信息预测个人在其所从事的不同岗位或事情上, 这个人能学到多少知识, 又或是这位应试者能取得多大成就。借助这些信息, 决策者能够对其做出定性决定, 找到属于该个人的最合适的位置。

最后, 还有许多决定是个人决定。每个个体在人生的诸多十字路口所做的决定就属于此类。比如是要继续攻读硕士学位还是参加其他类型的研究生职业培训? 还是毕业后直接就业? 如果选择就业, 要找一份什么样的工作? 如果以后要做这样的决定, 大学期间应该制定什么样的课程选修计划? 指导老师们常常运用标准化的测试帮助年轻人们做这样的决定。人们对自己的兴趣和能力了解得越多, 考虑得就越全面, 个人的决定也就越稳妥。

## 1.4 测试与决定

通过提供更全面准确的信息, 一些心理和教育测试方法能帮助人们做出更好的决定。这本书旨在指出和描述那些有助于人们做出合理决定的测试手段的特征, 以及那些对决策者最有用的测试结果的呈现形式应是什么。处理每种不同类型的评估方法时, 我们会提出这样的疑问: “某一特定的方法用于哪些类型的决定才能提供有价值的信息?”其中有诸多因素需要考虑, 包括缺乏动力、情绪低落、教育不足, 或来自非典型语言文化背景等。所有这些因素都可能导致测试、问卷或其他评估程序产生不可靠的结果。与此同时, 我们也应考虑预防措施, 以防参考这些信息做决定时出现其他未知情况。

## 做决定过程中的价值取向

做决定的不是测试程序而是人。测试程序最多只能提供一些有关影响决定的因素的信息。学业能力倾向测验 (SAT) 结果能在一定程度上说明格雷丝 (Grace) 在接下来的大学阶段的成绩和表现。基于锡沃斯大学 (Siwash University) 工程学专业对学习能力水平的需求程度的相关信息, 通过格雷丝的测试分数可以对其在这一专业中可能的表现做出准确的评估。然而, 只有格蕾丝自己才能决定是否选择锡沃斯大学及其工程学专业。她是否对工程学感兴趣? 她选择锡沃斯大学而非其他是否因为个人原因? 是否出于经济因素的考虑? 格蕾丝给自己在这个社会中的定位是什么? 或许她根本无意进修, 而是想成为一名有竞争力的冲浪运动员。

上述例子告诉我们有关行动路线的决定不仅基于事实, 还基于一定的价值观。 通过学业能力倾向测验 (SAT) 可得到一个分数, 这属于事实。这一事实或许能使我们预测出格蕾丝被锡沃斯大学录取的概率是六分之五, 而被斯坦福大学录取的概率是六分之一。如果她认为斯坦福大学的理想程度是锡沃斯大学的十倍, 那么, 即使被斯坦福大学录取的概率相对低很多, 她仍旧选择申请这所大学的决定也是合乎情理的。测试分数无法反映个人价值观。在格蕾丝能够自己做出合理的决定之前, 须通过其他方法获得做出决定所需的相关信息。咨询顾问的一个重要职能就是使人们认识到促使自己做出相应决定的价值观。

公共机构决策者和个人的决定都受着价值观的影响。通过一项能力测试便可以判断非洲裔或西班牙裔或是美洲原住民学生与白人或亚裔学生相比, 在一些学业或专业技能培训方面取得优秀成绩的可能性大小。然而, 有关录用与否的决定, 无论直接或委婉, 都需要考虑其对社会价值的影响, 比如增加某一行业白种人或亚裔人种比重与增加非洲裔、西班牙裔或美洲原住民比重相比, 何者具有更高的价值。过去的 35 年以来, 人们越来越关注社会正义及教育决策过程中的机会公平和结果公正。最近几年, 美国三大州, 包括加利福尼亚州、华盛顿州和密歇根州, 均已制定法律明令禁止教育决策中的种族歧视。

一旦涉及价值观问题, 事情往往变得复杂而棘手, 而且常常与做决定有着千丝万缕的联系。很少有不带有某种价值观色彩的决定, 意识到这一点很重要。同样需要注意的是我们的价值体系中存在的不确定性和矛盾等问题不应归咎于能够提供更有效的信息的评估程序。意即, 不能因为收到的消息不是自己所想就扼杀送信人, 抑或是遮住眼睛和捂住耳朵以拒绝接收消息, 而应该想办法改变这些自己不愿接受的事实。

正如这章最初所提到的, 人类行为的方方面面都涉及做决定。我们不得不做决定。甚至某种情况下的不作为也是某种决定。在大多数情况下, 人们会权衡出现各种不同结果的可能性, 其中利弊以及每种可能的结果中所蕴含的价值观。教育和心理评估程序仅仅是为了提供一些信息, 而人们可以参考这些信息做出某些特定类型的决定。实践证明, 若使用得当, 通过这些测试程序提取的信息实用性强, 且较其他方法具有更高的准确性。研究教育心理测评可了解获取做出某些特定类型的决定所需的信息的方法和技巧。除此之外, 还有运用这些方法和技巧评估所提取的信息, 衡量这些信息的真实效度, 以及了解这些信息固有的局限性的标准。

继加利福尼亚州公民投票揭去大学录取体制中的种族主义标签之后, 州教育部提出取消以学习能力倾向测验 (SAT) 成绩为大学录取的参照标准。原因不言而喻, 即测验中白人和亚裔美国学生取得的分数普遍高于非洲裔和西班牙裔学生, 因而前者进入本州大学的概率远高于后者。若相关体制的行政人员旨在实行比例代表制, 使所有种族平等享有接受教育的机会, 那么以测试分数为标准则没有意义, 否则又会回到教育机会分配失衡的情况。然而, 华盛顿州立法人员却支持对其学生在官方的评估测试中的成绩优于教育部规定的平均水平的学校和地区给予资助奖励。华盛顿州自主测验的结果与学习能力倾向测验 (SAT) 相似, 即不同种族学生的学习能力和水平不一。不同的是华盛顿州重视对成绩优异者给予奖励的积极效应胜过种族不平等带来的负面效应。由于各自所奉行的价值观不同, 两州的教育机制对使用标准化测试也持截然相反的看法。

上述讨论的是具有实际行动意义的决定。心理测试对于提供信息以指导我们做出理论上合理的决定同样重要。如上例所示, 理想的结果不是知其然, 而是知其所以然。某一年龄阶段的女孩阅读水平是否高于男孩? 为了获得做出相关决定所需的信息就需要进行一项阅读测试。考前易焦虑的学生是否比那些不焦虑的学生在实际考试中的表现要糟糕? 为此需要进行有关“考前焦虑症”的问卷调查及有关学习成绩的测试, 获取有效信息以推断出这一问题的结论。即使是像老鼠穿过迷宫得到的 “奖赏”大小是否会影响它穿行的速度这样浅显的问题也同样需要调查人员进行测试。12测试是解决几乎所有科学问题的基本方法。而这里的科学问题不仅包括自然科学, 还包括人类行为科学和生物科学。我们提出的问题和问问题的方式源自我们对现实本质的揣测和内在的价值观的启发, 而同时也受其所限。

## 1.5 测量程序的具体步骤

这本书介绍如何测量人类的能力、兴趣爱好及性格特质。但首先应当说明一下测量具体是指什么。如果正式宣布已进行一项测量, 需要满足哪些要求。同时还需要了解用于测量人类兴趣特征的那些可行方法在多大程度上切实地满足了这些要求。

任一领域的测量都包括三个基本步骤: (1) 明确所测量的特征或属性, (2) 设计全套操作方案将该属性分离出来进行观察研究, (3) 确定一套程序或定义体系以量化研究结果, 将其转化为反应程度和数量的直观数据。了解这些基本步骤及每一步骤中的难点是理解心理和教育测量的程序和其中的问题的良好基础。

## 1. 特征识别与定性

我们测量的并非某件事或某个人, 而是某一事件或人的一个特征或属性, 比如桌子的长度, 高炉的温度, 汽车轮胎的耐久性, 碳酸饮料的风味, 小学生的智力或是青少年的心理成熟度。心理学家和教育家们用构念这一术语指代那些抽象的难以观察的属性, 比如人的智力和性格。

测量物体的长度等简单的物理属性时, 我们几乎不会去思考这些属性的定义或意义。长度的含义似乎在很久以前世间万物的历史演进中便早已确定。随着时间的流逝, 长度单位和体现属性的方式不断变化 (我们不再使用 “一掌” 或 “一肘” 作为长度单位), 然而这其中隐含的概念却没变。虽然掌握长与短的概念对于学龄前儿童来说是极大的进步, 但这些对成人来说则是自然而然就当知道的。一说到长度, 没有人不明白它是什么意思。

长度的定义具有统一的标准, 长度的运算原理也人人皆知。然而, 并非所有的物理属性都具有这样明确的定义且得到大家的一致认同。汽车轮胎的耐久性具体指什么? 指的是抗道路磨损, 防尖锐物穿刺, 抗日光照射或自然老化还是上述三者兼而有之, 或许还掺杂一些其他因素? 测量得以进行的前提是就耐久性的含义达成一致。 在此问题 (即耐久性这一概念的定义) 上的争议将导致在选择合适的测量程序时产生同样的分歧。不同的测量程序最终很可能产生不同的测量结果, 因此必然也会对某一特定品牌轮胎的耐久性得出不同的表征数值。

就心理学家或教育家关注的那些属性特征而言, 需要就某一特定构念的含义达成一致的问题则变得更加尖锐无法回避。智力的含义是什么? 哪些行为属于高智商的表现? 是否首先应该从想法和抽象概念的角度去定义这一构念? 它是否也涉及实际存在的具体物体? 在一些新情形中, 智力首要指代的是否也是某种行为? 是否包括在熟悉环境中的反应? 它是否是指反应速度和灵敏度或与时间无关的反应的复杂程度? 是否包括社交技巧? 什么样的成就才是智力结出的果实: 原子结构理论、芭蕾舞表演还是一个简单的雪人? 对于高智商的行为表现, 我们每个人都持有一些大体一致的看法, 但在明确定义使其达到测量所需的精确程度的过程中一定会存在许多具体的分歧点。所有心理学构念都存在需要精确界定属性的问题, 只是难易程度不同而已。心理学家和教育家们在测量属性的过程中面临的首要问题就是对这些属性做出清晰精确的且为大多数人所接受的定义。

当然, 还有在界定属性这一问题出现之前就存在的另一个不容忽视的问题。要进行有用的描述, 首先必须区分哪些属性与测量相关且重要。由于测量的特征或属性不相关, 获取的信息可能对于正在进行的调查没有什么参考价值。以描述一幅画为例, 我们可以准确地说明其高度和宽度及重量, 并就这幅画的每一种属性的程度达到高度一致。如果是为了将它装箱托运, 如上描述正是我们所需要的信息。而若是为了说明这件艺术品的特征, 这些描述则没有意义, 因为它们与这幅画作为一件艺术品的品质没有任何相关性。

类似地, 如果选错了描述的属性, 那么对于描述一个人也几乎是没有用处的。在卡车司机岗位面试中, 雇人的公司可能会十分准确地测试应聘者的语言理解能力和定量分析问题的能力。然而, 从这些方面获得的信息很可能对于筛选出事故记录低且能长期稳定从事这一岗位的应聘者毫无帮助。其他一些因素, 如眼手协调能力、空间感及能控制冲动情绪等, 与如上测试的项目相比, 或许还与卡车司机所面临的责任和压力具有更高的相关性。测试程序对其所服务的目的的有用程度称为效度。

设想有一位对学生对于一些诸如“皇帝协奏曲”的作曲者是谁, 以及行板是否比快板快的事实的掌握程度进行了全面测试的中学音乐老师。这位老师能够在未向他们介绍一个音符或一丝旋律, 抑或是一点一滴有关现行音乐的见解和评价的情况下对学生对于音乐和音乐家的了解程度做出准确的估计。就音乐鉴赏评估而言, 这样的测试看起来似乎没有什么价值。因为它只涉及些许有关音乐和作曲家的事实性知识, 而不是可以说明鉴赏音乐本身的能力的有效信息。心理学家和教育家们容易掉入的陷阱之一在于他们往往因为操作简单而不是因为能获取高度相关的信息而选择测试某些属性特征。测试与将要做出的决定具有较高关联性的特征十分重要, 而不应仅限于那些易获取的属性。在第五章中介绍效度时, 将对关联性做进一步的论述。

## 2. 确定隔离和表现特征的操作程序

测量程序的第二步即设计全套操作方案, 以将该属性分离出来进行观察研究。 如测量物体长度一一比如桌子……的方法步骤已经沿用了好几百年。早在小学阶段, 学校就会向孩子们教授这类知识。普通的尺子、米尺及卷尺都是公认的标准长度测量工具。将它们之一靠在物体的一侧也是标准的显示、测量普通桌子、书桌或其他物体长度的一般方法。但其他测量长度或距离的操作过程却并非总是如此简单。比如, 如何测量从纽约到芝加哥的距离, 地球到太阳的距离, 抑或是太阳系到仙女座中的巨大螺旋星云的距离? 还有结核杆菌的长度及中子直径又该如何测量? 测量工具增强了我们的感官能力, 还有与简单地将测量工具贴在物体表面进行直接测量不同的非直接的测试方法, 使我们也可以轻松地应对测量对象过于巨大或过于微小的情形, 这些都得益于自然科学的发展进步。有些测量长度或距离的操作方法和步骤开始变得灵活而精细, 而且精确度越来越高。这些不是那么直观的方法 (比如测量光谱中处于红光端的某些光的波长的变化规律) 也为人们所接受, 因为由此得出的结论具有一致性、可验证性, 且实用性高, 但这些方法与测试属性的联系却远非如此显然。

回顾汽车轮胎耐用性的例子可见, 得出或显明这种属性的操作过程取决于人们认可的有关此构念的定义, 而且两者往往相互影响。若定义依据的是抗磨损程度, 则需要制订一些标准和统一的程序以供测量样品在摩擦力测试中的橡胶损耗度, 即标准化的道路模拟损耗测试。若以抗穿刺能力为核心概念, 则需要考虑如何施加不同等级的穿刺力度。若定义考查的是抗日晒、油渍或其他毁坏性介质造成的老化或损坏, 则需要将样品与在这些介质接触并计算出其强度和弹力的损耗程度。耐用性的定义若涉及上述不止一个方面, 则需要对每一方面进行测量, 不应有所偏重, 且灵活地将多个方面的数据整合到一起。比如说, 我们对耐久性的定义同时考查了抗磨损、 穿刺及老化的能力, 则须评估所有属性且综合每种属性的测试数据得出一个能说明汽车轮胎耐久性的性能指标。我们希望测量的很多心理学和教育学领域的建构概念都与耐久性的构念相似, 即整体构念或多或少都包括一些更简单的独立的构念。怎样将个人根据一些不熟悉的材料推理论证的能力、短时记忆能力、对一些文化色彩浓厚的事实的掌握能力, 以及其他一些相对狭义的构念综合到人的智力的整体构念中去, 或者究竟是否需要综合, 这一直是心理学和教育学研究领域一个热议的话题。

属性的定义与了解其具体内容和特征的操作程序互相影响。一方面, 我们确定的定义决定哪些操作是相关且合理的。反之, 修正完善操作程序以理解和阐明属性的内容也是定义该属性必不可少的一部分。以测量方法定义一种属性的方式称为操作型定义。我们愿意接受 (或因缺乏独创性不得不接受) 的说明汽车轮胎耐久性的那套操作程序对我们来说即为耐久性的操作型定义, 而这可能会局限我们对它的认识。

自 20 世纪及进入 21 世纪以来, 心理学和教育测量的发展史就是一部发明工具和程序来在统一的条件下采用标准方法研究作为人类相关属性外在指征的行为的历史。由比内及其后继者设计的一系列任务即为阐释高智商行为表现的操作方法, 而斯坦福一比内及其他测试则提供了智力的操作型定义。事实上并不存在所有人都认同的测试, 不同测试中设计的任务和对人的特征进行排列的规则也丰富多样, 这说明对于智力的内涵及阐明这一概念的合适的测试程序不存在完全统一的看法。缺乏共识是心理和教育测量现状的总体特征。定义的不明确性及用于阐明相关行为表现的设计方案的多样性, 测量同一特征的不同方法程序可能导致实验对象被归入截然不同的等级。因此处理测试结果时需要保持高度谨慎, 既不能过度概括也不能牵强附会。

课堂上也会需要对所测试的特征进行操作型定义。评估学生成绩是老师的日常工作, 但这里所谓的成绩与评估的方式密切相关。只有老师们对学生成绩的操作性定义在一定程度上达成一致, 对学生表现的评估才具有可比性。如果一位老师进行评估时侧重的是快速记忆能力, 而另一位侧重于原理应用能力, 在某种不确定的程度上, 他们评价的是不同的特征, 因此他们对学生成绩的评估也有着不同的含义。这并不是说侧重点不一样就不合时宜, 只是教育家们应该对这一现象给予关注。定义的变化多样也促进了标准化的成绩测试的发展, 因为这类测试被视为测量的具体方法, 同时还能给出所测属性的基本定义。测试中所做的定义或许不能精确概括上述任意一位老师对于某科目成绩的含义的看法, 但它通常能得到多数老师的认同。

## 3. 属性的量化

就阐明一种属性的操作方法和程序达成一致后, 即进人测量程序的第三步一量化通过操作获得的结果。有时测量也被理解为根据一套既定的规则使物或人具有一定的数值意义。这些数值就是某个人或某件事中该属性的量的反映。

运用数值有几个优点, 其中有两个和我们相关。其一, 量化可使交流更加精确高效。从 “拉尔夫身高 1 米 8 , 体重 79 千克”中获得的信息量要远大于使用一些非量化的词语对其身材所做的描述。第三章将集中介绍数值在进行测量的具体语境 (即使物或人具有数值意义所遵循的规则)中的意义。经过量化处理的信息在语境中更简洁, 更容易理解, 且通常比其他形式的信息更准确, 比如口头描述或照片。然而, 由于对诸如温度或年龄等一些类型的信息的量化形式过于熟悉, 以致我们在面对其他形式时会显得极其不适应。

量化的另一个优点在于, 运用数学知识处理测量结果可以有更多更深入的发现。 设想描述一个班学生的阅读能力测试分数或棒球比赛中击球手的成绩。在任一情形中, 我们都习惯用平均成绩描述少数几个学生的个人表现。出于多个目的考虑, 加、 减、乘、除运算对于充分挖掘一系列信息中蕴含的意义十分有效。部分有关数学运算的操作将在第二章中进行介绍, 心理学家和教育家们可以借助这些运算对信息进行归纳和量化处理。

量化的首要且关键的一步就是遵循一套规则赋予人或物数值意义, 使我们能够知晓有关数量问题的答案。这套规则叫作量表。同样以桌子长度为例, 便可以提问 “有多少英寸?”或“有多少米?”这里的英寸或米即为长度的基本单位, 所遵循的这套规则不仅包括测量工具本身, 还包括用工具测量物体的具体行为。

将两个一英寸长的物体并排摆在一起可以看到两者具有相同的长度, 由此可以说明一英寸具有统一的长度标准。这一演示直接明了地证明进行一些最简单的物理测量只需运用等量原理。对于温度计等测量工具, 其计量单位具有统一的规定。因此, 根据规定, 等量的水银体积的膨胀对应同度数的温度增长。据规定, 一摄氏度等于水的冰点和沸点之差的 \( 1/{100} \) 。这一定义与丰富的日常经验相契合而显得十分有用, 因为由此获得的实验结果与许多其他物理测量方法具有较强的关联性 (超过某一临界点一一水银的沸点——这一定义就不成立了。但是, 其他不受这一条件范围约束的测量程序仍然可以得出与水银温度计相同的结果。由于原理相同, 教育家们可以连续好几年运用一系列分级测试评估学生的成绩是否进步)。

然而, 心理学方面的属性中没有哪个能用英寸或磅等度量单位来直接比较等量关系。比如, 如何证明就算术能力的量而言, 计算一道算术题的能力与计算另一道算术题的能力相等? 如何说明一种焦虑症状与另一种焦虑症指标是一样的? 对于那些心理学家和教育家关注的特征, 我们往往不得不取用稍微有些宽泛且不太严谨的定义, 以保证至少有单位可用且量化处理得以进行。大多数情况下, 假设一项任务已成功完成, 比如给一个词语下定义, 解出一道算术题, 完成一项类比分析, 或是一项表明态度的声明得到认可等, 它的功能作用等同于一系列任务中的其他任何一个。关于个人的成功或受到认可的任务数量即表示这个人某一特定属性的价值。成功完成的任务或某一特定类型的选择的数量可以使我们得到一个看上去合理可信且易处理的关于量的定义, 但是却仍没有足够证据来证明不同的测试任务或问卷调查结果之间的等价性。比如,我们如何才能证明“1、3、6、10、15、_____、_____、_____？ _____”这样的数列运算与“热与冷相对应, 就像湿与_____相对应?”的词语或文字类比中所需的智力是等量的?

即便做最乐观的估计, 我们能企及的等价任务的定义及此后的心理测试中的单位的定义仍旧是十分宽泛且不可靠的。以老师评定学生的合作意识或上司评价员工的积极主动性为例, 分别有 “卓越”、 “优秀”、 “良好”、 “满意” 和 “不满意” 五个等级分类, 用来表示这些评级结果的单位蕴含的意义则比单位之间的界限更加模糊而不可信。最近布兰顿和雅卡尔 (Blanton & Jaccard, 2006) 也论述了心理学领域衡量标准的任意性问题。第三章将介绍一些方法, 用于解析一些含有产生近乎等价单位的测量结果, 但我们将看到, 即使这些单位具有统一的衡量标准, 也只能表达一个模糊的相对概念,而不是明确的绝对数量。

## 4. 测量过程中的问题

在心理和教育测量中, 上述三个基本步骤的每一步在实践过程中都会遇到相应的问题。

首先, 如何选择目标属性及对其做出共同认可的清晰明确的定义。即使是像阅读能力这样浅显的概念都存在许多种不同的理解。定义它时应在多大程度上包括以下这些方面的能力?

(1)快速阅读

(2)将文字符号转变为声音符号

(3)理解文本的字面意义

(4)得出言外之意

(5)了解作者的个人观点和偏见

给协作能力、焦虑、调整或僵化等更复杂和更晦涩的概念下定义时可能会出现更多各不相同的理解。

其次, 如何设计合理程序阐释相关属性中也会碰到问题。关于某些属性, 我们已经具有一些成熟的操作机制, 使受试者的该属性清晰地呈现, 以供在统一的标准化的条件下进行观察和研究。这一成功主要体现在有关个人能力的研究方面, 诸多研究受试者某些能力的标准化测试百花齐放, 比如阅读与理解能力、定量分析能力, 或找出正确的词或短语表达法等。但仍有许多属性, 我们很显然还没有成熟的甚至足够完善的对其进行测试的操作机制。使阐明诸如应聘者的积极主动性、客户的焦虑特征, 或士兵的战斗能力等这些属性的测试结果具有可解读性的标准化的操作程序是什么? 通过不断且富有创新性的调查研究或许可以进一步完善操作机制, 使表现出来的这些属性或特征的测试数据更可靠。但有许多心理学属性, 要找出与其合适对 \( \square \) 的测量操作仍然十分困难。

最后, 即便是目前可用的最佳心理测量单位仍有待完善。在定义的规约下, 这些单位具有统一的标准。定义看上去似乎十分合理, 但却无法确保单位的统一性。因此, 对所得分数进行的比较或加减运算总是或多或少有些不可靠。而且, 属性评估的精确度, 即在不同的环境中或由不同的人进行评估时所遵循的标准的一致性, 常常是不容乐观地低。

尽管有如上这些心理和教育测量机制在完善发展过程中的问题, 但这项任务总的说来还是十分具有研究价值的。实践证明, 现在可用的测量程序能够有效帮助个人做出有关人类社会生活各个方面的各种各样的决定。合理应用测量并准确解析测量结果提高了教育效率, 同时促进了机会平等。测量中, 兴趣和性格特征数据库的采用使大众对白身有了更清晰的认识, 从而降低心理不适感。有关人类能力的测量也已逐渐应用于没有民族或种族歧视的教育和职业选拔。

测试批评家们又迅速指出测试中仍存在不平等现象。然而, 这 25 年以来, 测试人员谨慎地解析测试结果的能力得到了极大的提高, 同时也更加关注受试者的权益。 一般通过直接测试提取到的信息比由其他途径获得的准确性更高。我们总会面临一些必须要做的决定, 而当根据一些准确的信息和对自己价值观的清晰认识通常可以做出最佳决定这一点得到社会普遍认可时, 心理和教育测量与评估程序对我们将会越来越重要。

## 1.6 一些测量中的当前问题

然而, 教育和心理测评还亟待发展完善。从最初系统地发展测试方法和技巧所做的努力和尝试以来, 测试程序一直是众多批评家的靶子。这些关于对测试的盲目推崇及应用测试中的计划不周和对测量结果的片面解析的批评, 绝大部分是有理有据的。接下来的章节将详细说明如何应用测试和分析测试结果, 对如上批评和那些有关测试结果的可靠性和效度的技术性问题保持高度警惕。接下来将对其中部分尤其需要注意的问题做简要阐述和评论。

## 1. 少数族裔个体测试

以有着不同于社会大众一般人群的经历和文化的少数民族与其他社会群体为目标人群的测试及测试的结果一直以来都受到社会的广泛关注。当然, 美国社会中存在各种各样的亚社会群体这一点毋庸置疑, 各群体之间在很多方面也各不相同。最鲜明的可能是一般少数民族群体和非英语为母语的少数社会群体。对于这些人往往需要设计合适的能够反映典型中产阶级经历和价值观的测试和问卷, 而美国白人对问题最为开放。近几年, 非英语母语背景的美国人口数量增长迅速, 以致许多种能力与成绩测试开始被翻译为西班牙语。并且, 一些女权主义团体也声称测试材料往往以男性为中心。现在,一些主要的出版商竭尽全力以确保其印刷的测试材料对于女性群体或其他少数民族群体和非英语母语背景的少数社会群体都是公平公正的。比如, 一般测试使用者、老师、咨询顾问及学校心理咨询师往往需经过一定培训, 能够察觉并尽可能减少所使用的特定的测试工具对受试者并不合适的情形的潜在不良后果。

关于成绩的测试, 即评估学生学会了什么, 也有一些问题待解决。有些问题主要是关于针对社会中的劣势文化群体的教育目标应在多大程度上与平均水平保持一致。阅读并理解标准英语的能力对非裔美籍儿童, 西班牙裔美籍儿童或美洲原住民儿童都一样重要吗? 美国宪法知识对这些社会群体和对中产阶级白人背景的八年级小孩生活的影响又是一样的吗? 由此可知, 就语言和算术等基本技能而言, 同样的教学目标在诸多场合都适用。而当涉及历史和文学方面的内容, 则需要制订更加多样化的教学目标。

有些问题则集中于用于分析基本技能的具体测试材料。阅读测试中一段关于祖鲁人生活的阅读文章对西班牙裔美籍孩子或美洲原住民孩子与对中产阶级白人背景的孩子而言是否同样合适? 又或者是否应该根据每一个不同民族群体的生活和经历为其量身定做相应的测试材料和教材? 我们对影响学生在诸如阅读理解等方面成绩表现的某些特定内容的相关因素重要性了解甚微, 因此需要进一步调查, 使做出的决定建立在充分了解情况的基础上。

另一个问题与少数族裔群体力争在学校测试中表现优秀的动机有关。有些群体对学业成绩十分重视, 比如近年来的东南亚移民。另一些则更看重集体成就和团体认同, 比如美洲原住民群体。在面对一些学生的学习障碍时, 必须了解这些学生是否因为遭遇了一些不愉快的在校测试经历而否定了整个测试做法, 以致他们不愿再考试也不愿努力尝试。达到既能使学生拥有满意的包含各种学业任务的在校测试体验, 又能提高成功率的双重目的, 这可能是整个教育模式所面临的一个挑战, 而非仅仅只是如何选择测试工具的问题。任务也好, 测试也罢, 都应该使其尽可能地适应每一个学生当前的能力和关切。况且, 责任问题也同样要求这些任务或测试绝不能影响到学生成就。

通过测试来作为确定一个人是否能够学会某些事情的基础, 即能力倾向测试, 可能出现更多更严重的问题。根据一个人当前的测试分数对其在将来某个时间点能否学会某件事所做的推论很明显比仅陈述其当前会做的事具有更多疑点。因为许多事件会干预进程导致预测无果而终。而相应地受个人偏见等因素影响的可能性也会变大, 以致一些有关少数族裔群体成员的测试会产生与所做的预测南辕北辙的结果。 根据当前事实所做的有关某个少数族裔群体的预测有可能对其中某个成员并不适用, 因为测试者忽略了其在接受测试之前的特殊经历。谨记, 人免不了要做决定, 但测试中涉及不同背景的人时应学会判断什么样的推论是恰当的, 以及需要对测试体系做出什么样的调整或修改, 以使推论和决定对所有人来说尽可能地公平准确。那些通过监控程序评定每位学生进步的体系很可能才是最佳决策机制。这些体系灵活性强, 最初的决定如有错误, 亦可修正。

## 2. 侵犯隐私

第二个常常提到的问题即侵犯隐私。在哪些情况下要求受试者提供什么样的个人信息才是合理的? 这一问题涉及测试和由个人提供的及与个人相关的各种信息两个方面。哪些记录应该得到妥善保管? 而又有哪些人能获得查看这些资料的许可? 此范围内最基本的是职业知识与技能测试, 比如在文秘测试中, 若测试的技能与相应应聘者申请岗位具有显而易见的相关性, 几乎没人会提出异议, 同时只有潜在的雇主才能获得这些信息。不应仅凭有关文字处理软件运用能力的测试来挑选文字处理将成为其主要工作职责的那个最佳应聘者, 这一点无可辩驳。与此截然相反的是自我描述机制。通过它可推断个人情绪稳定性或分析一些有关在谎言和偷窃的诱惑下人的诚实度测试的结果。在后面这些测试中, 受试者被引导提供一些个人信息, 这些都是在受试者不清楚自己提供的是什么样的信息及测试者将如何解读这些信息的情况下进行的。然而, 这些手段机制的使用似乎也仍颇有争议。处于此范围中间层次的是有关不同程度的自我表露及看似对决定有不同程度的直接关联性机制。

这一问题不仅与获得的信息内容有关, 还关乎获得这些信息的目的。获取这些信息是否是应受试者的要求以帮其解决个人或职业方面的问题或者是因为咨询顾问需要? 事实上,一个人若主动寻求帮助则表示他或她是出于自由意愿提供给予其帮助者所需的个人信息。在这种情况下, 侵犯隐私的问题则相对弱化了。然而, 若获取的信息是为进一步的制度性目的之用, 即有关雇主、教育机构或是所谓的 “科技” 的信息, 这就涉及侵犯个人隐私权利的问题。我们应该找到个人的价值和权利与其社会价值和权利之间的某种平衡。比如, 学生们更倾向于使用问卷调查其职责关乎许多人生命的民航飞行员而非银行职员的情绪稳定性 \( \left( {{75}\% \text{ 对 }{34}\% }\right) \) 。个人权利是相对的, 但人们常常认为这些权利在过去并未受到充分重视。

法院正在越来越大的程度上决定着他人的什么信息是可以知晓的。有些诉讼案件在该机制应用于职业选拔之前就已经采用了, 并要求证明测试分数或性格分析材料等与工作表现的关联性及数据的效度。法院做出的这些裁决同样会影响收集的信息类别及哪些人有权查看这些信息。由于使用电脑存储文件的安全性越来越低, 人们对个人隐私泄露的担忧也日益显著。

## 3. 使用常模对照组

解析测试结果是测量过程中的重点, 关于此有一个稍微有点不同的问题, 即将一个人的表现与代表一个国家或地方抽样群体典型表现的常模组进行比较。这一点受到越来越广泛的关注, 许多基于测试的决定, 尤其是那些教学性决定, 并不要求对比不同的受试者, 因此一旦进行对比分析反而更容易使人感到困惑。受试者能否完成某一特定任务是最基本的信息, 基于此进而才能决定教授的内容或是应该进行的下一步任务。当然, 不可否认存在一些对比不同的受试者对做出合理可靠的判断和决定至关重要的情形。比如, 人事部接收的最近一位求职者电脑操作是否熟练? 那么若不从对比其他求职者的表现着手, 我们该如何定义 “电脑操作熟练”? 打字速度每分钟 60 字, 平均出现两处错误, 这样的描述是无意义的, 除非与一般商科学校毕业的学生进行对比, 比如他们每分钟能打 70 字, 而且或许平均只会出现一处错误。雇主希望招到表现能够达到典型标准的雇员, 而这一标准也是根据其他员工的表现制定的。同样地, 学校若要按照 “良好”、“满意” 或 “有待提高” 三个等级评价其六年级学生的阅读成绩, 也需要一些可用于比较其学生平均水平的基本标准。关于阅读水平, 不存在绝对恒定的标准。对森特维尔 (Centerville) 地区六年级学生阅读和理解《读者文摘》中某篇文章能力的预期是否合理, 只能根据全国具有代表性的六年级学生能否阅读和理解同样的或相似的文章来判断。

以往, 含有测试外参照组的常模比较常常用于指导一些与其甚少甚至完全不相关的决定。现在标准参照测试和精通程度测试以及成绩评估得到越来越广泛的重视。这些程序对做出某些类型的决定起着十分重要的作用, 但并非全部决定。我们22需要了解不同情形中应该使用什么样的合适的比较方法。什么时候提出如下问题, 比如一名受试学生能否完满地完成某一特定任务或是与其他学生相比该学生表现如何, 才显得恰当? 第三章中将对这一问题做更详细的阐述。

## 4. 影响测试分数的其他因素

困扰专业测试人员和向测试手段寻求帮助者多年的一个问题就是外界因素对测试中的表现的干扰。焦虑就是其中一个这样的因素, 而且前人对此进行了大量的研究。焦虑对成绩测试中受试者的表现会产生积极还是消极的影响? 考试焦虑是否会对人的表现产生整体的影响? 老师或考官能够或者应该做点什么以将不良影响降至最小?

一些其他因素, 比如学生营养状况或集中注意力于即将进行的任务的能力等, 也可能影响测试分数。如下两个因素被认为具有极大的理论研究价值, 一个是测试者与受试者之间可能涉及的种族、民族或性别关系, 另一个是测试中测试者对受试者的指导对测试结果的影响。虽然外界因素的具体影响尚不明朗, 但公众对其潜在影响的担忧也促使教育家们和一些专业测试人员不断提高对此的关注度。

## 5. 受试者的权利和责任

以生物体为研究对象的所有科学领域研究者——包括心理学家和教育研究人员——都越来越关注和重视其研究对象的权利。专业的心理学家和咨询顾问对其客户的责任意识同样也变得更强。在研究方面, 这一趋势促进了大学和各种资助机构的机构研究评审委员会 (IRBs) 的发展, 这些委员会对关于人类或动物的研究计划进行审查以保障研究对象的权益, 这于研究而言具有一定进步意义。

在心理和教育测试领域, 一些与测试内容和测试操作程序等紧密相关的专业组织发行的出版物中也传达了保障受试者权益的意识。其中最具影响力的是美国心理学协会 (APA) 于 1954 年首先制订的一系列教育心理测试指导原则。自那以后, 这些指导原则共进行了四次修订。最近一版是由美国教育研究协会 (AERA)、美国心理学协会 (APA) 和国家教育测量委员会 (NCME) 于 1999 年联合发布的版本, 标题为《教育与心理测试标准 (标准)》, 其中阐述了有关设计、实施和解析一项测试的一些现行规范或标准, 以保障受试者权益。

美国心理学协会 (APA) 还有专门的网站: http://www.apa.org/science/ testing. html, 专门用于保障测试的合理应用和公正的结果分析。在该网站上可以看到其关于“受试者的权利与责任”的声明, 它强调测试中测试者和受试者双方都应承担一定的责任与义务。比如,受试者具有事先了解相关测试程序及其用途和目的的权利。与此同时, 受试者也应承担相应的责任, 即当对某一测试阶段的某些方面存在不理解或有疑问时应及时提出, 以及认真负责地完成测试。该网站不仅含有大量与测试相关的资源外链,而且通过它还可以订购最新版《标准》指南系列。

此外, 美国心理学协会 (APA) 发表了有关重大考试 (即测试结果会在很大程度上影响受试者的人生) 和美国公共教育各个方面的许多文章。这些文章可在其官方网站 (http://www.apa.org) 上找到。其他一些组织, 比如美国咨询协会、全国学杉心理学者协会、国家教育测量委员会 (NCME) 及产业和组织心理学学会等, 也有各自运行的网站, 偶尔会更新一些有关测试材料和测试程序的内容。如上一段中提到的在美国心理学协会官网首页的大标题下方可见指向这些网站的超链接“转到其他测试相关网站”。有一个将会用到的特别有用的网站将在第六章中详细介绍, 该网站原于布洛斯心理测试研究所 (Buros Institute of Mentoy Measurements)。

## 1.7 总 结

本书旨在完善评估不同测试程序的机制, 更加清晰明确地阐述每种测试程序的内容和目的及其准确效度, 以使人们在做决定时能够掌握更多背景知识并对自身有更清晰的理解认识。为此, 我们将详细讲解准备测试材料的过程, 制定用于评估所有类型的测试程序的有效可靠的一般标准, 能熟练掌握各种不同的呈现测试分数的力式方法, 并且介绍和评估许多用于评价人类特征的工具和技巧。本书的成功取决 3 读者朋友在做决定时, 能在多大程度上灵活充分地利用但不滥用测试结果。

## 1.8 习 题

1. 请列举一些近期的例子, 关于一些教育或心理测试在你做的有关自己的决定或他人做的有关你的决定中具有一定作用。将这些决定进行以下分类: (1) 教学性的, (2) 选拔性的, (3) 确定类别或等级的, (4) 个人相关的。

2. 根据你的一次个人做决定经验, 举出一个或多个有关心理或教育测试本该有帮助却没有帮助的例子。决定实际是根据什么做出的?

3. 除了心理或教育测试, 还有哪些方法对我们做如下决定时具有一定参考价值?

(1)一年级阅读课程中看字读音教学时长应该占多大比重?24

(2)如何在 15 位电脑程序员应聘者中挑选出 5 位合格者?

(3)是否应该鼓励查尔斯・特纳去实现自己上大学和法学院并成为一名律师的梦想?

4. 与一些测试或问卷相比, 你在第 3 题中提出的那些方法分别有哪些优缺点?

5. 第 3 题中所列举的每个决定在多大程度上如何可能受到个人价值观的影响?

6. 为以下每种类型的测试各举一个例子:

(1)标准参照成绩测试

(2)规范参照成绩测试

(3)能力倾向测试

(4)兴趣偏好测试

(5)性向或调整测试

(6)特质或建构测试

7. 选择下面列举的其中一种属性并完成如下任务: (1) 定义该属性, (2) 制订一些程序对该属性进行观察, (3) 对该属性的测试结果进行量化处理。

(1)批判思维能力

(2)发善

(3)小学生的“良好公民”意识

(4)汽车驾驶员的胜任能力

8. 测试对于一些有关少数群体成员决定的有用性取决于决定的类型。哪些决定最适合标准化测试? 哪些决定最不适合标准化测试?

9. 以下哪些做法你认为是恰当的? 哪些属于侵犯他人隐私? 影响你看法的因素是什么?

(1)医学专科学校申请者应该:1)参加化学成绩评估测试,2) 填写关于情绪稳定性测评的问卷,3)进行关于对全民医保制度看法的调查。

(2) 秘书工作申请者应该: 1) 参加一般智力测试, 2) 参加电脑打字速度和准确度测试, 3) 填写关于可靠性和可信赖度测评的问卷。

(3) 对于一个阅读能力只有八岁孩子水平的十岁小男孩应该采取:1) 非语文智力测试,2) 以交流家庭情况为中心的访谈,3) 一系列有关特定阅读技能的诊断性测试。

10. 为什么了解并遵循专业建议对考试使用者合理利用考试来说十分重要?

11. 写出一些你认为测试者和受试者应该享有的权利和承担的责任。然后查看美国心理学协会官网(http://www.apa.org/science/testing.html)上的相关权利和责任声明, 这些在本章的前面部分有所提及。网站上列出的那些方面是否有你没有想到的? 同样你概括的内容是否也有网站上没有涉及的?

## 推 荐 阅 读

Alexander, L., & James, H. T. (1987). The nation's report card: Improving the assessment of student achievement. Washington, DC: National Academy of Education.

American Educational Research Association, American Psychological Association, & National Council on Measurement in Education. (1999). Standards for educational and psychological testing. Washington, DC: American Psychological Association.

Anastasi, A., 8. Urbina, S. (1997). Psychological testing ( 7 th ed. ). Upper Saddle River, NJ: Prentice Hall.

Blanton, H., & Jaccard, J. (2006). Arbitrary metrics in psychology. American Psychologist, 61, 27-41.

Brennan, R. L. (2006). Perspectives on the evolution and future of measurement. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 1-16). Westport, CT: Praeger.

Cohen, R. J., & Swerdlik, M. E. (1999). Psychological testing and assessment: An introduction to tests and measurements (4th ed.). Mountain View, CA: Mayfield.

Cronbach, L. J. (1975). Five decades of public controversy over mental testing. American Psychologist, 30, 1-14.

DuBois, P. H. (1970). A history of psychological testing. Boston: Allyn & Bacon,

Gottfredson, L. S., & Sharf, J. C. (1988). Fairness in employment testing: A special issue of the Journal of Vocational Behavior, 33(3). Duluth, MN: Academic Press.

Gregory, R. J. (1996). Psychological testing: History, principles, and applications (2nd ed.). Boston: Allyn & Bacon.

Haney, W. (1981). Validity, vaudeville, and values: A short history of social concerns over standardized testing. American Psychologist, 36, 1021-1034.

Hartigan, J. A., & Wigdor, A. K. (Eds.) (1989). Fairness in employment testing: Validity generalization, minority issues, and the General Aptitude Test Battery. Washington, DC: National Academy Press.

Howard, G. S. (1985). The role of values in the science of psychology. American Psychologist, \( {40},{255} - {265} \) .

Jones, L. V. (1971). The nature of measurement. In R. L. Thorndike (Ed.), Educational measurement (2nd ed., pp. 335-355). Washington, DC: American Council on Education.

Koretz, D. M., & Hamilton, L. S. (2006). Testing for accountability in K-12. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 471-516). Westport, CT: Praeger.

Linn, R. L. (1989). Current perspectives and future directions. In R. L. Linn (Ed.), Educational measurement (3rd ed., pp. 1-12). New York: Macmillan.

Murphy, K. R., & Davidshofer, C. O. (2001). Psychological testing: Principles and

applications (5th ed.). Upper Saddle River, NJ: Prentice Hall.

Rogers, T. B. (1995). The psychological testing enterprise. Pacific Grove, CA: Brooks/Colc. Thorndike, R. M. (1990). A century of ability testing. Chicago: Riverside.

Vold, D. J. (1985). The roots of teacher testing in America. Educational Measurement: Issues and Practice, 4(3), 5-8.

Wigdor, A. K., 8. Garner, W. R. (Eds.). (1982). Ability testing: Uses, consequences, and controversies: Pt. 1. Report of the committee. Washington, DC: National Academy Press.

## 第2章 测量与数字

## 2.1 如何理解测试分数

凯瑟琳。约翰逊 (Catherine Johnson) 和皮特・考德罗 (Peter Cordero) 想统计各白六年级班上学生的学习成绩情况。他们对各自班上的学生进行了 45 题的阅读理解测试, 短文摘自他们近期的阅读文章, 还有 65 题出自课本的数学复习题测试及 80 题针对过去六星期所学单词的听写测试。两人在批改试卷后计算出分数并进行了记录, 然后将两班学生的三门测试成绩制成了汇总表。另外, 他们还标示了每位学生所属的班级 (“1”代表约翰逊老师班, “2”代表考德罗老师班) 和性别 (“1”代表男生, “ 2 ”代表女生)。现在有 52 名学生, 每名学生有 5 项信息, 那么该如何分析所有这些数字呢?

测试和评估必然会产生一些分数, 分数就是一系列数字。若要让这些数字派上用场, 则要学会利用这些数字进行思考。对这些代表分数的数字进行归类整理后可以回答一系列问题, 但首先我们得知道要问哪些问题。一旦头脑中有了问题, 就可以开始思考如何处理这些数字才能找到答案。

请看表 2-1 中有关六年级两个班学生的这些数字 (分数)。面对这些数字, 两位老师可能会提出什么样的问题? 你会提出哪些问题? 在继续往下读之前, 请先看看这些分数, 粗略记下你能由此联想到的问题, 看你涉及多少种如下讨论的问题类型。



表 2-1 52 名六年级学生在阅读、拼写及数学测试中的分数

<table><tr><td>姓</td><td>名</td><td>性别</td><td>班级</td><td>阅读 \( {\left( {45}\right) }^{x} \)</td><td>拼写(80)</td><td>数学 (65)</td></tr><tr><td>安德鲁斯</td><td>亚伦</td><td>1</td><td>1</td><td>32</td><td>64</td><td>43</td></tr><tr><td>比格斯</td><td>拜伦</td><td>1</td><td>1</td><td>40</td><td>64</td><td>37</td></tr><tr><td>考恩</td><td>查尔斯</td><td>1</td><td>1</td><td>36</td><td>60</td><td>38</td></tr><tr><td>戴维斯</td><td>唐娜</td><td>2</td><td>1</td><td>41</td><td>74</td><td>40</td></tr><tr><td>爱德华兹</td><td>艾琳</td><td>2</td><td>2</td><td>36</td><td>69</td><td>28</td></tr><tr><td>佛朗哥</td><td>费尔南多</td><td>1</td><td>1</td><td>41</td><td>67</td><td>42</td></tr></table>

续表

<table><tr><td>姓</td><td>名</td><td>性别</td><td>班级</td><td>阅读 \( {\left( {45}\right) }^{ * } \)</td><td>拼写 (80)</td><td>数学 (65)</td></tr><tr><td>贾拉拉加</td><td>盖尔</td><td>2</td><td>1</td><td>40</td><td>71</td><td>37</td></tr><tr><td>亨利</td><td>哈波</td><td>1</td><td>1</td><td>30</td><td>51</td><td>34</td></tr><tr><td>伊格纳西奥</td><td>伊琳达</td><td>2</td><td>1</td><td>37</td><td>68</td><td>35</td></tr><tr><td>约翰森</td><td>杰克</td><td>1</td><td>1</td><td>26</td><td>56</td><td>26</td></tr><tr><td>杰士</td><td>克莱文</td><td>1</td><td>1</td><td>26</td><td>51</td><td>25</td></tr><tr><td>拉潘斯基</td><td>拉文</td><td>2</td><td>1</td><td>26</td><td>57</td><td>53</td></tr><tr><td>麦迪逊</td><td>玛丽</td><td>2</td><td>1</td><td>30</td><td>68</td><td>37</td></tr><tr><td>纳茨</td><td>内森</td><td>1</td><td>1</td><td>22</td><td>47</td><td>22</td></tr><tr><td>奥炭</td><td>奥普拉</td><td>2</td><td>1</td><td>36</td><td>59</td><td>33</td></tr><tr><td>彼得斯</td><td>普图拉</td><td>2</td><td>1</td><td>32</td><td>64</td><td>33</td></tr><tr><td>魁克里</td><td>魁杜拉</td><td>2</td><td>1</td><td>21</td><td>44</td><td>19</td></tr><tr><td>罗伯茨</td><td>拉希姆</td><td>1</td><td>1</td><td>22</td><td>64</td><td>43</td></tr><tr><td>萨利可</td><td>萨利姆</td><td>1</td><td>1</td><td>41</td><td>76</td><td>33</td></tr><tr><td>坦克</td><td>托马斯</td><td>1</td><td>1</td><td>35</td><td>65</td><td>38</td></tr><tr><td>额本</td><td>乌萨卡</td><td>2</td><td>1</td><td>41</td><td>65</td><td>38</td></tr><tr><td>巴斯克斯</td><td>维克多</td><td>1</td><td>1</td><td>37</td><td>68</td><td>40</td></tr><tr><td>佳奈</td><td>渡边</td><td>2</td><td>1</td><td>25</td><td>65</td><td>21</td></tr><tr><td>薛斯西</td><td>夏娜姆</td><td>1</td><td>1</td><td>25</td><td>54</td><td>33</td></tr><tr><td>杨</td><td>元</td><td>1</td><td>1</td><td>37</td><td>59</td><td>24</td></tr><tr><td>泽布里斯</td><td>泽布伦</td><td>1</td><td>1</td><td>42</td><td>73</td><td>44</td></tr><tr><td>阿什</td><td>安吉拉</td><td>2</td><td>2</td><td>43</td><td>64</td><td>52</td></tr><tr><td>布朗</td><td>贝琳达</td><td>2</td><td>2</td><td>33</td><td>38</td><td>41</td></tr><tr><td>科文</td><td>夏洛特</td><td>2</td><td>2</td><td>36</td><td>47</td><td>50</td></tr><tr><td>杜布朗</td><td>多米尼克</td><td>1</td><td>2</td><td>39</td><td>65</td><td>33</td></tr><tr><td>埃里克森</td><td>埃里克</td><td>1</td><td>2</td><td>39</td><td>65</td><td>47</td></tr><tr><td>弗朗斯</td><td>弗朗西斯</td><td>2</td><td>2</td><td>38</td><td>59</td><td>49</td></tr><tr><td>加西亚</td><td>桂多</td><td>1</td><td>2</td><td>31</td><td>52</td><td>29</td></tr><tr><td>胡安</td><td>希拉里</td><td>2</td><td>2</td><td>38</td><td>61</td><td>48</td></tr><tr><td>伊万诺维奇</td><td>伊戈尔</td><td>1</td><td>2</td><td>33</td><td>53</td><td>43</td></tr><tr><td>约翰逊</td><td>吉尔</td><td>2</td><td>2</td><td>42</td><td>61</td><td>47</td></tr><tr><td>诺尔斯</td><td>卡里恩</td><td>1</td><td>2</td><td>35</td><td>55</td><td>51</td></tr><tr><td>路易斯</td><td>拉里</td><td>1</td><td>2</td><td>30</td><td>40</td><td>34</td></tr><tr><td>玛斯翠欧尼</td><td>莫</td><td>1</td><td>2</td><td>36</td><td>58</td><td>39</td></tr><tr><td>诺维斯</td><td>南希</td><td>2</td><td>2</td><td>28</td><td>44</td><td>44</td></tr><tr><td>奥德福</td><td>奥登</td><td>1</td><td>2</td><td>35</td><td>53</td><td>38</td></tr></table>

续表

<table><tr><td>姓</td><td>名</td><td>性别</td><td>班级</td><td>阅读 (45) *</td><td>拼写 (80)</td><td>数学 (65)</td></tr><tr><td>波波维奇</td><td>皮特</td><td>1</td><td>2</td><td>36</td><td>52</td><td>53</td></tr><tr><td>魁汀</td><td>昆西</td><td>1</td><td>2</td><td>33</td><td>48</td><td>33</td></tr><tr><td>罗斯特罗波维奇</td><td>朗达</td><td>2</td><td>2</td><td>31</td><td>50</td><td>31</td></tr><tr><td>斯德本斯</td><td>莎莉</td><td>2</td><td>2</td><td>33</td><td>51</td><td>32</td></tr><tr><td>斯瓦特斯</td><td>塞尔玛</td><td>2</td><td>2</td><td>38</td><td>43</td><td>45</td></tr><tr><td>乌达</td><td>乌利亚</td><td>1</td><td>2</td><td>42</td><td>61</td><td>60</td></tr><tr><td>沃特</td><td>维尔玛</td><td>2</td><td>2</td><td>29</td><td>49</td><td>36</td></tr><tr><td>维特布克</td><td>威廉</td><td>1</td><td>2</td><td>33</td><td>54</td><td>33</td></tr><tr><td>西娜</td><td>薛斯西</td><td>2</td><td>2</td><td>30</td><td>57</td><td>37</td></tr><tr><td>洋茨</td><td>雅尼塔</td><td>2</td><td>2</td><td>44</td><td>63</td><td>49</td></tr><tr><td>佐罗</td><td>泽芬娜</td><td>2</td><td>2</td><td>30</td><td>47</td><td>38</td></tr></table>

* 圆括号内为满分。



每名学生都有五个与其相关的数字, 但首先应该了解每个数字是否切实传达了量化信息。代表性别和班级的数字与测试分数是否具有相同性质的意义? 这个问题有关数字所代表的量级, 而且会影响到处理这些数字的操作方法。

第二类较宽泛的问题是, 这些分数的基本模式是什么? 它们是如何 “分布” 的? 它们看起来是 “什么样”的? 比如如何才能直观地分析学生数学成绩, 从而大致了解学生的整体水平呢? 要回答这类问题, 则需考虑制表或画图来统计分数。

第三类一定要问的问题是这组学生的平均水平如何。总体而言, 他们的成绩与同年级其他学生相比怎么样? 这组学生的普遍水平怎么样? 要回答这些问题需要找到某个可以代表整体的数字, 即计算出这组数据的中值。要回答这类问题, 则需了解可以计算出平均分数或典型分数的统计学知识。

第四, 要描述整组情况, 还需要知道分数围绕平均值的波动情况。这组学生的成绩水平完全一样还是差异很大? 这组学生成绩分布与其他班级学生相比有何差异? 在这三项测试中, 学生的成绩分布是否相同? 回答这类问题需了解相异性的衡量标准。

第五, 我们也许还会问到某名学生在某一项测试中的名次如何, 比如亚伦。安德鲁斯 (Aaron Andrews) 的数学成绩是好是坏。如果他的成绩被认定为好, 还需说明好的含义和程度。我们还可能问到亚伦的阅读和数学成绩哪门更好。要回答这个问题, 则需要可以衡量学生在两门差异较大的学科领域中的成绩的公尺, 即要有一些独立于某一特定测试之外的统一的标准和方法, 用以描述和分析某一个体的成绩表现。 与这组学生的整体水平相比, 这名学生的表现如何? 对于这一问题, 我们会在本章给出一些初步回答, 并在第三章详细介绍。

如下属于第六种类型的问题: 那些阅读成绩优秀的学生, 数学成绩也优于他人吗? 同一学生的这两门成绩均为优秀的程度有多大? 一门科目成绩优秀的学生可能在另一门科目中也表现优秀吗? 要描述两组测量数据之间的关联, 我们需要熟悉相关性指数。

考试分数也经常被用来预测将来的成绩。因此, 第七类要解决的问题是如何对某个个人在其他任何一项测试中或是某些决定结果的测试中的成绩表现做出精准的预测, 比如年终考试的成绩测评。这一预测功能经常在美国学业能力倾向测验等重要考试中使用, 这就需要了解回归分析。

分析考察一组分数的过程中还可能出现许多其他问题。最重要的是如何从一组有限的样本数据中得出具有普遍适用性的结论。比如, 这组学生中 26 名女生的阅读平均分为 35.0,26 名男生的平均分为 33.9 。这是有关这些男女生所参加的这次测试的描述性事实。但是可以将这些学生看作一个更大人群的样本, 比如整个学区或者全州的学生。根据这两个班级的成绩, 我们可以估算该更大的学生群体的平均阅读水平。是否可以有把握地做出从中进行抽样测试的整个女生群体的阅读成绩都超过男生群体这样的结论也有待考察。这类问题则是推论性问题。有关统计推论的问题是高级数据处理工作中的主要问题。若想了解统计推论的原理和应用, 可参考本章结尾列出的一些有关统计方法的书目。对个人或小组的测试分数进行初步的基础分析时并不会涉及这些问题, 所以这里不做进一步阐述。

将数字进行整理并用来解答各式各样的问题的操作就是统计学。有些人看到统计学这三个字就会想到和数字打交道, 会觉得很可怕。幸运的是, 很多数字运算工作现在都可以由计算器或计算机来做, 所以我们可以专注于提问及思考如何分析整理这些数字以解答我们提出的这些问题, 而无须为计算细节担心。接下来我们要讨论如何解答上述七类问题, 并介绍一些进行必要运算所需的便捷的计算机程序。主要有两类广泛使用的程序: 一类是社会科学统计软件包 (SPSS), 另一类是微软的 \( {\text{Excel}}^{@} \) 电子制表软件程序。两者各有缺点,但都相对容易上手。

## 2.2 测量量表

定义测量的方法之一是根据一套规则为一定的对象赋值, 使其具有意义。这些规则叫作量表。了解赋予数字意义的量表对于正确解读测量结果至关重要。比如, 凯瑟琳。约翰逊和皮特・考德罗老师将数字 1 赋予男同学, 数字 2 赋予女同学, 那么这些数字包含了怎样的信息呢? 撇开女性主义思想不谈, 数字 2 是否表示这些女同学的性别特征比男同学更明显呢? 显然不是。在这个例子里, 数字并没有数量上的意义。数字 1 只是用以标识“男生”这一性别标签, 数字 2 用以标识“女生”而已, 我们也完全可以用 163 和 27 来进行区分和标识。是言语标记赋予了每个数字某种意义。 在这种情况下的测量量表叫作名目量表, 即用数字代替名称。你所在大学几乎百分之百会给你配备一个学号。这一数字是名目量表上的 “分数”, 就像运动员制服后背上的号码一样。这些数字并无数量上的意义, 所以不能把它们看作普通数值。我们往往无法对它们进行加法或其他数学运算并求得一个有意义的值。通常名目量表下的数字只能供我们计算每个数值出现的次数。在表 2-1 中有 26 个 1 和 26 个 2 , 所以我们知道男女生的人数是相同的。

有时候数字还可以代表个体在某项特征上的顺序。表 2-1 中没有这样的例子, 但是假设考德罗老师决定基于学生拼写测试的成绩进行排名, 分数最高的学生多米尼克。杜布朗排名第一, 第二高的学生安吉拉 - 阿什排第二, 依此类推。这些数字又传达了怎样的信息呢?

这组名次代表了学生在某项特征上的排列顺序, 但同样不具有数量上的意义。 更重要的是, 不同的数字所代表的意义并不是恒定不变的。第 1 名和第 5 名之间的区别与第 11 名和第 15 名之间的区别不一定相同。两组排名都是相差四个名次, 但是与中间部分相比, 同样的四个名次在一组的两极部分时差异往往更大。能够说明一组人的排名情况, 谁在某项特征上更突出, 但非表示数量上的意义的测量量表叫作顺序量表。第三章将对呈现测试分数的一些常用方法做简单介绍, 其中会用到顺序量表。

如同表 2-1 中三项测试的评分方法, 这类测试中的每一道题具有等价的分值。 做对 10 道题得 10 分, 同理对 20 道题得 20 分, 对 30 道题得 30 分。因为每道题的分值一样, 那么同等的分值差异所表示的特征的差异程度也是一样的。虽然这样的设想在测量人的能力时有些站不住脚, 但它与温度测量中使用的诸如摄氏或华氏等单位量表的原理相同。分数数值上的差异对应同等程度的该测量属性的差异。当我们做出这样的假定时, 所使用的测量量表叫作等距量表。用测试分数所做的大部分运算要求我们假定测量表为等距量表。

假设泽布伦・泽布里斯 (Zebulon Zibberits) 尽最大努力依然不能拼对考德罗老师拼写测试中的任何一个单词, 这是否说明他的拼写能力为零? 很可能不是。这项拼写能力测试的衡量量表远在零点以上, 因此在这项测试中得分为零并不代表拼写能力为零。在心理学和教育学领域几乎没有量表会如此界定, 即测试中获得零分意味着完全没有某项特征或属性。这也是布兰顿和杰卡德 (Blanton & Jaccard, 2006) 对心理学和教育学量表的任意性表示担忧的原因之一。高度、重量和时长等量表 (非任意性衡量量表) 除外。如果某种量表界定零分即等于完全没有某一特征, 则称为比例量表。这类量表下的单位具有等价性, 数值上两倍的差异等同于对应的特征上两倍的差异。解决同一个问题, 花了 10 分钟的人的时长是花了 5 分钟的人的两倍, 而花了 20 分钟的人是花了 10 分钟的人的两倍, 是花了 5 分钟的人的四倍。比例量表使我们能够以比例的形式进行表述。心理学和教育学领域里很少用到比例量表, 但幸运的是, 等距量表足以应付大多数必要的数据分析。将测量量表分为名目量表、 顺序量表、等距量表和比例量表是由史蒂文斯 (S. S. Stevens) 于 1951 年提出的, 并得到广泛应用, 不过心理测试领域的一些专家, 比如托格森 (1958), 也提出过其他分类方法。

## 2.3 频率分布表的准备

在表 2-1 中, 我们记录了 52 名六年级学生的测试分数。现在让我们来看一下数学成绩这一栏的分数, 想想怎样将它们进行重组以更加清楚地体现学生们在数学测试中的成绩情况。最简单的方法就是将分数从高到低如下排列:

\( \begin{array}{lllllllll} {60} & {49} & {44} & {41} & {38} & {37} & {33} & {31} & {24} \end{array} \)

\( \begin{array}{lllllllll} {53} & {49} & {44} & {40} & {38} & {36} & {33} & {31} & {22} \end{array} \)

\( \begin{array}{lllllllll} {53} & {48} & {43} & {40} & {38} & {35} & {33} & {29} & {21} \end{array} \)

\( \begin{array}{lllllllll} {52} & {47} & {43} & {39} & {37} & {34} & {33} & {28} & {19} \end{array} \)

\( \begin{array}{llllllll} {51} & {45} & {43} & {38} & {37} & {34} & {33} & {26} \end{array} \)

\( \begin{array}{llllllll} {50} & {45} & {42} & {38} & {37} & {34} & {32} & {25} \end{array} \)

与表 2-1 相比, 这样重新调整后展示分数走向的效果会稍微好点。我们不仅能一眼看到最高分 (60) 和最低分 (19), 还能轻易看出中间水平在 35 分上下浮动。粗略查看可知大多数学生的得分在 30 到 50 之间。但是这样简单的重新排列还是太过于宽泛, 细枝末节较多, 以致很难清楚地看出其中的基本模式。因此需要将数据进一步压缩。

通常, 将分数进行整理呈现的第一步就是绘制一张显示每个分数出现频率的表格, 即频率分布表。表中列出分数的分值和出现次数。表 2-2 就是数学成绩频率分布表的一部分。然而表 2-2 仍然不够好, 因为图表太长且数值分散。这里我们只截取了其中一部分, 实际上它有 42 行, 数字数量几乎和原来一样多。在频率一栏, 有些分数的频率是零, 有些分数之间会有显著差异。



表 2-2 52 名学生的数学成绩频率分布表

<table><tr><td>分数(X)</td><td>频率</td><td>分数(X)</td><td>频率</td></tr><tr><td>60</td><td>1</td><td>38</td><td>5</td></tr><tr><td>59</td><td>0</td><td>37</td><td>4</td></tr><tr><td>58</td><td>0</td><td>-</td><td>-</td></tr><tr><td>57</td><td>0</td><td>-</td><td>-</td></tr><tr><td>56</td><td>0</td><td>-</td><td>-</td></tr><tr><td>55</td><td>0</td><td>28</td><td>1</td></tr><tr><td>54</td><td>0</td><td>27</td><td>0</td></tr><tr><td>53</td><td>0</td><td>26</td><td>1</td></tr><tr><td>58</td><td>0</td><td>37</td><td>1</td></tr><tr><td>-</td><td>0</td><td>-</td><td>1</td></tr><tr><td>-</td><td>-</td><td>28</td><td>0</td></tr><tr><td>-</td><td>0</td><td>22</td><td>1</td></tr><tr><td>58</td><td>0</td><td>21</td><td>1</td></tr><tr><td>39</td><td>1</td><td>19</td><td>1</td></tr></table>



## 1. 分组频率分布

通常我们将分数分组以便更清晰地呈现数据。我们会舍弃数据中一些过于琐碎的内容以便更好呈现整组数据的大致走向。在这个例子中, 我们把三个相邻的分数分为一组, 所以每组区间内包含三个分数, 14 组区间代表了 19 到 60 之间的所有分数。分组完成后得到了如表 2-3 所示的相对紧凑的表格, 每个分值区间有多少人清楚可见, 比如 19-21 这组区间内有两人。我们不知道其中有多少人得了 19 分、 20 分或 21 分, 这部分信息在进行分组时舍弃掉了。我们假定这些分数是平均分布在各分组区间的。在大多数情况下, 没必要去考虑某个分数可能比其他分数出现的现频率更高, 而且这一假设也是合理可靠的, 也许分组的过程会对准确性造成少许影响, 但是却能更加简洁方便地分析和呈现数据 (在一些特殊情形中应用时, 比如家庭收入调查, 某些特定数值出现的频率会更高, 比如 1.8 万美元、 2.5 万美元、 5 万美元。在对这类材料进行分组时, 要提高警惕。注意要使出现频率最高的数值出现在分组区间的中间段以减少误差)。

## 让计算机来帮忙

频率分布

Excel 表格并非是用来制作上述频率分布表的, 而是用于制作我们下一部分将要介绍的分组频率分布表。社会科学统计软件包 (SPSS) 可以进行频率分布统计, 但在查看时需特别仔细, 因为频率为零的分数会忽略不计。使用 SPSS 对表 2-1 中的数据进行整理制作频率分布表格时, 首先打开应用程序, 输入表 2-1 中的数据或者打开保存这些数据的文件, 点击屏幕上方菜单栏的分析 (Analyze) 键, 选择描述性统计 (Descriptive Statistics), 调出的界面应如下图所示 (所用 SPSS 版本不同界面具体布局可能会有一些差异):







选择频率 (Frequencies) 后, 会弹出一个会话框, 选择需要分析的变量。点击该变量的名称进行选取, 然后点击箭头所示的键, 将待分析的变量添加到变量 (Variables) 窗口。若使用的是表 2-1 的数据, 选择数学作为分析变量, 就能从中导出一份完整的频率分布表。表格的部分内容如表 2-2 所示。这一程序还可进行其他分析, 但在具体涉及这些内容之前暂不介绍。



表 2-3 以 3 为区间宽度, 52 名学生数学测试成绩的分组频率分布

<table><tr><td>区间</td><td>频率</td><td>区间</td><td>频率</td></tr><tr><td>60 — 62</td><td>1</td><td>36---38</td><td>10</td></tr><tr><td>57—59</td><td>0</td><td>\( {33} - {35} \)</td><td>9</td></tr><tr><td>54 — 56</td><td>0</td><td>30 ……32</td><td>3</td></tr><tr><td>\( {51} - {53} \)</td><td>0</td><td>27—29</td><td>2</td></tr><tr><td>48—50</td><td>4</td><td>24 — 26</td><td>3</td></tr><tr><td>45—47</td><td>0</td><td>21----23</td><td>2</td></tr><tr><td>42 — 44</td><td>6</td><td>18---20</td><td>1</td></tr><tr><td>39—41</td><td>4</td><td>1</td><td/></tr></table>



在实际操作中, 我们经常面临决定分组区间宽度的问题。比如, 是按照 3 个、5 个、 10 个来分组, 还是其他数量的分数来进行分组。这个决定是权衡考虑的结果, 即放弃数据的某些细节, 从而找到一种简洁简单的方法呈现测试结果。区间跨度越大, 损失的细节就越多, 但数据的呈现也会更加简洁明了。一种经验方法是选择可以将所有分数分为 15 组的区间宽度。在如上例子中, 最高分是 60 , 最低分是 19 。分数从 60 到 19 , 中间有 41 分的间隔。用 41 除以 15 得出 2.7 。与 2.7 最近的整数是 3 , 所以我们按 3 个数一组进行划分。除了这个方法, 区间宽度为 \( 5\text{、}{10}\text{、}{15} \) 或 10 的倍数时分组也十分方便。因为将分数进行分组的目的是便于清晰地呈现数据, 所以便利性是主要考虑因素。如表 2-3 所示, 使用区间宽度的倍数作为区间下限值也是常见做法。

如果需要用分组数据绘制图表, 取奇数作为区间宽度会比较便利, 比如 3、5、7 , 因为有时需用处在分数段中间的某个分值代表该区间内的所有分数。如果取偶数作为区间宽度, 中间值则处在两个分数之间, 而取奇数, 中间值就是某个分数, 这样图表显得更整洁。

另外还需注意的是, 有时并无进一步分组的必要。如果初始的分数之间跨度不超过 20 分, 则无须分组。还有, 借助于现代化的计算设备通常能使对初始分数进行统计指标的计算时更为轻松简单, 除非数据一开始就是分组频率分布的形态, 我们接下来会介绍到这些内容。在此情况下, 大多数计算机程序需要有特殊编程, 这不属于本书的介绍范围。

## 让计算机来帮忙

## 分组频率分布

Excel 表格可用来制作分组频率分布表, 但必须按照特定的步骤按部就班地进行操作, 过程可能有时会比较烦琐, 但习惯就好。打开需要分析的数据所在的文档后, 首先要决定分组区间的数量。这些区间在 Excel 表格中叫作接收区域。以数学测试的分数为例, 确定使用多少个接收区域的最简单的办法就是对分数稍加整理, 明确分数的总体区间跨度。点击数学这一栏里的任意一个分数, 然后点击分类图标。 分数就按顺序排列好了, 最高分和最低分也便一目了然。知道了分数的区间跨度为 41 分之后, 运用 “十五规则”, 即用 41 除以 15 , 同样得出归入每个接收区域的分数数量为三个 (注意 Excel 也可用于制作原始数据的频率分布表, 如同我们使用 SPSS 制作的表格, 但那样的话几乎每一个分数就得归入一个接收区域。)

现在需要设定接收区域, 首先要明确归入每个接收区域的最高分。因此, 若将接收区域设为 3 , 则最低的分数段的接收区域内的值应为 20 分 (以保证每个接收区域的下限为 3 的倍数)。Excel 表格将分数在接收区域里按由低到高进行升序排列。 也就是说, 所有分数导入后, 程序会自动将小于或等于接收区域下限的分数全部归入第一个接收区域中。如果统计从下限低于最低分的接收区域开始, 将得到频率为零的结果, 但若从下限高于最低分而容量却大于之前所确定的区间宽度的接收区域开始, 最小区间宽度又会过宽。

完成了第一个接收区域的设限之后, 每往后一个接收区域, 其限制就增加一个区间宽度。比如, 我们设置第一个接收区域的最低分限制为 20 分, 那么以此类推, 后面各个接收区域的下限则依次为 23 分、 26 分、 29 分……53 分、 56 分、 59 分、 60 分。接收区域必须按升序排列, 即下限最低的接收区域位于栏首。在导入的数据右边新建一栏 (比如, 第 I 栏), 在首行中输入接收区域一词。然后在这一栏头下面的单元格中依次输入接收区域的分数限制, 从最低分数开始。

Excel 频率分析工具是直方图工具的一部分, 而直方图包含于 “工具” 菜单的 “数据分析”工具组中 (直方图会在下一小节中进行介绍)。点击菜单栏的工具 (Tools), 然后选择数据分析 (Data Analysis) (小提示: 别忘了点击任一含有数据的单元格来激活数据分析功能), 弹出一个含有许多数据分析选项的对话框。点击直方图 (Histogram) 后选择确认, 你会看到如下所示叠加在数据上面的界面。

Excel 表格需要明确分析对象所在的数据表区域。表格中的 \( \mathrm{G} \) 栏是数学测试的成绩, 栏首单元格中已标明数学 (Math), 从 G2 到 G53 之间的所有单元是具体的分数。看到刚刚弹出的直方图会话框, 点击输入区域 (Input Range), 点击接下来的弹窗中的接收区域 (Bin Range)。然后选择主屏幕中接收区域的分数限制, 就是之前在 “接收区域”一栏下面的单元格中输入的数值。这些参考数值将会出现在此窗口中。 最后, 点击出现的弹窗中的输出区域 (Output Range) 键以激活该窗口, 点击窗口内任







意地方。随后点击选择一个单元格, 分组频率分布统计将由此处开始 (通常建议选择接收区域一栏右侧首格, 在上述例子中即为第 I1 单元格)。然后点击确认。若使用表 2-1 的数据, 按照如上指示进行操作, 则会看到如下所示的界面:



XMicrosoft Excel Estatistics example.xls (1998) The Marketics (1998) The Marketics (1998) The Marketics (1998) The Marketics (1998) The

<table><tr><td>11</td><td>A: Bin</td><td/><td/><td/><td>Jew Insert Format Isois Data Window Help Adobe PDF D @ B -9 5 ③ ③ ⑦ ③ D - ③ Σ - 21 ⑩ ⑦</td><td/><td>:[Microsol] Hacebook Statistics example, His Radiation Statistical Laborator Radiabation Statistical Laborator Radiation Statistical Laborator Radiation Statistic Laborator Radiation Specification Survey Radiation South Trans. Type a question for help \( \; + \; + \; - \; - \; \times \) 、10、8 / 11 三 7</td></tr><tr><td/><td>B</td><td>C:</td><td>D</td><td/><td/><td>: H</td><td>Formula Bar火</td></tr><tr><td>1 First</td><td>Last</td><td>Gender</td><td>Class</td><td>Reading</td><td>SpellingMath</td><td>bins</td><td>BinFlequency</td></tr><tr><td>2 Quadra</td><td>Quickly</td><td/><td>2</td><td>21</td><td>44</td><td>1920</td><td>201</td></tr><tr><td>3 Nathan</td><td>Natts</td><td/><td>1</td><td>22</td><td>47</td><td>2223</td><td>232</td></tr><tr><td>4 WAKANE</td><td>Watanabe</td><td/><td>2</td><td>25</td><td>53</td><td>2126</td><td>263</td></tr><tr><td>_____</td><td>Xerxes</td><td/><td>1</td><td>25</td><td>54</td><td>3129</td><td>292</td></tr><tr><td>6 Jack</td><td>Johanson</td><td/><td>1</td><td>26</td><td>56</td><td>2632</td><td>323</td></tr><tr><td>7 Kleven</td><td>Klipsch</td><td/><td>1</td><td>28</td><td>61</td><td>2535</td><td>369</td></tr><tr><td>8 Nancy</td><td>Nowits</td><td/><td>2</td><td>228</td><td>44</td><td>4438</td><td>3810</td></tr><tr><td>9 RANAN</td><td>Roberts</td><td/><td>1</td><td>129</td><td>64</td><td>4341</td><td>414</td></tr><tr><td>10 Larry</td><td>Lewis</td><td/><td/><td>229</td><td>40</td><td>3444</td><td>446</td></tr><tr><td>11 Velma</td><td>Yauter</td><td/><td>2</td><td>229</td><td>49</td><td>3647</td><td>473</td></tr><tr><td>12 Harpo</td><td>Henry</td><td/><td>1</td><td>130</td><td>51</td><td>3450</td><td>504</td></tr><tr><td>13 Xena</td><td>Xerxes</td><td/><td>2</td><td>230</td><td>57</td><td>3753</td><td>634</td></tr><tr><td>14 Zephina</td><td>Zoro</td><td/><td>2</td><td>230</td><td>47</td><td>3856</td><td>560</td></tr><tr><td>15 Guido</td><td>Garcia</td><td/><td>1</td><td>231</td><td>52</td><td>2959</td><td>590</td></tr><tr><td>16 Rhonda</td><td>Rostropovich</td><td/><td>2</td><td>231</td><td>50</td><td>3162</td><td>621</td></tr><tr><td>17 Aaron</td><td>Andrews</td><td/><td>1</td><td>32</td><td>64</td><td>43</td><td>More0</td></tr><tr><td>18 Petula</td><td>Peters</td><td/><td>2</td><td>32</td><td>64</td><td>33</td><td/></tr><tr><td>19 Yuan</td><td>Young</td><td/><td>1</td><td>132</td><td>59</td><td>24</td><td/></tr><tr><td>20 Bellinda</td><td>Brown</td><td/><td>2</td><td>233</td><td>38</td><td>41</td><td/></tr><tr><td>21 (Chariotta</td><td>Cowen</td><td/><td>2</td><td>233</td><td>47</td><td>50</td><td/></tr><tr><td>22 loor</td><td>Ivanovich</td><td/><td>1</td><td>233</td><td>53:</td><td>43</td><td/></tr><tr><td>23 Quincy</td><td>Quirn</td><td/><td>1</td><td>233</td><td>AB:</td><td>33</td><td/></tr><tr><td>24 Sally</td><td>Stebbens</td><td/><td>2</td><td>233</td><td>41</td><td>32</td><td/></tr></table>

that a composition of the Dirac Error of Error Distral 2.45pm



标注 “更多” (More) 一行表示的是超出接收区域上限的分数。社会科学统计软件包 (SPSS) 没有制作分组频率分布表的程序。

## 2. 累积频率分布

若想知道有多少人的得分低于某一特定值, 最直接的方法就是统计累积频率分布, 即列出每个分数或区间, 以及有多少分数处在该区间内或低于该分数。有了频率分布表或分组频率分布表, 制作累积频率分布表就不难了。表 2-4 所示即为累积频率及每个区间内分数频率的统计表。 “累积频率” 这一栏的每个条目表示得分等于或小于此区间内最高分的总人数。也就是说, 有一名学生得分等于或低于 20 , 那么 \( \left( {1 + 2}\right)  = 3 \) 名学生得分等于或低于 \( {23},\left( {3 + 3}\right)  = 6 \) 名学生得分等于或低于 \( {26},\left( {6 + 2}\right)  = \) 8 名学生得分等于或低于 \( {39},\left( {8 + 3}\right)  = {11} \) 名学生得分等于或低于 32,依此类推。累积频率分布在计算相对位置时尤其有用, 第三章中将会对此做相关阐述。遗憾的是, 不论是社会科学统计软件包 (SPSS) 还是 Excel 制表程序都不能直接制作累积频率分布表, 但是二者可用于计算累积频率百分比, 它们各自的频率分布统计程序都可以进行如下运算求值:

累积频率百分比 \( = \) 累积频率 / 总数量

所求的值如表 2-4 所示。只要运用社会科学统计软件包 (SPSS) 进行频率分布统计就能求得累积频率百分比。而 Excel 中则需要点击直方图会话框中的累积频率百分比 (Cumulative Percentages) 会话框。



表 2-4 以 3 为区间宽度, 52 名学生数学测试成绩的累积频率分布

<table><tr><td>区间</td><td>频率</td><td>累积频率</td><td>累积频率百分比</td></tr><tr><td>60 — 62</td><td>1</td><td>52</td><td>100</td></tr><tr><td>57—59</td><td>5</td><td>51</td><td>98</td></tr><tr><td>54 —56</td><td>5</td><td>51</td><td>98</td></tr><tr><td>51 — 53</td><td>4</td><td>51</td><td>98</td></tr><tr><td>48—50</td><td>4</td><td>47</td><td>90</td></tr><tr><td>45—47</td><td>4</td><td>43</td><td>83</td></tr><tr><td>42 — 44</td><td>6</td><td>40</td><td>77</td></tr><tr><td>39 ——41</td><td>4</td><td>34</td><td>65</td></tr><tr><td>36—38</td><td>10</td><td>30</td><td>58</td></tr><tr><td>\( {33} -  - {35} \)</td><td>9</td><td>20</td><td>38</td></tr><tr><td>30 — 32</td><td>3</td><td>11</td><td>21</td></tr><tr><td>27—29</td><td>2</td><td>8</td><td>15</td></tr><tr><td>24---26</td><td>3</td><td>6</td><td>12</td></tr><tr><td>21 — 23</td><td>2</td><td>3</td><td>6</td></tr><tr><td>18—20</td><td>1</td><td>1</td><td>2</td></tr></table>



## 3. 图示法

将如表 2-3 中所示的数据用图形来呈现往往能使数据分析达到事半功倍的效果。一种常用的图示法叫作直方图, 如如图 2-1 所示。这种图可被称作 “叠罗汉”, 尽管听起来有点令人毛骨悚然。基线 (或横坐标) 表示的是表 2-3 中数学成绩的分数区间, 与之垂直的桩高 (或纵坐标) 表示得分在相应区间内的学生人数。从图 2-1 可以看出区间 18-20 相应的桩上有一人, 21-23 区间相应的桩上有两人, 以此类推 (因为这个直方图是用 Excel 生成的, 所以每个区间都标示了该接收区域的上限值)。这个图形清楚展示出了分数的累积情况, 大多数得分在 30 分到 45 分之间, 极高和极低的分数区间内人数较少。





图 2-1 52 名学生数学成绩直方图



让计算机来帮忙

直方图

SPSS 和 Excel 制表程序都可以用来绘制分组频率分布图, 但是制图方法迥异。 目前相比而言, Excel 制表过程更易操作, 但从技术层面上讲, Excel 默认生成的图形准确来说应该叫条形图, 而不是直方图, 因为每个方形条都是分开的。这个问题通过双击任意方形条, 选择 “选项”, 将 “间隙宽度” 设为零即可解决。但是, 图表上表示区间的数值为每个区间的上限值, 而不是中间值, 所以若不事先说明可能会在解释图形时出现问题。由此可知, 查看计算机的输出内容时要加倍仔细, 因为程序员编写的程序最终产出的结果并不一定会与你所预期的完全一致。

SPSS 会自动将数据分成 15 组, 生成图形 (这里所举的例子中的默认设置是 13)。最终得到一个工整的直方图 (方形条之间没有间隙, 不过仍可能需要调整一下才更好看), 而且还可以双击鼠标对图形输出结果进行编辑调整。可以试验一下图形编辑功能到底有何能耐。由 SPSS 绘制的学生数学成绩统计图如图 2-2 所示, 并运用 SPSS 编辑功能进行了调整, 以尽可能接近这套数据的分组频率分布。但此图不能完全代表表 2-4 的分组频率分布。





图 2-2 由 SPSS 生成的数学成绩直方图



SPSS 令人感到奇怪的一点是它将数值范围看作是完全连续的, 这会导致一些问题。我们常常会遇到无法获取默认区间宽度值和阈值的情况, 比如求得的区间宽度值为 \( {3.33}\text{、}{5.17} \) 等诸如此类。心理学和教育学测量结果通常不会有分数,所以这种情况下生成的直方图不利于数据的解析。还有, 注意上图中表示 “数学” 的横轴上给出了区间的上限值, 其中 57-60 这一区间在 SPSS 中的界定是从高于 57 分 (57.000001) 开始往上直到正好达到 60 这一最高分 (包括 60 分)。这与我们 “手动” 绘制的图表会有所差异, 但只有最高分值和分值最高区间的上限值一致时才会出现这样的情形, 这也是 SPSS 所特有的呈现数据的方式会产生的不可避免的影响 (这与心理学和教育学测量的传统相悖)。

我们可以采用一个相似的程序制作累积频率分布图。此图为累积频率曲线图 (有时也叫肩形图), 以纵坐标表示累积频率值, 横坐标表示分数或分数区间。一个点代表一个分数或区间的累积频率, 将这些点连成线, 就得到如图 2-3 所示的曲线图。 注意不可能出现横向下降的累积频率曲线图。 让计算机来帮忙





图 2-3 累积频率曲线图



## 累积频率曲线图

通过同时勾选累积频率百分比 (Cumulative Percentage) 和图表输出 (Char Output) 可运用 Excel 制表程序绘制累积频率百分比分布统计表。如前所述, 还需对生成的图表进行编辑以清除多余的部分, 而图表本身能够正确反映分组频率分布中的累积频率值。美中不足的是, 纵坐标只能通过少量的抽样调查而非查看完整的数据表现分析结果。删除直方图的部分方形条并重新调整后会得到如图 2-4 所示的图形。





图 2-4 由 Excel 绘制的累积频率曲线图



点击图表 (Graphs) 菜单并勾选连线 (Line), 则可通过 SPSS 生成累积频率表或累计频率百分比图。点击定义 (Define), 选择你想制成图表的变量, 然后添加到分类轴 (Category Axis) 会话框中。选择 “累积 \( \mathrm{n} \) 例 (Cum \( \mathrm{n} \) of cases),” 然后点击确认。也可选择“累积案例百分比 (Cum% of cases)”生成累积频率百分比图表。但由此生成的累积频率曲线图是根据该程序中生成的累积频率分布表进行绘制的。也就是说, 绘制这个图表的程序设定会像频率分布统计的过程一样将频率为零的数值变量省去, 而且会将所有不同的值一一列出。同样, 分析图表时也要格外仔细, 因为事先并不会知道程序已省略了部分数值。

## 2.4 集中趋势测量

要确定一组分数中的范值、平均值或中间值, 常常需要借助于统计学方法。统计学的目的在于为我们提供一个简单的测量方法以快速掌握某个既定范围内的分数的分布情况。以下将介绍三种这样的统计学方法, 它们对中心数值的定义各不相同, 且包含的信息也有些许差异。

## 1. 众数

确定范值的一个极其简单的方法就是选择出现频率最高的分数。这个分数就是众数, 与直方图的最高点相对应。查看 “频率分布表准备”一节中的统计表中所有学生的数学成绩, 你会发现 33 分和 38 分各出现了五次。在这一情形中, 众数的值并不是唯一的。而如果这些学生中有一名得 37 分的同学得的不是 37 分而是 38 分, 那么 38 就成为了这组数据的众数。同理, 若有一位得 34 分的同学得的也不是 34 分而是 33 分, 那这组数据的众数就是 33 。数据中这些极其细小的变化都会影响到众数的值, 因此它只是一个未经处理的原始数据, 对确定范值的指示意义不大。如表 2-3 所示的分组频率分布, 众数区间为 36-38。如此分组的话, 那么众数区间的中值 37 即可视为这组数据的众数。

我们介绍的两种计算机程序确定众数的方法相同, 都是从原始数据中寻找那个出现频率最高的分值。我们常常会遇到两个或两个以上的分数出现频率相同的情况, 此时应以值更小的分数为众数。由此, 两种计算机程序都会得出这组数学测试分数的众数为 33 , 即使 38 具有相同的出现频率。SPSS 的运算中会出现众数有多个值的情况, 而 Excel 制表程序不会。将此结果与分组频率分布统计表中的最高点进行比对, 会发现有很大误差。如表 2-3 所示, 众数很显然位于区间 36-38 中, 而由此得出的区间中值即众数为 37 。

## 2. 中值

另一种确定范值或平均值的更有效的方法就是找到将该组分数平分为上半部和下半部的值。这个值被称为中值。上述例子中, 共有 52 个分值, 将其平分则上半部分的高分段和下半部分的低分段各有 26 名学生。只要按照前述的方法将分数按大小依次排列或直接使用 Excel 表格的排序 (Sort) 功能, 就能轻易地从这些数学分数中找到我们所需要的值。我们需要确定这组分数的中点, 找出与之相邻的后一个分值。52 的一半是 26 , 因此必须计算出 26 名学生得分在其以下的那个点。从最低分开始数, 直至数到第 26 。

将所有分数按章首的表格那样从大到小排列后开始清点, 可知第 26 位学生的得分为 38 分。使用 Excel 将数学成绩整理排序, 排在第 25 位的学生是盖尔。贾拉拉加, 成绩为 37 分。因此还需要在往上数一位学生, 以凑足 26 个数。而下一个分值 (38 分) 由五名同学共享, 即有 5 名学生同时取得了 38 分。我们取这五名同学中的一名即可。但面对五名同时取得 38 分的同学, 我们又该如何取舍呢? 如前所述, 若每个区间内的数值是均匀分布的, 这一假定是合理可靠的, 那么要从五个分数中取一个就得沿着由最低分往最高分的方向再继续数一名学生。

此时,需要明确 38 分这一分值的定义。首先, 请注意虽然测试分数是以 1 为公差递增的等差数列 (或离散递增数值), 比如 37、38、39 , 但这些测试分数代表的其所测量的人的潜在能力却被看作是连续的, 比如 37 到 38 之间的任意一个点同样代表着该个人相应的能力值, 而并非毫无意义。这就好比一个电子时钟。虽然时间是连续的, 但时钟的记录方式却是离散的, 即分针每走过一格就意味着过去 1 分钟。

图 2-5 很好地阐明了这一点。底部的水平轴表示能力连续体。我们指定 38 为该连续体上最接近 38 分而不是 37 分或 39 分的一个区间。因此 38 即为图中从 37.5 延伸至 38.5 之间的这一小段。虽然具有一定的任意性, 但这样对分数进行定义是合理可靠且得到大多数专家权威认可的。如图所示, 36-38 这一分数区间实为从 35.5 延伸至 38.5 之间的这段连续体。我们不取 37 到 38 或 38 到 39 之间的其他分值, 并不是因为那些分值所代表的相应特征的量为零或没有意义, 而是因为我们的测量工具无法显示 37 到 38 或 38 到 39 之间的其他值 (这与 SPSS 表示分数的方式不同。运用 SPSS 处理数据时, 38 这一分值表示的是从 37 到 38 的这段连续体, 其中不包括 37, 包括 38 在内且不超过 38 。所以在 SPSS 中, 分数为该区间的上阈值而非中间值。44这点差异对结果的影响不大, 但却说明了手动计算或通过其他软件程序得出的结果与 SPSS 得出的结果略微有所出入的原因)。





图 2-5 分数与能力连续体关系图



我们需要从 37.5 -38.5 这一区间中的五个相同分数中取一个, 因此必须将这一连续体区间进行五等分运算, 得到如下值:

\[1/5\left( {{38.5} - {37.5}}\right)  = 1/5\left( 1\right)  = {0.2}\]

这就是五个分数中我们应该选择的那个与该区间内 38 分这一分值的具体距离, 以便在区间内包含 5 人中的 1 人, 并找出 26 人在其之下的那个点。将含有中值的这一分数区间的下限值 37.5 加上 0.2 得出这组分数的中值为:

\[{37.5} + {0.2} = {37.7}\]

注意中值可以是分数, 而众数只能是整数。

## 让计算机来帮忙

## 中值

包括 SPSS 和 Excel 制表程序在内的大多数计算机程序, 都将中值定义为中间那个人所得的分数, 而不考虑有多少人得分相同。这些程序会考察每个分值区间内分数的累积频率百分比, 然后将统计过程中遇到的第一个累积频率百分比超过 \( {50}\% \) 的区间中的分数定为该组数据的中值。上述例子中, 38 分这一分值的区间就是第一个累积频率百分比超过 \( {50}\% \) (实际为 \( {57.7}\% \) ) 的区间。那么这两种程序都会取 38 为中值。这种计算中值的方法其实与前面讲解的方法差不多, 因此测试者们无须花费太多精力在这两者上。但处理分组数据时会有明显的差异。SPSS 能够处理分组数据且能得出与上述完全一致的分析结果, 但 Excel 无此功能。若求取中值时遇到的正好是两个不同的分值, 这种特殊情况下的最佳方案就是取二者得分的中间点。例如, 有 100 个人参与测试, 第 50 名学生的成绩是 30 分, 第 51 名学生的成绩是 32 分, 那么中值的最佳值就是这两者的中间数, 即 31 分。Excel 和 SPSS 都能得出如上结果。

## 3. 百分位数值

计算中值的方法步骤同样可以用于确定该组数据中的任一百分比在其之下的那个分数。这些值被称为百分位数值。中值就是一组数据中的第 50 位百分位数值, 即该分数范围内 \( 5\% \) 的人的分数在其之下的那个值。同理,要找到第 25 位百分位数值, 则必须找到该分数范围内四分之一的人得分所低于的那个分值; 52 的四分之一是 13 。以这 52 名同学的数学成绩为例, 13 名同学的得分为 32 分。同样从最低分开始数到分值为 32 分 \( \left( {\mathrm{{cf}} = {11}}\right) \) 的同学后,接下来也有 5 名成绩同为 33 分的同学,而我们要从中选出 2 名。因此第 25 位百分位数值与 32.5 33.5 这一区间中的下限阈值距离为 0.4,那么得出的值为 \( {32.5} + \left( {2/5}\right)  = {32.9} \) 。

再比如,计算第 85 位百分位数值。用 \( {85}\% \) 乘以 52 可知,该组中有 44.2 人构成该组中得分最低的 \( {85}\% \) 的人。由于 44 名同学的成绩所处区间为 47.5-48.5 。在下一区间中也有两人是同样情况, 因此第 85 位百分位数值与该区间中的上限阈值距离为 \( {0.2}/2 = {0.1} \) ,由此得出的第 85 位百分位数值为 \( {48.5} + {0.1} = {48.6} \) 。同理可求得其他百分位数值。

通过分组频率分布统计表求取中值或其他的百分位数值的方法步骤也完全一样, 除了一点需要切记, 那就是这里的区间宽度大于一个分值单位。要通过如表 2-3 所示的分组频率分布表确定中值, 同样要先从最低分数开始数到第 26 名学生。第 26 名学生是区间 36-38 里 10 名学生中的一位。得分在该分数区间以下的学生共有 20 名 (区间 33-35 也为 20), 为此需从该区间的 10 人中取 6 人以凑足 26 个分值。 所以中值与该区间中的下限阈值距离为 \( 6/{10} = {0.6} \) 。由于这里的区间宽度为 3 个分值单位,因此需用 0.6 乘以 3 得到 \( {1.8}\left( {{60}\% }\right) \) ,即从该区间中取出我们所需的 6 名学生。区间从 35.5 (这一区间中的第一个分数的下限阈值) 开始, 那么所得中值为:

\[{35.5} + {1.8} = {37.3}\]

百分位数值用处颇多, 特别是在有关测试规范和测试分数的解析等方面。第三章对此也会有相关介绍。

## 让计算机来帮忙

## 百分位数值

Excel 制表程序计算百分位数值的方法与我们截至目前所介绍的方法都不一样。通过菜单栏的插入 (Insert) 键 (在工具栏中也可以找到, 与筛选图标相邻) 可对表中的单元格进行函数 \( \left( {f}_{x}\right) \) 运算操作。首先选中一个单元格,最终求得的百分位数值将会出现在其中。点击函数 \( \left( {f}_{x}\right) \) 图标 (有些版本的 Excel 表格中,这一图标在求和图标 \( \sum \) 旁边) 会出现一系列诸如“数学与三角函数”和 “统计” 等函数类型。选择统计功能组, 又会出现一系列多到令人眼花缭乱的函数供选择, 其中包括 “百分位函数”。 用此方法可以计算任何一个你想求取的百分位数值, 以及很快将会介绍到的大部分其他描述性统计数值。选择统计功能 (Statistical) 后, 再选择百分位函数 (Percentile), 会出现如下所示的界面:







选中所有需要分析的数据所在的单元格 (这里 52 名学生的数学成绩即为从 G2 到 G53 之间的所有单元格中的分数)。点击输入框 \( \mathrm{K} \) 并输入你想求取的百分位数值 (比如输入 \( {50}\% \) 计算中数)。然后点击确认,前面选中的那个单元格中就会出现相应的百分位数值。

Excel 制表程序计算百分位数值和中值的方法相同。它将特定的百分位数值与一系列累积频率百分比进行对比,然后选取所遇到的第一个累积频率高于 \( \mathrm{p} \) 的分值作为第 \( \mathrm{p} \) 位 (比如第 17 位) 的百分位数值。这样计算出的结果虽然不如上一页中介绍的方法精准 (比如有时同一个分值对应多个不同的百分位), 但一般来说其准确度还是比较高的。下一部分将介绍如何使用 SPSS 计算百分位数值。

## 4. 算术平均值

另一种确定一组数据中间值的十分常用的统计学方法就是人们平时常用的平均数。由于统计学家们把许多测量集中趋势的方法都用平均数来指代, 故将此方法定为算术平均值(M)。计算方法就是用一组数值的总和除以这组数值的总数。那么, 4、6、7 这三个数值的算术平均值就等于:

\[\left( {4 + 6 + 7}\right) /3 = {17}/3 = {5.67}\]

以数学成绩为例, 将这组数据中所有 52 名学生的得分相加之和 1985 除以 52, 得到的平均值为 \( \mathrm{M} = {38.17} \) ,即这组数据的算术平均值。

计算平均值的过程可用一个简单的公式来表示。统计学家们用大写的希腊字母西格马 \( \left( \sum \right) \) 代表求和过程。若以字母 \( \mathrm{X} \) 代表变量,比如数学成绩,那么 \( \sum \mathrm{X} \) 则表示所有 \( \mathrm{X} \) 的值相加求和。由于平均数还需用总和除以数值的总数(N),所以计算平均值的表达式为:

\[\mathrm{M} = \sum \mathrm{X}/\mathrm{N} = {1985}/{52} = {38.17}\]

很多地方都需要用到这个公式以及其他与之类似的方程式。 让计算机来帮忙

算术平均值

Excel 和 SPSS 都能计算算术平均值和绘制一些其他分析分数分布的图表。 Excel 制表程序数据分析 (Data Analysis) 包中包含一个程序, 叫作 “描述性统计”。 点击该程序, 然后点击确认键就会出现如下所示的界面:







点击该弹窗中的输入范围 (Input Range), 出现一个新的会话框, 然后选择计算算术平均值所需的所有分数。以表 2-1 中的数据为例, 则输入的数学成绩应为 G2- G53 单元格的所有分数。点击接下来的弹窗中的 “输出范围” (Output Range), 然后点击任一单元格开始, 比如第 I 栏第一排, 最终得出的值将显示在此单元格中。最后, 确认 “总结统计” (Summary statistics) 会话框中的检查 (check) 选项已被勾选后点击确认。这一程序中有三种方法可以测量集中趋势, 这在前面已经介绍过了。另外还有十种其他的统计方法, 我们将会对其中一部分作简要介绍。务必要查看 “计数” (count) 统计功能以确保用于进行运算的分值数量输入正确。另外还可以使用 (f) 统计功能 (请看到百分位会话框出现的前一个弹窗), 也就是平均数 (Average) 功能, 只计算等差中项的值。

若使用 SPSS 进行描述性数据统计, 在制作频率分布表的过程中就能得出任何需要求取的值。打开频率统计 (Frequencies) 应用程序, 选择你想分析的变量, 然后点击统计 (Statistics) 进入如下所示的界面。







点击会话框内你想要用来计算求值的统计功能, 如下选择了平均值、中数、众数和总和; 三个具体的百分位数值 (10、27 和 46); 还有即将介绍的三种测量变量的方法。记得勾选 “计算数据中间值” (Values are group midpoints) 会话框中的检查 (check) 这一选项, 这样 SPSS 就会按照本章前面所介绍的方式计算中值和百分位数值。若未勾选, 程序将自动取遇到的第一个累积频率百分比超过某一特定值的分值为中值。点击继续 (Continue), 然后点击确认就能得出所需的统计摘要。

## 5. 集中趋势与分布形态

很少出现众数、算术平均值和中数这三者的值同为一个数值的情形, 但一般而言它们之间也不会相差太远。上述例子中所得的中数和平均数分别为 37.7 和 38.17 , 而众数的一个可能的值是 38 。只有当这组数据的分布出现严重倾斜时, 也就是大多数分值都集中在一端而另一端的分值却寥寥可数时, 这三者的值才会出现巨大差异。 如图 2-6 所示的分数分布情况, 三个图形的倾斜程度和方向各不相同。最上面的图形为正倾斜, 即高分段分值分布较稀少。调查美国个人收入情况可能会得到这样的分布图形, 因为美国大多数人的收入都处于中等偏低的水平, 而高收入人群只占极少一部分。中间的图形为负倾斜。若是对一个班进行一项极其简单的测试, 大部分学生都取得了满分或近乎满分的成绩, 就会得到这样的分布图形。最下面的图形为对称分布, 它没有往两个方向中的任一方倾斜。心理学和教育学领域许多变量的测量结果都会产生这样的图形。

Excel 制表程序和 SPSS 各自也有计算表征倾斜度指数的描述性统计包。若指数为正数, 则说明为正倾斜分布。若指数为负数, 则为负倾斜分布。若指数的值约等于零, 则说明数据分布近乎对称。

若为对称分布, 平均数和中数都可作为这组数据的平均数。但是若数据分布有所倾斜, 则以中数为平均数更佳, 因为分布在末端的零星数据形成的 “长尾” 对它的影响较小。平均数更常用于对称分布情况中, 具体原因会在后面介绍到正态分布的相关内容时进行阐述。这种情况下较少使用众数是因为其稳定性不如平均数和中值, 尽管相比之下计算众数的步骤更简单, 这些都能在上述例证中得见。而且, 众数与我们想要求取的其他值关联性不大。





图 2-6 不同斜率的频率分布

(a) 正倾斜 (b) 负倾斜 (c) 对称分布



## 2.5 差异性测量

描述一组分数时揭示数据的差异程度十分重要, 即所有分数由高到低的分布情况。以两组儿童为例, 若一组儿童的年龄分布情况为 9-11 岁, 而另一组为 6-14 岁, 虽然两组儿童年龄的中间值都是 10 岁, 但两者却会有十分不同的文化程度差异。 因此, 把握这一点对解析一组数据很重要。

## 1. 全距

分析差异程度的一个简单方法就是确定该组分值的全距, 简单来说就是最高分与最低分的差。以上述数学测试为例, 学生的成绩分布在 60-19 之间, 由此得出全距为 41 分。一组数据的全距取决于这组数据中的最大值和最小值。这一点降低了全距的可靠性, 因为仅随意添加或删除任意一个处于数据两极的值就可能会使全距产生较大的变化。比如若乌利亚。乌达没有参加此次数学测试, 那么这组数据的全距则应该是 53 减 19 等于 34 , 而不是 41 。

## 2. 半四分位数间全距

确定一组分值全距并抽取整组数据的特定部分 (通常为中间的 \( {50}\% \) ) 进行考察, 这样分析差异程度的效果更佳。中间 \( {50}\% \) 的数据即为第 25 位到第 75 位的百分位数。按照前面详细介绍的方法步骤进行计算, 在该例子中可得第 25 位百分位数值为 32.9 , 第 75 位百分位数值为 44.0 。那么第 25 位到第 75 位百分位数的差则为 11.1 分,也就是分布在中间部分的 \( {50}\% \) 分值或中间 26 位学生成绩的全距。

第 25 位和第 75 位百分位数被称作四分位数, 因为它们分别是由去掉头尾四分之一的数据所得, 两者之间的分值差叫作四分位间全距。一个常见的衡量差异程度的统计方法就是半四分位数间全距(Q),也就是四分位数全距的一半。它是中数到两个四分位数的平均距离, 也就是四分位数分值与中数之间的平均距离。上述例子中的半四分位数间全距为:

\[Q = \frac{{44.0} - {32.9}}{2} = {5.55}\]

如果这组数据中间的 26 个分值间距是原先的两倍,那半四分位数间全距(Q)的值也会增大一倍; 反之,若间距只有原先的一半,则半四分位数间全距(Q)的值也要减半。如图 2-7 所示, 这两组数据分布具有相同的平均数, 相同数目的考察对象以及相同的一般形式, 唯独不同的是一组数据的差异程度是另一组的两倍。





图 2-7 仅差异程度不同的两组数据分布

(a) 差异程度较大 (b) 差异程度较小



让计算机来帮忙四分位数

SPSS的频率统计程序可进行有关四分位数的运算。点击 “四分位数” (Quartiles) 会话框并确保程序会以相应数值为该组数据的中间值。以数学成绩为例, SPSS 的结果与如上通过计算第 25 位百分位数值得到的结果相比误差并不大, 因为 SPSS 程序所套用的公式适用范围较广。而且在 0.01 的误差范围内, 二者得出的结果一致。四分位数间全距和半四分位数间全距(Q)的值需要手动计算。虽然可以借助 Excel 制表程序中的百分位 (Percentile) 函数计算第 25 位和第 75 位的百分位数值, 但由于 Excel 程序有关百分位数的默认设置, 最终得到的结果将是整数分值。计算出四分位数后, 半四分位数间全距的值也就出来了。

## 3. 标准差

半四分位数间全距和中数同属一个统计学范畴。而百分位数范围更广, 二者都可算作百分位数中的特殊情况。算术平均值这一门类下分析差异程度的统计方法还可以进一步细分, 这些方法主要考察以平均数为基础的分数偏差。其中最常用的就是标准差。请往下看。

假设有四个分数: \( 4\text{、}5\text{、}6\text{、}7 \) 。将所有分数相加后除以其总数可知这组数据的算术平均值为:

\[\left( {4 + 5 + 6 + 7}\right) /4 = {5.5}\]

但现在我们想知道这些分数围绕该算术平均值的波动幅度。如果计算出每个分数和算术平均值的差,即用每个分数减去 5.5,依次可得 \( - {1.5}\text{、} - {0.5}\text{、}{0.5} \) 和 1.5。 这些值分别表示这四个分数与算术平均值的偏差。这一运算过程可用如下等式来表示:

\[\text{偏差} = X - M\]

偏差越大说明这组数据围绕其算术平均值的波动幅度越大。若所列举的分数为 \( 2\text{、}5\text{、}6\text{、}9 \) ,这组数据的算术平均值仍然是 5.5,但相应的偏差值却分别为 \( - {3.5}\text{、} - {0.5} \) 、 0.5 和 3.5 。这些偏差值的平均数即为我们衡量该组数据的差异程度或波动幅度的指标。

若是将如上四个偏差值简单相加会发现结果为零, 正偏差值正好与负偏差值相抵消。无论何时这一运算都会得出这样的结果, 因为算术平均值的定义之一即是说围绕等差中项的偏差值总和为零 (注意上述两个例子中的偏差值总和均为零)。表达式为:

\[\sum \left( {X - M}\right)  = 0\]

因此我们需要另辟蹊径, 寻找其他可以衡量波动幅度的指标。统计学家们想出了如下处理正号 (正数) 和负号 (负数) 的方法, 即将所有偏差值乘二次方, 这样得到的值就全都是正数 (负负得正)。将所有偏差值的二次方相加, 再除以该组数据中的对象总数, 就能得到一个平均值。这个值叫作方差。这一统计方法也广泛应用于更高阶的统计程序中。我们将方差定义为一组数据中的所有数值相对于其平均数的偏差二次方的算术平均数, 或用如下公式表示:

\[\text{方差} = \sum {\left( X - M\right) }^{2}/N\]

因为上述运算中所有偏差值都乘以了二次方, 因此还要对求得的平均值开二次方。最终所得的值即为标准差 (SD)。标准差是一组数据中的所有数值相对于其平均数的偏差的二次方的算术平均数的二次方根 (大多数计算器都只需要按特定的键就可以对相应数字进行二次方根运算)。以前面列举的第一组分数为例, 计算过程如下:

\[{SD} = \sqrt{\frac{\left\lbrack  {\left( -{1.5}\right) }^{2} + {\left( -{0.5}\right) }^{2} + {\left( {0.5}\right) }^{2} + {\left( {1.5}\right) }^{2}\right\rbrack  }{4}}\]

\[{SD} = \sqrt{\frac{\left( {2.25} + {0.25} + {0.25} + {2.25}\right) }{4}} = \sqrt{5/4}\]

\[{SD} = \sqrt{1.25} = {1.12}\]

由上可知, 这组分数的方差为 1.25 , 标准差为 1.12 。同理可得, 前面所列举的第二组差异程度更大的分数的标准差为:

\[{SD} = \sqrt{\frac{\left\lbrack  {\left( -{3.5}\right) }^{2} + {\left( -{0.5}\right) }^{2} + {\left( {0.5}\right) }^{2} + {\left( {3.5}\right) }^{2}\right\rbrack  }{4}} = \sqrt{{25}/4} = {2.5}\]

二者对比可知,第二组分数围绕其平均数的波动幅度比第一组更大。

运用计算平均数的公式中的同一套符号,可将标准差(SD)的公式表示如下:

\[{SD} = \sqrt{\frac{\sum {\left( X - M\right) }^{2}}{N}}\]

从这一公式可知计算标准差的步骤如下:

1. 用每个分数减去平均数得出相应的偏差值 (例如: \( 2 - {5.5} =  - {3.5} \) )。

2. 将每一个偏差值乘以二次方。

3. 将所有偏差值的二次方结果相加求和。

4. 用所求的和除以这组数据中的对象总数(N)。

5. 对上一步中所得的值开二次方。

计算标准差的过程中有一个因素会导致使用计算器或计算机处理得到的结果与运用上述公式手动计算出来的结果不一致, 或是你和你的同学两人处理同一组数据得出的结果不一致。先前在这一章节中, 我们提到统计推论指的是根据抽样数据推断更大组别 (假设全部样本) 的属性特征。无论是抽取一部分样品还是分析整组数据都对其平均数都没有影响 (通过部分样本和全部样本这两组数据计算会得出相同的值), 但会影响到标准差。用所有相对于该组样本平均数的偏差值的二次方的总和除以样本数量(N)所得的标准差这一数值说明的是所抽取的这部分样品的差异程度。 而用所有相对于该组样品平均数的偏差值的二次方的总和除以 \( N - 1 \) 而不是 \( N \) 才能 (根据分析样本所得的数据) 对从中抽取了样本的整个样本的标准差做出最可靠的推断。以 \( N - 1 \) 作为分母能够使对整个样本标准差的估计值比由样品数据计算所得的值稍微偏大。这点细微的差别对大多数测量程序并无实际意义, 却反而会令人在将测量结果与问题进行对比时感到困惑。可以查看一下你所使用的计算器的说明书, 了解其应用版本 (许多说明中都是如上两种中的任意一种), 这样的话就不必为自己计算出来的值与用计算器求得的值有轻微的差异而苦恼了。若想了解这两种方式计算出来的值存在差异的原因, 可查阅相关统计学基础人门书籍。

## 让计算机来帮忙

## 标准差

大多数计算器及所有电子表格和数据统计包都包含计算一组数据标准差的程序。Excel 制表程序和 SPSS 中的诸多程序同样也都能用于计算方差和标准偏差。 SPSS 中, 只需要点击频率统计 (Statistics of Frequencies) 会话框中的标准差54(Standard Deviation) 键即可。SPSS 中的描述统计 (Descriptives) 应用程序的标准输出可得相应标准差的值。而 Excel 能够通过描述性统计 (Descriptive Statistics) 的常规运算得出标准差和方差。

SPSS 相关程序计算得出的标准差并非原数据的值,而是常常以 \( N - 1 \) 为分母进行运算,而通过 Excel 的 \( {f}_{x}\left( \sum \right) \) 运算程序所得的标准差即为原样本数据的值。函数功能列表包括两种运算方式,即 STDEV (以 \( N - 1 \) 位分母) 和 STDEVP (以 \( N \) 为分母)。这两种运算所得的值之间的差异几乎可以忽略不计, 除了所分析的对象数目特别少的情况。但这一差异小而不等于没有这一事实却能在一定程度上解释不同的人对同一组数据的总结的不一致性。

## 2.6 标准差分析

无论是想用几个简单术语还是绘画或几何术语将标准差解释清楚几乎都是不可能的。主要是因为标准差是一种表征数值分布的波动幅度的统计方法。它随着一组数值围绕其等差中项波动幅度的增大而增大。标准差值越大, 个人之间的差异性越明显。有时有人可能会问, 那么一个较小的标准差意味着什么? 一个较大的标准差又意味着什么呢? 深究起来, 如上这两个问题的答案也没有人能说得清楚。假设某一组分析对象的重量标准偏差是 10 , 那这个值是大了还是小了? 这取决于是按盎司、磅还是千克来算, 以及所考察的是老鼠、人类还是猛犸象的重量。

有一种类型的数值分布, 即正态分布或正态曲线, 其标准差的意义能够得到十分清晰明了的说明。用一个专门的数学方程式就能解释其标准差的意义, 但对日常使用者来说, 定义更多的是从绘图角度着手的。正态曲线是一条形状像钟的对称曲线。 实际上, 它也常被称为钟形曲线。分析对象大部分集中在中间的分数段, 由中间向两边延伸, 对象数量逐渐减少。减少的速度刚开始比较缓慢, 紧接着开始加快, 而后又开始放缓, 这样就导致两端都拖着相对较长的 “尾巴”。典型的正态曲线如图 2-8 所示。该正态曲线与根据表 2-1 中的数学成绩所绘制的直方图完全吻合。它们具有相同的算术平均值、标准偏差, 且都以整组数学测试分数为总分析范围 (所考察的对象数目)。数学成绩直方图 (图 2-1) 也显示在下图中, 由此这条理想曲线与实际分值分布的吻合程度更加清晰可见。由于该正态曲线是完全对称的, 所以其平均数、中数和众数为相同值。





图 2-8 正态分布 (钟形曲线) 与 52 名学生数学考试成绩直方图的叠加



回想一下直方图中的那些方形条。每一个的宽度都是相同的, 其高度表示该方形条所占据的区间内所有分值的频率。因此, 每个方形条所占据的区域代表着该区间内相应比例的分值数目。也就是说, 图表中某个方形条所占据的部分与这组数据中分布在该区间中的分值的量是相对应的。成绩分布在 \( {33} - {35} \) 和 \( {36} - {38} \) 这两个分数区间内的人共有 \( 9 + {10} = {19} \) 人,因此图中相应的方形条所占据的区域代表的对象数量也是 19 人。测试学生总人数为 52 人, 用 19/52 得 0.37, 即 37%的学生分布在区间 \( {33} - {38} \) 中。

在正态曲线的情形中, 标准差与对象的数量呈严格的数学关系。若标准差出于相同波动幅度内, 那么相应的对象数目永远是一致的。这种数学关系如图 2-5 所示。 由此图可看出任意正态曲线图都是如此,即三分之二 \( \left( {{68.2}\% }\right) \) 的分析对象分布在相对于其平均值的差值为 +1.0 和 -1.0 的偏差范围内。因此, 如果平均值是 50 , 标准差为 10,那么约有 \( {68}\% \) 的分析对象得分在 40-60 之间 (分别有 \( {34}\% \) 得分在 40-50 之间, \( {34}\% \) 得分在 \( {50} - {60} \) 之间)。约 \( {95}\% \) (实际上是 \( {95.4}\% \) ) 的人分布在相对于其平均值的差值为 +2.0 和 -2.0 的偏差范围内。相对于其平均值的差值为 +3.0 和 -3.0 的偏差范围内几乎囊括了所有考察对象。标准差与分析对象的数量之间这种数学关系是恒定不变的,由此可推知在正态分布中,得分相对于平均值的偏差为 +1.0 的人的水平会超过同组 \( {84}\% \) 的测试对象,也就是得分低于平均值的那 \( {50}\% \) 加上得分相对于平均值的偏差在 0.0 到 1.0 之间的那 \( {34}\% \) 。



表 2-5 正态分布中分布在某一特定标准差范围内的分析对象比例

<table><tr><td>得分所处的偏差范围</td><td>对象占比 \( \left( \% \right) \)</td></tr><tr><td>介于平均值和 \( + {1.0}\mathrm{{SD}} \) 或 \( - {1.0}\mathrm{{SD}} \) 之间</td><td>34.1</td></tr><tr><td>介于平均值和 \( + {2.0}\mathrm{{SD}} \) 或 \( - {2.0}\mathrm{{SD}} \) 之间</td><td>47.7</td></tr><tr><td>介于平均值和 \( + {3.0}\mathrm{{SD}} \) 或 \( - {3.0}\mathrm{{SD}} \) 之间</td><td>49.9</td></tr><tr><td>介于 +1.0SD 和 -1.0SD 之间</td><td>68.2</td></tr><tr><td>介于 \( + {2.0}\mathrm{{SD}} \) 和 \( - {2.0}\mathrm{{SD}} \) 之间</td><td>95.4</td></tr><tr><td>介于 +3.0SD 和 -3.0SD 之间</td><td>99.8</td></tr></table>



正态分布中, 固定单位的标准差与分值的分布之间这种恒定的关系赋予了标准差一种标准意义, 即分值的一个单位长度。它也因此成为了纵向判断哪些不同组的数据可以在一起进行对比或是横向比较某个特定分析对象所体现的几个不同特征的标尺。例如, 约翰的阅读理解成绩比平均值大一个单位长度的标准差 (SD), 而他的数学成绩比平均值大两个单位长度的标准差, 那么相对于这两个变量各自的平均值来说, 他在数学测试中的表现比阅读测试中的要好 (使用标准差和正态分布对个人表现进行对比分析将会在第三章中做相关介绍)。虽然单位长度的标准差与分值分布的关系只适用于理论上的正态分布这一分布形态, 但测试分数的分布形态结合其他一些测量方法往往相当接近正态分布, 从而使我们依然能够使用标准差的这一定义, 尽管准确性会稍有降低。

总的来说, 应用较多的分析一组数值差异程度的统计方法主要还是计算半四分位数间全距和标准差。半四分位数间全距是基于百分位数值的运算, 具体地说就是计算一组数据的第 25 位和第 75 位百分位数的数值。这一方法常用于将中值作为一组数据的中间值的情形中。而分析数据差异程度的标准差则离不开算术平均值。标准差主要用于测试领域, 因为其标准测量单位, 可使两门不同的测试科目具有可比性。

## 2.7 个体分数分析

以标准差单位表示的一组数据中个人的分数,我们称之为标准分数或 \( Z \) 分数。 一个人的 \( Z \) 分数就是其得分与平均数之间的差除以标准差所得的值。假设 \( X \) (比如数学测试) 为变量,以 \( {X}_{i} \) 代表一个人的原始成绩,那么其 \( Z \) 分数为:

\[{Z}_{{X}_{i}} = \frac{{X}_{i} - {M}_{X}}{S{D}_{X}}\]

同理,同一个人在阅读理解测试 (后面都以变量 \( Y \) 来代替) 中的 \( Z \) 分数则为:

\[{Z}_{Y} = \frac{{Y}_{1} - {M}_{Y}}{S{D}_{Y}}\]

设 \( {M}_{X} = {38.17},{M}_{Y} = {34.44},S{D}_{X} = S{D}_{Y} = {5.55} \) (这些值分别是表 2-1 中数学和阅读这两组数据的等差中项和标准偏差),则亚伦・安德鲁斯在这两个变量上的 \( Z \) 分数的值分别为:

\[{Z}_{X} = \frac{{43} - {38.17}}{8.93} =  + {0.54}\]

\[{Z}_{Y} = \frac{{32} - {34.44}}{5.55} =  - {0.44}\]

(亚伦的原始成绩分别为 43 和 32。) 从如上这两个 \( Z \) 分数可知,亚伦的数学成绩比平均值约大半个单位长度的标准差, 而阅读成绩比平均值约小半个单位长度的标准差。

第三章会对个人分数分析中可能出现的问题做更加详细的介绍, 主要针对操作规范和测量单位两方面。经过上述分析可知前面刚介绍的两种方法, 即百分位数值和标准分数, 能够为我们提供一个考察某个特定对象成绩表现的基本框架。两者都是通过对比特定的参照组进行考察。通过计算百分位数值可以根据分数分布情况了解该组数据中超过某一特定部分分值的点, 而求取标准差可以得知该组数据中任一值与其平均值之间有多少个单位长度的距离。由此某一特定个人的得分则可转换为代表大于或小于平均数值的普通单位长度。通过这种方式便能够将一个人的身高和体重进行比较并得出一个明确且有意义的答案。

## 2.8 相关性测试

我们现在来探讨表现两组数据相关性的统计方法。以表 2-1 中的数据为例, 每名学生有三项成绩, 分别为阅读、数学和拼写。那么那些数学考得好的学生, 在多大程度上其阅读考得也好呢? 这种情况下, 我们将每名学生的这两门成绩抽取出来, 并绘制成一个二维图表, 每一边代表一门测试。如图 2-9 所示, 这种图叫作散点图。 表 2-1 中的第一位学生, 亚伦 - 安德鲁斯的阅读成绩为 32 分, 数学成绩为 43 分。如图 2-9 所示, 他的分数用 \( * \) 表示, 即纵坐标 (阅读) 32 与横坐标 (数学) 43 的交点。图中的每个点分别代表其他 51 名学生的 51 对分数。例如阅读 21 分与数学 19 分在图中的交汇点代表的就是魁杜拉・魁克里 (Quadra Quickly)。

贯穿图中的垂直线和水平线是这两组变量的平均数, 将该散点图平均分成四个部分或象限。若一名阅读成绩良好 (得分大于平均数) 的学生的数学成绩也是良好, 那么代表这对分值的点则分布在右上象限中。两门测试成绩均不佳 (得分小于平均数) 的学生, 代表其分值的点相应地分布在左下象限中。而当一门测试成绩佳而另一门不佳时, 代表这些分值的点则分布在另外两个象限, 即左上和右下象限中。两门测试成绩正好都在中间的学生, 代表其分值的点则会位于图的正中心。查看图 2-9 会发现分数的分布表现出一些从左下象限往右上象限方向延伸的趋势, 即从阅读和数学两门测试的低分段往高分段的走向, 当然还有很多例外。要解释清楚变量之间的相关性远没有这么简单。这又是一个与程度有关的问题, 因此需要某种指数来表示这种相关程度。





图 2-9 阅读和数学分数散点图



广泛使用的一种表示相关度的统计指数即相关系数,用符号 \( \gamma \) 表示。分析关于 \( \gamma \) 的公式可对其特有的性质和特征有初步的了解。相关系数的定理表达式如下:

\[\gamma  = \frac{\sum {Z}_{X}{Z}_{Y}}{N}\]

其中 \( {Z}_{X} \) 和 \( {Z}_{Y} \) 为某一学生的一对标准分数 (比如前面求得的亚伦・安德鲁斯在数学和阅读上的标准分数 +0.54 和 -0.44 )。这个公式表示将每个人在这两个变量上的标准分数相乘后求和, 然后用所得的值除以这组数据中的对象总数。

现在来看看那些成对的标准分数。如果得分大于平均值, 则标准分数为正数; 反之, 为负数。若两项得分均大于平均值 (右上象限), 则两个标准分数都是正数, 相关系数为正数。同理, 若两项得分均小于平均值 (左下象限), 则两个标准分数都是负数, 相关系数仍为正数。而如果两项得分与平均值相比一大一小 (左上象限或右下象限), 则两个标准分数一正一负, 相关系数为负数。若在这两个变量上, 学生总体成绩分布均偏向于平均项的同一侧, 那么将所有对象相应的标准分数相加的总和为正数. 相反地, 若在一个变量上学生总体得分大于平均值而在另一个变量上小于平均值, 那么最终求得的标准分数总和将为负数, 反之亦然。最后将所得总和与所考察的对象数目相除, 即为其不同变量之间的相关系数。

相关系数的值一般介于 +1.0 到 -1.0 之间 (包括 0 )。若相关系数为 +1.0 , 则表示两个变量呈完全正相关。也就是说在一项测试中 \( Z \) 分数排在第一位的同学在另一项测试中的 \( Z \) 分数也排第一位,而排名第二的同学在另一项测试中也排第二, 直至最后一名, 整组学生都是完全匹配。这类数据的散点图上所有点会排成一条直线, 从左下象限斜向上延伸至右上象限。若相关系数为 -1.0 , 则表示两个变量呈完全负相关。每位学生在两项测试中的成绩排名完全相反, 即在一项测试中得分最高的同学在另一项测试中得分最低, 排名第二的同学在另一项测试中则排倒数第二, 以此类推。这种情况下的散点图中所有点也会排成一条直线, 但是是从左上象限斜向下延伸至右下象限。若相关系数为 0 , 则表示完全没有相关性。意即没有迹象表明在一项测试中得分较高的同学在另一项测试中得分是高于还是低于平均值 (得出的所有正值与所有负值正好完全抵消)。完全没有规律可循, 其散点图呈圆形。若相关系数为除这三个值之外的任意中间值, 则表示考察的变量之间的相关性有一定的规律可循, 但分析结果与实际情况会存在一定误差, 如图 2-9 中的例子所示。

每一个相关系数包含两点内容。一个是相关系数前面的符号, 由此可以判断考察对象在两组变量中的排列顺序是相同 (正号) 还是相反 (负号)。另一个是相关程度的大小, 即联系有多紧密。若相关系数为 +0.50 或 -0.50 , 其所表示的相关性紧密度相同, 但前者代表考察对象在两组变量中的排列顺序相同, 后者代表考察对象在两组变量中的排列顺序相反。如图 2-10 所示为四个不同的相关程度。图 2-10(a) 中相关系数为零, 因此这些点散开分布似一个圆形。所有的四种组合, 高一高、低一低、 高一低和低一高, 数量均匀。图 2-10(b) 中相关系数为 +0.30 , 可以看出一点代表相应分数的这些点从低一低往高一高方向延伸分布的趋势。如图 2-10(c) 所示, 相关系数为 \( + {0.60} \) 时,趋势更加明显。图 2-10(d) 中相关系数为 \( + {0.90} \) 时,其趋势较图 2-10(c) 更为明显。当相关系数为-0.60(如图 2-10(e)) 或 -0.90(如图 2-10(f)) 时,这些点散开的形状与图 2-10(c) 和图 2-10(d) 仍旧一样, 只是延伸的方向相反, 即从左上角往右下角沿对角线延伸分布。但是即便相关系数高达十 0.90 , 分数的分布仍然非常分散, 不会由低一低往高一高方向整齐地排在一条直线上。图 2-9 中的这组数值所对应的相关系数为 \( + {0.62} \) ,这个值与心理学和教育学领域考察的大多数变量之间的相关系数相比算相当高了。





图 2-10 具有代表性的相关系数值对应的分数分布

(a) 相关系数为0.00; (b) 相关系数为 \( + {0.3} \) ; (c) 相关系数为 \( + {0.60} \) ; (d) 相关系数为 \( + {0.90} \) ; (e) 相关系数为-0.60; (f) 相关系数为 -0.90



和标准差一样, 许多先进的袖珍计算器也都内置有计算相关系数的程序。无独有偶,一些电子数据表和统计软件包往往也都具备计算相关系数的程序和功能。有关这些内容的介绍归到接下来会讨论的回归这一小节中, 该主题与上述内容高度相关。 让计算机来帮忙

相关系数

SPSS 和 Excel 制表程序都有非常简便的同时计算多个变量之间相关系数的常规方法。SPSS 的分析 (Analyze) 菜单选项中有一个关联 (Correlate) 应用程序。点击进入该应用, 系统会提供三种可计算的相关系数类型。选择 “双变量” (Bivariate), 即一次对比两个变量。接着会出现一个会话框, 添加你想要关联的变量。然后再将需要计算相关系数的变量依次添加到变量 (Variables) 会话框中。皮尔森相关系数就是前面所介绍的, 同时也是我们所要求取的那个相关系数, 选择它然后点击确认。最后的结果呈现为一个四方表, 其中的每一个条目都是横排中的两个变量与数列中的这两个变量之间的相关系数。表格中对角线上的两栏中的值都会是 1.0 , 因为任一变量与其自身都是完全正相关的。每个单元格中还会显示计算相关系数所考察的对象数量以及该相关系数的统计显著性 (“Sig”) 测试 (即对从中抽样的更大总样本而言, 该相关系数表现为除零以外, 十 1.0 到 -1.0 之间任意值的概率)。一般西格 (Sig) 的值都不会超过 0.05 , 否则得出的相关性就不可靠。

Excel 中, 只需选择数据分析 (Data Analysis) 菜单中的相关性 (Correlation) 选项, 接下来会出现一个要求设置输入范围 (Input Range) 的会话框。务必保证所有分数被选中以供程序分析, 或是从表格左上方第一个单元格下拉到右下方含有数值的最后一个单元格以选中所有分数所在的单元格区域。然后点击 “输出范围” (Output Range) 会话框中的 “输出范围” (Output Range) 键, 再点击表格中一个空单元格, 最终得出的相关表右上角的数值将出现在其中。Excel 最后得出的结果将只有如上通过 SPSS 计算得出的表格的下半部分, 包括对角线栏位上的数值。Excel 制表程序的求和 \( \left( \sum \right) \) 或函数 \( \left( {f}_{x}\right) \) 菜单中还有一个相关系数 (Correl) 函数,可供计算一对变量的相关性系数。选中一个变量相对应的所有分值为数列一 (Array 1), 然后选中另一个变量相对应的所有分值为数列二 (Array 2)。点击确认, 所求取的相关系数就会显示在你之前下达计算函数指令的单元格中。

如下三种重要情形会涉及计算与测试和测量有关的相关系数。其一是确定测量程序的精确度和一致性。若想知道测量运动员 50 米冲刺速度的程序的可靠程度, 可以每个人测两次, 或许还可以连续好几天对这些运动员进行测量。计算这两组数据的相关系数就能得知这一关于跑步速度的测量程序的稳定性, 或者说可靠性。其二即研究两种不同的测量程序的相关性, 以其中一个作为另一个的预测参照物。比如可以测量高中生的学习成绩以预测他们在大学中的成绩表现。测试分数与学生实际表现两者的相关性可以作为衡量该测试效度的指标。相关系数在如上两种情形中的应用在第四章和第五章中会有更详细的介绍。

相关系数在第三种情形中的应用更加完全是描述性的。我们对变量之间的相关性感兴趣, 往往只是因为想更好地理解人类不同行为之间的联系。人的语言能力和数字分析能力在多大程度上相关? 对操作机械或是操作机械设备的相关知识感兴趣两者的相关性又如何? 生理发育速度与智力发展速度相关吗? 许多有关人类行为的研究问题最好或者也许只能通过分析其自然发展过程中的相互关系进行研究, 这些相互关系通常以相关系数表示。

处理每个案例时,我们都会面临评估所计算的相关系数的问题。假设两组 50 米冲刺成绩的相关系数为 \( + {0.80} \) ,这是一个令人满意的结果吗? 假设上述例子中高中生的成绩测试分数与他们在大学的成绩这两个变量的相关系数为 \( + {0.60} \) ,这一结果是令人高兴还是令人沮丧? (从如上措辞可感觉到我们实际希望得到更高的相关系数值。当相关系数用于衡量一项测试的可靠性或一致性, 抑或是预测所关注结果的准确性时, 我们当然是希望相关系数越高越好。然而在其他情况下, “大”并不一定就等于“好”。或许此时我们不会再希望相关系数的值越大越好, 甚至反而希望其越小越好。)

图 2-10 中那些点的分布在一定程度上反映了第三个问题的答案。很显然, 相关系数越高, 两个变量中的所有分值分布越紧密。若将这些点与从低一低延伸至高一高的这条对角线之间的偏差看做一个个 “错误”, 那么相关系数越大, 这些错误就越小。同样地,若将学生在 \( \mathrm{Y} \) 测试中成绩的标准差看作预测其在 \( \mathrm{X} \) 测试中可能取得的分数中所犯的错误,那么由 \( \mathrm{X} \) 和 \( \mathrm{Y} \) 之间的相关系数大小可知以 \( \mathrm{X} \) 测试预测变量 \( \mathrm{Y} \) 时的错误减小的程度。由相关系数的平方 \( \left( {\gamma }^{2}\right) \) 可知,与不使用 \( \mathrm{X} \) 测试的成绩相比, 以 \( \mathrm{X} \) 测试预估学生在 \( \mathrm{Y} \) 测试中的分数时误差减小的程度。但即使是就特别高的相关系数而言, 比如图 2-10 所示的那些, 存在的错误偏差仍然是不容乐观地巨大。必须时刻注意这些偏差且明白即便测试分数与在校实际成绩二者的相关系数达到了十0.60 (这大约也是这类测量程序通常所能达到的高度), 仍然有很多学生, 其在校的实际成绩与我们能够根据测试做出的最佳预测会存在较大差异。这些问题将在第五章中作进一步阐述。

可是, 万事万物皆是相对的。因此对任何一个特定相关系数的分析都应该有相关常用系数标准为参照。表 2-6 中概括了一些前述不同类型变量之间的相关性, 阐述了这些分数之间的本质上的相关性特征, 并给出了相关系数的具体值。从这个表格中可获取一些解析这些相关系数的基础背景知识。接着往下看, 你会接触到更多大小不同的相关系数, 同时随着对测试和测量不断深入的了解, 你会发现相关系数将会承载越来越多的意义。



表 2-6 所选变量之间的相关性

<table><tr><td>变 量</td><td>相关系数</td></tr><tr><td>双胞胎的身高</td><td>0.95</td></tr><tr><td>双胞胎的智力测试分数</td><td>0.88</td></tr><tr><td>三年级和六年级学生的阅读测试成绩</td><td>0.80</td></tr><tr><td>教师工作习惯评级与所教的高中班级排名</td><td>0.73</td></tr><tr><td>十岁儿童的身高和体重</td><td>0.60</td></tr><tr><td>算术运算测试与非文字智力测试分数 (八年级学生)</td><td>0.54</td></tr><tr><td>兄弟身高(控制年龄)</td><td>0.50</td></tr><tr><td>智力测试分数和父母的职业水平</td><td>0.30</td></tr><tr><td>抓握力度与跑步速度</td><td>0.16</td></tr><tr><td>成年人的身高与智力测试分数</td><td>0.06</td></tr><tr><td>头的长宽比与智力测试分数</td><td>0.01</td></tr><tr><td>新兵的军事资格测试分数与复读的年级数目</td><td>-0.27</td></tr><tr><td>有关成为艺术家和银行家兴趣的测试分数</td><td>-0.64</td></tr></table>



## 2.9 预测 结 果

我们已知道相关系数可以说明两个变量的关联程度, 以及二者是正相关还是负相关。再结合预测变量和标准变量的平均值和标准差, 就可以解答第七类问题, 即怎样基于每个人的预测分数对其标准表现做出可能的最乐观估计? 要实现这一目的需用到回归方程。在已知其预测分数的情况下, 通过回归方程可计算出我们对一个人在某个变量中可能取得的分数所做的最准确估计, 即效标分数。

介绍回归方程之前, 请先看卡瑟琳。约翰逊和皮特。考德罗老师各班六年级学生的阅读和拼写成绩之间相关性的散点图。假设我们想以拼写测试成绩预测转学生海洛薇兹。阿伯拉德 (Heloise Abelard) 的阅读理解能力水平。如图 2-11 所示为两班学生成绩的散点图。另外图中还有两条线, 其中一条水平线表示所有测试学生的平均阅读成绩。这也是在对海洛薇兹一无所知的情况下我们对其可能的阅读水平所能做的最准确估计。通常来讲, 在没有任何其他参考信息的情况下, 平均效标分数就是我们对一个人的成绩所能做的最佳估计。回归方程的主要用途是使我们能够将可获得的其他任何相关信息物尽其用。如下散点图中的另一条线, 即回归线, 体现了回归方程的作用和功能。这条线是根据预测分数的相关信息对学生成绩做出的最准确的估计。

回归线有两种用途。第一种是如图 2-12 所示的直观形式。假设海洛薇兹在拼





图 2-11 学生在卡瑟琳・约翰逊和皮特・考德罗老师进行的阅读和拼写测试中所得成绩的散点图, 含平均效标分数线和回归线



写测试中的成绩为 50 分, 如果从横坐标 (拼写测试) 的 50 分刻度出发画一条垂直线, 与回归线相交, 直到纵坐标 (阅读测试) 刻度顶端。交点所对应的纵坐标上的刻度值就是我们对拼写测试取得这一分数的人的阅读成绩能够做出的最佳估计。对海洛薇兹阅读成绩做出的预估约为 32 分。





图 2-12 直观应用回归线对海洛薇兹的阅读成绩进行最准确的估计



如果图 2-12 反映的是有关一个数量庞大的样本变量之间的相关性, 则会有很多人分布在拼写测试成绩为 50 分的这条线上。这条线与回归线的交点所对应的纵坐标上的阅读成绩值即为所有拼写得 50 分的人的平均阅读成绩。图 2-13 即体现了散点图的这一特征。同样从拼写测试的 50 分刻度处往上穿过散点图画一条垂直线, 图中的正态分布曲线反映的是该数量庞大的样本中拼写测试得分低于 50 的所有人的分布情况。如此一来, 我们便可以通过回归线对新个体的成绩做出预测。以拼写测试得 50 分为参照, 这组理论上的受试者相应的平均阅读成绩即为我们的预测分数, 亦即是拼写测试的 50 分刻度线与回归线的交点对应的阅读测试刻度值。散布在回归线附近的点显示出预测可能的误差范围。





图 2-13 关于在拼写测试中成绩为 50 分的所有学生的阅读和拼写成绩分布情况的散点图, 其中显示的是阅读测试分数的分布情况。这组分布数据的标准差为标准预估误差



回归线的第二种用途是直接计算预测分数。任意一条直线都可以用一个简单的方程式表示, 而回归方程则是描述回归线的方程式。回归方程的通式如下:

\[\widehat{Y} = {B}_{YX}X + A\]

其中 \( \widehat{Y} \) 代表有关标准变量的预测分数, \( {B}_{YX} \) 为根据 \( X \) 预测 \( Y \) 时回归线的斜率 (即数轴中每单位标准变量与参照变量长度之间的比率相应的回归线升高或降低的单位长度数), \( X \) 则表示个人在参照变量上的成绩, \( A \) 为截距。所谓截距,即回归线交叉标准变量轴 (纵坐标) 的点所对应的坐标值, 也是参照变量值为零时对应的我们对某个对象的标准变量值所能做的预估。

已知根据拼写成绩预测阅读成绩的斜率和截距分别为 0.393 和 11.8 , 那么根据变量之间的相关性做如下简单计算就能得出所预测的海洛薇兹的阅读成绩为:

\[{\widehat{Y}}_{\text{Heloise }} = {0.393}\left( {50}\right)  + {11.8} = {31.45}\]

前面分析散点图中的回归线所得的预测分数为 32 分, 由此可见, 此处计算得出的分数与之也十分接近。

## 确定回归线

定义回归线的系数和相关系数之间具有紧密的联系。事实上, 如果绘制一张有关标准分数 (Z 分数或者两个变量具有相同标准差的任何十进制分数) 分布的散点图,图中回归线的斜率就是这两个变量的相关系数。也就是说,当 \( S{D}_{Y} = S{D}_{X} \) 时,

\[{B}_{YX} = {\gamma }_{YX}\]

然而,当两个变量的标准差不等时, \( B \) 与 \( \gamma \) 的比值等于各自标准差的比率。具体地说,根据 \( X \) 对 \( Y \) 进行预测时,其中关系可表示为:

\[{B}_{YX} = \left( \frac{S{D}_{Y}}{S{D}_{X}}\right) {\gamma }_{YX}\]

要了解具体的运算过程, 可以拿两个六年级班级的测试数据为例计算其回归线的斜率。已知两个变量的标准差分别为 \( S{D}_{\text{拼写 }} = {9.04},S{D}_{\text{阅读 }} = {5.55} \) 。这两个变量之间的相关系数为 \( {\gamma }_{YX} = {0.64} \) ,因此计算 \( {B}_{YX} \) 的方程式为:

\[{B}_{YX} = \left( {{5.55}/{9.04}}\right) \left( {0.64}\right)  = \left( {0.61}\right) \left( {0.64}\right)  = {0.393}\]

\( A \) (斜率) 的值由 \( B \) (斜率) 和两个变量的平均值决定。前面曾解释过截距即为回归线上一个参照变量 \( X \) 为零时的点所对应的标准变量 \( \left( {Y\text{轴}}\right) \) 上的值 (或说是回归线与 \( Y \) 轴的交点所对应的标准变量刻度值),因此为了填补从 \( X = 0 \) 到 \( X = {M}_{X} \) 的这段距离,则必须在 \( X \) 原值的基础上再加上 \( {M}_{X} \) 。但如果将 \( X \) 的值加上了 \( {M}_{X} \) ,那么回归线也会相应地变为 \( B\left( {M}_{X}\right) \) 。由于在变量 \( Y \) 的分值分布中,我们唯一确定的值只有其平均值 \( \left( {M}_{Y}\right) \) ,因此 \( A \) 可以表示为:

\[A = {M}_{Y} - {B}_{YX}{M}_{X}\]

用文字来描述即, 截距等于标准变量的平均值减去斜率与参照变量的平均值的积。示例中两个变量的平均值分别为 \( {M}_{\text{阅读 }} = {34.44},{M}_{\text{拼写 }} = {57.54} \) 。由此由以下方程可得 \( A \) 的值为:

\[A = {34.44} - \left\lbrack  {\left( {0.393}\right) \left( {57.54}\right) }\right\rbrack   = {11.8}\]

可见,计算得出的值与图 2-12 中显示的截距长度也是一致的。有了等式 \( \widehat{Y} = \) \( {0.393X} + {11.8} \) ,我们想对其他多少学生的成绩进行预测都可以。这一方程式也可用于预测所有新生成绩, 但需要先搜集他们在相关标准变量上的成绩数据, 以了解在什么样的情况下将其计入我们的抽样数据中并运用回归方程验算相关的值。

## 让计算机来帮忙

回归分析

运用 SPSS 或 Excel 制表程序进行回归方程相关运算的操作都非常简单。二者都有一个叫作回归分析 (Regression) 的应用程序, 能够计算出所需的值。SPSS 里的回归分析程序在分析 (Analysis) 菜单下方。该应用程序中有好几种类型的回归分析方程, 我们需要的是 “线性回归分析” (Linear)。当你进入到如下所示的界面时, 只需将标准变量添加到因变量 (Dependent) 框中, 将参照变量添加到自变量 (Independent) 框中。点击最下面的统计 (Statistics) 键输出其他值, 比如平均值和标准差 (描述性的)。然后点击确认, 系统就会为你计算出回归线的斜率和截距。标示为常量 (Constant) 的一行中显示的值为截距, 而标示参照变量的一行中显示的值则为参照变量。该应用程序能够同时处理多个参照变量, 但具体如何操作本书不再赘述。







Excel 的回归分析程序在工具 (Tools) 菜单里的数据分析 (Data Analysis) 选项中。进入这一程序,首先需要进行“输入 \( Y \) 变量范围” (Input \( \underline{Y} \) range) 和 “输入 \( X \) 变量范围” (Input \( \underline{X} \) range) 操作。 \( Y \) 即为标准变量,选中表格中 \( Y \) 变量的所有分数所在的区域进行输入,然后对 \( X \) 变量也进行相同操作。若想让计算结果与原始数据呈现在同一张表单中, 选择输出范围 (Output Range), 然后选定原表格中的一个单元格, 通常为原数据右侧空白单元格, 最终结果将会出现在该单元格中。以如上数据为例, 操作界面应如下图所示。

使用两者中的任一程序进行这一小节中如上所述的分析操作, 最终得出的值与手动计算出来的值都会存在少许误差。以上两种程序计算得出的值均为 \( B = {0.394} \) , \( A = {11.76} \) 。存在误差的原因在于这些程序在计算过程中精确到小数点后的更多位数。因此, 通常手动计算的值都会与计算机得出的值存在一定误差。







## 2.10 总 结

所有测量都需要跟数字打交道。通常应对通过测量获得的数字进行概括总结, 由此既可以解答关于测量对象的具体问题, 又可以得出一些一般性结论。我们重点关注如下七大类基本问题。

1. 测量量表的类型是什么?

数字的使用方法不同, 对于同一组数据, 我们能够做出不同的解读。在名目量表中, 数字用于替代各种标签。顺序量表则通常表示排列次序。通过等距量表和比例量表则可得知平均数和标准差的值。

2. 一组普通数字的 “外在形态” 是什么样的? 它们的排列组合规律又是什么?

解答这类问题需要将数值进行频率分布 (表 2-2) 或分组频率分布 (表 2-3) 整理。 通过直方图 (图 2-1) 同样能够对数据进行如上解析。

3. 典型对象有哪些特征? 或者说一组数据的中间值如何确定?

众数、中数 (第 50 位百分位数值) 及平均数均表示一组数据的中间值。平均数或算术平均值, 是确定一组数据中间值最常用的方法。

4. 一组数据中的每个分值围绕其中间值的波动幅度有多大? 或者它们与中间值的偏差是多少?

全距 (或称极差)、半四分位数间全距 (第 25 位和第 75 位百分位数值之间分值间距的一半) 以及标准差, 即以平均值为基础的平均分数偏差, 这些都可以用来表示分值的波动幅度。

5. 如何分析个人的分值? 这一问题将在第三章中进行介绍。

6. 两组测量分数在多大程度上 “相互匹配”? 或说两组分值的相关程度有多高?

一般来讲, 相关系数是测量相关性最有效的方法。该指数的浮动范围从表示分析对象的两个特征完全正相关或完全匹配的 +1.0 , 到二者之间无关联性的零, 再到表示二者完全负相关或完全不匹配的 -1.0 。正相关或负相关表示分析对象的两个特征在两组数据中的排列次序是相同还是相反。相关系数也是一个说明测量程序本身稳定性以及通过一个特征预测另一个特征好坏程度的重要系数和有效手段。

7. 怎样根据一个人在一项测试中的表现对其在另一测试中的表现做出可能的最准确的预测?

通过回归线可以根据一个人在变量 \( X \) 上的分数对其在变量 \( Y \) 上可能取得的分数做出最准确的估计。回归线包括斜率 \( B \) 和截距 \( A \) 。斜率即每单位长度的 \( Y \) 与 \( X \) 之间的比率相应的回归线升高或降低的单位长度数,而截距为当 \( X \) 的值为零时所对应的 \( Y \) 的值。斜率与相关系数的表示符号相同,随两个变量标准差比值的变化而变化。

## 2.11 习 题

1. 如下有三组分数, 每组选择一个你认为最合适的区间进行统计并制成表格:



<table><tr><td>测试</td><td>对象数目</td><td>分数范围</td></tr><tr><td>数学:</td><td>103</td><td>15 - - 65</td></tr><tr><td>阅读理解</td><td>103</td><td>60—140</td></tr><tr><td>火趣调查</td><td>582</td><td>65—248</td></tr></table>



2. 标出如下每组数据分布中的分数间距、区间中间分值及区间的实际阈值 (即区间的分界值):



<table><tr><td>a.</td><td>b.</td><td>c.</td></tr><tr><td>4 -7</td><td>\( {17} - {19} \)</td><td>60—69</td></tr><tr><td>8----11</td><td>20—22</td><td>70—79</td></tr><tr><td>\( {12} - {15} \)</td><td>23—25</td><td>80—89</td></tr></table>



3. 使用表 2-1 的数据制作一个频率分布表和直方图, 计算中数以及这组数据中的第 25 位和第 75 位百分位数值, 还有根据原始分数计算的算术平均值和标准差。

4. 人口普查局一般用中数计算人均收入。为什么是用中数而不是平均数?

5. 对桑尼塞德中学的五个班, 共计 150 名学生, 进行了 50 道题的数学测试。分数范围为 16 到 50 分, 其中有 93 名学生成绩在 40 分以上。这组数据会如何分布? 你觉得这项测试对他们而言难易程度怎样? 最适于测量这组数据的集中趋势和差异性的统计方法是什么? 为什么?

6. 一位高中老师对生物课堂上的两组学生进行了同一项测试, 结果如下:



<table><tr><td/><td>A 组</td><td>B 组</td></tr><tr><td>中数</td><td>74.6</td><td>74.3</td></tr><tr><td>平均数</td><td>75.0</td><td>73.2</td></tr><tr><td>第 75 位百分位数</td><td>79.0</td><td>80.0</td></tr><tr><td>第 25 位百分位数</td><td>71.0</td><td>64.4</td></tr><tr><td>标准差</td><td>6.0</td><td>10.5</td></tr></table>



根据这些数据描述两组学生的情况, 并根据测试结果反映的情况针对这两组学生提出合适的教学建议。

7. 对 2500 名十年级学生进行历史测试所得的平均分和标准差值分别为 52 和 10.5 。下列学生有多少标准差高于或低于平均分?



<table><tr><td>姓名</td><td>成绩</td></tr><tr><td>希瑟</td><td>48</td></tr><tr><td>克丽丝塔</td><td>56</td></tr><tr><td>罗伯</td><td>60</td></tr><tr><td>蒂娜</td><td>36</td></tr><tr><td>马克</td><td>31</td></tr><tr><td>比尔</td><td>84</td></tr></table>



8. 如果第 7 题中的分值分布近似正态分布, 那么这组数据中希瑟、克丽丝塔、罗伯、蒂娜、马克以及比尔分别超过的学生百分比是多少?

9. 假设一组分数为正态分布, 其平均数为 82 , 标准差为 12 , 那么如下三个分值对应的百分位数分别是多少?

a. 74

b. 85

c. 99

10. 请说明以下各相关系数的含义:

a. 阅读测试成绩与一般智力团体测试分数之间的相关系数为 +0.78

b. 学生文明市民等级评定与暴力指数之间的相关系数为 -0.56

c. 体重和交际能力之间的相关系数为 \( + {0.02} \)

11. 詹森在桑代克能力倾向测试 \( \left( {\mathrm{{TP}}}^{4}\right) \) 中获得了 87 分。该项测试数据中,平均数为 100 , 标准差为 20 。富兰克姆特大学大一新生平均绩点 (GPA) 为 2.5 , 这组数据的标准差为 0.5 。那么 \( {\mathrm{{TP}}}^{4} \) 测试分数与富兰克姆特大学新生成绩这两组数据之间的相关系数为-0.60。

a. 请用回归方程计算斜率和截距 (注意运算过程中的正负号)。

b. 对詹森在富兰克姆特大学的 GPA 所能做的最准确估计是多少分?

## 推荐阅读

Dretzke, B. J., & Heilman, K. A. (1998). Statistics with Microsoft Excel. Upper Saddle River, NJ: Prentice Hall.

Heiman, G. W. (2000). Basic statistics for the behavioral sciences (3rd ed.). Boston: Houghton Mifflin.

Kirk, R. E. (1999). Statistics:An introduction (4th ed.). Fort Worth, TX: Harcourt Brace.

Runyon, R. P., Coleman, K. A., & Pittenger, D. J. (2000). Fundamentals of behavioral statistics (9th ed.). New York: McGraw-Hill.

Stevens, S. S. (1951). Handbook of experimental psychology. New York: Wiley.

Sweet, S. A. (1999). Data analysis with SPSS. Needham Heights, MA: Allyn & Bacon.

## 第3章 赋予分数意义

## 3.1 分数的本质

魁杜拉・魁克里在拼写测试中得了 44 分, 这个分数意味着什么? 我们应该怎么解读这个分数?

单就这个数字来讲, 44 没有任何意义, 也完全无从理解。从最浅显的层面上看, 甚至无法得知这个分数究竟代表的是在总分为 44 分的测试中取得了满分 44 分, 还是相对于总分较低的一个分值, 比如 100 分的测试取得了 44 分。即使我们知道是在总分为 80 分的测试中得了 44 分,或说答对了 \( {55}\% \) 的题目,那又如何呢?

请看下表 3-1 中所示的两项各含有 20 个单词的拼写测试。在测试 A 中得 15 分与在测试 B 中得 15 分的意义大不相同。一位学生若在测试 A 中仅正确拼写出 15 个单词, 其在二、三年级水平中不算突出。让一些同学或朋友参加测试 B, 你很可能会发现没有几个人能正确拼写出 15 个单词。一个参加测试 \( \mathrm{B} \) 的研究生班级中, 仅有 \( {22}\% \) 的学生准确拼对了 15 个以上的单词,因此在心理学和教育学测量领域,研究生在测试 B 中取得 15 分属于不错的成绩。



表 3-1 两项含有 20 个单词的拼写测试

<table><tr><td colspan="2">测试 \( A \)</td><td colspan="2">测试 \( \mathrm{B} \)</td></tr><tr><td>酒吧 (bar)</td><td>脚 (feet)</td><td>巴洛克式的 (baroque)</td><td>可行的 (feasible)</td></tr><tr><td>猫 (cat)</td><td>扮演 (act)</td><td>黏膜炎 (catarrh)</td><td>食宿 (accommodation)</td></tr><tr><td>形式 (form)</td><td>比率 (rate)</td><td>甲醛 (formaldehyde)</td><td>就职典礼 (inaugurate)</td></tr><tr><td>罐子 (jar)</td><td>英寸 (inch)</td><td>花盆 (jardiniere)</td><td>微章 (insignia)</td></tr><tr><td>打盹 (nap)</td><td>租金 (rent)</td><td>石脑油 (naphtha)</td><td>威慑(deterrent)</td></tr><tr><td>碟, 盘 (dish)</td><td>嘴唇 (lip)</td><td>可辨别的 (discernible)</td><td>桉树 (eucalyptus)</td></tr><tr><td>肥胖的 (fat)</td><td>空气 (air)</td><td>使人劳累的 (fatiguing)</td><td>调查问卷(questionnaire)</td></tr><tr><td>开除 (sack)</td><td>外缘 (rim)</td><td>亵渎神明的 (sacrilegious)</td><td>旋律 (rhythm)</td></tr><tr><td>富裕的 (rich)</td><td>必须 (must)</td><td>反弹 (ricochet)</td><td>不学无术的人 (ignoramus)</td></tr><tr><td>坐下 (sit)</td><td>红色的 (red)</td><td>柑橘属植物 (citrus)</td><td>累积的 (accrued)</td></tr></table>



如此看来,魁杜拉拼对了 44 个单词,或说其拼写正确率为 \( {55}\% \) ,这一事实没有任何直接或重要的意义。只有以一定标准进行对比以及在一定的参照体系内进行分析时, 这一分值才有意义。

## 1. 参照系

一项测试的背景或参照体系决定了我们分析此测试分数意义的方式。参照体系包含三个基本方面。第一, 即为我们所说的时间维度: 我们的关注点是对象目前的能力水平还是在一段时间之后的能力水平? 或者我们是想描述现状还是预测未来?

第二个方面关于将对象能够做什么与其想做或通常会做什么进行对比。评估学生能力时, 我们判定学生的最佳表现, 但测试的是个人偏好或习惯时, 我们评估的是典型表现。最佳表现意味着测试中的一系列任务是以正确与否为评判标准, 即有 “正确”答案。而典型成绩中没有所谓的正确答案, 但是我们可以看某个个人的回答是与大部分人的答案相似还是在某种程度上与众不同。

第三个方面有关用于比较个人行为表现的标准的性质。有时测试内容本身就是参考标准, 有时也会以测试对象在其他情况下或其他测试中的表现为参考标准, 还有些时候是通过与其他受试者的表现做比较。因此, 某个特定的测量方法要么是以现在为导向, 要么是以未来为导向; 要么评估最佳表现, 要么评估典型表现; 还有要么将个人表现与由测试本身所决定的参考标准联系在一起, 即受试者在某项特定的测试或其他测试中的得分, 要么将其表现与其测试对象的表现进行对比。

学校做出许多指导性的决定都需要对单个学生或整个群体目前的能力水平有一定的了解。例如,学生渡边 - 佳奈 (Wakana Watanabe) 在其朗读过程中多数出错。 那么, 在制订相关教学策略以帮助她克服困难时, 首先要确定导致其出错的原因。为此可能需要考虑的一个问题就是, 她能否将单词与其开头的辅音匹配起来。或许老师可以针对该技能单独让佳奈进行一项简单的测试, 而其他学生则进行其他任务, 这样能帮助我们确定缺乏此项技能是否为导致其朗读屡屡出错的原因。上述例子中, 测试本身即为我们评判佳奈表现的参照标准。

我们或许还想了解佳奈所在的班里有多少孩子已经掌握了专有名词首字母大写的规律。如表 3-2 所示, 对特定学生进行一项这样有针对性的测试可以为我们提供做出是否有必要进一步教授这项技能的决定所需要的信息。从更加广泛的层面上来讲, 我们可以调查森特维尔 (Centerville) 学区目前正在进行的数学教学方案是否取得了满意的成效。以全国或整个地区学生平均水平为标准, 对森特维尔学区的学生进行一项数学成绩测试调查, 我们可以将其表现与全国其他学生的表现进行对比。 综合对比结果和森特维尔学区学生及这些学校的其他相关信息, 我们就可以确定取得的进步和成效是否令人满意。



表 3-2 专项测试专有名词大写测试

说明: 阅读以下段落。该段落中标点正确, 除每句句首单词的首字母大写外, 其他地方均无大写。但有些单词首字母需要大写, 请在首字母应该大写的单词下划线。

We saw mary yesterday. She said she had gone to chicago, illinois, to see her aunt helen. Her aunt took her for a drive along the shore of lake michigan. On the way they passed the conrad hilton hotel, where mary's uncle joseph works. Mary said she had enjoyed the trip, but she was glad to be back home with her own friends.

昨天我们碰见了玛丽, 玛丽说她去伊利诺伊州芝加哥市看了姑姑海伦。她姑姑开车带她沿着密歇根湖岸边转了一圈。他们沿途经过了康勒达希尔顿酒店, 玛丽的叔叔约瑟夫就在那儿工作。玛丽说自己很享受这次旅行, 也很高兴能回到家和朋友们相聚。



每当遇到评估个人能力水平的问题时, 我们也免不了要回答做出相关评价的目的的问题。教育领域中的能力水平评估有两个基本目的。一个是对个人迄今为止的成绩表现进行总结, 比如老师们在每次阅卷结束时会给出学生的总得分。以此为目的的成绩评估叫作总结性评估, 主要概述学生的学业成绩。相比之下, 老师和辅导员们更多地利用测试来判断学生的弱项和强项, 即他们在哪些方面表现较好, 同时在哪些方面表现较差。以为未来教学提供指导为目的的评估叫作形成性评估。这类测试结果通常用于反映或设计教学课程。

有关阐述个人学会了何种能力的最佳表现测试被称为成绩测试。单独对佳奈进行的朗读测试, 即表 3-2 中的首字母大写测试, 以及对森特维尔学区学生进行的数学测试都是不同类型且对比鲜明的成绩评估的实例。单词头辅音测试关注的是单个学生对某项具体技能的掌握情况, 而不会出现类似佳奈在这方面的技能与其他学生相比是好是坏这样的问题。唯一需要回答的问题是, 她在这项测试任务上的表现是否足够好, 好到足以让我们排除缺乏这一技能是导致其朗读困难的原因之一的这种可能性。

佳奈的老师同样关注的是班级里整体对通用英语某项具体技能的掌握程度。关于这类特定技能掌握程度的测试通常被称为领域参照测试或标准参照测试, 因为在某项具体技能上达到测试所要求的标准成绩水平是其唯一的关注点。测试本身及其所体现的领域的内容就是我们的参照标准。许多, 或说绝大多数教学决策方面的评估都属此类。

我们或许可以将这类测试与评估森特维尔学区学生数学成绩的调查测试进行对比。这里我们需要关注的是, 与其他城镇或具有类似森特维尔学区教学体系的地方的学生相比, 其学生的成绩是否令人满意。评估学生成绩所依据的标准不是测试任务本身, 而是对比一些更大的参照群体的表现。以这种方式进行的测试称为常模参照测试, 因为是通过对比其他人的表现得出对测试对象成绩的评价。常模参照测试适用于许多与课程设计、建议指导或调查研究决策有关的情形中。在这本书中, 我们将会时常就标准参照成绩测试和常模参照成绩测试的建构、需要了解的特征以及具体应用等方面对其进行比较和对比。

有些需要做的决定要求我们具备一些有关个人能够学会什么的基本信息。例如, 海伦是否能掌握计算机编程的技巧? 学会微积分对拉希姆来说难易程度如何? 尤其是有关选拔和分级的决定需要基于个人目前的特征表现预估学生未来的学习成绩和能力。用以作为评估未来学习成绩的参照的测试叫作能力倾向测试。这类测试通常属于常模参照测试。

有些情形下, 我们需要依据对个人可能会做什么的评估来做决定。在公交车司机、警察或其他诸多工作应聘者的选拔中主要应考虑个人品性。我们肯定不会愿意聘一个有严重暴力倾向的人来在狭窄的街道上驾驶大型车辆, 抑或是让脾气暴躁的人来手持武器维护和平。在这些情形中, 典型表现测试能发挥很大用处, 而且这类测试通常也属于常模参照测试。

需要注意的是, 预测未来学习能力和表现最有效的方法中有一些是基于对过去学习能力和表现的测量。因此, 要预测学生在计算机编程和微积分上的成绩和表现, 一个可能有效的办法就是进行一项测量其高中代数学习能力的测试。虽然这类测试测量的是以前学习的知识和技能, 但我们可以此来预测测试对象未来的学习情况。 任何测试, 无论名称是什么, 其评价的都是个人现在的特点。我们无法直接测量一个人所谓假定的“天然的”或“先天的”特征, 只能评估其此时此地能够做什么和愿意做什么。由此提取到的信息可用于评估过去的学习情况, 如通过代数测试确定学生洛葛仙妮在其代数课程中是否能得 \( \mathrm{A} \) ,也可用于预测未来的学习情况,如辅导员需要判断学生洛葛仙妮是否具有顺利完成微积分这门课程的充分可能性。能力倾向测试与成绩测试之间的区别更多地在于如何运用测试结果, 而非测试的本质或内容。

## 2. 标准参照测试和常模参照测试的领域

所有成绩测试 (事实上是所有测试) 或多或少都有界定明确的自己的领域, 明白这一点很重要。上述例子中的数学调查测试涉及范围相当广泛, 而关于单词首字母大写规律的测试仅限于考察狭义范围内的一系列人类行为。因此, 仅以标准参照测试适用于某个严格界定的领域, 而常模参照测试并非如此这一点来区分两者不太恰当。结构合理清晰的常模参照成绩测试会体现出一个界定十分具体的领域, 一般比76标准参照测试的领域更加多样化, 而且针对既定的主题和教学目标, 试题数目也很少。而标准参照成绩测试体现的是一个严格界定且范围相对狭小的领域。因此, 相较于同样长度的常模参照测试, 标准参照测试对指示对象内容的解析更加全面透彻。

运用通过成就测试所提取的信息的过程中还有一点需要注意。除了上文所述的标准参照测试和常模参照测试在各自适用的领域范围大小上的传统区别外, 另一点即有关如何呈现和应用测试成绩的水平等级来帮助我们做决定。

无论是在标准参照测试还是在常模参照测试中取得的分数, 其含义都来源于测试所反映的领域的内容, 但老师或辅导员根据该测试分数做出的推断可能是绝对的或者相对的。老师根据测试分数进行判断, 如果是关于某个学生或某一学生群体在一项测试内容上达到了某一特定的熟练程度, 测试结果显示他们对测试题目和材料充分了解, 那么这一判断就是绝对的, 即掌握或没掌握。最终得出的结论只能是, 要么学生掌握了这项测试内容, 要么没掌握, 而不考虑其掌握程度如何。这类推断叫作掌握推断。标准参照测试一般被定义为适用领域较窄和用于做掌握推断的测试。

相比之下, 老师们也能运用测试判断教学目标的相对完成情况。相对熟练程度需要估计学生所掌握的内容占该领域内容的百分比。例如, 在某领域的拼写测试中, 共有 20 个单词, 学生能拼对 19 个, 那么老师就可以判定他们的表现达到了相应领域的教学目标。同理可知, 如果一位中等水平的学生在该拼写测试中得了 14 分, 那么其老师同样能推断出该生掌握了这一领域 \( {70}\% \) 的内容。我们将这类推断称为相对成绩推断, 其参照体系仍然是测试内容的领域, 仅关注当前受试者的表现而不考虑其他测试对象。

典型的常模参照测试在反映测试对象的能力水平时不会采用以上两种推断方式中的任何一种, 而是参考一个更大的群体, 即常模组或常模样本。从常模参照测试的角度对测试分数进行解析可以得出以下结论, 某一测试对象在测试中表现出的水平与程度适中的参照组对比非常高。但同样的表现从标准参照测试的角度来看却可能远没有达到熟练掌握的水平。反之,一名九年级学生在正常情况下对乘法运算掌握的准确度能够达到 \( {95}\% \) ,但与同年级其他学生相比,可能会发现其水平并不算高。

## 3.2 标准参照评估

我们可以从上文提到的两种不同观点出发探讨使用参照体系解析测试结果的问题。标准参照评估主要关注测试中的任务本身, 而常模参照测试关注的是典型测试对象的表现。以表 3-1 里拼写测试 A 中的 20 个单词为例, 如果已知这些单词是从三年级学生的拼写教学计划中抽取的, 而且出于某些原因 (这一点不做详细说明) 大家一致同意,在以听写的形式进行且有例句解释的单词拼写测试中, \( {80}\% \) 的正确率代表可接受的标准成绩, 那么我们就可以说, 艾伦在测试中正确拼写出 18 个单词得了 18 分, 这表明她在三年级水平单词拼写测试中的表现达到了标准水平, 而皮特拼对了 12 个单词获得 12 分, 这表明其未达到标准水平。上述例子中的测试内容是从一个相对狭小的领域中挑选出来的, 并从熟练程度测试的角度对其进行了解析。因此, 此项测试属于标准参照测试。第一, 测试任务取自某一具体的教学领域, 且与其相关。 第二,任务的呈现形式及其答案是根据相应的教学目标来确定的。第三, 提前确定好可视为合格的成绩表现水平, 以便比较每位学生的表现。换言之, 标准参照测试具有详细界定的领域, 且主要关注的是具体行为目标的达成情况, 其测试结果通常 (但并不一定) 用于做掌握推断。

“掌握”的参照体系适用于一些特定类型的教育决策, 比如对艾伦和皮特进行进一步深入的拼写教学时应该使用什么样的材料和方法, 这些最终都会回归到一个基本问题上, 即他们在三年级单词拼写中的表现是否达到了特定的标准熟练水平。更重要的是, 在像数学这样逻辑性较强的科目中, 要决定是否开始新一单元的教学介绍减法中的借位运算时, 首先要考虑学生是否已经掌握了不需借位的二位数减法运算, 已达到了标准的掌握程度。

虽然标准参照评估和常模参照评估二者测试内容的参照领域与判断学生成绩的掌握推断这一方法一脉相承, 但应当注意的是绝不能将其混为一谈。还有一点特别重要的是, 它们同样适用于社会政治领域, 且可从常模参照测试的角度进行解析。例如对于一名三年级学生而言, 我们对其对乘法和拼写的了解的期望值应该是多少? 答案取决于我们对二年级和四年级学生的期望值分别是多少, 而且我们对这些学生的期望值会因为常模参照标准限制老师对三年级学生教授的内容。由于专业的判断结合多年的经验积累, 老师能够设置一个合理的教学内容领域以及对学生表现的期望值。因此, 针对这些学生设计的测试也会与相应水平的内容相匹配。

鉴于所设计的测试内容都具有特定的领域, 那么对相应的测试分数进行解析时也应该严格参照该内容领域, 或者在常模参照体系下通过对比个人的表现与其他人的表现进行分析。领域参照分析指的是参照测试本身和设计此项测试所依据的教学目标对测试对象的成绩水平进行评估。评估结果可能使我们得出二分的结论, 即测试对象已熟练掌握测试材料且做好了相应准备, 以接受下一阶段教学、获取资格证书或执照, 抑或是与测试目标相关的任何决定。另外, 评估结果也可能使我们得出关于掌握程度的判断, 这一点与老师们阅卷评分的工作类似。而前一种用途类似于合格或不合格的判断, 或说是否开始新一阶段教学的决定。许多常用的测试都是在《有教无类法案》(见第七章) 的规定下进行设计的, 这些测试用于在学生们完成了各个阶段的教育时就教育者所期望的学生对相应内容的掌握情况进行合格或不合格判断, 但此处所指的内容范围非常广泛。

那些所谓的典型标准参照测试中的标准, 从其所衡量的相关具体教学目标的定义中可知。当我们要做出的决定属于掌握推断时, 对内容的描述以及老师、学校或教学体系共同认可达到其教学目标所规定的可接受的掌握程度的成绩水平, 为我们提供了一个绝对的标准。因此, 表 3-2 中有关专有名词首字母大写且带示例的领域参照测试即为一个考察该项具体能力的具有代表性的例子。若以该测试中的任务为典型样本,且完成任务的过程中 \( {80}\% \) 的准确率被视为最低可接受标准,那么也就是说在 13 个需要划线的单词中正确划出 10 个得 10 分的话, 则在绝对意义上达到了该最低标准。

即使是二分判断或掌握推断, 也都属于社会政治学领域, 因此也免不了需要从常模参照测试的角度分析。教师或学校需要确定熟练或掌握的具体含义, 而有一些说不清道不明的社会压力会影响其做出这类决定。大多数教师都以如下方式定义达到熟练程度的成绩水平, 即 “一定的” 最小数量的学生成功掌握相关内容。实际上, 这也就是说经过一段时间后, 该教师会就某一门教学课程对这群典型学生在测试中表现出来的水平有一个准确的了解。无论是实行评分制还是合格或不合格的评级制, 教师都会对这些测试进行调整以保证始终有适当数量的学生通过测试。从这些测试所设定的合格标准来看, 也毫无疑问是一个常模参照决定了! (参考 Shepard, 1984 有关标准参照测试中的标准设定的探讨, 或 Cizek and Bunch, 2006 有关标准设定方法的论述。如何根据《有教无类法案》设定那些能力测试中的评定标准, 是当今教育学领域的一大争议所在。美国许多州现在不断出现大批学生无法达到其立法中设置的成绩标准的情况, 而且数量惊人。)

用于总结评估的一般课堂测试中, 间接地实行着这样的不完善的标准, 即一方面由教师挑选决定测试的任务, 另一方面又由教师按照自己的标准来评估答案。因此, 教师们设计一项测试时会选择他们认为合适的能够体现自己学生学习水平的任务。 认真尽责的教师不会使用类似表 3-1 中的拼写测试考察一般高中生或使用测试 B 考察三年级学生。当答案像论文写作一样有好坏之分时, 老师会根据自己对这些学生的合理的期望值制定与之相符的评分标准。若对一名九年级学生和大学历史系学生提问 “导致 1812 年英美战争的原因有哪些?”, 我们可能会得到完全不同的答案。

然而, 老师的个人内在标准多少带有一些主观性和不稳定性, 而且不适用于比较不同的班级和不同地区的学生能力水平。以此为衡量标准也无法回答如下这些问题,比如 “A 校孩子的阅读水平高于 \( \mathrm{B} \) 校的孩子吗”? “詹尼弗擅长阅读胜过数学吗”? “雅各布的代数水平和其他九年级学生一样好吗”? 为了能够解读那些分析评估受试者特征或在更广泛的层面上调查学生在学校课程中能力水平的心理学和教育学测量, 我们需要制定适用范围更广和统一性更强的教学目标以及稳定的参照标准。 本章大部分内容集中于阐述和评估几个用来赋予测试分数标准意义的参考标准体系。

## 3.3 常模参照评估

解析测试成绩最常用的参考体系不是基于一个看似随意地选取某段特定的内容, 并以其为该内容领域合格的掌握程度的代表而制定的标准, 而是立足于测试中其他人的表现, 这是从常模参照评估角度进行的解析。因此, 表 2-1 中的 80 个单词拼写测试中, 夏洛特。科文 (47) 和盖尔 - 贾拉拉加 (71) 的分数可与一个更大的参照组进行对比考察, 这一参照组可能是另一个学校具有代表性的六年级学生群体。我们并不仅仅只是以掌握或未掌握的绝对标准或以对某一科目熟练程度的相对标准来衡量他们的表现, 相反地, 我们通过与参照组进行对比以高于、等于或低于平均水平的标准进行衡量评估。我们还需找到完善相对表现衡量量表的方法, 这样一来就可以对所测量的特征的各个方面进行量化分析。

为了找到表示测试对象所表现特征的量的量表, 我们要以单位的形式呈现测试结果, 这些单位需具备以下特征:

1. 同一标准在不同测试中的含义需保持一致, 以保证由不同测试得出的数据具有可比性, 比如比较不同的阅读测试, 将阅读测试与数学测试进行比较或对比成绩测试和学习能力倾向测试。

2. 单位大小要一致, 以确保同样是 10 分的差距在衡量量表的不同部分代表的含义相同。

3. 零分表示测试对象无此特征的说法成立, 这样在量的层面认为一个分值是另一个分值的两倍或三分之二也是合情合理的。80

针对那些测试制定的不同类型的常模参照量表标志着在这些目标中的头两个上取得了显著进步, 因此能够满足应用等距量表的要求。第三点说的是比例量表的典型特点, 而在心理学和教育学测量领域相关特征的测试中这一点很可能永远都无法实现。将 5 个 1 磅重的面包放在天平一端的托盘里, 在另一个托盘里放一袋 5 磅重的面粉, 二者会达到平衡。 “重量为零”表示的就是 “没有重量”, 而重量单位可以进行加法运算, 因为 2 磅是 1 磅的两倍。但在心理学和教育学测量领域没有那样的零分机制, 也无法进行加法运算。两个成绩低于平均水平的学生 “相加” 不会等于一个天才, 就好比两个拼写能力不佳的人一起仍然不能赢得拼写比赛一样。有些情况下, 这一缺陷来源于我们所选择的测量该特征的特定方式, 但对于心理学和教育学领域的大多数特征而言, 它是我们如何定义测试的特征本身所导致的结果。

简单来说, 测试的初始分值只有在与某种类型的一个或多个群体, 即常模组, 做对比的情况下才会被赋予标准意义。我们不会说典型测试中的某个分值是高是低或是好是坏, 而是看与其他人的得分相比, 该分值是更高或更低还是更好或更坏。在常模参照体系下对单个测试对象的分值进行分析的方式有两种。其一是与一系列区分等级的群体中的对象进行比对, 找出与其分值相匹配的对象。在这些群体中, 每一组通常代表学校里某一特定的年级或年龄段。这一方法的另一种形式是准备一套等级分明的实验样本, 比如手写笔迹样本或对论述题的回答。然后将每个测试对象的表现与那套标准样本对比, 并找出与之匹配度最高的样本分值。

第二种设定常模参照标准的方式是以该群体中某一测试对象得分超过的人数占总人数百分比的形式, 或者从这组数据的平均值和标准差出发, 确定其在此特定群体中所处的位置。这两种方法衍生出四种分析个人测试分数的模式, 具体如表 3-3 所示。接下来, 我们将对其各自的优缺点逐一进行介绍。在本章末尾, 我们会考察第三种赋予分值定量意义的方式, 此方法的前提是受试者在测试中以特定的方式作答, 称为项目反应理论或 IRT。



表 3-3 心理学和教育学测试中的主要常模分类

<table><tr><td>常模分类</td><td>对 比 分 类</td><td>群 组 分 类</td></tr><tr><td>年级常模</td><td>与群体表现相一致的个人</td><td>连续的年级群组</td></tr><tr><td>年龄常模</td><td>同上</td><td>连续的年龄段群组</td></tr><tr><td>百分位数常模</td><td>该群体中个人得分超过的人数占总人数百分比</td><td>测试对象所属的单一年 龄段或年级群组</td></tr><tr><td>标准分数常模</td><td>个人得分高于或低于该组平均数的标准差数目</td><td>同上</td></tr></table>



## 1. 年级常模

学生升入下一个年级时任一特征表现出相对统一的进步和增长, 我们就可以确定年级常模或年级当量。从此意义上来说, 任意一个年级的常模即该年级中所有学生得分的平均值。因为学校活动和相应的认知能力的增长都或多或少是连续的, 尤其是年级常模的值通常精确到小数点后一位。整数表示年级, 小数点后数值表示在该年级内就读时的月份。因此, 年级当量为 5.4 所对应的是在五年级中就读第四个月的普通小孩的成绩表现。

简要来讲, 建立年级常模的过程中需要在多个连续的年级中抽取具有代表性的学生作为样本对他们进行测试, 计算每个年级的平均分, 然后确定中间分值的年级当量。因此, 于 11 月分别对二、三、四、五年级的学生进行一项阅读理解测试, 比如从爱荷华州基础技能测试 (ITBS) 中抽取的九年级 J 型阅读题, 我们会得出如下结果:



<table><tr><td>年级</td><td>平均原始分数</td></tr><tr><td>2. 3</td><td>13</td></tr><tr><td>2.3</td><td>22</td></tr><tr><td>2. 3</td><td>31</td></tr><tr><td>2. 3</td><td>37</td></tr></table>



测试得出的这些原始分数的年级当量分别为 \( {13}\text{、}{22}\text{、}{31} \) 和 37。然而,中间分数也需要有年级当量, 且通常通过算术上的插值法计算得出, 虽然有时也可能通过在学年中的其他时间点进行实地测试确定中间点的位置。完成插值法运算后所得结果如下表 * :



<table><tr><td>原始分数</td><td>年级当量</td><td>原始分数</td><td>年级当量</td></tr><tr><td>10</td><td>1. 9</td><td>24</td><td>3.5</td></tr><tr><td>11</td><td>2. 0</td><td>25</td><td>3. 6</td></tr><tr><td>11</td><td>2.2</td><td>26</td><td>3.7</td></tr><tr><td>13</td><td>2.2</td><td>26</td><td>3. 8</td></tr><tr><td>14</td><td>2.5</td><td>28</td><td>3.9</td></tr><tr><td>15</td><td>2. 6</td><td>29</td><td>4. 0</td></tr><tr><td>13</td><td>1. 9</td><td>30</td><td>4.1</td></tr><tr><td>13</td><td>2.9</td><td>31</td><td>4. 3</td></tr><tr><td>18</td><td>3. 0</td><td>32</td><td>4.4</td></tr><tr><td>19</td><td>3. 1</td><td>33</td><td>4. 5</td></tr><tr><td>20</td><td>2.2</td><td>34</td><td>4.7</td></tr></table>

续表

<table><tr><td>原始分数</td><td>年级当量</td><td>原始分数</td><td>年级当量</td></tr><tr><td>21</td><td>3. 2</td><td>35</td><td>4.9</td></tr><tr><td>22</td><td>3.3</td><td>36</td><td>5.1</td></tr><tr><td>23</td><td>3.4</td><td>37</td><td>5. 3</td></tr></table>

* 注: 这一系列测试的最新形式是首先计算发展标准分数 (详见下面部分的介绍), 然后从中计算得出年级当量对应的分值。

资料来源: 爱荷华州基础技能测试 \( {}^{ \oplus  } \) (ITBS*)。版权(C) 2006,由河滨出版公司出版。保留所有权利。 未经河滨出版公司书面许可, 不得以任何形式或任何方式对此内容进行复印或传送, 无论是电子还是纸质形式, 包括影印和记录, 或是使用任何形式的信息存储或检索系统, 联邦版权法明文规定属合法行为的除外。敬请垂询河滨出版公司合同与许可部, 地址: 伊利诺伊州罗林梅多斯市戈尔夫路 3800 号, 邮编 60008-4015。

Source: Iowa Test of Basic Skills \( {}^{\circledR } \) (ITBS®). Copyright 2001,2006 by The Riverside Publishing Company. All rights reserved. No part of this work may be reproduced or transmitted in any form or by any means, electronic or mechanical, including photocopying and recording or by any information storage or retrieval system without the proper written permission of The Riverside Publishing Company unless such copying is expressly permitted by federal copyright law. Address inquiries to Contracts and Permissions Department, The Riverside Publishing Company, 3800 Golf Road, Suite 100, Rolling Meadows, Illinois 60008-4015.



这项测试的原始分值范围为 \( 0 - {49} \) ,因此需要了解一些为分布更偏两端的分数设定年级当量的方法。确定这类年级当量常常是通过将我们正在分析的这一水平的测试中所得的分数与从同一系列中更低或更高水平的测试中所得的分数对应起来, 年级当量也与更低或更高的年级相对应。这样年级当量的范围就可以向下延伸至幼儿园阶段的第一个月 (以 K. 1 表示), 向上延伸至大学第一学年的最后一个月 (以 13.9 表示), 从而得到将原始分数转化为年级当量的完整表 (从这一特定版本的爱荷华州基础技能测试中选取的阅读测试题实际上是一个多层次的测试, 其中有六套具有一定重叠性的短文, 都出白于同一本小册子。这样, 有些相同的题目就可用于三种不同水平的测试中, 同时也简化了年级当量的计算过程, 并使得到的数据更准确)。

如果詹尼弗在该测试中的原始成绩为 28 分, 那么她相应的年级当量为 3.9 。这一分值可以解释为, “她的表现等同于完成了三年级阶段九个月学习的一般儿童的水平。”这样理解的一个优点就是可以将测试分数与我们所熟悉的教育发展阶段对应起来。这样解析一个孩子的表现确实有令人无法抗拒的简洁优势, 但同时也有诸多缺点。

第一个有关年级常模的主要问题就是它们是否具有精确的, 甚至是仅仅近于相同的衡量单位。在何种意义上 3.2 至 4.2 年级学生的短文阅读能力提高与 6.2 至 7.2 年级学生在此方面能力的提高是相同的? 然而支撑这种相等假设的论据显然十分匮乏。当考察的是在全校范围内教授的技能时, 或许我们可以有理由相信一个年级某一水平的学习能力约等于另一水平的学习能力。而且有证据表明在小学阶段 (大概也在初中或高中阶段), 年级当量单位用于处理相关测量问题时足够有效。然而, 即使在这一教学具有连续性的区域范围内, 这种相等假设都只能是一个近似结果。另一方面, 如果考察的是像西班牙语这样的科目, 这是在进入中学以前不会开展的典型课程, 或是考察生物课的内容, 而这门课程的教学主要集中在某个年级中进行, 在这些情形中年级当量就变得毫无意义。更有甚者, 学校对于诸如阅读和算术中的基础技能等许多技能的教学会随着年级的上升逐渐减少, 且大多到高中就停止了, 因此年级单位在这一水平也几乎没有任何意义可言。也正是由于上述原因, 许多成绩测试组合以年级当量为 \( {10.0} + \) 或 \( {11.0} + \) 表示整个高分段的分数。当年级当量达到 12.5 这样的值时, 这并非真正代表十二年级中间阶段受测试学生的平均成绩, 而是人为假想的有关分值量表的推断, 用以对表现最佳的八年级和九年级学生的分数进行调整。

有关分数常模的分析理解还有一点不容忽视。以一个聪明且在学业上比较超前的孩子为例, 假设其在一项标准化数学测试中的得分所对应的年级当量为 5.9 。这一数值并不是指这个孩子熟练掌握学校教授的五年级水平的数学知识。虽然此分值和处于五年级阶段末尾一般水平的儿童学习能力所对应的年级当量一样高, 但该儿童获得比同年级学生更高的分值的原因几乎可以肯定很大程度上在于其掌握了超过一般三年级学生的课业内容。而学校针对在自己的年级水平所教授的那些科目上, 一般水平的学生与满分之间还有一段相当大的距离。有能力的学生仅因为完全熟练掌握了当前年级的课业内容就能够获得很多额外加分 (年级当量也因此更高)。对于这一点要时刻保持警惕。存在某个三年级学生所对应的年级当量为 5.9 这一事实并非表示这个孩子已经做好了提前进入六年级阶段学习的准备。年级当量反映的仅仅是该分值的本质意义, 而与取得这一分值的方法和过程无关。要判断这个孩子对五年级水平教学内容的掌握是否真的已经熟练到足以进入六年级阶段的学习, 还需参照其答对的那些问题的具体内容。故年级当量不可用于做是否掌握知识推断。

最后, 还应考虑一个学科与另一个学科之间年级当量的可比性问题。一个人在语言学习上超前 (或滞后) 自己当前的年级水平一个学年, 与其在算术能力上同样程度的超前 (或滞后) 相比, 二者所对应的量是否相等? 稍后在这一章中会介绍到相关的支撑论据。在不同学科上能力水平的增长速率不一, 这取决于课上的教导和课下的自学。因此, 将学生在不同学科中的表现对应的年级当量进行空泛肤浅的对比, 可能会导致得出具有误导性的结论。

总之, 年级常模可以将单个对象的表现与各个不同年级的一般水平的个体表现对应起来, 这在建构分析小学生学业成绩的整体框架时尤其实用。鉴于这个目的, 年级常模相对便捷且受欢迎, 虽然年级单位相等的假设或是相同量的差异在不同学科之间完全对等不太可能。

年级常模相对容易确定, 因为它们立足于在学校体系中已经确立的实验组。直接考察教学领域中测试对象的成绩, 从年级的角度或许比从年龄的角度更有意义, 因为前者是按年级水平来区分等级, 这样学生的表现更易分析和理解。离开了校园环境, 年级常模也就失去了意义。

(1)发展标准分数

我们知道以年级当量作为某一个对象表现的表征标准的过程中有诸多的问题, 特别是需要清楚明白地给出假设, 即相邻两个学年中学生受测试的某项能力提高的量相等。显然, 许多能力都不满足这一假设条件, 所以测试发布者们研究出一种基于学业成绩的分数量表。它更接近等距量表, 我们称之为发展标准分数量表。

发展标准分数 (DSSs 或 SSs) 以每个年级内的常态分数分布为出发点 (详见本章稍后对常态转换的介绍)。所制作的量表中两个年级的刻度值都是随意选择的, 然后根据年级内平均值和标准差来在该量尺上定位其他的年级当量。例如, 爱荷华州基础技能测试的研发者们以固定刻度 200 表示四年级学生成绩的中值, 以刻度 250 表示八年级学生在春季进行测试所得的中值。测试手册所表示年级当量与发展标准分数 (DSSs) 之间的关系如下所示:



<table><tr><td>年级</td><td>K</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td><td>11</td><td>12</td></tr><tr><td>DSS</td><td>130</td><td>150</td><td>168</td><td>185</td><td>200</td><td>214</td><td>227</td><td>239</td><td>250</td><td>260</td><td>268</td><td>275</td><td>280</td></tr></table>



从上表对比可知, 很显然同样程度的差异在年级和发展标准分数上的体现并不是相互对应的。表示 DSS 的量尺上设置的区间长度本应该是相同的 (10 个单位长度所表示的差异在该量尺上的任何地方都具有相同的含义)。而对比显示, 在校的早期教育阶段从一个学年到下一学年的过渡中学生能力水平的变化差异更大, 比如从一年级到二年级的变化差异是 18 分, 从八年级到九年级时为 10 分。

与年级当量不同, 发展标准分数的一个主要缺点就是本身不具有意义。挑选作为定点的值具有极大的任意性。只有依存于年级当量量表而言时它们才具有意义。 比如, 我们可以说一名为 255 的学生的表现相当于就读于九年级阶段十二月的学生水平。由于发展标准分数体系过于复杂且缺乏具体的意义, 很难对它们进行准确无误的理解分析。虽然有许多测试发布者对其进行分析, 但还是应该慎重使用。统计发展标准分数的测试发布者们往往还会提供一些其他形式的常模参照信息。例如, 从分析呈现爱荷华州基础能力测试中常模分数的过程可知, 得益于其等距量表的特质首先得出的是发展标准分数, 然后可以制成表格, 将发展标准分数转换为其他类型的常模分数, 这部分会在本章中进行介绍 (年龄常模除外)。

## 2. 年龄常模

如果考察的特征可能在年龄上表现出一定的连续性且其量的增长与年龄的增长幅度相对一致, 那么这组原始数据或许适合转换为年龄分数或年龄当量进行分析, 这也是一种常见的分数量表。童年时期, 我们的身高和体重会连续增长, 在解剖学上对成熟的定义中有各种各样的指数和一系列知觉的、动作的和认知的人类行为表现标准可用来对此进行衡量。如果说一个八岁儿童的身高有一般的十岁儿童那么高, 力气有一般的九岁儿童那么大, 可用于表达的词汇量有一般的六岁儿童那么多, 这样的描述会让我们有一种大概的了解。在智力和能力倾向测试的早期发展阶段, 人们尤其倾向于将原始分数转换为年龄当量, 而所谓的心理年龄这一术语也进入到心理测试和公众的词汇库中, 虽然时不时会出现一些副作用。

当然, 年龄当量也就是对某一既定年龄段进行测试所得分数的平均分, 可从处于 8 岁、9 岁、10 岁等诸如此类的年龄群体中抽取一些具有代表性的例子进行考察分析。在这一点上, 年龄当量与前述的年级当量相似。再者, 如考察年级当量时举的例子所示, 这里的主要问题在于以一个学年中学生能力水平的提高代表一个标准统一的单位是否合理。从 5 岁到 6 岁和从 10 岁到 11 岁的能力提高是等量的吗? 还有, 在我们规定的量表上, 任意一年与任意的另外一年中测试对象的能力提高又是等量的吗? 将年龄量表上移, 很快就会发现某一年中个人能力的提高很显然与量表上所规定的不符。在一些时点上, 有时是在青少年时期或在 20 岁的头几年, 个人身上几乎所有我们能够进行测量的特征的增长速度会开始放缓直至停止。如图 3-1 所示, 它说明的是女生平均身高的正常增长速度, 可见女生到十四岁左右时身高的增长速度明显开始放缓。 14 岁以后, 一年中的身高变化显然比数轴上稍早的年龄段里某一年中的身高变化要小得多。对于女生而言, 到了 14、15 岁的时候, 其身高随着年龄增长的增量这一概念几乎就没有任何意义可言了。我们所测量的几乎所有人类特征都会出现这个问题, 即到了一定时间点就只能看到年龄变量在变化, 而几乎看不出身高变量的变化, 反映在图中就是一条扁平的增长曲线 (当然, 每个人成长成熟的速度各不相同, 所以在测量的特征上, 某一个人可能比普遍的时间点提前或推后停止增长。 这同时也解释了使用平均值或任何测量集中趋势的方法表示个人分值的问题)。





图 3-1 女生身高对应的年龄常模



在考察得分远高于一组数据平均分的对象时, 出现扁平增长曲线的现象所反映的问题会愈发明显。这时与一个 5 英尺 10 英寸 (70 英寸) 高的女生相对应的年龄当量应该是多少? 如果我们要赋予它任意一个具有年龄意义的数值, 就必须想象和模拟增长曲线继续往后延伸的情况, 如图 3-1 中虚线所示的部分。这条线表示的是一种假想的情况, 即女生的身高在 14 岁以后仍以 14 岁以前的典型增长速度增长。按照这条外推曲线, 与 5 英尺 10 英寸相对应的年龄值则应该是 16 岁半。但这是一个完全任意捏造的年龄当量, 它与 16 岁半女生的真实平均身高并不对应, 也不符合任一年龄层的女生身高。而遗憾的是, 从这些由外推曲线所得的年龄当量中也找不到任何说明其任意性本质的线索。这里涉及外推年级当量, 因此面临的问题更加严峻。

年龄常模是以分析每个年龄层具有一般水平的个人特征为基础的, 因而其用于解析某一特定个人状态的框架体系更易理解和领会。但年龄单位的等量性仍颇具争议, 并且当一个人成长到青少年时期和成人时期时, 年龄作为表示个人表现水平和能力的衡量单位将不再有任何意义。年龄常模最适合的阶段是婴幼儿时期, 且尤其适于分析个人的一些共有的一般性特征, 比如身高、体重或齿列。普通心智发展, 比如认知特征, 也就是我们常说的心理年龄的概念, 具有十分通用的模式, 可作为个人状态的有效常模指标。但一般来说, 年龄常模不应用于分析小学阶段以上的认知特征, 因为这些能力的增长模式中正规学校的教学经验痕迹太重, 又或是没有适于分析年龄常模的必需的增长模式。

## 3. 百分位数常模

从上述年龄常模和年级常模的例子中可以看出, 确定了所属的年龄和年级群体之后, 代表平均水平的那个测试对象的分数就具有了意义。但这样设置对照组常常不太合适, 而需要选取其他更实用的群组。例如, 我们常常需要评估小学阶段之外的对象表现, 但是年级常模又只有在分析小学阶段的年级时表现力才最佳。或者我们可能想分析性格或态度特征, 而恰巧年龄常模和年级常模在此范围内完全不适用。 又或者我们想获取的信息需要确定具体的测试群体, 这又会导致群体范围过窄且以致无法进行分析年龄常模或年级常模实际操作。还比如我们或许想考察处于同一年龄层或同一年级的对象。

每个人同时属于多个不同的群体。一个 18 岁的人就属于如下列举的某些群体, 而不属于其他群体: 比如 18 岁的人群, 正在上十二年级的 18 岁人群, 申请了大学的 18 岁人群, 未申请大学的 18 岁人群, 申请美国常春藤大学的 18 岁人群, 在公立 (或者教区) 学校上学的 18 岁人群以及在加利福尼亚州的学校上学的 18 岁人群。出于某些目的,将对照组的范围设置得比年级常模或年龄常模更小是十分有益且必要的。 百分位数常模体系就是广泛应用的常模体系之一。

分析典型的百分位数为常模, 或说百分等级, 所需的信息即为第二章中所介绍的计算百分位数值所需的信息, 只是计算的方法步骤稍有不同。计算出的百分等级与所获取得分值相对应。一项测试若有 10 道题目, 就能产生 11 个不同的原始分数, 即 0 到 10 之间的所有整数。于是就可以假设与该测试相对应的百分等级也只可能有 11 个值, 即每一个百分等级对应一个原始分数, 但不排除计算出的百分等级为任何数值的可能性。比如, 我们可以按照第二章中介绍的方法, 像计算第 67 位和第 68 位百分位数一样计算第 67.4 位百分位数。但只有从测试中获得的那 11 个分值才有与之对应的百分等级。从常模参照角度解析测试分数时更常用到百分等级, 而非百分位数, 因为测试结果往往是整数且数量有限。

计算百分等级首先要制作一张如表 3-4 所示的频率分布表。和计算百分位数时一样, 假定 (1) 测试所测量的本质特征是连续的, (2) 每一个考察的分数都处在某个区间连续体的中间, 还有 (3) 获得某个给定原始分数的人均匀分布于该区间中。由于每一个初始分数都位于区间的中间位置, 那么就可以认为区间中高于和低于该中间分值的人各占一半。即使某一特定区间中只有一人, 我们也同样假定这个人的高于和低于该中间分值的部分各占一半。



表 3-4 计算一项十题测试的百分等级

<table><tr><td>原始分数</td><td>频率</td><td>累积频率</td><td>百分等级</td></tr><tr><td>10</td><td>1</td><td>60</td><td>99</td></tr><tr><td>9</td><td>3</td><td>59</td><td>96</td></tr><tr><td>8</td><td>5</td><td>56</td><td>89</td></tr><tr><td>7</td><td>12</td><td>51</td><td>75</td></tr><tr><td>6</td><td>15</td><td>39</td><td>52</td></tr><tr><td>5</td><td>9</td><td>24</td><td>32</td></tr><tr><td>4</td><td>7</td><td>15</td><td>19</td></tr><tr><td>3</td><td>4</td><td>8</td><td>10</td></tr><tr><td>2</td><td>2</td><td>4</td><td>5</td></tr><tr><td>1</td><td>1</td><td>1</td><td>2</td></tr><tr><td>0</td><td>1</td><td>1</td><td>1</td></tr></table>



通过统计得分在某个原始分值以下的人数, 然后除以所有测试对象的总数, 就能计算出与该分值对应的百分等级。而得分在某个原始分值以下的总人数包括所有测试分数低于该原始分值的人加上所有得分等于该原始分值的人数的一半 (后者被视为在原始分值以下, 因为这群人的得分被认为分布在区间的后半部分)。以计算表 3-4 中的原始分数 4 所对应的百分等级为例, 首先统计得分低于 4 分的共有 8 人, 然后还要加上得分等于 4 分的 7 人的一半,也就是 \( \left( {8 + {3.5}}\right) /{60} = {11.5}/{60} = {0.1917} \) 。 百分等级的计算结果一般会四舍五入精确到小数点后两位数, 然后乘以 100 去掉小数点, 量表两端的值除外。因此, 与原始分数 4 对应的百分等级就是 19 。

计算百分位数 (比如中值) 和百分等级的方法步骤上的主要差异在于入手点不同, 从表 3-4 中的那些数据可知。要计算百分位数, 首先需要确定一个想要计算的百分比, 比如第 25 位或第 60 位百分位, 然后从连续的分值量表中找到与之相对应的点求解案, 关于这些步骤在第二章中有详细介绍。与这些百分数对应的值很少但并非一定得是整数。而计算百分等级时, 首先从分值量表上的某个点出发, 这个点表示一个可获得的分值, 然后计算得分在该分值以下的人数占总人数的百分比即为所求的答案。

百分等级的适用范围十分广泛。只要有合适的常模参照组, 就能以百分等级为标尺。对于年轻或年长的群体, 它都适用, 而且有关教育、心理咨询或是工业方面的决定也都可以参考它。得分超过所参照的对照组人数的 \( {90}\% \) 表示相应的同等优秀程度, 无论所测量的这个特征或能力是一个人能以多快的速度解答联立方程, 还是一个人的口水能吐多远。百分等级使用范围广泛, 且表达的意义很容易理解。如果没有我们接下来要阐述的两点问题, 使用百分等级解析测试分数的体系近乎趋于完美。

使用百分等级时面临的第一个问题就是明确常模组。确立常模应该基于哪种类型的群体? 很显然, 我们将需要不同的常模组以与整个群体中不同的年龄层和年级水平相匹配。对一个九岁儿童必须按照九岁儿童的标准或说以九岁儿童为常模进行评估, 同理对六岁儿童也应按照六岁儿童的标准, 而对房地产经纪人这一工作的应聘者, 同样应该按照房地产经纪人申请者的标准进行审核。无论在什么情形下, 测试对象所属的相关群体就是最合适的常模组, 我们会在这一环境中评估该对象的状态表现。例如, 以高中毕业生为常模, 即以这一群体为基准, 与医学专科学校申请者们在一项生物测试中的成绩进行对比来评估申请者们的表现是毫无意义的。若测试是由医学专科学校一方组织的, 那么测试者必须先确定适合与这些申请者进行对比的常模组或自行制定相应评估基准。

因此, 涉及百分等级的使用时, 通常需要确定多组常模。我们需要适合测试所针对的每一种不同类型群体或情形的常模。稍好的测试发布者们已意识到并认可这一条件, 并研究出多种常模, 不仅适于分析各种不同年龄层和年级水平的群体, 而且适合一些特殊类型的教育或职场人群。但测试发布者们能够为之确定常模的具有显著特征的群体数量有限, 所以那些已发布的百分位常模常常会需要测试者在使用过程中继续补充完善, 因为测试者们能够根据实际情况进行调整以确立尤其满足具体需要的常模组。因此, 一个既定的学校体系常常会发现根据具体特点为评估自己的学生确立百分位常模更有意义和价值 (大多数测试发布者会协助学区研究和确立满足地方需要的常模)。这样我们就可以以部分群体为参照评估单个学生的成绩, 与在全国、整个地区或整个州的范围内进行对比相比, 这样进行比较对地方决策者做出相关决定可能更有意义, 也更重要。同样地, 一位对某一特定类型工作岗位申请者进行测试的雇主可能也会切实地感受到搜集一段时间内的测试结果并为该特定群体确立相应的常模的实用性和效度。这些严格根据局部特点确立的常模将会大大简化评估新申请者的过程。因此, 虽然我们可以为不同测试的使用明确确立许多不同的常模组, 但它既是一个优点, 因为这样能得到更加准确的对比结果, 也是一个缺点, 因为操作过程会变得更加复杂。

使用百分等级时会出现的另一个问题与等量单位有关。我们能否认为百分位量表上的五个百分位数所对应的测量特征的量是相等的? 第 50 位到第 55 位百分位数之间的差距与第 90 到第 95 位之间的差距又是否相同? 要回答这类问题, 就必须明白一组测试对象的测试分数是如何排列组合的。第二章中的图 2-1 所示的直方图对测试分数的呈现十分直观。该图对于呈现多种情形中测试分数的分布情况相当具有代表性。测试对象集中分布在中间分数段, 而两端的对象数目渐次稀少。这类分数分布的理想状态是正态曲线, 这也和标准差一起在第二章中进行了详细的阐述 (详见表 2-5 和图 2-6), 也可参照图 3-2。标准的正态曲线是一个理想的数学模型, 但许多种测试结果中分值的分布都近似正态曲线, 大多的测试对象集中分布在中间部分, 而两端较少,一般呈完全对称形式。





图 3-2 关于选定的百分位点的正态曲线



图 3-2 中标出了四个点, 即第 50、55、90 和 95 位百分位数。水平基准线表示以均匀单位的量表进行测量的特征。这些单位可能是一项测试中受试者答对的题目数或是身高有多少英寸。有 \( 5\% \) 的受试者 (分布在第 50 和第 55 位百分位数之间的那 \( 5\% \) 的测试对象) 的得分分布在中值附近,形成一个又高又细的方形条。而“尾巴”部分同样有 \( 5\% \) 的受试者,他们的得分分布形成的是相对矮宽的方形条。第二种情形中那 \( 5\% \) 的测试对象的得分分布范围比前者宽得多。就相同的百分位数值差对应的分值量表上的距离而言, 第 90 到第 95 位之间的距离是在中值附近时的三倍, 即如图所示 \( {\mathrm{P}}_{90} \) 到 \( {\mathrm{P}}_{95} \) 的距离是 \( {\mathrm{P}}_{50} \) 到 \( {\mathrm{P}}_{55} \) 的三倍。沿着尾部往后延伸得越远,情形就越极端。

因此, 就原始分数单位而言, 百分位单位在本质上显然是不等的。在一个 100 人的受试群组中, 第 1 名和第 2 名之间与第 50 名和第 51 名之间的差异可能相差好多倍。因此相同的百分位数值差所代表的测量特征在量上的差异一般是不同的。任何情况下分析百分位常模时, 必须将这样的前提考虑在内, 即该量表上分值的分布一般中间多两端少。玛丽在算术测试中的成绩对应第 45 位百分位数, 在阅读测试中的成绩对应第 55 位百分位数, 这反映了她在这两项能力上的细微水平差异; 而爱丽丝在这两项测试中分别对应第 85 和第 95 位百分位数, 爱丽丝在这两项能力上的水平差异比前者更大, 明白这一点对需要做出相关决定的决策者至关重要。

## 让计算机来帮忙

百分等级

给出一组原始分数, SPSS 和 Excel 制表程序都可以计算相应百分等级的近似值, 但 SPSS 的处理过程更加简单且准确度更高。这些应用程序计算百分等级的方法各不相同。SPSS 会先对一组数据中的每个分值进行排序, 然后用相应的排列名次除以总的对象数。当测试对象总数为奇数时, 计算就会出现误差, 因为排在正中间的那个分值无法被分成两半, 但这一误差对结果没什么影响。我们指出这一点是为了让大家知道, 手动计算出来的结果可能会与计算机得出的值有少许出入。

使用 SPSS 计算百分等级, 首先必须使用转换 (Transformation) 菜单中的对象排序 (Rank Cases) 功能。你会看到如下所示的界面:







在变量 (Variables) 会话框中输入想要计算百分等级的变量, 然后点击排序类型 (Rank Types), 会出现如下所示的界面:







点击该会话框中的 “按% 分数排序”, 点击继续 (Continue), 然后点击确认 (OK)。 程序会在数据文件中生成两个新的变量, 一个是每个分值的排列名次, 另一个是分值对应的百分等级, 但上述误差不可避免。对于每个分析的变量, 程序会自动生成两个新的变量。每一个新变量的命名与原变量相同,但各自前面会带有字母 \( \mathrm{r} \) 和 \( \mathrm{p} \) ,分别表示排列名次和百分等级。若原变量的名称含有 8 个字母, 那最后一个字母就会被舍弃。数据文件中的新变量对应的值将会带有 “排列名次是……” 和 “分数排序百分比是……”这样的标签。

使用 Excel 计算百分等级,须用到 \( {f}_{x} \) 或 \( \sum \) 的 “函数” 选项。统计列表中有一个函数就是百分位距 (PERCENTRANK)。选中这一函数, 会弹出一个如下所示的会话框, 覆盖在你的数据表格上。接下来必须输入数据表格中选中的分值范围, 以及你想计算百分等级的具体分值。这里选择的是 \( \mathrm{G} \) 列 (数学) 变量相应的 52 个分数 (从第 2 行到第 53 行), 然后请求计算 33 分这一分值的百分等级, 程序最终计算出的该分值的百分等级为 0.215 。







遗憾的是, 由于系统原因, 根据 Excel 应用程序的相关指示计算出的结果误差特别大。该程序反馈的某一分值的百分等级约等于用 SPSS 计算下一个分值所得的值, 但这个不是改正这种误差的可靠办法。比如, 这组数据中的 33 分对应的百分等级是 25.96 (13.5/52), 这也是我们认可的那个正确的值, 而 SPSS 应用程序反馈的值为 26.92(14/52)。我们已知通过 Excel 制表程序得出的值为 0.215 , 百分等级为 21.5 , 这个值约等于 32 分所对应的正确的百分等级。由于 Excel 程序常常得出不正确的且不易纠正的结果, 所以我们不建议用它来计算百分等级。

由于系统原因, 百分位单位的值并不是均匀的, 这表明它是一个顺序量表。数值越大表示个人表现出的相应特征越明显, 但相同差异的百分等级并不表示相应特征在量上的差异也相等。不像前面介绍的年龄当量和年级当量, 百分等级不处理等量单位的问题。

百分等级量表中的非等量单位问题会造成的一个不良后果是, 在许多数学测量程序中, 百分位数无法得到妥善处理。例如, 将两个百分等级相加得不到一个有意义的结果。将两个原始分数对应的百分等级相加或求平均值与直接计算这两个分数的和或平均值的百分等级, 这两者不可能得出一样的结果。需要为百分位当量单独制作一张表格, 以免要计算任意原始分数组合在一起后对应的百分等级。此外, 稍好的测试发布者们会提供与所有测试分数子组合相对应的百分等级换算表, 也包括这些子测试分数本身。

## 4. 标准分数常模

因为基于百分等级的分数体系中的单位不均匀众所周知, 所以不得不寻找一些其他单位, 其对应的值在整个范围内都是均等的。标准分数量表就是为这一目的而存在的。

经过第二章的介绍, 我们了解了用于测量一组分数波动幅度或分布范围的标准差(SD),以及用于表示分值分布中某个分数相对位置的标准分数 (或 \( Z \) 分数)。标准差是单个人的得分相对于平均值偏离的差值。或许任何一个分数都可以相对于平均值偏离的标准差值表示。对九年级学生进行的成绩与能力测试中, 数学这组数据的平均值和标准差分别为 24.1 和 9.8 , 那么成绩为 30 分的学生则排在高于平均值

\[\frac{{30} - {24.1}}{9.8} = {0.60}\]

个标准差单位的位置。同理, 成绩为 15 分的学生则排在低于平均值 0.93 个标准差单位的位置。按照标准差单位或 \( Z \) 分数的表达方式,这些值应该分别表示为 \( + {0.60} \) 和 -0.93 。

在任何一种分值分布中,用一组数据中所分析的原始分数(X)减去平均值(M) 所得的差值除以标准差,就能确定这组数据的 \( Z \) 分数的值:

\[Z = \frac{X - M}{SD}\]

如果计算出原始分值分布中每一个分数的 \( Z \) 分数,我们就能得到一个新的 \( Z \) 分数分布图,这组新数据的平均值将是零,标准差将是 1.0 。所有这些 \( Z \) 分数中,约有一半是负数,表示相应得分低于平均值,还有约另一半是正数。大多数 \( Z \) 分数 (约 99%) 都介于 -3.0 和 +3.0 之间。

假设在秋季对九年级学生进行 \( \mathrm{G} \) 等级的达标与能力测试,如下是两名学生分别在数学和阅读理解测试中的成绩:



<table><tr><td>学生</td><td>数学</td><td>阅读理解</td></tr><tr><td>赫克托</td><td>30</td><td>48</td></tr><tr><td>乔斯</td><td>37</td><td>42</td></tr></table>



接下来看看如何用标准分数来比较同一个人在这两项测试中的表现, 或是两个人在某一项测试中的表现。

上述两项测试中学生成绩的平均值和标准差如下:



<table><tr><td/><td>数学</td><td>阅读理解</td></tr><tr><td>平均值</td><td>22.7</td><td>33.8</td></tr><tr><td>标准偏差(SD)</td><td>9.4</td><td>11.1</td></tr></table>



赫克托的数学成绩高于平均值 7.3 个点。他的 \( \mathrm{Z} \) 分数为 \( {7.3}/{9.4} =  + {0.78} \) 。他的阅读理解成绩高于平均值 14.2 个点,因此 \( Z = {14.2}/{11.1} =  + {1.28} \) 。由此可知,相对于常模组, 赫克托在阅读理解上的表现比其在数学上的表现大约好 0.5 个单位的标准差。对于乔斯而言, 在数学上相应的计算方程则为:

\[\left( {{37} - {22.7}}\right) /{9.4} =  + {1.52}\]

在阅读理解上相应计算方程为:

\[\left( {{42} - {33.8}}\right) /{11.1} =  + {0.74}\]

因此, 赫克托在数学上的表现与乔斯在阅读理解上的表现几乎一样好, 而乔斯在数学上的表现比赫克托在阅读理解上的表现大约好 0.25 个单位的标准差。

每一个学生的优秀水平都可以高于或低于对照组平均值多少个标准差单位来表示。在任何一项测试中, \( Z \) 分数都具有统一的标准测量单位。如需分析标准分数所代表的优秀水平,详见表 2-5 。

## 让计算机来帮忙

## 标准分数

SPSS 和 Excel 制表程序都能用于计算 \( Z \) 分数,但使用 SPSS 进行计算的过程仍旧更加简单, 因为该程序会针对分值分布中的每个人的成绩计算一个新的标准分数变量, 并将其保存在相应数据文件中。要使用 SPSS 计算新的标准分数变量, 只需在分析 (Analysis) 菜单栏简单勾选描述 (Descriptives) 选项, 会出现如下所示的会话框:

选择想要求取其标准分数的变量, 然后点击会话框中的 “将标准值保存为变量”。







相应数据文件中就会生成一个与原变量名称相同但以 \( Z \) 为前缀的新变量,该程序唯一的问题在于,它是以标准差的整个样本估计值而不是抽样的估计值来计算 \( Z \) 分数的。这会导致计算得出 \( Z \) 分数的值稍微偏小,但该误差在不同个人和变量上波动不大, 而且对于达到一定数量的样本而言, 该误差可以忽略不计。

Excel 制表程序则需要先计算数据分布的平均值和标准差。然后使用 \( {f}_{x} \) 或 \( \sum \) 函数, 选择统计列表中的标准化 (Standardize) 按钮。然后系统会出现要求输入一个具体分值、平均值和标准差的提示。由此就能计算出所选定的分值的 \( Z \) 分数。Excel 制表程序的优点在于可以有效利用标准差,而缺点在于需要逐个计算每个分值的 \( Z \) 分数。我们将在下面部分介绍使用 Excel 制表程序获取 \( Z \) 分数的其他方法。

(1)调整后的标准分数

总之,除了以下两点不太便利的因素, \( Z \) 分数还是非常实用的: (1) 它们一般带有正负号, 这些符号容易被错印或忽视, (2) 它们一般带有小数点, 而小数点很容易错位。而我们往往容易带有这样的惯性思维, 即人的特征或属性没有正负之分, 也不会用分数表示。对于这一点,我们可以通过将每个 \( Z \) 分数乘以一个合适的常数,比如 10 , 以避免出现小数点, 同样还可以通过加上一个合适的常数, 比如 50 , 以避免出现负号。因此, 以赫克托在数学和阅读理解测试中的成绩为例, 可得:



<table><tr><td/><td>数学</td><td>阅读理解</td></tr><tr><td>分数分布的平均值</td><td>22.7</td><td>33.8</td></tr><tr><td>分数分布的标准差</td><td>9.4</td><td>11.1</td></tr><tr><td>赫克托的原始成绩</td><td>30</td><td>48</td></tr><tr><td>赫克托的 \( Z \) 分数</td><td>\( + {0.78} \)</td><td>+1.28</td></tr><tr><td>\( Z \) 分数 \( \times  {10} \)</td><td>8</td><td>13</td></tr><tr><td>加上一个常数 (50)</td><td>58</td><td>63</td></tr></table>



(一般做法是将调整后的分数四舍五人到最接近的一个整数, 目的是为了使这些数值更便于使用。) 因为我们按照共同比例 \( \left( {M = {50},{SD} = {10}}\right) \) 调整了赫克托在这两项测试中的得分, 这样就能直接对它们进行比较, 且直观地看到他在阅读理解上的表现比在数学上的表现稍佳。然而, 这样的对比需要这些测试具有相应的常模对照组, 这些稍后会详细介绍。

标准分数的调整基于一个简单的方程式, 这一方程式会改变单位的大小和平均值在分值分布中的位置。进行如上转换的方程式可用符号表示如下:

\[C = {10}\left( Z\right)  + {50}\]

其中 \( Z \) 表示前面介绍过的标准分数, \( C \) 为调整后的标准分数。通式即为:

\[C = S{D}_{A}\left( Z\right)  + {M}_{A}\]

此处 \( S{D}_{A} \) 和 \( {M}_{A} \) 分别表示出于运算的方便而选择的任意数值的标准差和平均值。

分别代表用于调整平均值和标准差的数值 50 和 10 是我们随意选取的。当然也可以使用除 50 和 10 之外的其他数值代入等式调整标准分数, 只要便于分析就行。 陆军用于分析其测试结果的标准分数量表中用于调整平均值和标准差的值就分别是 100 和 20。大学入学考试委员会一直以来使用的量表中用于调整平均值和标准差的值分别是 500 和 100 , 这些量表常用于分析学生在学业能力倾向测验 (SAT) 中的成绩, 还有研究生人学考试和由该委员会赞助研发的一些其他测试。海军同样使用的是 50 和 10 的搭配。智力测试一般使用的组合是平均值为 100 , 标准差为 15 。

分值的量表会如上所示随着转换而相应放大或缩小 (具体取决于原标准差比调整后的新值是大还是小), 但在整个量表上的单位仍然是均匀统一的。单位的长度改变了, 但是是在整个分值量表范围内的统一变化。如果在一开始原分值量表的单位就是均等的, 那么调整后的分值量表也一样, 但若一开始分值量表单位就不均等, 那调整或转换也无法使其变得均等。因为上述等式表示的是一种直线关系 \( (y = {ax} + \) \( b) \) 的方程,这种转换分值的方式叫作线性调整或线性转换(这里有必要解释一下相关术语。我们用符号 \( Z \) 代表原始标准分数,符号 \( C \) 代表某个 \( Z \) 分数的任意一种线性转换,而符号 \( T \) 常用于表示线性转换中的特例,即使用 50 作为平均值和 10 作为标准差的线性转换)。 让计算机来帮忙

## 线性转换

使用 SPSS 或 Excel 制表程序对任意一组标准分数进行任何线性转换都非常简单。使用 SPSS 进行该操作的最简单的方法就是使用转换 (Transform) 菜单中的计算 (Compute) 程序。首先必须按照上一个会话框中的要求新建相应的标准分数变量, 然后在目标变量 (Target Variable) 会话框中输入想要分析的变量名称, 再在数字表达式 (Numeric Expression) 会话框中输入转换等式。点击确认, 新变量就会出现在相应数据文件中。如下所示的会话框显示的是基于阅读测试分数计算新变量“ \( T \) 阅读” ( \( T \) -reading) 的过程,其中标准差和平均数的值同样分别定为 10 和 50 。注意, 起初我们设置的 \( Z \) 分数变量为 “ \( Z \) 阅读” ( \( Z \) -reading)。







用 Excel 转换变量的步骤也十分相似。首先, 必须新建相应的标准分数变量, 然后计算其转换变量。进行这些操作最简单的方法就是确定需要转换变量的平均值和标准差,然后输入用于计算如前所述的 \( Z \) 分数的转换函数。比如,表 2-1 中 52 名学生的数学成绩对应的平均值和标准差分别为 38.17 和 8.84 。用于计算魁杜拉 - 魁克里的成绩对应的 \( Z \) 分数的函数如下图所示。电子表 \( \mathrm{G}2 \) 单元格中的值是她的数学成绩,因此在 \( \mathrm{H}2 \) 单元格中套用函数 “ \( = \left( {\mathrm{G}2 - {38.17}}\right) /{8.84} \) ” 计算出她的 \( Z \) 分数为 -2.17。 选中剩下的所有单元格, 点击编辑 (Edit) 菜单中的填充 (Fill) 指令和向下 (Down) 选项,就能得出所有其他学生的成绩对应的 \( Z \) 分数 (或者直接使用 \( \mathrm{{Ctrl}} + \mathrm{D} \) 组合键也能得到同样的效果)。这一操作对 \( \mathrm{H} \) 栏中的所有单元格进行了相同的函数运算。计算出 \( Z \) 分数之后,就可以同样的程序进行其他任意一种线性转换了,计算出的 \( \mathrm{C} \) -scores 可以放在 \( \mathrm{I} \) 栏中。例如,用我们通常分析智力测试成绩的量表对 \( \mathrm{H} \) 栏中的 \( Z \) 分数进行调整,则应在 I2 单元格中输入函数 “ \( = \left( {\mathrm{H}2 \times  {15}}\right)  + {100}^{ \circ  } \) 。接着重复如上操作, I 栏中显示的结果就是所有学生的转换标准分数。



FTMCrosoft Executive Statistics Example.Jus | 2 | 3 | 5 | 5 | 5 | 5 | 5 | 5 | 4 | COMPORATIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONALIONAL

<table><tr><td/><td>14.2</td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td/><td/><td/><td>D</td><td/><td/><td/><td/><td/><td/></tr><tr><td>1</td><td>First</td><td>LastGender</td><td/><td>Recoing</td><td/><td>Math</td><td>2-scores</td><td>C-scores</td><td/></tr><tr><td/><td>Quadra</td><td>Quickly</td><td>2</td><td>121</td><td>44</td><td>19</td><td>-2.17</td><td>67.47</td><td/></tr><tr><td>3</td><td>Mainz</td><td>Naits</td><td>1</td><td>122</td><td>47</td><td>22</td><td>-1.83</td><td/><td/></tr><tr><td>4</td><td>Wakana</td><td>Watansbe</td><td>)</td><td>125</td><td>53</td><td>21</td><td>-1 %</td><td/><td/></tr><tr><td>5</td><td>Xenuates</td><td>Xerxes</td><td>I</td><td>25</td><td>54</td><td>31</td><td>-0.81</td><td/><td/></tr><tr><td>6</td><td>Jack</td><td>Johanson</td><td>If</td><td>26</td><td>58</td><td>26</td><td>-1.38</td><td/><td/></tr><tr><td/><td>Model</td><td>Klipsch</td><td>1</td><td>128</td><td>51</td><td>25</td><td>-1.49</td><td/><td/></tr><tr><td>8</td><td>Manicy</td><td>Momis</td><td>2</td><td>228</td><td>44</td><td>44</td><td>0.66</td><td/><td/></tr><tr><td>9</td><td>Radaims</td><td>Roberts</td><td>1</td><td>129</td><td>B4</td><td>43</td><td>0.55</td><td/><td/></tr><tr><td>10</td><td>Larry</td><td>Lewis</td><td>1</td><td>229</td><td>40</td><td>34</td><td>-0.47</td><td/><td>33</td></tr><tr><td>(1)</td><td>Verma</td><td>Valder</td><td>2</td><td>229</td><td>43</td><td>36</td><td>-0.25</td><td/><td>33</td></tr><tr><td>12</td><td>Harpo</td><td>Henry</td><td>1</td><td>130</td><td>53</td><td>34</td><td>-0.47</td><td/><td>364 (22)</td></tr><tr><td>13</td><td>Xena</td><td>Xerxes</td><td>2.</td><td>230</td><td>57</td><td>37</td><td>-0.13</td><td/><td>24 發</td></tr><tr><td>14</td><td>Zeprina</td><td>Zoro</td><td>2</td><td>230</td><td>47</td><td>38</td><td>-0.02</td><td/><td/></tr><tr><td>15</td><td>Gundio</td><td>Garcs</td><td>1</td><td>231</td><td>62</td><td>29</td><td>-1 &&</td><td/><td/></tr><tr><td>16</td><td>Resorda</td><td>Rostropower</td><td>2</td><td>231</td><td>50</td><td>31</td><td>-8 81</td><td/><td/></tr><tr><td/><td>Aaron</td><td>Andrews</td><td>1</td><td>132</td><td>64</td><td>43</td><td>0.55</td><td/><td/></tr><tr><td/><td>Penala</td><td>Peters</td><td>2</td><td>132</td><td>64</td><td>33</td><td>-0.58</td><td/><td/></tr><tr><td>19</td><td>Yuban</td><td>Young</td><td>1</td><td>132</td><td>by</td><td>24</td><td>-1.60</td><td/><td/></tr><tr><td>20</td><td>Balleda</td><td>Brewn</td><td>2:</td><td>233</td><td>38</td><td>41</td><td>0.32</td><td/><td/></tr><tr><td>21</td><td>Charboa</td><td>Cowon</td><td>2</td><td>233</td><td>4 ?</td><td>50</td><td>1.34</td><td/><td/></tr><tr><td>22</td><td>teor</td><td>Ivanavich</td><td>1</td><td>233</td><td>53</td><td>43</td><td>0.55</td><td/><td/></tr><tr><td>23</td><td>QUARCY</td><td>Quinn</td><td>1</td><td>233</td><td>48</td><td>33</td><td>-0.56</td><td/><td/></tr><tr><td/><td>Stav</td><td>Stobbens</td><td>2</td><td>233</td><td>61</td><td>32</td><td>-0.70</td><td/><td/></tr><tr><td>15</td><td>William</td><td>Weslerbeke</td><td>1.</td><td>233</td><td>64</td><td>33</td><td>-0.58</td><td/><td/></tr><tr><td>26</td><td>Themas</td><td>Table</td><td>1</td><td>135</td><td>85</td><td>38</td><td>-0.02</td><td/><td/></tr><tr><td>22</td><td>Keletteen</td><td>Kravies</td><td>2</td><td>235</td><td>55</td><td>51</td><td>1.45</td><td/><td/></tr></table>



## 5. 转换的正态分布

## (1)局部转换的正态分布

通常我们将与原始分数相对应的百分等级与经过线性转换的 \( Z \) 分数结合在一起,便形成了标准分数量表,这些 \( Z \) 分数与正态分布中的那些百分位等级相对应,而正态分布以测量特征对应的分值分布属于正态分布这样的假设为前提 (这叫作分数的区域调整, 由于不能用一条直线或线性方程表示整个转换过程, 我们也称之为非线性转换)。因此, 在数学测试中, 如表 2-1 所示可知, 33 分的成绩对应的百分等级为 26 。在正态分布表中,分布在 \( {26}\% \) 的测试对象以上的那个位置所对应的 \( Z \) 分数即为 -0.64 。如果数学测试分数分布情况属于标准的正态分布, 那么这就正是 33 这一原始分数对应的 \( Z \) 分数的值。因此,要得到有关该原始分数的区域正态分布情况, 就得赋予 33 这一原始分数与 -0.64 这一标准分数对应的意义。假设使用的量表中标准差和平均值分别为 10 和 50 , 则计算结果如下:

\[T = {10}\left( {-{0.64}}\right)  + {50} =  - 6 + {50} = {44}\]

通过区域调整制作正态化标准分数量表的过程中, 需要确定所获取的每一个原始分数的百分等级。正态分布情形中, 分布在特定百分比的测试对象以上的那个位置所对应的 \( Z \) 分数会取代原始分数值,基于从中获取这组数据的该样本得出一系列 \( Z \) 分数,其分布仍属于正态分布。接着,我们可以使用自己觉得合适的平均数和标准差值对这些 \( Z \) 分数进行线性转换。 (2)正态曲线当量

在教育领域越来越受欢迎的另一种正态标准分数量表即正态曲线当量量表或 \( \mathrm{{NCE}} \) 量表。该量表是基于上述正态化过程所得,所采用的平均值与 \( T \) 量表使用的一样, 但标准差的设定不再是 10 , 而是 21.06 。选择该特定值作为标准差是因为, 在其量表中, 1 分对应第 1 个百分等级, 而 99 分同样与第 99 位百分等级相对应。正态曲线当量与百分等级 (PRs) 之间的关系如表 3-5 中的头两列所示。教育领域发布成绩测试的大多数主要出版商也会制作有关 NCE 分数的图表, 因此我们可以利用这些表格比较测试对象在不同测试中的相对表现。然而, 正如这些出版商们提醒的, 不同的测试内容也大不相同, 因此, 适用于一项测试的某个通用分值量表对另一项测试来说并不一定也适合。同样地, 不同测试中的常模组也可能不具有可比性, 因此除非我们事先知道两项测试具有相同或可进行对比的常模, 否则对比不同测试中的正态曲线当量时还是谨慎一点为好。



表 3-5 正态曲线当量、百分等级和九分评分制的关系

<table><tr><td>正态曲线当量</td><td>百分等级</td><td>标准九分</td><td>百分等级</td></tr><tr><td>99</td><td>99</td><td>9</td><td>\( \geq  {96} + \)</td></tr><tr><td>99</td><td>97</td><td>8</td><td>\( {89} - {95} \)</td></tr><tr><td>80</td><td>92</td><td>7</td><td>77 -88</td></tr><tr><td>80</td><td>83</td><td>?</td><td>60-76</td></tr><tr><td>80</td><td>83</td><td>7</td><td>40—59</td></tr><tr><td>80</td><td>50</td><td>7</td><td>23—39</td></tr><tr><td>80</td><td>83</td><td>7</td><td>11-22</td></tr><tr><td>80</td><td>7</td><td>7</td><td>4 - 10</td></tr><tr><td>80</td><td>8</td><td>1</td><td>\( 3 \leq \)</td></tr><tr><td/><td>1</td><td/><td/></tr><tr><td/><td>1</td><td/><td/></tr></table>



基于任意的平均数和标准差制定标准分数量表的可行方法有两种。其一是线性转换法,其中以我们选取的平均数和标准差计算 \( Z \) 分数,再对所得的值进行转换,即先乘以一个任意的新标准差值, 再加上一个任意的新平均数。这一方法不会改变分值之间的相对距离, 也不会影响分值的分布形态。其二即整体区域转换或正态转换, 通过百分等级,即计算正态分布中分布在低于该 \( Z \) 分数对应的位置以下的测试对象所占的百分比,将 \( Z \) 分数的意义赋予相应的原始分数。接下来,任意选取自觉合适的标准差和平均数,对这些被赋予相应原始分数的 \( Z \) 分数进行转换调整。所得最终结果将为正态分布, 不论原始分数的分布形态是什么。

只要这组测试对象的数据看起来似乎是完整的, 系统没有自动去掉分布在两端的分值, 正态化的标准分数就有意义。还有原始分数的量表单位似乎不是均等的, 但其背后的特征可被合理看作为正态分布时, 正态化的标准分数也有意义。许多测试研究者打算对其测试结构进行系统的调整, 设计以中等难度的题目居多, 而减少简单和困难的题目量。这样做是为了使测试的难易程度适中, 细化对成绩分布在中间 \( {80}\% \) 到 \( {90}\% \) 的受试者的区分,同时不再细致区分分值分布在两端的受试者。也就是说, 分值分布中, 中间部分的原始分数单位较集中, 对应所测量能力的切实增量要小于分布在两端的分值单位。将此相应测量能力的 “实际” 分布抽离出来形成的是一个顶端扁平的分值分布图。而正态化的分布操作过程与之恰好相反。

## 6. 九分评分制

在教育领域的测试中, 有一种现在非常受欢迎的正态标准分数量表叫做九分 (标准九分量表的缩写词) 评分制。此标准九分量表的平均数为 5 , 九分制的每个单位长度等于基于相应量级特征的标准差的一半。九分评分制倾向于忽略分数之间的较细微差异, 而将注意力集中于那些会对结果或过程产生影响的较大的差异。标准九分量表和百分等级之间的关系如表 3-5 中的后两列所示。和前面介绍的经过区域转换的分数一样, 九分制被赋予的相应值同样以百分位数的计算为基础。

许多不同的标准分数量表 (经正态化处理之后) 之间的关系以及每个标准分数量表与百分位数和正态分布之间的关系如图 3-3 所示。此图为正态曲线的模型, 在正态曲线下方是标有很多分位数的量表和几个常用的标准分数量表。此图还阐明了分值的各种当量体系。因此, 大学人学考试委员会 (CEEB) 体系中标准分数为 600 , 陆军相关测试体系 (或陆军一般分类测试, 即 AGCT) 中标准分数为 120 , 海军相关测试体系 (或 \( T \) 分数量表,即转换等式中平均数和标准差的值分别为 50 和 10 的通用线性转换) 中标准分数为 60 , 九分评分制中为 7 , 百分等级为 84 , 正态曲线当量的值为 71 , 或是韦克勒斯智力测试中得了 115 分, 所有这些所表示的优秀水平 (相对于一般参照组而言) 都是相同的。人们一般会任意挑选某一特定分值进行计算, 但大多出于便利性的考虑。遗憾的是, 所有测试机构没能就制定统一通用的分值单位的问题达成一致。但在所有测试的实际应用中, 坚持使用相同的分值量表和具有可比性的常模参照组这一点十分重要, 这样我们或许就可以直接对比不同测试得出的结果。





图 3-3 有关百分位数和正态曲线的不同类型的标准分数量表

资料来源: 与差别能力测试 (DAT) 中的题目相似的样题。版权 (C) 1972,1982,1990, 由哈考特公司 (Psych Corp/Harcourt) 出版。经许可复制。保留所有权利。



我们在前面部分讲解了确定一个合适的常模组的重要性, 这样才能运用百分位常模分析原始分数。这一点对于在标准分数框架体系中考察个人特征时也同样适用。将原始分数转换成标准分数, 必须基于一个相关样本, 我们所考察的分值对应的测试对象可被视为该样本中的一分子。确定一个工程系研究生相应的标准分数时, 以高中学生的物理成绩为参照常模是再合理不过的了。而在如上例子中, 若以百分位数进行对比, 则达不到同等效果。

总之, 和百分等级一样, 标准分数也是相对于一个特定的参照组解析个人分数以评估其能力和表现的。二者的不同点在于, 标准分数相应的单位是均等的, 因此属于等距量表。基本单位就是该参照组的标准差, 个人得分则以大于或小于这组数据的平均值多少个标准差单位来表示。标准分数量表的建立可以基于对原始分值进行线性转换或者区域 (正态化) 转换。不同的测试机构使用的计分量表各不相同。标准分数量表和百分等级一样有人找不到合适的参照组的问题。

## 3.4 不同类型常模的互换性

无论使用哪种常模参照量表, 测试发布者都会将许多常模种类列成一张表。表上会有受试者在测试中可能取得的一些不同的原始分数, 且分别与所使用的常模体系中的分值当量相对应。许多测试发布者提供的表格往往不止一种分值当量。 表 3-6 中所示例子为秋季学期爱荷华州基础技能测试 A 类型第九级 (三年级水平) 中的词汇测试成绩常模, 共有五种类型。发展标准分数 (即以该测试发布者的术语体系而言的标准分数) 是基于对刚入学的三年级学生中某个群体进行的测试所得。用于分析这组刚升入三年级学生群体的正态曲线分值量表以 50 为平均值, 21.06 为标准差。那么,一名原始成绩为 21 分的男同学则具有以下特征:

1. 其得分对应的发展标准分数为 191 (四年级学生春季学期的测试成绩的平均数为 200)

2. 其得分对应的年级当量为 4.2

3. 在三年级学生群体中的排名对应第 78 位百分位数

4. 其得分对应的正态曲线当量为 66

5. 其得分在九分评分制中对应的值为 7



表 3-6 秋季学期爱荷华州基础技能测试 A 类型第九级 (三年级水平) 中的词汇测试成绩常模

<table><tr><td>原始分数</td><td>标准分数</td><td>年级当量</td><td>百分等级</td><td>正态曲线当量</td><td>九分评分制</td></tr><tr><td>0</td><td>121</td><td>K. 2</td><td>1</td><td>1</td><td>1</td></tr><tr><td>1</td><td>124</td><td>K. 4</td><td>1</td><td>1</td><td>1</td></tr><tr><td>2</td><td>128</td><td>K. 6</td><td>1</td><td>1</td><td>1</td></tr><tr><td>3</td><td>132</td><td>K. 9</td><td>1</td><td>7</td><td>1</td></tr><tr><td>4</td><td>136</td><td>1.1</td><td>4</td><td>7</td><td>1</td></tr><tr><td>2</td><td>141</td><td>1.4</td><td>6</td><td>17</td><td>2</td></tr><tr><td>3</td><td>147</td><td>1.7</td><td>9</td><td>22</td><td>2</td></tr><tr><td>7</td><td>152</td><td>1.9</td><td>3</td><td>26</td><td>3</td></tr><tr><td>8</td><td>157</td><td>2. 1</td><td>9</td><td>32</td><td>1</td></tr><tr><td>9</td><td>161</td><td>2.4</td><td>24</td><td>35</td><td>4</td></tr><tr><td>10</td><td>164</td><td>2. 6</td><td>29</td><td>38</td><td>4</td></tr><tr><td>11</td><td>167</td><td>2.4</td><td>34</td><td>11</td><td>4</td></tr><tr><td>12</td><td>170</td><td>2.9</td><td>35</td><td>44</td><td>4</td></tr><tr><td>11</td><td>170</td><td>3. 0</td><td>43</td><td>46</td><td>4</td></tr><tr><td>11</td><td>174</td><td>3.1</td><td>47</td><td>35</td><td>5</td></tr><tr><td>15</td><td>177</td><td>3. 3</td><td>54</td><td>52</td><td>5</td></tr><tr><td>10</td><td>179</td><td>3.5</td><td>58</td><td>35</td><td>1</td></tr><tr><td>17</td><td>181</td><td>3. 6</td><td>61</td><td>56</td><td>6</td></tr><tr><td>18</td><td>183</td><td>3.7</td><td>29</td><td>58</td><td>4</td></tr><tr><td>19</td><td>185</td><td>3. 8</td><td>68</td><td>60</td><td>6</td></tr><tr><td>20</td><td>188</td><td>4. 0</td><td>73</td><td>63</td><td>5</td></tr><tr><td>21</td><td>191</td><td>4.2</td><td>78</td><td>66</td><td>5</td></tr><tr><td>22</td><td>194</td><td>4.4</td><td>82</td><td>35</td><td>7</td></tr><tr><td>23</td><td>197</td><td>4. 6</td><td>86</td><td>35</td><td>7</td></tr><tr><td>24</td><td>200</td><td>4. 8</td><td>29</td><td>76</td><td>4</td></tr><tr><td>35</td><td>204</td><td>5.1</td><td>92</td><td>80</td><td>8</td></tr><tr><td>26</td><td>209</td><td>5.5</td><td>95</td><td>85</td><td>8</td></tr><tr><td>11</td><td>216</td><td>6.0</td><td>97</td><td>90</td><td>1</td></tr><tr><td>28</td><td>216</td><td>6.7</td><td>99</td><td>99</td><td>9</td></tr><tr><td>29</td><td>240</td><td>7. 9</td><td>99</td><td>99</td><td>9</td></tr></table>

资料来源: 爱荷华州基础技能测试 \( {}^{\text{⑧}}\left( {{ITB}{S}^{\circledR }}\right) \) 。版权(C) 2006 由河滨出版公司出版。保留所有权利。 未经河滨出版公司书面许可不得以任何形式或任何方式对此内容进行复印或传送, 无论是电子还是纸质, 包括影印和记录, 或是使用任何形式的信息存储或检索系统, 联邦版权法明文规定属合法行为的除外。敬请垂询河滨出版公司合同与许可部, 伊利诺伊州罗林梅多斯市, 戈尔夫路 3800 号, 邮编 60008-4015。



由表 3-6 很容易看出, 不同的常模体系只是以不同的方式呈现同样的内容, 每两者之间可以相互转换。因此, 若一名三年级学生在 11 月份测试中的成绩对应的正态曲线当量为 66 , 其相应的年级当量为 4.2 . 同样地, 若年级当量为 4.0 , 则对应的百104分等级为 73 , 九分评分制中的指数为 6 。不同解析机制的用途也各不相同。

然而, 测量不同的学科或特征时所使用的不同常模体系并非总是完全一致的。 出现这一差异性的原因在于相对于某一年龄段或年级水平的分值分布, 有些功能属性成长或变化的速度更快。这一点在对比类似阅读理解和数学这样的科目上体现得尤为明显。具体例子请看表 3-7 所示, 基于爱荷华州基础技能测试 (ITBS) 抽取这对分数。假设对达到了五年级第五个月 (学年中期测试常模) 学习水平的三名男生进行测试。约翰在两项测试中的成绩都只达到平均水平。他的成绩对应的年级当量为 5.5 , 在所有参加测试的达到五年级第五个月学习水平的小学生中排名接近第 50 位百分位数。而亨利的表现非常优秀, 但怎样比较他在这两门学科中的表现? 从某个角度来说, 他在两项测试中的表现一样好。从年级当量上说, 他都是仅比其他同学高一年。但从百分位数上讲, 其数学和阅读成绩分别对应第 74 位和第 65 位百分位数, 这样说来, 他在数学上的表现又要好于阅读。另一位学生威尔在阅读和数学测试中的成绩对应的百分数相同,但对应的年级当量却分别为 7.5 和 6.7 。



表 3-7 发展标准分数、年级当量和百分位数的比较

<table><tr><td rowspan="2">分 数 分 类</td><td colspan="3">阅读 理 解</td><td colspan="3">数学运算</td></tr><tr><td>约翰</td><td>亨利</td><td>威尔</td><td>约翰</td><td>亨利</td><td>威尔</td></tr><tr><td>发展标准分数</td><td>210</td><td>223</td><td>235</td><td>210</td><td>223</td><td>226</td></tr><tr><td>年级当量</td><td>5.5</td><td>6.5</td><td>7.5</td><td>5.5</td><td>6.5</td><td>6.7</td></tr><tr><td>百分等级</td><td>50</td><td>65</td><td>77</td><td>53</td><td>74</td><td>77</td></tr></table>



上述例子所示的不一致性源于学生在阅读和数学测试中的表现和成绩提高速率的多变性。阅读理解测试中, 相对于年级间的平均变化而言, 某一个年级群体内学生的成绩波动幅度较大。有些五年级学生的阅读能力比八、九年级学生的平均阅读水平还高, 因此五年级学生的阅读成绩对应的年级当量为 8.0 , 甚至是 9.0 的情况也并不是没有。事实上, 在该特定系列的测试中, 对于达到五年级第五个月学习水平的小学生而言,年级当量为 9.0 对应第 89 位百分位数。在测试的五年级学生中,有 \( {10}\% \) 学生的阅读水平与九年级学生的平均水平相当。相比之下, 几乎没有一位五年级学生在数学测试中的表现能够达到八年级或九年级学生的平均水平。部分原因在于五年级学生还没接触到或学到许多到六、七、八年级才会教授的数学原理, 而这些原理在相应年级水平的测试中大多都会考查到。而阅读理解中涉及的所有基础技能, 通常在五年级就已经完全掌握, 因此进一步掌握这些基础技能往往会导致学生在阅读测试中表现出更大的差异性。在数学测试中, 情况却截然不同。并非八年级学生在同一项技能上的水平不及五年级学生, 而是他们学习的内容有着本质区别。比如, 五年级学生很可能在学习整数和一些相对简单的分数运算, 而八年级学生将会开始学习小数点和复杂的分数以及几何运算。一位五年级学生可能具有较强的阅读能力, 能够达到理解八年级历史课本的水平, 但鲜有五年级学生能够进行八年级水平的数学运算。因此, 与阅读技能相比, 五年级学生在数学上的能力水平更加趋于一致。

上述这一点须时刻谨记于心, 尤其是对比不同学科之间的年级当量时。从年级当量的角度解析测试结果时会发现, 聪明的小孩往往在阅读和语言能力表现上会极其突出, 而在数学和拼写技能上则表现一般。这一差异性可能在一定程度上或完全是因为测试对象的特征在增长速率上的差异性, 而与其实际成长或变化过程中的不均衡无关。为此大多测试专家都不倾向于使用年级当量, 而对百分等级或某种类型的标准分数青睐有加。但是, 由于在学校这个特定的环境中, 年级当量具有简单而直接的意义, 因此在学校教职人员中间仍然颇受欢迎, 大多测试发布者制作常模表格时也会将它包括在内。

## 3.5 商 数

在智力测试的早期阶段, 在开始使用年龄常模几年之后, 将年龄分值量表转化为可以体现进步速率指数的需求越来越强烈。一个八岁的儿童对应的年龄当量为十岁半, 这显然说明其成长率或成熟率高于平均水平。但是具体高多少呢? 为此我们需要考察一些有关实龄或生理年龄 (实际生活和成长的时间) 的指标以及测试分数所对应的年龄当量 (分值所达到的等级或水平)。

相应地, 当时人们也提出了一则权宜之计, 即用测试对象的实龄除以其测试成绩所对应的年龄当量, 生成一个商数。该操作方法在智力测试中的应用尤其广泛, 测试成绩对应的年龄当量被称为心理年龄, 相应的系数被称为智商 (IQ)。到了 20 世纪 20 年代, 人们一般习惯将相应数值乘以 100 (消除小数点), 从而形成了在当今心理学和教育学领域普遍使用的年龄量表的通式 (参见第十二章)。但是, 在处理年龄当量分值计算商数的过程中也存在一些问题。而且, 测试的特征或属性停止增长后, 商数就开始下降,因为实龄仍在不断增长。

智商(IQ) 的概念深深扎根于心理学和教育学测试的发展过程和当代美国语言文化之中。智商测试这一词也已成为我们在日常生活表达中的一部分。我们很可能常常不可避免地会接触到它。但对于智商的定义方式又发生了新的变化。在各种情106形中, 智商已经成为了一种常态化的标准分数, 即以 100 为平均值, 15 为标准偏差, 同时使用者应该认同这种模式并在这种惯常模式下使用。这些值有时被当作智力商数偏差或智商偏差, 因为它们其实就是以高于或低于平均值 (100) 的偏差值的方式来表示的标准分数。为了更准确地反映分值真正的本质, 斯坦福-比内智力量表的 1986 年修订版以标准年龄值一词代替了智商, 许多测试都有样学样, 不再使用智商一词。

不幸的是, 分析和呈现智商的分值量表在不同测试中的含义并不完全一样。首先, 不同的测试中用于测量智力的任务各不相同。而且, 不同的测试选取参照常模的时间点以及抽样程序也不一样。这些程序上的差异性也会影响选取的常模参照组, 进而影响用于评估任一学校或社区群体智商的分值的分布情况。弗林 (Flynn, 1984, 1998) 所做的一系列研究表明, 全世界人类的智商在很长一段时间内保持着稳定增长, 具体至少可追溯到 20 世纪 30 年代中期。也就是说, 现在 15 到 20 岁的常模群体很可能不适于在研究中使用。这一有关全人类平均水平的变化会阻碍我们纵向比较不同时间段内数据或是在时间上具有连续性的多个测试结果。与智力以及测量智力的测试相关的问题会在第十二章中进行介绍。

## 3.6 分 数 组 合

前述各种不同的常模参照体系使我们能够以一些通用单位表示许多截然不同的测试中得出的分值, 所以比较这些分值能够得出有意义的结果。我们无法直接将在拼写测试中拼对了 30 个单词所得的成绩与在数学测试中算对了 20 道题所得的成绩进行对比。但是, 如果将二者的成绩同时转换为相应的年级等级或在某一特定的共同体中超过的人数所占百分比, 就能够进行有意义的对比了。以某一测量通用单位表示同一个人的一组不同的测试分数叫作分值组合。对于每个独立的分数, 可以将相应调整后的分值列成表格进行比较。类似的将多个小学生的分值进行调整的例子可参考图 3-4。将分值组合绘制成图表可以清晰明了地呈现不同子群组之间表现水平的对比结果。如图 3-5 和图 3-6 所示为两种不同的绘图方法。

图 3-4 和图 3-5 中分别呈现了班级成绩单和个人在爱荷华州基础技能测试 (ITBS) 中的综合成绩的一部分。测试发布者通过计算机分析测试分数, 将班级成绩单中的数据反馈给学校 由不同的计算机分析程序得出的结果所绘制的表格在具体细节上会有一定的差异性)。每个小学生在每项测试上会有四项常模参照分数 (如



LIST OF STUDENT SCORES lowa Tests of Basic Skills* (ITBS*) SS-Standard Scov GE-Chade English AB-Mathematic Standard Standard Fermi-device Rank - e-English program proposity proportions program information II-Absolved and IV-A corrections at that leverage \( a \) faults and improved.





图 3-4 学生成绩单

资料来源:爱荷华州基础技能测试 \( {}^{\circledR } \) (ITBS(R)。版权(C) 2001,2006 由河滨出版公司出版。保留所有权利. 未经河滨出版公司书面许可不得以任何形式或任何方式对此内容进行复印或传送, 无论是电子还是纸质, 包括影印和记录, 或是使用任何形式的信息存储或检索系统, 联邦版权法明文规定属合法行为的除外。敬请垂询河滨出版公司合同与许可部, 伊利诺伊州罗林梅多斯市, 戈尔夫路 3800 号, 邮编 60008-4015。

图 3-4 所示)。表上第一行为每名学生在 13 种分科考试和 8 种复合考试上的发展标准分数 (该测试发布者称之为标准分数)。第二行分值为年级当量 (GEs), 由于测试对象为达到了三年级第八个月学习水平的学生, 美国国内所有学生的整体平均水平即为 3.8。后两行分别为每名学生在九分评分制中相应的值 (NS) 和百分等级 (NPR), 计算这些数值时均以全美范围内 2000 年春季学期的学生为常模参照组。 由艾略特。约翰逊在阅读测试中的总得分可知, 这四种分值体系对其表现水平的评估描述基本上是一致的。他的阅读成绩对应的年级当量为 2.5 , 低于平均水平。这一点也反映在其在九分评分制中的等级和百分等级中, 二者的值分别为 3 和 18 。标准分数量表下相应分值为 164 , 在达到三年级春季学习水平的学生中同样属于低于平均表现水平。所有这四种参照体系都说明他在阅读能力上远低于平均水平。与阅





图 3-5 学生成绩组合图

资料来源: 爱荷华州基础技能测试 \( {}^{\circledR } \) (ITBS \( {}^{\circledR } \) )。版权(C) 2001,2006 由河滨出版公司出版。保留所有权利。未经河滨出版公司书面许可不得以任何形式或任何方式对此内容进行复印或传送, 无论是电子还是纸质, 包括影印和记录, 或是使用任何形式的信息存储或检索系统, 联邦版权法明文规定属合法行为的除外。敬请垂询河滨出版公司合同与许可部, 伊利诺伊州罗林梅多斯市, 戈尔夫路 3800 号, 邮编 60008-4015。



读相比, 艾略特在一些语言技能上的表现却好得多, 他在这些方面达到了相应年级学生的平均水平。

图 3-5 所示为同一名学生连续两年的测试数据 (五年级和六年级)。若认识上偏左一点理解所谓的 “发展量表”, 实际上指的就是年级当量 (GEs) 量表。因此, 该小学生在首次词汇测试中的成绩对应的年级当量为 3.7 。下一年在同样的测试中的得分对应的年级当量则为 4.6 。虽然在这两年中的任意一年里, 学生在不同学科上的表现水平都具有较大的差异性, 但其在每个子测试中的水平增长是相近的, 约为一个单位的年级当量。

测试结果表明, 其成绩大概等于或高于全国平均水平。在五年级测试中的分数组合显示她最擅长的能力和学科有首字母大写、科学、阅读理解, 最不擅长词汇和拼 PROFILE NARRATIVE FOR ELIOT JOHNSON Class/Geoup: Ness lowa Tests of Basic Skills* (ITBS*)







学校评语:

此处请保持空白, 以便老师填写评语或供学校填写其他格式信息之用。

艾略特·约翰逊的成绩：

艾略特2002年4月参加爱荷华州基础技能测试。 测试时, 他是达伦学区朗费罗学校的一名三年级学生。

综合成绩为其在所有测试中的整体表现水平。 艾略特的全国综合成绩对应的百分等级为 27 . 说明其得分超过了全国 \( {27}\% \) 的三年级学生, 但似乎略低于三年级学生平均水平。学生阅读能力会影响其学业上许多其他科目的成绩好坏。与全国其他三年级学生相比, 艾略特的阅读得分相对较低。可以对同一学生的不同成绩进行比较以发现其强项和弱项。艾略特在拼写、首字母大写、标点符号及数学解题和数据分析上的表现似乎相对较好, 而相比艾略特的其他测试科目, 尤其还需要加把劲的两门为阅读理解和词汇分析。

图 3-6 综合成绩描述报告

资料来源: 爱荷华州基础技能测试 \( {}^{\circledR } \) (ITBS(R))。版权(C) 2006 由河滨出版公司出版。保留所有权利。 未经河滨出版公司书面许可不得以任何形式或任何方式对此内容进行复印或传送, 无论是电子还是纸质, 包括影印和记录, 或是使用任何形式的信息存储或检索系统, 联邦版权法明文规定属合法行为的除外。敬请垂询河滨出版公司合同与许可部, 伊利诺伊州罗林梅多斯市, 戈尔夫路 3800 号, 邮编 60008-4015。

写。在比较其在几项连续的测试中的表现时, 会发现过分注重分数组合中过于微小的波动带来的不便。虽然近年来研究显示, 分数组合的波动幅度模式相对稳定, 但比较优势也会随着年龄的增长显示出细微的变化。

图 3-6 所示为另一种绘制反映爱荷华州基础技能测试结果的分数组合图的方法。图中含有艾略特。约翰逊在组合测试里每一项子测试中的成绩。注意这里每个独立的方形条代表着不同的测试, 而不是将不同的点连成一条线。这里使用的量表为百分等级量表, 但在绘制与各百分位数的值相对应的图表时会做适当的调整, 以尽量保证百分位量表单位的均匀度或均等性。也就是说, 每个百分位数相应的点的分布与正态曲线分布相同, 在高峰部分较稀疏, 在扁平的两端则较密集。该百分位量表与图 3-3 中所示的百分位当量量表相对应。微调后, 我们将个人百分位数对应的值110绘制在一张刻度单位均匀的图表上。由此, 我们就可以将两点之间的直线距离当作等量的能力水平上的差异, 不论这条线是位于图表的上部、下部还是中部。同样地, 相同的距离在不同测试中所表示的特征或能力也可认为是等量的。

在图 3-6 所示的分数组合表上,添加了阴影的中间那 \( {50}\% \) 的数据为平均水平范围内的常模组。图中由左向右的方形条表示该学生的各科成绩。在这类常模中, 整个群体的平均值即为该量表的锚点或定位点, 个人成绩评估则以此为参照。通过这类图表可以轻而易举看出个人在哪方面能力较强或较弱。还有一点需要注意的是, 该学生在全国常模组中的百分等级对应的数值显示在其分数组合表的左边。此外, 该特定的测试发布者提供的分值分析是从常模参照标准角度对其分数组合进行的解析。这同样有助于将老师和家长们的注意力吸引到学生表现中更值得关注的特征上来。因为这张分数组合图本来就以将学生的情况反馈给家长为目的, 表上还留有教师评语栏。

分数组合图是一个清晰地呈现单个人成绩的十分有效的方法, 但是解析这些分数组合时也要小心谨慎。首先, 绘制分数组合图的前提是测试中使用的常模具有可比性。为此, 在所有测试中, 年龄、年级或百分位分数必须基于等效的群组。所有子测试中的常模应该在同一时间点建立, 且基于同一组测试群体。这样就保证了内容各异的测试中的常模之间具有可比性, 这也是一套完整的测试组合最具吸引力的特征之一。若要绘制多项独立测试的分数组合, 测试之间各不相关, 通常我们只能希望基于测试对象建立的常模之间具有可比性, 且分数组合能够不含偏见地呈现不同学科或能力特征上的相对表现。当不得不使用多项来源各异的测试时, 有一种保证它们具有等效的常模组的方法, 即基于一个共同的测试群体因地制宜地建立地方常模, 并根据这些地方常模绘制个人的分数组合图。

解析分数组合的过程中的第二个问题, 即明确我们应在多大程度上关注分值的波动幅度。并非分数组合中出现的所有差异都有意义, 无论是从统计学还是实践意义上来说。因此, 我们要了解哪些差异值得花时间关注, 哪些不值得。出现这一问题是因为没有哪一项测试分数是完全准确的。这里不存在类似的神奇临界点, 某个分值差异达到那个临界点, 然后突然就变得有研究价值。此外, 任何一条经验法则最多也只能算是给我们提供了一个大致的方向。但在开始进行实践分析之前, 要先确定分值差异必须足够大到测试者有把握相信在重复测试中这些差异一直存在, 而且它们所表征的相应表现水平也具有实际明显的差异。在第四章中介绍信度时会对这一问题进行回顾。

## 3.7 标准参照分析报告

因为对从标准参照角度解析测试分数感兴趣, 测试发布者们也开始研究和制作反映学生在特定题目内容上成绩表现的分数组合图。一项精心设计的测试中的题目会考察到相关知识技能的各个方面。现代化的测试评分体系和计算机技术使我们可以分析呈现一个学生在一道大题中的子题集上的表现, 这些子题集本质上与特定类别的内容是一致的。图 3-7 所示为基于爱荷华州基础技能测试的相关分析报告。







图 3-7 学生标准参照技能分析

资料来源: 爱荷华州基础技能测试 \( {}^{\text{⑥}} \) (ITBS \( {}^{\text{⑧}} \) )。版权(C) 2006 由河滨州版公司出版。保留所有权利。 未经河滨出版公司书面许可不得以任何形式或任何方式对此内容进行复印或传送, 无论是电子还是纸质, 包括影印和记录, 或是使用任何形式的信息存储或检索系统, 联邦版权法明文规定属合法行为的除外。敬请垂询河滨出版公司合同与许可部, 伊利诺伊州罗林梅多斯市, 戈尔夫路 3800 号, 邮编 60008-4015。

图 3-7 中的分析报告列出了爱荷华州基础技能测试中每一项测试里的每一道子项目, 同时还标出了评估该项技能所对应的题目数。另外也给出了该学生回答的题112目数, 该学生的正确率, 全国范围内学生的正确率, 以及后两者的对比差。与一般的常模参照分析报告不同, 通过该分析报告, 老师能够更加尽可能细致详尽地了解学生强项和弱项的具体方面。例如, 从上述分析报告可知, 这名学生似乎尤其不擅长使用缩写符号、引号和冒号, 尽管她在标点符号测试中的整体表现达到了平均水平。虽然测量每一项子技能的题目过少, 以致不足以得出可靠性较高的评估结果, 但从中提取的信息对老师的课堂教学以及针对单个学生设计教学内容仍具有一定意义和价值。技能前标加号 \( \left( +\right) \) 表示该学生在此方面能力相对较强,而标减号(-)则表示相对较弱。

通过单项分析能够了解更多有关该学生表现的细节, 如图 3-8 所示, 即为一个班级有关数学概念和估算测试结果的部分细节内容。每一列代表一名学生, 每一行对应一个项目。根据每道题测量的技能将其编号, 并在表格上标出, 同时能看到学生给出的相应题目的答案正确与否 (实点表示正确, 非实点表示不正确)。教师从此图可经河滨出版公司书面许可不得以任何形式或任何方式对此内容进行复印或传送, 无论是电子还是纸质, 包括影印和记录, 或是使用任何形式的信息存储或检索系统, 联邦版权法明文规定属合法行为的除外。敬请垂询河滨出版公司合同与许可部, 伊利诺伊州罗林梅多斯市, 戈尔夫路 3800 号, 邮编 60008-4015。 以看到, 在第 23 道题上, 共有 8 名学生选择了正确答案, 1 名学生未答题, 7 名学生选了 \( \mathrm{A} \) 选项,2 名学生选了 \( \mathrm{C} \) 选项,还有 1 名选了 \( \mathrm{D} \) 选项。查看导致大多数同学出错的 A 选项, 这位老师就能判断出学生在哪项具体技能上还需要额外的练习。该校学生及该班学生和全国常模组在每道题上的正确率也显示在图中, 以便进行对比。





图 3-8 单项分析

资料来源: 爱荷华州基础技能测试 \( {}^{\circledR } \) (ITBS(R)。版权(C) 2001,2006 由河滨出版公司出版。保留所有权利。未



图 3-8 是对学生逐个进行分析, 阐述细节。但要考察班级整体在哪些方面的表现较强或较弱, 或许从如图 3-9 所示的图表中提取到的信息会更有用。这份分析报告, 将该班级的整体表现与全国常模组同一年级和整个学校进行比较。结果如图所示, 不仅以数字的形式, 还以图形的形式依次逐个列出了每道题的正确率。图中的两条垂直线表示当差异度小于 \( {10}\% \) 时,基本上就可以忽略不计了。该班级数据的分析结果表明, 其中大多数人在解决问题的能力和使用的方法步骤上优于常模组平均水平, 在其他方面的表现与全国常模平均水平相近 (注意对该班级数据的完整表格中考察其他方面知识技能的测试题目进行分析, 其结果与上述结论应该是一致的)。





图 3-9 分组项目分析



资料来源:爱荷华州基础技能测试 \( {}^{ \otimes  } \) (ITBS*)。版权(C) 2001,2006 由河滨出版公司出版。保留所有权利。 未经河滨出版公司书面许可不得以任何形式或任何方式对此内容进行复印或传送, 无论是电子还是纸质, 包括影印和记录, 或是使用任何形式的信息存储或检索系统, 联邦版权法明文规定属合法行为的除外。敬请垂询河滨出版公司合同与许可部, 伊利诺伊州罗林梅多斯市, 戈尔夫路 3800 号, 邮编 60008-4015。

基于内容和基于常模的参照体系可以同时在一项测试中使用, 且在分值解析上能起到互补的作用, 图 3-7 很好地阐述了这一点。分析报告显示, 在基于内容的参照体系下, 该学生的表现是依据其在涉及该内容的题目上的正确率, 其班级整体表现的平均水平以及该年级当量对应的全国常模组的平均水平进行评判的。比如, 有些其他分析报告中所显示的, 相对于全国常模、教学体系或教学水平 (在校表现), 对某个班级整体在每道题上的表现进行评判, 或是如图 3-7 中总结的整个班级中每一个人的信息。该测试发布者的测试日录清单上列出了三十多种可用的分析报告模板。但是, 谨记如下这一点十分重要, 即对标准化的测试进行标准参照常模角度的解析时, 所使用的与相应内容领域或教学内容有关的题目数量极其有限 (有些情况下甚至只有一道或两道题)。因此, 任何基于这样的数据得出的结论, 其可靠性肯定不高, 应该运用其他来源的信息对其进一步验证。

## 3.8 学校平均水平常模

到目前为止, 我们已经说明了如何分析个人在一项测试中的水平等级问题。有时我们会碰到有关一个班级、学校、学区, 甚至是整个州所有学生的相对表现的问题。 当前社会对教育问责制的重视也要求教育工作者们对评估上述任一群体中学生的表现给予足够的关注。在对比评估两所学校学生的成绩水平时, 就需要用到学校平均水平常模。

首先应该明确, 不同学校学生整体平均能力或成绩之间的差异性比单个学生之间要小得多。一所学校学生的平均水平不可能达到第一名学生的水平, 甚至连接近都极其困难, 同样它也不可能接近最后一名学生的水平。因此, 若一名刚上五年级的小学生在阅读上的成绩对应的年级当量为 6.2 , 则其排名在所有五年级学生中位于第 75 位百分位数所在处。而一所学校内所有刚上五年级的小学生的平均阅读水平对应的年级当量为 6.2 , 那这所学校该年级学生的整体水平会排在所有对比对象里的第 94 位百分位数处。表 3-8 对用于个人或群组的常模之间的关系进行了更详细的解释。这两种分值分布以同一点为中心, 但越往四周延伸, 个体之间的差异性表现得就越明显。以此测试为例, 其中某个测试对象的年级当量为 6.6 , 对应第 79 位百分位数, 但一所学校学生平均水平的年级当量为 6.6 , 则对应第 92 位百分位数。低于平均水平的成绩和表现同样如此。

若一所学校的校长或最高行政管理人员想要了解如何分析学校整体平均水平, 最适宜的方法就是建立和使用学校平均水平常模, 这些可以都要求测试发布者提供。 做得更好的一些测试发布者往往也会提供一些在整个班级、学校、学区或全州范围进行考察的单项目分析和标准参照分析报告。



表 3-8 针对五年级秋季学期学生进行的爱荷华州基础技能 A 类词汇测试中

个人和学校的平均常模

<table><tr><td>年级当量</td><td>个人百分等级</td><td>学校平均水平百分等级</td></tr><tr><td>9.4</td><td>99</td><td>99</td></tr><tr><td>7.2</td><td>87</td><td>97</td></tr><tr><td>7.0</td><td>87</td><td>96</td></tr><tr><td>6. 6</td><td>79</td><td>92</td></tr><tr><td>5.7</td><td>61</td><td>97</td></tr><tr><td>5.7</td><td>58</td><td>62</td></tr><tr><td>5.7</td><td>50</td><td>48</td></tr><tr><td>5.7</td><td>46</td><td>43</td></tr><tr><td>4.4</td><td>34</td><td>23</td></tr><tr><td>4. 0</td><td>50</td><td>11</td></tr><tr><td>3. 6</td><td>87</td><td>97</td></tr><tr><td>3.5</td><td>50</td><td>4</td></tr><tr><td>2.4</td><td>5.7</td><td>96</td></tr><tr><td>1.0</td><td>50</td><td>1</td></tr></table>

资料来源: 爱荷华州基础技能测试 \( {}^{\circledR } \) (ITBS \( {}^{\circledR } \) )。版权(C) 2001,2006 由河滨出版公司出版。保留所有权利。 未经河滨出版公司书面许可不得以任何形式或任何方式对此内容进行复印或传送, 无论是电子还是纸质, 包括影印和记录, 或是使用任何形式的信息存储或检索系统, 联邦版权法明文规定属合法行为的除外。敬请垂询河滨出版公司合同与许可部, 伊利诺伊州罗林梅多斯市戈尔夫路 3800 号, 邮编 60008-4015。



## 3.9 常模使用注意事项

对于一项评估个人在某一知识领域的能力或一些特征上的水平等级的测试而言, 常模是解析个人或群体得分最基本的方法。将任意一项测试中的分值逐一转换为相应的年龄或年级当量, 百分等级或标准分数, 我们在那一个层次水平里对该个体进行的分析对于该特定的测试而言就是有意义的。将某一测试对象的一组分数换算成通用测量单位, 放在一起比较, 或许还可以用这些值绘制分数组合图, 以对比该个体在不同学科领域的相对能力水平。

一所学校里的一个年级、班级, 或整个教育体系中就读同一个年级的所有儿童, 其平均水平可能都差不多。紧接着, 我么可以考察该群体内部所有成员在某一技能116上的平均水平或不同地区每一个同等条件的群体之间的相对表现。常模为我们提供一种参照体系, 在该参照系中会出现一种对比效果, 将这些对比效果集中起来就能找到一个共通的点。现在问题来了, 这里所说的对比效果具体指什么, 在实践中如何处理和运用?

很显然, 要在短短几页篇幅内得出与每一组实际测试的分值相对应的现成分析结果是不可能的。但是, 我们可以介绍一些通用的准则和原理, 或许能够起到预防一些对测试结果考虑不够全面的分析理解。

应该牢记的最基本的一点, 即以任何常模量表呈现的测试结果都是在描述是什么, 而不是规定应该是什么或将会成为什么 (尽管测试也会对考察对象将来可能的表现做出相关预测)。测试结果使我们能够针对学业成绩或性格特征上的一个或多个方面, 将某一个体或班级与另一个体或班级进行对比。但这些结果并不一定能说明某一个体的表现是“好”还是“不好”, 导致出现这一想象的原因有好几个。

常模分数传达的信息往往是相对的, 而非绝对的。通过它只能判断某个学生或某一班级的成绩或平均水平是否和其他一些学生或班级的一样高, 而无法了解学生是否掌握了基本数学概念, 或者他们的阅读水平是否达到了能够理解个人所得税申报表填写说明的程度。此外, 从中也无法得知, 在我们的教育体系始终保持一个更高的效率运转的前提下, 老师能够对所有学生的提升空间抱多大期望。

记住有多少人高于平均水平, 就有多少人低于平均水平, 这是相对分数的本质特征。当“常模”表示某一参照组的平均水平时, 从统计学角度看, 该群体中必然有大约一半的人或多或少低于平均水平。不仅在单个学校中, 甚至在全州范围内的立法中, 都存在大量有关要将学生成绩“提高到年级常模水平”这样荒谬可笑的做法。如果我们的教育体系效率骤升的话, 这在短时间内或许是可行的。但是, 在该测试中再次建立新的常模之后, 则需要绝对意义上更高的能力水平, 比如达到六年级学生的平均阅读水平。所以又回到了一半人高于平均水平, 一半人低于平均水平的情形。而且, 万一该学校的效率又回到之前的水平, 就有可能会出现不容乐观的局面, 即超过一半的学生在测试中的表现 “低于年级常模水平”。

相对性是常模的本质特征, 这一点在标准参照测试的发展过程中已经得到了认识和认可。当一位教师或某个学校想衡量学生在一些特定教学目标上是否达到相应掌握程度时, 在一些代表相应可接受掌握程度的标准的规约下, 设计一些评估该教学目标的测试练习题来确定哪些学生已掌握以及哪些没掌握该特定教学内容, 与通过对比其他学校的同年级学生来判断该学校学生的表现相比, 可能更有效。结合上下文可知, 所有人均达到掌握水平是有可能实现的, 只是一些学生与另一些相比能更快掌握相关内容。即使是在标准参照体系中, 个人成绩水平也会存在一定的差异。

输出须根据输入进行评估。测试结果是典型的信息输出, 即在个人或群体进行测试的时间点输出其在接受了一段既定时间的教育之后的一些信息。但输入又包含了些什么? 对该群体的输入是从什么时候开始的?

输入的概念十分微妙且复杂。要理解它, 不仅要在我们的能力范围内考察所测量的该特定能力在其早期阶段的状态以及该个人潜在的学习能力, 还要考虑到个人成长的家庭环境, 因为有些儿童更适应家庭环境中的学习氛围。父母对孩子的期望和鼓励、他们在引导和辅导孩子学习方面的能力、其自律和自我约束能力、语言技能和家中能接触到的文化资源都是输入的一部分, 好比这些也是影响该年轻个体生理特征发展变化的毋庸置疑的一部分。此外, 尽管可能并非永久性的, 但就某个儿童的学习能力的预期情况而言, 同龄群体之间的交往和态度也是输入的另一个实实在在的组成部分。要明白评估输入时要充分考虑所有因素并非易事, 并且对相应的输出结果做出的 “满意” 或 “不满意” 的评估也并没有十分的把握, 甚至可以说很低。

输出须根据预定目标进行评估。那些已发布的标准化测试的设计、内容和参照常模都是基于这些测试的研发者自己对于一般国家课程教学目标的理解。其中的题目, 相对重要的点以及所考察的水平或等级均反映了他们所理解的一般的国家教育体系模式。因此, 从某种意义上来说, 如该测试研发者所解释的, 某一特定的学校体系偏离了国家规定的相关教学目标和课程设计的重点, 那么则可预测其某一年级水平相关测试结果的输入也会偏离国家常模水平。如果学生的计算机使用能力未得到重视, 会发现其计算机设备可能不够先进。若地图识别能力低于测试所考察的相应年级水平, 则可能会发现测试对象在与此相关的内容上得分表现惨淡。与国家常模相比, 地方分数组合往往参差不齐, 由此我们会思考, 那些低分是否说明为达到自己的教学目标设计的教学内容和计划是失败的, 抑或是其在教学设计上偏离了更典型的一般国家教育体系模式中设置的重点。有意更改课程设计所导致的学生表现不佳, 远没有按照所规定的该课程设计的重点进行教学而得到同样的结果更值得我们提高警惕。如果满足了上述这些条件, 毫无疑问也会影响甚至改变原来的分析结果。

从某种意义上来说, 各州都为自己所有的学区设定了统一的最低教学目标, 而且往往可以与一些测试发布者签订合约, 以使用一些精心设计的用于测量这些教学日标中学生成绩的标准化测试。现在, 有几个州已经与一些专业的测试研发组织达成合约关系, 以根据州教育委员会提出的具体要求设计相关测试。这类测试通常用于118学校教育计划中某些特定的时间点对学生成绩进行评估, 比如小学毕业升初中、初中毕业升高中或高中毕业时。

如果学校的老师、校长、相关负责人或校董事会谨记上述考虑因素和在后两章中将会介绍到的一些条件, 在解析这些测试结果的分析报告时就会越来越得心应手了。

## 3.10 第三参照系: 项目反应理论

有关测试的许多最新研究进展都源自所谓的项目反应理论 (IRT), 或潜在倾向理论 (这两个术语在这本书中会或多或少地互换使用)。这一研究方法最初可追溯到 1910 年以前, 在 20 世纪 20 年代期间, E. L. 桑代克和 L. L. 瑟斯通对该理论原理做了详细的阐述 (详见罗伯特・M. 桑代克, 1999a), 但理论的实际应用要视计算机的可操作性而定。反过来, 项目反应理论本身也会在一定程度上制约计算机在测试中的使用。接下来看一下该理论体系和在计算机中实际应用时的可操作性之间的关系和相互的影响与发展。我们将主要从认知能力角度展开介绍, 但项目反应理论同样可以应用于人格或其他心理特征方面的测量。更多详细信息可参考延和菲茨帕特里克 (Yen and Fitzpatrick, 2006)。

潜在倾向理论的前提是存在一个相对统一或一致的潜在特质或特性, 即某个测试对象是否具有能成功完成一些特定类型认知任务的能力。这些潜在属性可能是词义的理解、算术推理或空间想象能力。我们可以用一条水平轴表示该特征 (如图 3-10 所示), 将任务和测试对象按顺序依次列在上面。该例子中所采用的任务即词语解释, 测量特征为对词义的理解。相应地, 测试中的题目则会考察到多个与此相关的方面, 但每道题都应该相对清晰明确地针对某一个具体特征。





图 3-10 词汇知识量表



如上这个标有这些任务的量表可被看作一个标示难易程度的量表 (或者也可当作做出这道题所需的能力水平), 如此图中单词的难度则从左到右依次增加。一道题的难度是依据受试者中有一半人能够答对所对应的能力水平而定的。对于每一道题,答对的概率为 \( {50}\% \) ,量表上相应的点用 \( b \) 表示。那么,这五个需要学生解释的单词则对应五个不同的 \( b \) 值或题目的难度系数。

对人而言, 则可将该量表看作一个能力标尺。通过一个人刚好能够完成的任务等级可以了解其能力水平, 即该受试者能够答对测试中的一半题目所对应的难易水平程度。因此, 若乔极有可能了解 “借 (borrow)”一词的词义, 则说明他的能力超过了这道题的难度, 但如果乔有很大可能不知道 “切口 (incision)”一词的词义, 则说明这道题的难度超过了他的能力水平。比利能够正确解释“借”的可能性相对较低, 但他很可能能够正确解释“挖 (dig)”一词的意义。个人和任务对应节点的排列顺序形成了这一水平量表。我们以第八个希腊字母 \( \theta \) 表示个人的能力水平。那么比利的能力对应的 \( \theta \) 值相对较低,乔和琼斯先生的 \( \theta \) 值属于中等水平,而汤普森博士的 \( \theta \) 值则相当高。

值得注意的是在这一模型中, 个人的能力水平是会随着时间的维度而变化的。 也就是说,如果现在比利六岁,那他在该能力量表上的位置,也就是他的 \( \theta \) 值,会随着他的成长成熟而变化。相反地, 即使是从整个样本中抽取更大更具代表性的样本进行测试,这些 \( b \) 值,即上述单词的相对难度,在较长一段时间内几乎是不会有太大变化的。正是因为难度量表的稳定性,能力量表才有意义可言。

能力或难度量表是人们自主定义的, 就像华式温度量表 (华氏度) 一样。我们也可使用单位大小不同的量表 (比如摄氏度) 或临界温度不同的量表 (比如摄氏度或开氏度)。但一个既定的量表, 其单位一般都是均匀分布的。单位的大小或临界点的位置并不会影响个人或任务在数轴上的相对位置。以温度量表比较为例, 并不是因为夏天某一天温度读数为 \( {20}^{ \circ  }\mathrm{C} \) 或 \( {68}^{ \circ  }\mathrm{F} \) ,冬天某一天温度读数为 \( {0}^{ \circ  }\mathrm{C} \) 或 \( {30}^{ \circ  }\mathrm{F} \) ,所以夏天这一天才比冬天的这一天暖和。这两天在各自量表上的相对位置是相同的, 比如春天的某一天温度读数为 \( {10}^{ \circ  }\mathrm{C} \) 或 \( {50}^{ \circ  }\mathrm{F} \) ,则这一天在相应量表上位于夏天和冬天的正中间。同样地,当温度达到 \( {100}^{ \circ  }\mathrm{C}\left( {{212}^{ \circ  }\mathrm{F}}\right) \) 以上时,水就会沸腾 (标准大气压下),而低于该温度时则不会。

能力水平与答对一道一定难度的题之间并非有或没有的关系, 而是一个概率性问题。图 3-11 所示为个人能力与答对一道题的概率之间的关系图。该图形中的曲线被称为题目特征曲线或题目轨迹曲线, 每道题有一条这样的曲线与之对应。由题目特征曲线可知, 个人答对一道具有一定难度的题的概率随着其能力水平的上升而增大。因此, 如果在针对与乔同等水平的群体进行的测试中, 出一道题要求解释切口一词,那么将有 \( {25}\% \) 左右的人能够回答正确。若针对与琼斯先生同水平的群体,则会有 \( {85}\% \) 左右的人能给出正确解释。反过来说,乔能够正确解释 \( {25}\% \) 左右的难度与切口一词相近的单词,而琼斯先生能够正确解释 \( {85}\% \) 同等难易程度的词。120





图 3-11 关于“切口”一词词义理解的题目特征曲线



由图 3-11 可知, 个人答对一道题目的概率与个人能力水平的相应关系形成了一条曲线, 其两端上升趋势较平缓而中间测试对象的能力水平与该道题的难度相匹配的部分上升较陡。测试题目的差异性在那些能力略高或略低于该任务难度的测试对象上的反映最明显, 而在能力远高于或远低于该任务难度的测试对象上几乎没有任何体现。汤普森博士和其他和她处于同等水平的人几乎能够答对所有难度与“切口” 一词相当的题, 由此可知她的语言能力较高, 但无法知道具体有多高。为了更准确地了解汤普森博士的能力水平, 我们也会需要难度在 “序言 (prologue)” 和 “教义 (tenet)”之间的单词或词语, 因为这些词的难度系数足够大, 而汤普森博士不可能全部答对。

一道题的轨迹曲线表示的是该道题独立于特定测试对象之外的某个特征, 而要绘制出整条曲线取决于我们结合一组能力水平各不相同的群体考察这道题的能力, 选择这样的样本是为了考察到所有层次的能力水平。如果只对具有与乔和琼斯先生同等能力水平的群体使用与“切口”一词难度相近的题目进行测试, 就只能看到两者之间的那段曲线。因为该范围涵盖了相应题目的难易水平 (个人能力数轴上 \( {50}\% \) 的受试者能回答正确的点或这道题的 \( b \) 值),结果不会太差,但如果测试对象都是与比利和汤普森博士同等水平的群体, 关于题目的难度可能就得不出特别具有说明性的结果。

每一道题都有与各自的难易程度 (回答正确的概率达到 \( {50}\% \) 所对应的点也被称为 \( b \) 参数) 相对应的特征曲线和区分度。区分度即该题目将能力较高的受试者与能力较低的受试者区分开来的能力。有关题目区分度的一个广泛使用的指数就是在测量某一特征的一道题上的得分与在整套题上的得分之间的相关系数。受试者在一道题上的正确率随着个人能力变化的速率的其中一个作用即区分不同的能力水平。转化为图形,该变化率即为该题特征曲线的斜率,我们用 \( a \) 表示该曲线的斜率。而 \( a \) 参数即为曲线上回答正确的概率达到 \( {50}\% \) 所对应的点。如图 3-12 所示为难度不同而区分度相同的两道题目相应的特征曲线。这两条曲线的形状是相同的,但它们的 \( b \) 参数和回答正确的概率达到 \( {50}\% \) 所需的能力水平不同。





图 3-12 难易程度不同的两道题目的特征曲线



图 3-13 所示为难度相同但区分度不同的两道题。与第二道题相比, 第一道题的 \( a \) 参数或个人正确率变化的速率上升趋势更急剧。这说明一道题的得分与整套题的得分之间具有更高的相关性。题目的区分度越高, 对受试者能力水平之间的差异性就越敏感。在能力连续体这一横轴上标出的两个人很好地阐明了这一点。在第一道题上, 约书亚回答正确的概率为 0.25 , 雅各布回答正确的概率为 0.75 。而在第二道题上, 二者回答正确的概率则接近得多。由于该题目特征曲线的斜率更低, 也就是题日与受试者能力水平的相关系数更小,所以二者回答正确的概率差只有 \( {20}\% \) ,而非 \( {50}\% \) 。对于这两位受试者而言,这道题本质上是一样的 (但第二道题的确反映了更多不同层次的能力水平)。





图 3-13 难易程度相同而区分度不同的两道题目的特征曲线



对于那些会提供一组既定答案供受试者选择的题目 (判断对错、多项选择以及类似的给出选项供选择的题型), 相应的特征曲线还可以反映通过运气或猜测答对题目的概率。当曲线变得扁平, 即答对题目的概率约等于零时, 反映的即为此现象。曲线趋平时的概率值叫作 \( c \) 参数或猜测参数。 图 3-14 所示曲线中的 \( c \) 值即为 \( {20}\% \) 。这不同于图 3-13 中第二道题对应的曲线的情况。在后一种情况中, 尽管图表中的图形轨迹并没有下降到接近零点值, 但曲线仍然呈现下降趋势。 如果该抽样人群中出现了能力水平极低的对象, 我们也应该考察到相应的受试者答题正确率为零的能力水平。在一些需要受试者自主作答的题目上可能会出现这种情况, 比如单词解释, 而不是从列出的若干选项中选择与该单词相对应的正确解释。需要受试者自主作答的题目, 比如简答题和词义解释题, 这类题目的轨迹图往往会趋向于零, 而那些给出选项供选择的题型则不会。





图 3-14 通过猜测答题的题目特征曲线



计算机自适应测试 (CAT)

要在项目反应理论体系下进行最高效的测量, 需要我们能够为每一位受试者提供最适合该相同水平群体的测试题目。测量这个特征, 计算机必不可少, 而选择相应的测试题目的技术叫作计算机自适应测试, 或 CAT。人们将发展迅猛且具有广泛适用性的计算机技术与项目反应理论结合, 促进了计算机自适应测试的发展。该自适应测试指的是通过计算机对测试任务的难度做出快速调整, 以适应测试对象的能力水平。如前所述, 任务对受试者来说过难或过易都反映不出其真实能力水平。 例如,一位正在申请大学的受试者知道 “挖 (dig)”一词的词义, 根据这一点我们根本无法判断其是否有希望被录取。因为基本上任何一位高三学生应该都了解“挖” 这个词的词义。如果一位该受试者没能给出 “腐败产热的 (fracedinous)”一词的解释, 我们也无法据此判断出其能力水平。很可能十万高三学生中也没有一人知道这一词语的意思。(《韦氏大词典》完整版给出的解释是 “腐败过程中产生热量”。) 使用一些我们预先不知道受试者是否能答对的任务或题日更利于分析其真实能力水平。

理想状态中, 自适应测试首先从一个偏难的水平开始, 我们几乎无法确定受试者是否能够答对这道题。对相应年龄或年级群体而言,该水平通常指约有 \( {50}\% \) 的受试者能够答对该道题。因为没有其他任何特别的信息作参考的情况下, 这是我们能够对该测试对象的能力水平所做的最佳猜测。受试者每答对一道题, 我们对其能力水平的评估就相应有所提高, 进而就能够测试其在下一个难度级别稍高一些的题目上的表现。只要该受试者一直能够回答正确, 我们对其能力水平的评估也会相应地不断提高, 同时提供给该受试者的题目难度也会不断加大。如果最初的猜测是准确的, 即测试开始时选择的难度水平接近其能力水平, 那么该受试者应该很快就会在给出的题目上出错, 如此的话就可以稍微降低我们对其能力水平的评估, 而换一个稍微简单一些的题目进行测试。通过不断的正确与错误检验, 我们很快就能将题目难度调整到接近受试者的能力水平, 而且我们也能根据这些对错测试记录得出有关该测试对象的一个最终的较准确的评价。

通过精心设计的自适应测试程序可以在评估中达到任一既定水平的精确度, 但在针对一个完整的年龄或年级群体设计的传统测试中, 可能需要使用至少一半测试题目。因为在这类测试中, 为了保证题目能满足受试者不同的能力需求, 测试中必须要有难度极低或极高的题目。传统测试中, 只有相对较小的一部分题目对于特定的测试对象而言是符合一般难度水平的。对测试对象所做评估的精确度将在第四章中进行介绍。

具有相应的题库, 并可以从中找到难易程度与我们对受试者当前能力水平的评估最匹配的题目, 这样的自适应测试程序才是真实有效的。而要实现有效自适应测试, 只有计算机才能快速高效地完成该搜索过程。整个题库可以储存在一个硬盘上, 标上难易程度, 如有需要还可以标上题目的区分度和内容类别。此外, 可以编写一个计算机程序, 设置一个合适的答对和答错题目的比例, 以调整其对受试者能力水平评估的准确性, 同时为暂未使用的题目找到新的最佳匹配对象。我们会持续跟进和记录对受试者能力水平的评估以及该评估的准确度。在受试者回答完特定数量的题目或达到了某一具体要求的预估水平时, 计算机程序会自动终止测试。几乎所有计算机程序都是这样设置的, 比如美国学业能力倾向测试和美国研究生人学考试 (GRE)。有关如何使用计算机自适应测试可参考魏纳 (Wainer,1990) 的专著。

计算机自适应测试的特征之一是在任一既定群组中, 每一个人的测试都是独一无二的, 因为他们各自答对或答错了哪些题, 这一点几乎是不可能雷同的。一个表现十分稳定的人, 其测试时间不会太长, 因为程序很快就能确定其能力水平。相反, 若受试者的表现忽好忽坏, 即有时连很难的题目都能答对, 而有时却在一些相对简单的题上犯错, 如此的话, 测试时间可能会相对较长, 以便计算机程序能够对其能力做出同样准确的评估。

项目反应理论和计算机自适应测试还有一个有趣的用途, 即运用统一的评分标准和程序对不同班级的学生或学生在一门课程的各个不同模块上的表现进行评估。 设计像学业能力倾向测试这样的标准化测试的目的之一就是为了能够比较不同学校学生的成绩水平。如果在由不同学校自主设计或用于某一课程不同章节的地方性测试中加入一些经过项目反应理论程序调整的题目, 比如这些学校已经将学生按学习能力进行分班, 那这些测试则具有普适性, 且可以通用的统一量表对这些不同班级学生的相对表现进行评估。有许多不同等级的认知能力测试 (CAT) 使用项目反应理论制定通用量表, 这样的测试分数被称为相应的不同等级测试的通用量表分数。美国大学入学考试同样使用项目反应理论为好几项不同的测试制定通用量表, 这些含有完全不同题目的测试却用于同一组受试者。

如果已在相关通用量表下确定了某一资源充足的题库内题目的难度指数, 我们就可以从中抽取题目进行一系列有用且有趣的测试。其中一些如下所列:

1. 使用任意一套题评估受试者能力水平。如果可以得知一个大题库中用于测量一般特征的题目难度系数, 我们就能通过该题库中的任意一套题对某一个体在该特征上的能力水平做出公正的评估。评估的精准度取决于题目数量, 所选取的题目越多, 测试的精准度也越高。它同样也取决于题目难度与受试者能力水平的匹配度, 匹配度越高, 准确度也越高。但在正确率 (或说选择题中选对的概率) 为 0 或 1 以外的值时, 在任何情况下都不会出现系统性的错误。若正确率为 0 或 1 , 那我们根据这道题完全无法判断该受试者的能力水平。

2. 设计形式具有同等意义的测试。通过从题库中抽取平均难度一致、难度系数波动幅度一致及平均区分度一致的题, 我们可以设计出一些形式具有同等意义的测试。在这些测试中, 任一既定的原始分数均表示受试者相应的同等水平能力, 不论测试的具体形式为何。我们可以使用这些形式的测试测量或评估一些教学领域内容, 在一段特定的教学时间前进行一次测试, 之后再进行一次。或者在有些情况下, 可以采取对座位交替的个体使用不同形式的测试方式避免潜在的试题安全或考生作弊的问题。如果因为某些原因, 受试者不适于某一项测试, 也可以随时调用其他形式具有同等意义的测试。

3. 在测试中进行矩阵式抽样。有时研究人员可能想充分了解和调查一些领域的内容, 其目的或许不在对某些具体的测试对象做出一些判断, 而是想要评估某一班级、学校或学校体系的表现水平。此时就没有必要使用每一道题对每一位受试者进行测试。每个人可以做其中的几道, 直到测试中每一道题都被用上。接下来, 调查人员就可以将该班级、学校或学校体系当做一个综合的 “个体” 进行考察。计算出测试对象在这些已知难易程度的题上的正确率后, 研究人员便可以据此评估该群体的能力水平, 无论是对整个样本还是对样本中某个具体的小部分。该方法使我们可以在合理的范围内进行测试, 而无须涉及整个领域内该调查人员感兴趣的所有内容。

## 3.11 总 结

仅仅是分值本身并不含有任何意义。如果结合测试题目所涉及的相关教学内容领域考察, 此时分数就被赋予了含义。这样我们就可以从个人或群体对该领域内容的掌握程度或测试前对比标准组的表现这两个角度评估其表现。这些赋予原始分值含义的方法被称为标准参照分析。它们适用于针对单个或少量精心挑选的测试对象的测试, 并且用于衡量受试者表现的标准要么基于经验, 要么基于逻辑推理。

因为许多测试的设计初衷即评估测试对象的表现, 而且大多数测试都不存在有意义的绝对标准, 所以我们通常通过与一个或几个参照组进行比较赋予分值意义。 这种赋予分值含义的方法叫作常模参照分析。我们可以与以下类型的常模进行比较:

1. 一系列年级群体 (年级常模)

2. 一系列年龄群体 (年龄常模)

3. 某单一群体, 通常以该群体超过某分数的对象占整个群体的百分比来表示其表现 (百分位数常模)

4. 某单一群体, 通常以该分值大于或小于该组数据的平均值多少个单位的标准差来表示其表现 (标准分数常模)。(这类常模可以通过遵循一定的线性转换来消除小数点或将负值变为正值, 或者通过非线性转换使分数分布正态化。)

每一种方法都有一些优缺点。

智商等商数的提出只是为了用一个简单的指数来表示个体在多大程度上偏离了自己的年龄组。由于商数本身的各种局限性, 它逐渐被标准分数所取代, 在专业术语的使用方面也不再适用了。

如果适用于一些不同测试的常模属于同一类别, 且有对照组, 那所有这些测试则都具有可比性。这样的话, 测试结果也可以分数组合的形式制成图表。分析分数组合重点在个人的分值差异。处理分数组合时, 需格外注意不要过分在意那些过于细微的波动。

常模往往是在描述性框架体系下解析个人、班级群体或更大样本的测试分数。 然而, 在对某一个人或群体的表现是好是坏做出判断之前, 需先考虑其能力水平、文化背景以及所上课程阶段。常模仅仅只是一个平均值, 而不是可以强制每一个人遵从的统一要求。它基于一些特定的对照组对个人当前的能力表现进行说明。126

除传统的方法外, 还可以通过项目反应理论和计算机自适应测试程序赋予分值意义。项目反应理论可以确定每道题的难易程度, 并将该道题放在一段难度连续体中与其他题进行对比考察。同样地, 它也将多个受试者放在相应的能力水平连续体中进行考量。计算机自适应测试 (CAT) 也因此被用来基于某测试对象答对和答错的题目难度, 为其挑选下一道最合适的题。

## 3.12 习 题

1. 为什么用来解析测试分数的参照体系不同, 分析结果也会有差异?

2. 同一个测试是否既可以在标准参照体系中解析, 也可以从常模参照角度解析? 如果是, 这两种解析方式有何不同?

3. 一名六年级小学生在爱荷华州基础能力测试第 12 级阅读测试 (J 类型) 中取得的原试分数为 25 分。解析这个分数还需要哪些额外的信息?

4. 为什么针对高中生的标准化测试几乎从不使用年龄或年级常模?

5. 在西弗吉尼亚乡村的一个县级学校体系中使用全国常模有哪些局限性? 地方学校体系该如何处理和应对这些局限性?

6. 研究和使用年龄常模、年级常模或正态化标准分数都有哪些前提假设?

7. 在图 3-3 中, 为什么标准分数是均匀分布的, 而百分位分数却不是?

8. A 州每年 5 月分别对四年级、八年级和十一年级学生进行一套学业成绩组合测试。该州每个学区中每一门学科的年级水平中值分别汇报给州教育委员会。这些结果有必要汇报吗? 如果是, 报告中还应该包含哪些信息? 州教育委员会可能会如何运用这些分析结果来提高教育质量? 同时应该避免数据在哪些方面被误用?

9. \( \mathrm{P} \) 老师在每年的测试中,能让自己四年级班上 \( {85}\% \) 的学生在每门科目上“达标”, 并且她对此倍感骄傲。这是否应该成为一种教学目标? 从中你能看到哪些局限和危害?

10. \( \mathrm{F} \) 学校根据转校生在学业成绩组合测试中的得分对应的年级当量将他们分配到相应年级。因此,一个年均年级当量为 5.3 的男孩会被分配到五年级, 而不论其年龄或其在之前学校所在的年级。这种做法有什么优点和弊端?

11. 爱荷华州江景区学校的学监发现, 在一学业成绩组合测试中, 斯普林代尔小学的学生一直处于平均比全国常模低半个年级的水平。他为此感到十分苦恼, 因为这些学校学生的平均表现在该市所有学校中是最低的。他的不满意在多大程度上是有道理的? 要回答这个问题, 你是否还需要其他相关信息? 如果是, 具体需要哪些信息?

12. 东森特维尔地区教育委员会注意到其学区四年级和五年级学生在数学上远低于全国平均水平, 虽然他们在其他科目上达到甚至超过了该平均水平。因此, 教育委员会拟对此展开深入研究。请问他们还需要哪些额外信息?

13. 大城校区一些三年级教师打算用一项 30 道题的测试评估学生对乘法运算的基本概念和理论的掌握情况。那么应该以多少分作为“掌握”的标准? 我们又要如何确定这个分数?

14. 根据九分评分制或者正态曲线当量分析测试结果和呈现测试数据分别有哪些优点和缺点?

15. 参阅某考试手册, 并基于相应常模对其进行分析。

a. 常模样本的数量是否足够? 做出相关判断所需信息是否足够充分?

b. 计算测试中通过猜测或蒙对的题目得分 (即可能通过瞎蒙答对的题目分值有多少), 这里需要注意测试对象的年级常模。这说明使用该测试具有哪些局限性?

c. 对于处于测试群体中上限的那部分对象而言, 该测试在实用性方面具有哪些局限之处?

d. 有多少原始成绩绩点达到了该年级当量量表整年的水平? 该分数绩点数目在整个测试范围内都是一致的吗?

16. 你是否参加过计算机自适应测试? 如有, 你觉得它与普通的书面笔试相比有何不同? 如没有参加过任何计算机自适应测试, 你能否思考一下这种测试形式可能在哪些方面影响你的表现?

## 推 荐 阅 读

Angoff, W. H. (1971). Scales, norms, and equivalent scores. In R. L. Thorndike (Ed.), Educational measurement (2nd ed., pp. 508-600). Washington, DC: American Council on Education.

Cizek, G. J., & Bunch, M. B. (2006). Standard setting: A guide to establishing and evaluating performance standards on tests. Thousand Oaks, CA: Sage.

Cohen, A. S., & Wollack, J. A. (2006). Test administration, security, scoring and reporting. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 355-386). Westport, CT: Praeger.

Flynn, J. R. (1998). WAIS-III and WISC-III gains in the United States from 1972 to 1995; How to compensate for obsolete norms. Perceptual & Motor Skills, 86, 1231-1239.

Hambleton, R. K., & Pitoniak, M. J. (2006). Setting performance standards. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 433-470). Westport, CT: Praeger.

Holland, P. W., & Dorans, N. J. (2006). Linking and equating. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 187-220). Westport, CT: Praeger.

Holland, P. W., & Rubin, D. B. (Eds.). (1982). Test equating. New York: Academic Press.

Hoover, H. D. (1984). The most appropriate scores for measuring educational development in the elementary schools: GE's. Educational Measurement : Issues and Practices, 3, 8-14.

Jaeger, R. M. (1989), Certification of student competence. In R. L. Linn (Ed.), Educational measurement (3rd ed., pp. 485-514). New York: Macmillan.

Kolen, M. J. (1988). Defining score scales in relation to measurement error. Journal of Educational Measurement, 25, 97-110.

Kolen, M. J. (2006). Scaling and norming. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 155-186). Westport, CT: Praeger.

Livingston, S. A., & Zieky, M. J. (1982). Passing scores: A manual for setting standards of performance on educational and occupational tests. Princeton, NJ: Educational Testing Service.

Michell, J. (1986). Measurement scales and statistics: A clash of paradigms. Psychological Bulletin, 3, 398-407.

Nitko, A. J. (1984). Defining "criterion-referenced test." In R. A. Berk (Ed.), A guide to criterionreferenced test construction (pp. 8-28). Baltimore:Johns Hopkins University Press.

Petersen, N. S., Kolen, M. J., & Hoover, H. D. (1989). Scaling, norming, and equating. In R. L. Linn (Ed.), Educational measurement (3rd ed., pp. 221-262). New York: Macmillan.

Shepard, L. A. (1984). Setting performance standards. In R. A. Berk (Ed.), A guide to criterion-referenced test construction (pp. 169-198), Baltimore: Johns Hopkins University Press.

Thorndike, R. L. (1982). Applied psychometrics. Boston: Houghton Mifflin.

Thorndike, R. M. (1999a). IRT and intelligence testing: Past, present, and future. In S. E. Embretson and S. L. Hershberger (Eds.), The new rules of measurement: What every psychologist and educator should know (pp. 17-35). Mahwah, NJ: Erlbaum.

Wainer, H. (1990). Computer adaptive testing: A primer. Mahwah, NJ: Erlbaum.

Yen, W. M. (1986). The choice of scale for educational measurement: An IRT perspective. Journal of Educational Measurement, 23, 299-325.

Yen, W. M., & Fitzpatrick, A. R. (2006). Item response theory. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 111-154). Westport, CT: Praeger.

## 第4章 测量程序应有特性:信度

## 4.1 引 言

要使用测试或其他测量程序提取有用信息作为我们做出某些决定的参考时, 我们首先面临的就是如何选择所需要的测试或程序的问题, 抑或是究竟有没有任何手段方法能够真正有效地使我们做出最佳决定。通常对于某一个决定, 可用的测试有好几套, 且这些测试至少看起来对我们做出相关决定具有一定的参考价值和指导意义。我们应了解这些可用的测试是否真的可为决策者提供有用信息。如果任意一项测试都可以, 那么哪一项最佳? (为简单起见, 我们在这一章及下一章中都只使用测试一词, 但我们处理的问题实际上适用于所有的测量形式和所有的信息来源。对于特殊情况, 我们会在该章节内结合相应类型的评估程序进行解释说明。)

在评估测试结果的过程中往往会涉及许多的具体因素, 但我们主要从以下两个方面进行考察, 即信度和效度。信度指的是测量程序的准确性和精确度。信度指数表示通过某一特定测量程序得出的分值的一致性及可复制性有多高。效度则表示从测试分数中提取到的信息与据此做出的推断之间的相关度。因此, 对于效度的判断常常需要基于具体的决定或所使用的测试, 并明确这一点, 即对一个决定有参考价值的测试分数, 对另一个却并不一定同样适用。第三点基于整体的考虑即可操作性。 这一点涉及诸多因素, 比如经济性、便利度, 还有可解析度等, 这些都会影响到测试的实际可行性。关于可操作性的问题将在第六章中进行介绍。

选择测试时, 暂且不论其可操作性如何, 信度和效度二者是缺一不可的。在实际应用中, 测试分数的效度对任意一项测试而言都不可或缺, 但信度在一定程度上也是效度的一个必要前提条件。测试分数首先必须至少具有一定的信度, 得出的结果才可能具一定的效度, 但一项可靠的测试也可能得不出如我们所预期的有效的结果。 虽然在实际应用中, 效度是衡量是否选择该项测试的最低标准, 但首先应该考虑信度, 因为测试的信度是测试结果具有效度的一个必要条件。效度将在第五章中进行探讨。130

## 4.2 信度和一致性

当提到测试的信度, 我们指的不是测试所测量的具体内容, 而是测量该具体内容时的准确度。测量结果的准确度具体指什么? 对同一个体重复进行测量时, 得到的结果能在多大程度上具有一致性?

所有测量程序都会表现出一定程度的不一致性。假如我的一位朋友买了一台新的数码电子体重秤, 因为他觉得自己用了 20 年的弹簧秤不够准确。我也把这台新秤带回家, 试着称了一下, 第一次显示的读数似乎还算合理。接着, 为了看看这个秤是不是比之前的更准确, 我又试了一次。这次的读数竟然比第一次少了 7 磅! 就算是节食也没有这么快见效吧。然后, 我又试了第三次和第四次。试称十分钟之后, 我决定退货, 因为这几次称出来的体重误差范围达到了 15 磅之多。

这个小小的例子揭示了信度的核心问题。事实上, 无论使用什么样的测量方法, 我的真实体重是不变的, 但通过不同的测量方法测出来的数值却各不一样。若将我的真实的、恒定不变的体重称为真实值(T),那么每一个观测值或测量值(X)则等于该真实值加上一些测量误差(e)。表达式即:

\[X = T + e \tag{4.1}\]

观测值与真实值之间的差值即为测量误差。因此:

\[e = X - T\]

就这个体重秤而言, 当然包括所有的测量手段或方法, 许多测量误差都是随机出现的; 有时可能是正向的, 导致观测值偏大, 而有时可能反向的, 导致观测值偏小。大多数情况下, 误差值都非常小, 但也有一些可能会非常大。它们的分布类似第二章中提到的正态分布。

还有一些其他的测量误差, 在不同的测量程序中是固定不变的。可能每一次重复测量, 体重秤上显示的读数都比真实值高 10 磅。我们无法通过反复测量发现这类误差, 而必须与另一种准确的测量工具对比。但这种固定误差不会导致不稳定的测量结果, 因此也不会影响测量工具的信度。

这个不准确的体重秤正好给我们提供了一个绝佳的实践机会来检测测量过程中的随机误差, 因为我们可以在知道真实值恒定不变的情况下, 用它重复进行独立的测量。因此, 从该秤上读出的数值都有一定的误差。但是, 在教育或心理测量领域绝不可能出现上述情形。有关人类行为的测量特别容易受到不一致性的影响, 且很少可以通过反复进行测量来直接揭示这些测量结果中的不一致性。

再举一例, 可能也有些许虚构的嫌疑, 但是却更接近真实的测试环境。假设要连续两天测量一个班上的所有女同学能够将橄榄球掷出的最远距离。为此可能需要在田径场上画一条起点线, 给每一位女同学发一个体育部用来进行小组训练的橄榄球, 让一个人在场上协助标出球落地的位置, 然后告诉每位女同学尽全力将球掷出。通过卷尺, 我们就能量出从起点到助手标出的球的落地点之间的距离。我们连续两天让每位同学各掷一次, 那么相应地关于每位女生掷橄榄球的能力则会得到两个测量值。

比较每个人两次的测量值, 会发现几乎没有完全一样的。在这些测试中, 大多数的测量值之间差异都非常小, 但也有一些会相对较大。两次测量值具有一定差异性说明, 仅以一次的测量结果判断个人的掷球能力并不完全可靠。从某种程度上来说, 第一天和第二天投掷的距离不可能完全一致。职业橄榄球四分卫球员的特色之一就是他们每次投球的距离能够保持高度的一致性, 这是他们的天分和后天训练共同作用的结果。

## 不一致性的来源

导致前后两天的投掷距离或重复两次的任何其他形式的测量结果不一致的来源主要有三个。

1. 测试对象可能在第一次测试和第二次测试之间发生了变化。比如, 该女同学第一天的精神状态比第二天要好。也可能她在第一天中的表现比第二天更积极, 或者她甚至还可能在两次测试之间接受了家长的橄榄球特殊技能训练。若两次测试的间隔时间恰巧是几个月而不是几天, 测试对象甚至还可能在身体发育方面发生更加实质性的变化, 而且不同的人, 其成长发育情况还各不一样, 这也会影响两次的测试结果。上述例子涉及会影响受试者表现的成长发育方面的变化, 但这使我们很容易联想到也可能会影响智力测试或有关个人情绪或兴趣自评的相似的变化。

2. 两次测量中的任务可能有差异。例如, 贝蒂第一天使用的球充气很足, 而第二天使用的球却是软趴趴的, 因此造成了其两次投掷时抓握球的难易差异。又或者第一天测试者允许女孩们进行一段助跑后投球, 而第二天可能只允许大家在离起点线只有一两步的距离内进行投掷。还有一些客观因素, 比如第一天刮逆风, 而第二天没有。这些因素中的任何一种都可能会导致一些女孩的表现比另一些要好。在书面测试中, 我们常常这一次使用一种形式的测试, 而在下一次使用另一种形式相似的测试。测试中的具体题日不同, 但有些学生可能碰巧更擅长完成这一项测试中的任务,132而其他学生更擅长其他测试中的任务。

3. 有限的测量次数也可能会导致不稳定和不可靠的测试结果。即使我们让每位女同学使用同一个球按照相同的要求投掷两次, 中间只有五分钟的休息间隔, 也很难得到两个完全一样的结果。如果每个人只投一次, 好比测试中一道单独的题, 关于该特征的抽样调查数据又显得过于贫乏。而且抽样调查和对调查结果的评估还会受到诸多不确定因素的影响。或许贝蒂投球的时候手滑了。或许她那一次手脚没有配合好, 投掷时有点不协调。又或者标记点比球的实际落地点更偏前或更靠后了些, 球落地时标记员正在看别处, 或是贝蒂投球的时候正好刮过一阵风。这些都有可能发生, 有些因素会使人超常发挥, 相反地, 有些则会使人发挥失常。这些随机且不可预料的因素对所考察的某一特定特征的影响说明, 有限的测量次数无法得出有关该个体相关特征的稳定且可靠的概括, 无论测量的是投掷橄榄球的距离还是句子理解。 与投掷一次所得的成绩相比, 根据使用同一个橄榄球投掷一百次所得的平均距离对个人在此任务上的能力做出的判断要准确得多。同样地, 根据个人在一百道阅读理解题上的平均表现所做的评估也比单凭一道题要更加可靠。

## 4.3 表示信度的两种方法

## 1. 标准测量误差

表示一组测量结果, 或从相反的角度来说, 该组测量结果内的差异性或测量误差的信度或精确度的方法有两种。一种是直接计算针对某一个体重复进行测量所得的数据可能存在的误差值。如果我用该体重秤称了两百次体重, 或者条件允许的情况下, 贝蒂投了两百次橄榄球 (暂且假设在不考虑熟练度的提升和体力消耗的影响的情况下, 这是可行的), 我们就能够绘制一个关于我的体重和她的投掷距离的频率分布图。我们可以把该频率分布的平均值看作是我的“真实”体重或贝蒂能够将橄榄球掷出的 “真实” 距离。该频率分布同样有其标准差, 说明这些测量值围绕其平均值波动或偏离的范围。因为不同的波动幅度是由测量误差造成的, 所以我们称该测量误差中的标准差为标准测量误差。它表示的是有关投掷橄榄球的能力或我的体重的测量中的误差值分布的标准差。回顾方程式 (4.1) 可以发现,如果 \( T \) 为常量,那么两次测量结果若出现差异, 则一定是由测量误差引起, 且这些测量值的分布就是误差围绕真实值的分布。

涉及处理心理学和教育学领域的数据时, 我们通常无法对每一个测试对象都进行一整套的测量, 因为需要考虑到重复同一任务的过程中个人熟练度的提升和体力的消耗造成的影响, 还有时间上的限制, 比如我们无法在较短的时间内完成反复对某一测试对象进行两百次阅读理解测试或兴趣调查。通常能够对于每一个测试对象能够得到两个测量数据就很幸运了。但是, 如果针对每一个测试对象有一对测量值, 就可以据此推断设想中对这组数据里平均水平的个体不断重复进行测量所得数值的分布情况了 (详细参考本章中稍后将介绍的有关信度数据分析的板块)。如果能够对同一个体进行重复测量, 由此所得的波动幅度指数, 即标准测量误差, 就能揭示我们所预期的相关测量结果的不一致程度。

## 2. 信度系数

群体中的每一个体在每一次测试上的排列顺序基本一致同样说明测量结果比较稳定可靠。在第一轮投掷橄榄球的测试中得分最高的女生在第二轮中得分仍然排第一, 并且在后续的几轮测试中, 该测试群组中每个人的成绩应该也差不多排在相对稳定的位置。相关系数是统计学上的一个指数, 表示两个测量值相符的相关程度或使每个人保持在其相对的位置上, 即高分与高分或低分与低分排列在一起。如果我们进行匹配的两个变量正好是同一测量手段或方法的两次测试结果, 那么所得的相关系数即为表示测量数据的信度指数, 我们可以称之为信度系数。在第二章中我们已经介绍过相关系数的一些特征。但现在我们面对的是由相同或等效的测量工具得出的两个测量值的相关关系。因此, 个体在第二次测试中的成绩排列顺序与其在第一次中的顺序越接近, 该相关系数就越高, 该测试的信度也越大。

信度系数和标准测量误差有着紧密的联系。想想如与方程式 (4.1) 所对应的某个观测值的相关组成部分。它等于真实值加上测量误差。假设我们对一组对象进行了一项测试,这组观测值的方差 \( S{D}_{X}^{2} \) 表示这组数据内部的波动幅度。但每一个观测值均由真实值和误差组成。因此, 假设该群组中所有成员的真实值并不一定都是相同的, 误差也是随机且互不影响的, 那么我们可以用一个等式表示观测值的方差, 它是真实值的方差 (不同测试对象之间的真实差异) 与测量误差的方差之和。也就是:

\[S{D}_{X}^{2} = S{D}_{T}^{2} + S{D}_{e}^{2} \tag{4.2}\]

其中, \( S{D}_{X}^{2} \) 表示测试分数观测值的方差, \( S{D}_{T}^{2} \) 表示真实值的方差, \( S{D}_{e}^{2} \) 表示测量误差的方差。

注意 \( S{D}_{e}^{2} \) 为测量标准误差的平方。针对同一特征的两个测量值之间的相关性——即信度系数——也可表示 (Feldt & Brennan, 1989; Lord & Novick, 1968。) 如下:134

\[{r}_{tt} = \frac{S{D}_{T}^{2}}{S{D}_{X}^{2}} \tag{4.3}\]

也就是说, 信度系数等于观测值方差的分数, 它是由测试对象之间的真实差异所致。

我们也可将测量标准误差表示为观测值与信度系数标准差的函数:

\[S{D}_{e} = S{D}_{X}\sqrt{\left( 1 - {r}_{u}\right) } \tag{4.4}\]

由等式 (4.4) 可知, 显然在一个具有一定差异性的群组中, 标准测量误差会随着信度系数的增大而减小。个人在一项信度很高的测试中的得分差异主要源自测试对象之间的真实差异。

## 4.4 评估信度的方法

所以, 进行重复测量时, 如果个人得分或其在该群组中的排列位置几乎是完全一致的, 即表现为较低的标准测量误差 (同一个体在反复测试中的成绩差异性较小) 或说该测试的信度系数较高 (即在多次的测量中每一个体在该群组中的排名十分稳定), 那么这种测量手段或方法才是可靠的。但是究竟需要哪些具体类型的数据才能对测量的精确度或稳定性做出准确的判断? 接下来我们将分析三种各不相同的可能情形, 包括它们的异同点和优缺点。这三种情形分别是:

1. 重复进行相同的测试或测量 (测试与再测试)

2. 实施另一种 “等效” 的测试形式 (又称平行或替代测试形式)

3. 在单次测量中, 将原测试内容进一步分成两个或多个等效的部分 (单次测量方法)

## 1. 同材料重复测试

要想了解对某一测试对象投掷橄榄球能力的推断在多大程度上是可靠的, 我们可以让其测两次。让两位测试者分别独立操作这两次测量可能也是有必要的。因为我们不希望测试者对第一次分数的记忆影响其对第二次分数的印象。另外两次测试或许也最好安排在不同的两天进行, 至于间隔多久, 取决于我们想要测量的特征或属性。若想考察根据某一个体在一个特定时间点的单次投球 (或许单组投球更佳) 对其相应技能做出的判断的准确度, 两次测量应该接连进行, 中间不宜有太长的时间间隔。这样我们就能保证该个体在连续两次的测试中发挥水平基本是一致的, 那么测试结果中的差异或“误差”就只可能是来自于测量程序及操作本身。若要考察在不同时间对某一个体进行重复测量所得数据的准确性, 即根据第一次测量数据对时隔一周后第二次测量结果的预测有多接近真实值, 则最好在两个不同的时间点对该个体进行测量。在第二种情形中, 我们关注的是个体在不同时间点表现水平的差异, 还有因测量程序的实际操作造成的差异。现在, 由于造成测试结果差异性的可能原因有两种, 我们只能希望后者表现出更明显的测量误差。

我们有时会关注某一个体在不同时间点表现出的差异; 而有时不会。我们有时会问: “现在对山姆进行测量的结果有多准确?” 或者, “根据当前对山姆进行测量的数据对其在明天或一周后或一个月后的表现做出的预测准确度又有多高?”这两个问题都值得思考, 但二者本质上是不一样的。得出第一个问题的答案所需搜集的数据与得出第二个问题答案所需的并不相同。

研究有关生理特征测量结果的信度, 比如个人的体重或身高, 重复进行测量是最直接且往往能得到令人满意的结果的操作方法。上一次体重秤上显示的结果并不会影响下一次该体重秤的读数。简单地重复测量人类行为的一些较浅显的特征, 比如反应速度或类似投掷橄榄球这样的运动技能, 似乎不仅适用性较高且一般也能得到比较理想的结果。但是, 若以考察对受试者阅读理解能力所做的评估的信度为例, 则可能另当别论了。假设该测试由六段阅读短文组成, 每段之后分别设五道题。在第一次测试之后, 立刻再进行一次。看看会出现什么样的结果。当然, 这些受试者肯定不会将他们刚刚读过的所有阅读材料重读一遍。他们可能会重读其中的某些部分, 但在第二次测试中, 他们在很大程度上都会凭记忆再次勾选第一次测试时所选的答案。另外, 第一次没能做完的题, 在第二次测试中也能集中精力处理, 因为前面做过的题可以凭记忆选择而加快其答题进度。即便是在一段相对更长的时间里, 这些仍旧在一定程度上站得住脚。很显然, 在上述例子中也是对受试者进行重复测量, 但第二次测试中的题与受试者第一次完成的题虽然内容一样但性质却不一样, 因为接受第二次测试的这些受试者不再是进行第一次测试时的他们了; 进行第二次测试时, 他们已经对这些测试题目有了一定程度的了解。

在重复进行类似阅读理解这样的测试时还有另一点需注意。假设该测试中的六段短文里有一段是关于棒球的, 而某一位女同学正好精通棒球。那对她而言, 这段阅读材料则是小菜一碟, 而她实际上也的确因此多得了好几分。那她在测试中这部分的表现则会使我们对她阅读能力的一般水平估计过高。但是值得注意的是在题目相同的两次测试中, 她在这部分题上的表现一直都会比较稳定。因此, 在这两次测试中对于该个体的测量误差则为固定误差。因为该误差对她在两次测试中得分的影响是136相同的, 这会使该测试显得比较可靠而非不可靠。

在诸多类似阅读理解的能力上, 我们必须考虑到个人在整个领域内各个板块或内容上的水平并不完全一致的可能性。个人兴趣爱好、经历及背景都会造成其在擅长和不擅长的方面上的差异。某项具体的测试只是测量该行为特征的整个领域里的一个样本而已。在相关测试上, 某一个体相比其他受试者的表现很可能在一定程度上取决于我们从所评估的有关能力或性格特征的特定领域中抽取的这份样题里的任务。与使用不同的题相比, 如果两次测量中的样题相同, 该测试对象的行为表现也将更有可能基本保持一致。

到目前为止, 我们考察了造成个体在重复测试中的表现差异的三大主要因素, 这些因素会降低反映个人某一能力或特征的特定分数的一致性或稳定性。这三大因素概括如下:

1. 某一特定时间点个人对相关任务的反应在每次尝试中都有所差异;

2. 同一个体在不同的时间点具有一定差异性;

3. 从反映某行为的领域中抽取的具体示例任务具有一定差异性。

使用完全相同的测试对同一个体进行重复测试会反映出前两种 “误差” 因素, 但这种方法无法用来考察如上第三种造成测量结果差异的因素。而且, 如上例子中涉及的个人记忆能力或测试中熟练度的提升也可能影响测量结果。

## 2. 平行测试形式

从有关该行为特征的领域中选取的具体示例任务造成的测量结果差异, 针对该问题我们需要运用另一套评估信度的程序。如果选取的题目是造成测试对象表现差异性或测量 “误差” 的主要原因, 而实际情况通常也是如此, 要想了解根据测试对象在一套样题中取得的某一具体分值概括出来的结果的准确性, 该套样题中的任务反映了一个更宽广领域里的内容且只是其中很小的一个部分和方面, 则必须研发一些能考虑到由样题本身造成测试结果差异性这一情况的测量程序。为此我们或许可以将从形式上可替换、平行或等效的测试中所得的两次成绩关联起来。

一项测试的替代形式可当作是根据相同的要求设计的类似形式的测试, 测试的任务或题目均与测量同一特定行为特征的领域相关, 只是各自任务或题目的具体内容不同。因此,一对平行阅读测试中的阅读文章和相应的问题应该具有相同的难度。 所提问题应该属于同一类别, 比如考察细节和文章大意的题目数量应该差不多。测试中的每段阅读文章也应为相同类型, 比如说明文、议论文或记叙文。但文章的具体内容和所提问题不应一模一样。

若有一对不同形式的试题, 则可以让每一位受试者在第一次测试时做第一套题, 第二次测试时做另一套。如果不考虑接连测试中体力消耗等因素的影响, 则可以在完成第一次测试后立即进行第二次, 或者如需考虑此因素, 在两次测试之间则可以有一定的时间间隔。考察这两项不同形式测试之间的相关关系可以得出一个较理想的信度系数。若两次测试之间允许有一定时间间隔, 那上述三种造成测试结果差异性的因素来源都有可能体现出来, 即来自测量程序本身、个人在不同时间点相关特征的变化以及样题任务的差异性。

从具有一定时间间隔的一对平行测试中得出相同的结果是这种情形下所能达到的最高标准, 因为上述三种差异性来源都能够影响测试结果。并且, 若要通过测试结果来推测下周或下个月詹妮弗在这种一般测试的其他任务上可能的表现, 那么以此标准来评估测试的信度则再合适不过了。在大多有关教育的情形中, 这也正是我们想要运用测试结果进行分析的方式, 所以评估一项测试的信度时, 通常尤其应该予以重视的就是从形式上等效且具有一定时间间隔的不同测试中提取到的相关信息。

使用一对平行形式的测试的确能够提高评估心理学和教育学领域相关测试的信度。但是该方法也有一些实际应用方面的问题。比如, 首先我们需要有一对可用的平行形式的测试, 其次还需要时间上允许我们对每个测试对象分别进行两次测试。 但事实是, 我们常常找不到也设计不出类似形式的另一套测试, 又或是第一次测试后再也找不到适合进行第二次测试的时机。就手边可用的资源来看, 第二次测试常常很可能会难以继续进行。由于需要考虑到实际操作中的便利性和可行性等问题, 测试设计者们开始试着接受一些其他方法, 比如根据单次进行某种形式的一项测试的结果评估测试的信度。但这类方法或程序最多只能算是一个折中方案。在所有实际操作中, 人们往往倾向于通过考察一对平行形式的测试之间的相关关系来评估测试的信度, 这两次测试之间一般间隔几天或几周。

## 3. 单次测量方法

## (1)细分测试

有一种一直以来广泛使用的根据单次测试结果评估测试信度的方法, 即将原测试进一步分为两个大致相等的两部分。重组的这两项子测试的内容和题目难度都经过了仔细的考量, 以在技术上保证二者内容设置和难易程度基本一致。事实上, 这与设计一对简短的平行测试, 再将二者组合起来进行一次测试是一样的。完成测试后, 再将两项测试分开计算每位受试者的得分。这两项子测试之间的相关关系即为评估整个测试信度的依据。但只有当所设计的测试用于测量至少两个的特征时才能使用这种方法, 因为测量每个特征的题目必须均匀分布在这两项子测试中。在该方法中, 我们也可以仿照平行形式的测试, 为这两项子测试设置几个小时、几天或几周的时间间隔, 但是很少进行过实践操作。

为了将原测试均分为两部分, 人们常常使用的一个更简单的方法就是交替将每一个题目分别归入两项子测试中, 即将编号为奇数的题归人一项子测试中, 而将编号为偶数的题归入另一项子测试中。该方法通常具有一定合理性, 因为一项测试中题型、内容或难度相似的题常常排列在一起。一项长度适中的测试,一般不少于 60 题, 按照如上方法将其分成两部分或许能在一定程度上抵消诸如题型、涉及内容和难度等因素带来的影响。这两项子测试将在很大程度上是 “等效的”。

使用这些方法将测试分成两部分只是为了分开计算受试者的得分, 而不是为了分别单独用来进行测试。换句话说, 这仍然是在同一时间和同一地点对同一群体进行的单次测试。两个独立的分数分别只能是来自一项子测试或奇数编号的题组成的测试, 和另一项子测试或偶数编号的题组成的测试。这两个分值的相关关系, 又叫作奇一偶信度系数, 或说得更宽泛一点就是折半信度, 也是一种测量和评估测试准确度的方法, 该测试主要用于在特定时间点测量某个体的特征属性。折半信度表示的是我们对在同一时间进行的两项等效的测试之间的相关性所做的推测。

但是要注意由此计算出的是将一项测试截成两半所得的两项子测试之间的相关关系。这个值并不能直接用于阐述原测试, 因为它才是实际应该使用的初始材料。 一般而言, 抽查的样本数量越多, 测量结果就越可靠。也就是说, 记录越多测试对象的行为特征或针对某一特征进行反复测试, 关于该个体行为表现的测量结果或针对一些具体任务的抽样中的偶然性就越小。单次碰巧因为运气答对或一时注意力不集中造成的失误等都将在更大程度上被排除掉。

从中得出实际上相互关联的两个分值的这两项子测试是等效的, 因而我们能够根据两项子测试的相关关系对整个测试的信度所做的推断也是不偏不倚的。该推测结果可用如下方程式表示:

\[{\widehat{r}}_{it} = \frac{2{r}_{AB}}{1 + {r}_{AB}} \tag{4.5}\]

其中 \( {\widehat{r}}_{u} \) 表示所推测的完整测试的信度, \( {r}_{AB} \) 表示两项子测试之间的实际相关关系。这两项子测试并不一定得按照奇偶对半分; 它们也可以是仔细考量每道题后平均进行划分的结果。

那么, 如果该测试的两项子测试之间的相关系数值为 0.60 , 由等式 (4.5) 可得:

\[{\widehat{r}}_{u} = \left( {2 \times  {0.60}}\right) /\left( {1 + {0.60}}\right)  = {1.20}/{1.60} = {0.75}\]

所求的值即为对该完整测试中得分信度的最佳推测。该等式通常被称作斯皮尔曼一布朗预测公式 (Spearman-Brown prophecy formula), 是根据其功能和提出该公式的人所命名, 通过它就能够计算根据单次进行某一项测试所得的结果对其信度所做的推测值。该方法在内部一致性上十分有利 (阐述如下), 因为它无需所有题目在内容上具有同质性, 而只需要两项子测试之间是等效或等价的, 但是它仍然属于单次测量方法范畴。

然而, 该方法却很容易受到两项子测试之间均等性的影响。如果两项子测试中的题目不均等, 那根据二者之间的相关系数对完整测试的信度所作推测也会比实际偏小。将原测试分为两项子测试的任何一种特定方法都具有一定的随意性, 而且不同的划分方法可能会导致出现不同的有关该测试信度的推测值。因此, 人们研究出一些可以在一定程度上提高内部一致性的方法, 以克服这类问题。

(2)内部一致性信度

实际操作中常常只能根据单次进行某一项测试所得的测量结果推测其信度的值。一百年前出现的折半法现已在很大程度上被如下划分方法取代, 即按照原测试中的每道题都可以独立成为一项测试的想法将其划分为若干项子测试。那么含有 \( n \) 道题的完整测试则可被看作一组含有 \( n \) 项极其简短的子测试的平行测试 (这里的 \( n \) 表示相应测试中的题目数量)。通过对单个题目的统计分析可得关于原测试信度的推测值。

根据单次进行某一形式的测试评估其信度取决于每一个体在每道题上的表现的一致性, 同时也会受到测试分数之间以及各个独立的题目之间差异的影响。以其最简单的形式表示即为阿尔法系数, 表达式如下:

\[\alpha  = \left( \frac{n}{n - 1}\right) \left( \frac{S{D}_{X}^{2} - \sum S{D}_{i}^{2}}{S{D}_{X}^{2}}\right)  \tag{4.6}\]

其中 \( \alpha \) 表示信度推测值, \( n \) 表示该测试中的题目数量, \( S{D}_{X}^{2} \) 表示测试分数的方差, \( \sum \) 表示对所有这 \( n \) 道题的分值 “求和”,还有 \( S{D}_{i}^{2} \) 表示一组测试对象在一道题上得分的方差。所以 \( S{D}_{i}^{2} \) 一共有 \( n \) 个值,这些值求和后进人分子部分。

计算得出的阿尔法系数的值即为所有可能的斯皮尔曼一布朗校正折半相关系数的平均值, 这样一来就消除了潜在的因对半划分不均带来的影响。

现在我们通过一个小小的例子来看看等式 (4.6) 是如何应用的。假设我们对 5 名受试者进行了一项测试, 其中有 3 道简短的论述题。每道题 5 分, 那么在该测试中能够取得的成绩范围则为 0 分 (每道题得零分) 到 15 分 (每道题得满分)。这五位受

试者的成绩分别如下:



<table><tr><td>受试者</td><td>第一道题</td><td>第二道题</td><td>第三道题</td><td>测试总分</td></tr><tr><td>1</td><td>1</td><td>3</td><td>1</td><td>6</td></tr><tr><td>2</td><td>3</td><td>3</td><td>1</td><td>9</td></tr><tr><td>3</td><td>4</td><td>5</td><td>4</td><td>13</td></tr><tr><td>4</td><td>3</td><td>4</td><td>5</td><td>12</td></tr><tr><td>5</td><td>4</td><td>4</td><td>5</td><td>14</td></tr><tr><td>\( \sum X \)</td><td>18</td><td>19</td><td>18</td><td>54</td></tr><tr><td>\( \sum {X}^{2} \)</td><td>63</td><td>75</td><td>18</td><td>626</td></tr><tr><td>方差</td><td>1.04</td><td>0.56</td><td>2.24</td><td>8. 56</td></tr></table>



将这些值代入等式(4.6)中, 得:

\[\alpha  = \left( {3/2}\right) \left\lbrack  {\left( {{8.56} - {3.84}}\right) /{8.56}}\right\rbrack   = \left( {1.5}\right) \left( {0.551}\right)  = {0.827}\]

这说明该简短的测试具有相当高的信度, 也就是说重复测试时, 这些受试者在这些题上得分的排名顺序基本能够保持完全一致。

若在每道题上的得分要么为 1 要么为 0 , 即要么答对要么答错, 那受试者在该道题上得分的方差即为:

\[S{D}_{i}^{2} = {p}_{i}{q}_{i}\]

其中 \( {p}_{i} \) 表示答对这道题的人数,而 \( {q}_{i} \) 表示答错这道题的人数。

等式(4.6)则变成了:

\[{r}_{n} = \left( \frac{n}{n - 1}\right) \left( \frac{S{D}_{X}^{2} - \sum {p}_{i}{q}_{i}}{S{D}_{X}^{2}}\right)  \tag{4.7}\]

这里 \( {r}_{tt} \) 为关于该完整测试信度的推测值。这个等式叫作库德一理查森公式 20 (Kuder-Richardson Formula 20, 简称 KR-20), 是根据提出此等式的人和他们最初的手记中提到的等式所命名。这是阿尔法系数的特殊形式, 即受试者在相关测试题目上要么回答正确得分, 要么回答错误不得分。阿尔法系数和 KR-20 都能计算关于一项测试中所谓的内部一致性的推测值。内部一致性即一项测试的所有题目所考察的该测试对象的特征具有多大程度的共通性, 以及不受测量误差影响的程度。当该测试内的题目具有同质性, 即每道题与其他各道题所考察的个人能力或性格特征上的一般特征基本相同, 那么将由此计算出的阿尔法系数假设 KR-20 值当作有关该测试信度的推断值则是合理可靠的。

假设测试中所有题目难度相同, 运算过程更为简单的另一个公式即为库德一理查森公式 21 (简称 KR-21)。该公式表示为 \( {M}_{t}\left( {1 - {M}_{t}/n}\right) \) ,其中 \( {M}_{t} \) 表示该组测试分数的平均分,即等式 (4.7) 中的 \( \sum {p}_{i}{q}_{i} \) ,由此等式计算出的值与 KR-20 所得的结果较接近, 但更保守。对于想要快速测出其课堂上使用的某项测试信度的老师们会发现 KR-21 很好用, 因为通过测试分数分布中的平均值和标准差轻而易举就能根据该公式计算出他们想要的值。然而, 要保证测试中的所有题目难度一致十分困难, 而且在实际操作中几乎是不可能的。鉴于这一事实以及 KR-20 和阿尔法系数公式中的部分运算只有通过计算机才能实现, 计算机能否成功完成这些运算等这些因素的综合作用下,KR-21 应较少地使用。新建一个 Excel 表格计算 \( \alpha \) 则相对容易一些。横行中依次为受试者, 纵列里依次为测试中的题目, 设置好后在每一列的最底部运用合适的方差函数就能计算出相应的所有 \( \sum S{D}_{i}^{2} \) 的值。横行中所有数值和的方差即为 \( S{D}_{X}^{2} \) ,然后在表中一个空的单位格内将相关单元格内的数值代入等式 (4.6),就能计算出想要求取的值。

由于这些提高内部一致性的方法程序用起来极其方便, 因而得到了广泛使用。 许多测试手册中介绍的都是这类信度系数,而非其他。遗憾的是,KR-20、KR-21,以及阿尔法系数自身都存在诸多的局限性。

首先, 因为在对某一测试对象进行一项单次测试时, 他或她给出的所有相应题目的答案代表的都只是那些特定时间点自己的表现。即便是一些只持续几分钟的事件也会在同等程度上影响受试者在几道题上的表现。换句话说, 该受试者每天都在发生变化, 无论是心理上还是生理上, 而这类信度系数是反映不出这一点的。我们只能通过它获取一些有关此精确度的有用信息, 即用来评估个人在某一特定时间点表现的准确度。

第二点有时会使题目组之间看起来很相似, 而并非真正将一套题划分成两套独立的平行形式的子试题。如果该测试中的题出自同一参考材料, 比如出自单篇文章的阅读理解题或全部来自描述某项实验的文章的科技类题目, 测试对象在所有这些题上的表现将在一定程度上取决于其去理解该参考材料的共同行为。因此, 答对这组题目里一道题的人答对其他题的概率也更大, 大于真正独立的、相互没有关联的题目。

在有些情形中, 要求某一测试中的所有题目所考察的为某个单一特征可能太过局限。一项关于通用科学知识的考试可能会含有一些有关生物、化学和地理的题。 若通用科学知识在一定程度上具有某个单一特征, 那么测试对象在这些题目上的表现则会相对稳定, 但如果生物、化学和地理知识各有其特征, 且相互间仅有微弱的关联性, 就会发现题目主要呈三大不同类型的群, 每一群组表现出极高的内部一致性, 而这三大群组之间的关联性可能相对较低。这样的测试不可能表现出较很高的内部一致性。相比之下, 可能我们努力将一项完整测试划分为一对平行测试形成的两项折半子测试之间的信度系数反而具有更高的内部一致性。

最后, 若需要以极快的速度完成一项测试, 那么所有根据该单次测试的测量结果推算出的信度系数都将变得毫无意义。比如让一组成年人在两分钟内完成一项简单的数学测试, 其中有 100 道难度如 \( 3 + 5 =  \) _____？_____的算术题。在这类测试上, 受试者的得分差异会非常大, 但该差异性主要来自做题速度, 而计算失误占的比重则极小。成绩为 50 分的人很可能只做到了第 50 题。个人能不能答出某道题几乎完全取决于这道题在该测试中所处的位置。因为几乎所有人只要是答到了的题都答对了, 所以这些题目的 \( p \) 值和 \( q \) 值是由其在该测试中的位置决定的,而且这会极大地提高个人能力水平表面上的稳定性。

但很少有测试会像上述为了阐明这一点而举的例子一样, 使受试者的成绩完全取决于做题速度; 但是许多测试确实也会在一定程度上涉及限时的问题。做题速度对测量的影响往往会使基于具有内部一致性的方法程序进行推断的信度值比真实值偏大。推断值超出实际值的差量多少取决于测试中做题速度的快慢, 速度在测试中的作用越大, 对测量结果的影响也就越大。但速度的问题在测量个人能力的测试中十分普遍, 因此求得的关于内部一致性信度的推测值通常应该适当减去一点。

对限时测试使用折半法确实也是一个不错的选择。将原测试均分为一对子测试, 就像两项相对简短且独立进行的限时测试一样。使用方程式 (4.5) 计算这两项独立进行的子测试之间的相关系数, 就能得出关于这类情形中相关测量结果信度的有效值。

与限时测试相对的是难度测试。限时测试中的得分差异取决于回答的题目数量。相应能力水平越高的人就能在限定时间内答出更多道题, 但对所有受试者而言, 只要做到了的题一般都做对了。难度测试没有时间限制, 只需要受试者最终完成测试, 但其中的题目难度各不相同。能力水平高的人能够答对相对难的题。实际上, 大多有关能力的测试基本都会涉及这两点, 即既考察受试者的做题速度, 又考察其能够处理的题目难度, 但实际哪点占的比重较大, 要视具体测试而定。我们会在介绍测试的效度时再次提及这一问题。

## 让计算机来帮忙

## 阿尔法系数

任何具有关联性的两个分值的信度指数当然也可以通过 SPSS 或 EXCEL 制表程序进行计算, 计算方法与第二章中介绍过的求取相关系数的方法相同。运用 SPSS 相关程序计算阿尔法系数, 最简单的方法就是使用分析菜单栏中量表 (Scale) 选项里的信度分析 (Reliability Analysis) 子程序包。根据提示将需要分析的变量, 即所有题目输入应用程序。如果该测试中共有 20 道题, 全都依次按照第 1 题、第 2 题……第 20 题的名称列在相关数据文档中, 则只需要将其录入相应的分析 (Analysis) 会话框中。这些 “统计” 选项经过程序处理会得出许多有用的数据, 有些甚至超出了我们的考察范围, 以及有关题目的描述性统计数据。该程序还有一个特别有趣的功能, 即计算分别将每道题移除后该测试的阿尔法系数。如果移除某道题会使阿尔法的值变大, 那该测试中的这道题很可能需要进行适当调整。

使用 EXCEL 制表程序计算阿尔法系数, 首先必须运用该程序计算出单道题上得分的方差和整个测试上得分的方差, 然后将这些值代入如前所述的方程式 (4.6) 中。至于标准差, EXCEL 制表程序中有两种计算其方差的方法。一种是描述性的, 基于手边所有抽样数据, 叫作样本方差 (VARP)。另一种有关整个样本推测的方差, 叫作总群方差 (VAR)。这里使用样本方差分别计算单道题得分的方差和整个测试得分的方差, 然后代入方程式 (4.6)。

## 4. 方法对比

如表 4-1 所示, 我们对一些不同的评估信度的方法进行了总结和比较。表中列出了前述四种因素 (差异来源), 这些可能影响有关个人在单次测试中表现的测量结果的准确性, 以及由每种评估信度的方法程序中的分值差异可以看出其受到了哪几种误差来源的影响。一般来说, 不同的方法或程序不可能是等效的; 纵列中变量 (题目) 越多, 关于该测试信度的推测值也就越保守 (即越低)。只有进行一对平行形式的测试, 且两次测试之间有一定的时间间隔, 才能反映出所有会造成测量结果不稳定的因素。除此之外的其他每一种方法都至少会有一种造成差异性的因素无法充分体现出来, 而无论是哪一个因素, 在测试的实际操作中都可能是至关重要的。重复使用一模一样的测试进行测量能够抵消样题本身造成的差异性。若所有测试在同一时点进行, 则可消除一定的时间间隔导致的个人心理或生理上的变化。当测试只有一道题或一个任务且要求在某一段具体时间内完成时, 则无须考虑答题速度造成的差异。 在评估测试手册或某项研究报告中的一些有关信度的数据时, 要谨记如下表格中总结的这些重点内容。测试者应该要求测试发布在做出有关信度的评估或推测时, 尽可能基于平行形式的测试且在一段时间后对同一组测试对象进行再测试, 这样就能对不可靠性因素的影响做出相对合理的推断, 进而才能对此进行评估。因为其便利性, 阿尔法系数是该研究领域最常用的衡量测试信度的指数。

表 4-1 评估信度的不同方法中所反映的造成差异化测试结果的因素来源



<table><tr><td rowspan="2">差异来源</td><td colspan="5">评估信度的试验步骤</td></tr><tr><td>无间隔重复 测试, 同一 测试</td><td>有间隔重复 测试, 同一 测试</td><td>无间隔平 行测试</td><td>有间隔平 行测试</td><td>单次测量方法 “</td></tr><tr><td>测量程序本身造成的测 试结果差异</td><td>\( \times \)</td><td>\( \times \)</td><td>\( \times \)</td><td>\( \times \)</td><td>\( \times \)</td></tr><tr><td>因时间间隔产生的个人 变化</td><td>\( \times \)</td><td>\( \times \)</td><td>\( \times \)</td><td>\( \times \)</td><td/></tr><tr><td>具体样题内容的差异性</td><td/><td/><td>X</td><td>\( \times \)</td><td>\( \times \)</td></tr><tr><td>个人答题速度的差异性</td><td>\( \times \)</td><td>X</td><td>\( \times \)</td><td>X</td><td/></tr></table>

注意: \( \times \) 表示该差异来源会影响通过相应测试方法得出的信度推测值。

\( {}^{n} \) 单次测量方法包括库德一理查森公式 20 和 21,阿尔法系数和折半平行测试。



## 4.5 信度数据分析

假如对一次小学学业能力倾向测试所得数据进行分析后得到的信度系数为 0.90 。我们应该如何解读这个结果? 某名小学生测试成绩的精确度具体指什么? 该测试的信度系数为 0.90 , 这是否是一个令人满意的结果?

## 1. 标准测量误差

分析信度系数和标准测量误差之间的关系是解读测试信度的一种方法。请注意, 标准测量误差是对同一个体反复进行同一项测试所得测量数据的标准差 (其前提条件是该测试对象不会因为测量过程发生任何变化)。根据等式 (4.4) 可知, 标准测量误差也可用信度系数表示如下:

\[S{D}_{e} = S{D}_{X}\sqrt{\left( 1 - {r}_{tt}\right) }\]

假设上述例子中信度系数为 0.90 的测试, 其标准差为 15 分。代入等式可得:

\[S{D}_{e} = \sqrt{\left( 1 - {0.90}\right) } = {15}\sqrt{0.10} = {15}\left( {0.316}\right)  = {4.7}\]

那么, 对同一个体进行反复测量所得的一组数据 (比如之前关于我的体重的测量) 的标准差 (即标准测量误差) 则可能为 4.7 分。注意, 在正态分布情形中会有一部分观测结果特别一致地分布在相对于平均值任意既定数量的标准差单位内; 约有 \( {32}\% \) 或三分之一的样本相对于平均值的差值大于一个标准差单位; \( {4.6}\% \) 的样本大于

两个标准差单位。图 4-1 所示为上述例子的分布图。





图 4-1 标准测量误差 \( \left( {S{D}_{e}}\right) \) 可用于确定评估某一个体的真实值范围



若上述例子中的标准差为 4.7 分, 那么我们则可以说, 三个人中有一个人的观测成绩与他或她的“真实”成绩 (即分布在表 4-1 中 68 %那部分之外的部分) 不一致, 要么多了 4.7 分, 要么少了 4.7 分。二十个人中有约有一个人, 其测试成绩与真实成绩至少相差 9.4 分 (两个标准测量偏差单位)。这次测试中, 将近三分之一学生的成绩可能存在 5 分左右或以上的误差, 而 25 人中约有 1 人的成绩将存在 10 分或 10 分以上的误差。

另一种解读标准测量误差的方法是表明个人在重复测试中的分值波动差异。每个人首次测试所得的分值都有一定的误差。这些误差大多都非常小, 但也有一些会比较大。约有一半的误差会是正的 (导致测量值偏高), 同样约有一半会是负的 (导致测量值偏低)。但最终得到的结果中, 我们只看得到一个测量值, 无法知道每一个体得分的测量误差有多大, 更不用说是正还是负了。

对于小学高年级的学生进行某一项非官方发布的学业能力倾向测试所得的标准分数而言, 分别为 0.90 和 15 的信度和标准差都是十分具有代表性的值。我们可以看到, 即便该测试的信度系数相对较高, 仍然有可能出现较大的测量误差, 虽然这部分分值占的比重不大。若该组数据的标准差为 15 , 因具体测试的差异性, 可能出现 5 到 10 分的差量也屡见不鲜, 而这纯粹只是因为测量误差。没有人会过分关注并设法解析 5 分的分值差异, 不论是关于两位受试者得分还是同一个人在类似上述测试中的两次测量成绩, 除非是误以为该测试具有其根本没有的精确度。进一步的测试有可能就会推翻原测量结果。对测试分数做出任何相关解析时都必须充分考虑到标准测量误差。

表 4-2 所示为标准测量误差与信度系数的关系。第一列为筛选出来的一些信度系数,第二列是由表达式 \( S{D}_{X}\sqrt{1 - {r}_{u}} \) 计算所得的值,第三栏和第四栏分别是当 \( S{D}_{X} \) 的值为 15 或 100 时对应的 \( S{D}_{e} \) 值。注意误差值会随着信度系数的增大而减小,另外若误差值足够大, 即便信度系数高达 0.90 或 0.95 , 其仍然会在测量结果中有所体现。解析个人分值时, 尤其应该注意的是标准测量误差。在高于测量值两个标准测量误差单位和低于其两个标准测量误差单范围内必然 (20 个人中有 19 个处于该范围内) 含有该个人的真实值。因此, 在该小节所举的能力倾向测试例子中, 我们大可以将 90 分的测试标准分数当作是类似 80 分和 100 分之间的那个真实值。如果从这些方面进行考虑, 或许能更加了解所使用的测试的不精确之处, 且在解析和运用测试结果时能够更谨慎。



表 4-2 不同信度系数值对应的标准测量误差

<table><tr><td rowspan="2">信度系数</td><td colspan="3">标准测量误差</td></tr><tr><td>通式 \( {}^{\mathrm{a}} \)</td><td>当 \( S{D}_{X} = {15} \) 时</td><td>当 \( S{D}_{X} = {100} \) 时</td></tr><tr><td>0.50</td><td>0.71SDx</td><td>10. 6</td><td>71</td></tr><tr><td>0.60</td><td>0.63SDx</td><td>9.5</td><td>63</td></tr><tr><td>0.70</td><td>0. \( {55S}{D}_{X} \)</td><td>8.2</td><td>63</td></tr><tr><td>0.80</td><td>0.45SDx</td><td>9.5</td><td>45</td></tr><tr><td>0.85</td><td>0.39SDx</td><td>5.8</td><td>63</td></tr><tr><td>0.90</td><td>0.32SDx</td><td>4.7</td><td>32</td></tr><tr><td>0.95</td><td>0.22SDx</td><td>9.5</td><td>22</td></tr><tr><td>0.98</td><td>0.14SDx</td><td>2. 1</td><td>14</td></tr></table>



注意: \( {\mathrm{{SD}}}_{\mathrm{X}} \) 表示该测试的标准差。

\( {}^{\mathrm{a}} \) 表示 \( \left( {S{D}_{X}}\right) \sqrt{1 - {r}_{tt}} \) 。

## 2. 信度系数

解析个人的测试分数时, 从标准测量误差着手且确定一定的误差范围会更容易, 同时在根据相关测试分数下结论时应该保守一点, 切忌武断。但在对比不同的测试以及许多分析测试的不同类型的方法时, 信度系数的实用性更高。关于以不同单位表示的测量方法, 比如以英寸 (或厘米) 表示身高、以磅 (或千克) 表示体重, 信度系数只能用于比较该测量方法的精确度。由于既定领域的竞争性测试 (比如阅读理解) 倾向于使用那种并不能直接进行比较的分数, 所以通常只能通过信度系数比较两项测试才有可能得到有意义的结果。同等条件下, 信度系数较高的测试, 即该组群体中的每个个体成绩排名更稳定的测试更佳。

其他可能不同的方面主要是关于测试结果的效度和实用性。就目前所能达到的评估程度而言, 效度是一个测量方法或程序必须具备且至关重要的特征。而一个测量程序只有先具备一定信度才可能具有一定的效度, 信度只有在这一点上才具有较高的重要性。一项测试的效度上限值依其信度而定。一项测试首先必须具备一定的测量能力, 才能有可能有针对性地用来测量我们想测量的特征或属性。从一个信度为零的测量工具中提取不出任何有用信息, 只有纯偶然性的数据结果。它本身就不具有任何关联性, 因此也不可能与其他任何东西关联起来。

假设已经使用测试-再测试或平行测试的方法求出了两项测试的信度系数, 那么理论上通过任意两种方法得出的信度系数之间的相关系数值不会超过二者乘积的平方根, 即:

\[{r}_{12} \leq  \sqrt{{r}_{11}{r}_{22}}\]

那么,如果已知一项选拔考试的信度系数为0.80,一套监管评级体系的信度系数为 0.50 , 则理论上二者相关关系值的上限为:

\[\sqrt{\left( {0.80}\right) \left( {0.50}\right) } = \sqrt{0.40} = {0.63}\]

通常就相关结果变量的信度系数所做的预测很少受到人为因素的影响, 除了从中获得一些有用信息, 但我们可以采取一些措施以保证对照测试组中得出的信度系数在一定程度上是合理可靠的。

如前所述,一项测试的测量结果有效则必然可靠, 但反过来可靠的结果却不一定有效。某一项测量结果或许具有极高的精确度, 但仍有可能对我们的目的没有任何效度可言。比如, 我们可以很准确地测量出一个人的头围, 但它实际上对我们评估其智力起不到任何作用。效度不仅仅只是测量结果的准确性。

综合考虑成本、便利性等因素, 我们有时可能也会选择信度相对较低的测试。我们可能会更倾向于使用一项 40 分钟的低信度测试, 而不是 3 个小时的高信度测试, 因为就测试的目的而言, 3 个小时的测试时间实在是太长了。这些都是一些超出测试理论范畴的一些臆断因素。

## 4.6 影响信度的因素

鉴于前文介绍的这些局限性, 我们更倾向于信度较高的测试。但是, 为了能够公正地比较两项或多项测试的信度系数, 必须考虑到如下几个方面的因素:

1. 样本内部个体在所测量特征上的差异性

2. 测试对象在所测量特征上的整体水平

3. 测试的长度

4. 预测信度的具体操作程序和方法

## 1. 测量对象的差异性

信度系数指的是一项测试如何具有一致性地确定某群组中每一个体相对于该群组中其他个体的位置。当进行重复测试或 \( \mathrm{A}\text{、}\mathrm{\;B} \) 两种形式的测试时,受试者的排列名次基本没什么变化,该测试就会有一个很高的信度系数。但受试者名次变化的差异大小取决于其成绩之间的差异大小。若要对比二年级学生和七年级学生在阅读能力上的差异, 甚至无须准确度特别高的测试。反之, 要想充分了解二年级某班所有学生的水平差异, 则困难得多。

如果将各个不同年级小学生的成绩放在一起对比考察, 可能会得到一个相对更高的信度系数。例如, 奥蒂斯智力测试试用版 (Otis Quick-Scoring Mental Ability Test-Beta) 手册中曾给出了针对单一年级群体分别进行测试的复本信度值, 其范围为 0.65 到 0.87 , 相应的平均值为 0.78 。但对所有年级 (四年级到九年级) 进行综合考察, 所得的信度系数为 0.96 。这些数据均来自于使用同一项测试和测试程序对同一群体进行测量的结果。它们实际上是同一批分值, 只是分组不同而已。它们反映的也是同一测量程序的精准度。但是单单只是用信度系数来表示各个年级的联合组中更大范围的个人差异, 对所有年级的整个组合群体而言, 它的值就要比对单个年级进行测量时高许多。标准测量误差表示的是对某一个体进行单次测试的相关测量程序的准确度。由于无法通过个人所在的整个群体相应的数据计算标准测量误差, 所以根据方程 (4.4) 可知, 测试的信度系数必然会随着群组内部差异性的升高而增大。

要评估上述信度系数, 必须考虑到受试群体的能力水平范围。针对不同年龄段或年级的组合群体进行测试所得结果的信度系数通常肯定会比实际值偏大。但即使是在不那么极端的情形中, 仍然必须考虑到该群组在相关测量特征上的差异性。与年级群组相比, 针对不同年龄段的组合群体的测试信度系数似乎更高, 因为同一年龄段测试对象之间的能力水平差异通常比处于同一年级的测试对象更大。对来自不同社会经济水平和背景的小学生与来自同一阶层的小学生进行测试, 前者得出的信度系数往往更高。比较不同的测试时, 则必须考虑该信度系数是基于什么样的测试群体得出的, 这一点目前可以参考测试发布者的相关说明。同时还应仔细对比和分析针对内部差异性较大的群体进行测试所推断出的信度系数及相应的测试和测量程序。

## 2. 测量对象的特征等级

一项测试测量结果的精确度可能还与测试对象的能力水平有关; 但是, 要解释清楚这层关系的本质, 没有什么简单原则可言。它取决于具体的测量方法和测试程序。 对于那些觉得该测试难度较大的对象来说, 比如完成任务或题目的过程中需要进行大量的猜测, 其准确率则可能相对偏低。在另一种极端情形下, 如果测试对相应测试群体来说特别简单, 比如所有受试者都能非常轻松地答对大部分题, 那这类测试在区分群组内部个体的能力水平差异上可能同样也会被认为是低效或无效的。因而, 这类测试的信度系数也会相对偏低。当大多数题目对于受试者而言比较简单时, 就好比将测试缩短了一样, 因为得分差异其实主要就在于能否答对少数难度更高的题, 而有些人能做出来, 有些人却做不出来。通过项目反应理论只能获取一些有关受试者在相关测量特征上的能力水平信息, 即其在某道题上能否回答正确的概率有多大。在是非判断测试中, 即要么掌握要么没掌握, 关注的重点一般是大多数受试者通过或未通过测试的原因。这一点稍后会在本章中的标准参照测试的信度这部分单独进行介绍。

另外, 对于各中间水平难度的测试, 其准确性也可能有所差异。一丝不苟的测试设计者会同时提供与不同得分水平相对应测试的标准测量误差。若测试指导手册中给出了不同的标准测量误差值, 那么我们就可以据此评估针对不同类型群体的测试精确度, 并且可以得出有关某一特定个体得分准确度的更加合理的推断。测试中每一个体的得分都可以根据其所属的测试难度水平对应的标准测量误差进行解析。如下表 4-3 所示,以年级当量表示的学生在爱荷华州基础技能测试 \( \mathrm{G}/\mathrm{H} \) 类中的成绩情况, 表中列出了该词汇测试中不同分数段对应的标准测量误差。



表 4-3 爱荷华州基础技能测试词汇测试对应的标准测量误差

<table><tr><td rowspan="2">年级当量区间</td><td colspan="3">以年级当量单位表示的标准测量误差</td></tr><tr><td>四年级</td><td>六年级</td><td>八年级</td></tr><tr><td>20—29</td><td>5.4</td><td/><td/></tr><tr><td>30——39</td><td>3. 8</td><td/><td/></tr><tr><td>40 — 49</td><td>3.1</td><td>9.0</td><td/></tr><tr><td>50—59</td><td>3. 6</td><td>6. 3</td><td>10.1</td></tr><tr><td>60—69</td><td>3.1</td><td>4.5</td><td>8.1</td></tr><tr><td>70—79</td><td>4. 9</td><td>3. 8</td><td>6.8</td></tr><tr><td>80—89</td><td/><td>3.1</td><td>5.9</td></tr><tr><td>90-99</td><td>3. 1</td><td>3. 8</td><td>5.5</td></tr><tr><td>100—109</td><td/><td/><td>6. 8</td></tr><tr><td>110—119</td><td/><td/><td/></tr><tr><td>120—129</td><td>3.1</td><td/><td>6. 8</td></tr><tr><td>总体分布</td><td>6. 3</td><td>5.5</td><td>6. 8</td></tr></table>



就该测试而言, 成绩分布比较靠近中间部分的小学生比分布在两端的小学生, 即只答对了几道题和几乎答对了所有题的测试对象, 其测量结果会稍微更准确一些。 该测试的设计者有意增加了许多中等难度的题, 而相对减少了非常难或非常简单的题目量, 从而对中间群体的能力进行区分。这样一来, 相对较长的测试更适合中等水平的大部分学生, 而非分布在两端的少部分, 且测量结果也较后者更准确。

## 3. 测试长度

由前面部分对折半信度系数的介绍可知, 测试的信度取决于测试长度。测试题日质量、这些题目所测量的特征以及受试者的性质相同的情况下, 测试的信度和测试长度之间的关系可以如下公式表示:

\[{\widehat{r}}_{KK} = \frac{k{r}_{tt}}{1 + \left( {k - 1}\right) {r}_{tt}} \tag{4.8}\]

其中 \( {\widehat{r}}_{KK} \) 表示所推测的长度为原测试 \( k \) 倍的测试的信度值, \( {r}_{u} \) 为原测试的信度值,而 \( k \) 为表示该测试长度的变量。该公式是公式 (4.5) 的通用版本。

假设有一项由 20 道题组成的拼写测试, 其信度值为 0.50 , 而我们想计算同条件下一项长达 100 道题的测试的信度。那么代入上述公式可得:

\[{\widehat{r}}_{KK} = \left( {5 \times  {0.50}}\right) /\left\lbrack  {(1 + \left( {4 \times  {0.50}}\right) }\right\rbrack   = {2.5}/{3.0} = {0.83}\]

随着测试长度的增大, 测量误差中的偶然因素或多或少地被抵消掉了, 个人成绩也在越来越大的程度上完全取决于其在相关测量特征上的能力水平, 因而由此对每一个体在测试中的表现所做的评估也就更准确。

当然, 测试的长度也会受到很多实际因素的限制, 如受试者可用于测试的时间、 受试者的体力和耐心, 有时甚至还包括我们客观上设计不出更多同等质量的测试题日。尽管受到诸多因素的限制, 适当增加测试长度仍然是可以提高其信度的。除此之外的唯一限定性在于使用每道题测量相关特征的结果信度都必然大于零。

但我们应该注意的是, 随着信度的增大, 通过增加测试长度所得的信度增量会逐渐减少。即当一项测试的信度已经达到一定高度后, 再继续每上升一点都是相应的大幅度增加测试长度换来的。将原 20 题的拼写测试增加到 100 题会使该测试信度有比较明显的增长 (从 0.50 到 0.83), 但如果将该测试长度再增大一倍, 即到 200 题, 其信度则只增加了一点, 从 0.83 到 0.91 。再增加一倍到 400 题, 其信度将达到 0.95 。可见测试时长的增加与测试信度的增长并不成正比。

还有一种特殊类型的延时方法, 即增加评分员的数量, 评分员就是对测试对象或测试对象在某方面特征或能力上的表现进行评分的人。对受试者相关表现判断的不一致性在一定程度上会造成评价结果的不可靠性, 而这一点通常可以通过增加判分员或评分员数量解决。如果有一些对测试材料同等熟悉或在有关个人能力评价类型的测试中对相关受试群体同样了解的评分员, 那么综合他们的评分则能够得到更可靠的测试结果; 通过公式 (4.8) 可计算出相应信度增量的近似值。例如, 若一对典型评分员对写作测试中学生表现所作评价之间的相关系数为 0.40 , 那么综合三位判分员的评分, 再将其与另外三位判分员给出的综合成绩关联起来, 求出的相关系数值如下:

\[\left( {3 \times  {0.40}}\right) /\left\lbrack  {1 + \left( {2 \times  {0.40}}\right) }\right\rbrack   = {1.2}/{1.8} = {0.67}\]

同样地, 我们也可以推断缩短测试长度引起的相应测试信度的减少量。假设有一项 100 题的拼写测试, 其信度值为 0.90 , 我们想要推测将原测试减少到 40 题后, 其对应的信度值是多少。那么,新测试的长度为原测试长度的 \( {40}/{100} = {0.40} \) 倍,因此对该缩短后的测试信度的推断值即为:

\[{\widehat{r}}_{KK} = \left( {{0.40} \times  {0.90}}\right) /\left\lbrack  {1 + \left( {\left( {{0.40} - {1.00}}\right)  \times  \left( {0.90}\right) }\right) }\right\rbrack  \]

\[ = {0.36}/\left\lbrack  {1 + \left( {-{0.60} \times  {0.90}}\right) }\right\rbrack   = {0.36}/{0.46} = {0.78}\]

该方法对于判断该缩短后的测试对我们而言是否具有足够的信度十分有效。

## 4. 评估信度的方法

我们所能获得的信度系数值的高低同样也取决于选用哪套操作程序和方法来进行推断和评估。由表 4-1 可知, 不同的测量程序会涉及不同的差异因素, 并且只有在具有一定时间间隔的情况下使用一对平行形式的测试才能对上述所有四种可能的导致不稳定性的 “误差” 来源进行考察。也就是说, 该推断信度的方法对测试的下述能力的定义更准确, 即保证重复进行时得到的测量结果的稳定性。因此, 单个测试对象不仅必须具备在不同样题或测试任务上表现的稳定性, 还必须保证其不会因为测试之间的时间间隔发生生理或心理上的变化。表 4-4 所示为一些关于同一项测试的信度系数, 但是由不同的程序计算得出的, 而且各自具有不同的时间间隔。



表 4-4 通过测试一再测试、库德一理查森公式 20 (KR-20) 及使用等效形式的测试计算得出的信度系数比较

<table><tr><td colspan="2" rowspan="2">测 试</td><td colspan="3">测试-再测试 (月 / 个)</td><td rowspan="2">KR-20</td><td rowspan="2">等效形式测试 \( {}^{b} \)</td></tr><tr><td>8</td><td>\( {24}^{\mathrm{a}} \)</td><td>\( {48}^{ \circ  } \)</td></tr><tr><td rowspan="3">认知能力测试, C 级</td><td>文字类</td><td>0.91</td><td>0.85</td><td>0.83</td><td>0.93</td><td/></tr><tr><td>数字类</td><td>0.87</td><td>0.82</td><td>0.79</td><td>0.91</td><td rowspan="2"/></tr><tr><td>非文字</td><td>0.86</td><td>0.75</td><td>0.73</td><td>0.93</td></tr></table>

续表

<table><tr><td rowspan="2" colspan="2">测 试</td><td colspan="3">测试一再测试 (月 / 个)</td><td rowspan="2">KR-20</td><td rowspan="2">等效形式测试</td></tr><tr><td>8</td><td>\( {24}^{\mathrm{a}} \)</td><td>\( {48}^{\mathrm{a}} \)</td></tr><tr><td rowspan="2">爱荷华州基础能力测 试, 五年级</td><td>数学综合</td><td>0.85</td><td>0.84</td><td>0.64</td><td>0.94</td><td>0.88</td></tr><tr><td>语言综合</td><td>0.88</td><td>0.89</td><td>0.75</td><td>0.96</td><td>0.91</td></tr><tr><td rowspan="2">盖茨一马克金蒂尔阅读 测 试 (Gates-MacGintie Reading Test,D 级)</td><td>词汇, 四年级</td><td>0.87</td><td/><td/><td>0.91</td><td>0.89</td></tr><tr><td>理解, 四年级</td><td>0.82</td><td/><td/><td>0.91</td><td>0.89</td></tr></table>

\( {}^{a} \) 间隔 24 和 48 个月复试不适用于盖茨一马克金蒂尔阅读测试。

\( {}^{b} \) 对于认知能力测试而言,不适用等效形式测试的相关系数。



表 4-4 中比较了时间间隔分别为 8 个月、24 个月或 48 个月的测试-再测试方法所得测量结果的信度相关系数, 通过时间间隔较短的具有等效形式的测试所得结果的信度相关系数以及通过 KR-20 公式计算出的内部一致性信度值。由表中结果可知, 测试一再测试方法得出的相关系数与其他任意一种方法计算出的值一样低, 甚至更低一些, 并且间隔时间较长的重复测试的相关系数普遍低于间隔时间较短的。这些不同的测量方法各有千秋, 但无论在哪种情形下, 都需要将得出的有关内部一致性的测量值适当减去一点。若以 8 个月的时间间隔进行一对替换形式的测试, 那么根据该不同形式且在不同时间点进行测试的结果推断出的相关系数则很有可能会比通过测试一再测试所得的信度系数高。

## 5. 实际信度和理论信度

美国教育研究协会 (AERA) 或美国心理学协会 (APA) 制定的《心理学和教育学测试标准》(美国教育研究协会、美国心理学协会及全美教育测量委员会,1999)要求测试设计者们在发布测试时应同步提供测试的信度和标准测量误差的相关信息以供测试者们使用和参考。因为可能使用这些测试的人会仔细检查发布该测试的人给出的推断相关信度的数据或资料, 所以这实际上对发布者来说提供的值越高越好。上述已经介绍过诸多能够影响一项测试表面信度的因素, 其中影响力最大的是测试群体内部的差异性和测试长度。另外有关测量分数还有一个误差来源, 即会增加不可靠性的因素, 是测试者或评分者个人的不稳定性或不一致性。对于采用电脑阅卷的测试, 该误差来源则仅限于测试的方法和程序, 而这基本为零, 但对于主观问答题测试、评价个人作品或论述, 还有许多有关临床和教育学领域测试的评估等, 该误差来源则的确是一个极大的潜在因素。

一项测试的分值信度还取决于设计该特定测量方法和程序时的背景。如果使用该测试时无法保证与标准形式的测试所需的条件一致, 那么所得分值的信度很可能也会出现差异。例如, 某测试发布者有可能基于一些测试协议对一项测试的信度做出推测, 这些协议是由两位以上具有专业培训经验的评分者评定过的, 且对于他们评定过程中的一致性也有相应的监督机制, 因此在很大程度上避免了评分者主观上的差异性。韦氏儿童智力量表 (Wechsler Intelligence Scale for Children) 第三版标准测试的数据结果 (WISC-III, 韦克斯勒, 1991a) 也是这样得出的。在这些限定条件下对相关测试信度的推断值为其可能达到的最大值或理论值。在实际应用中, 所得分值的真实或实际信度会低于标准化测试的信度评估值, 但具体程度不得而知。因为最初的评估者可能不像现在这样接受过专业的培训, 且当时的分数核查体系水平无疑也比现在要低。比如, 考夫曼 (Kaufman, 1990) 中的一些文件资料就存在大量的评分误差现象, 尽管这还是由经验丰富的临床医生就韦氏儿童智力测试中受试者的表现做出的评价。贝尔克、洛贝洛、雷和扎哈尔 (Belk, LoBello, Ray and Zachar, 2002) 都曾指出抽取一些研究生水平的实习生会发现其做出相关评价所依据的所有测试协议在程序操作或评分上都存在一定误差。含有误差的分值数量从 3 个到 116 个不等, 平均达到了 45.2 个。因此, 类似韦氏儿童智力量表第三版这样的测试, “在实际应用中”计算所得的标准测量误差与测试发布者在理想情况下获取的值相比会更高。 我们无法信誓旦旦地说计算得出的哪项测试信度的值是绝对准确的。要推测一项测试的信度, 在构思数据搜集的方法和程序时应该考虑到如下这一点, 即尽量保证该测试过程能够考察到信度研究中涉及的所有会造成差异性结果的误差来源。

## 4.7 最 低 信 度

很显然, 同等条件下, 一套测量程序的信度越高, 我们越满意。但总免不了有人会问, “可接受的信度下限值是多少?” 如果不得不给出一个确定的值或针对某一个体设置一些限制, 那么我们将会充分利用手边可使用的相关数据资料推算出该下限值, 不论得出的结果有多么不可思议, 只要不是零, 因为我们对信度为零的情况一无所知 (和前面一样, 当然这里需要考虑的最关键的因素还是测量程序的效度)。评价任何新的测量程序时往往都需要与其他相似程序进行对比分析。因此, 对于一项信度系数为 0.80 的高中数学测试, 若相同成本的测试的信度能轻易达到 0.85 或 0.90 , 相对而言 0.80 似乎就显得很一般了。但是, 相比信度系数一般只能达到 0.45 或 0.50 的类似评分体系, 一套评价 “领导能力” 的测量程序信度能达到将近 0.60 就会让人觉得这是相当不错的表现。

虽然我们无法为一套测量程序的信度设置一个绝对下限值, 但可以确定在评价某一个体或群组时为了达到特定的准确度所必需的信度水平。假设对两位受试者进行了一项测试, 一人的成绩在整个群体中排在第 75 位百分位处, 另一位排在第 50 位百分位处。若使用同一套题对他们进行再测试, 后者得分超过前者的概率有多大? 表 4-5 所示为该测试不同的信度系数值所对应的上述排名逆转的概率。因此, 若信度为零, 那么后者超过前者的概率则完全是一半对一半, 因为两者成绩评估过程中的误差完全是随机出现的。当信度系数为 0.50 时, 后者超过前者的概率仍然不低于三分之一。当信度为 0.90 时, 重复测试中后者反超前者的概率仍有十二分之一。信度系数须达到 0.80 , 重复测试时二者排名顺序仍旧保持不变的概率才会有五分之四。



表 4-5 关于排在第 75 位和第 50 位百分位数的成绩在后续测试中二者排序互换的概率百分比

<table><tr><td rowspan="2">信度系数</td><td colspan="3">重复测试中排名逆转的概率百分比</td></tr><tr><td>单个受试者成绩</td><td>小组平均值 (25 人/组)</td><td>小组平均值 (100 人/组)</td></tr><tr><td>0.00</td><td>50.0</td><td>50.0</td><td>50.0</td></tr><tr><td>0.40</td><td>40.3</td><td>10.9</td><td>0.7</td></tr><tr><td>0.50</td><td>36.8</td><td>4. 6</td><td>0.04</td></tr><tr><td>0.60</td><td>32.5</td><td>1.2</td><td/></tr><tr><td>0.70</td><td>27.1</td><td>1</td><td/></tr><tr><td>0.80</td><td>19.7</td><td/><td/></tr><tr><td>0.90</td><td>8.7</td><td/><td/></tr><tr><td>0.95</td><td>2.2</td><td/><td/></tr><tr><td>0.98</td><td>0.05</td><td/><td/></tr></table>



表 4-5 中还给出了对分别有 25 人和 100 人的两个虚拟群组中上述两名学生排名逆转的可能的概率值。比如, 假设 A 班有 25 名学生, 其中平均水平的学生在更大的参照组中排在第 75 位百分位处, B 班同样也有 25 名学生, 但其平均水平的学生在该参照组中排在第 50 位百分位处, 那么若重复进行该测试, 两班平均水平的学生在该参照组中的排名发生逆转的概率又有多大? 同样地, 在极端情形中, 即信度系数为零时, 排名逆转的概率仍然是一半对一半。但是随着测试的信度系数增大, 基于群组要比基于个人所得结论的准确性上升的幅度更大。若某项测试的信度系数为 0.50 , 那么对于 25 人的测试群体, 排名发生逆转的概率为二十分之一, 而对于 100 人的测试群体, 排名发生逆转的概率为两千五百分之一。若某项测试的信度系数为 0.70 , 那么对于 25 人的测试群体相应概率仅为千分之一, 而对于 100 人的测试群体则小到几乎没有了。因此, 信度相对较低的测试用于群体性研究, 尤其是样本数目较大的群体效果更佳, 且得出的结论也较可靠。但针对单个测试对象进行研究考察时, 若要得155出具有一定准确度的结果, 则相关测试必须具有非常高的信度系数。虽然《标准》并未详细说明信度系数的下限值, 但我们可以此为测试中通用的经验法则, 即评估有关单个对象的决策时所用测试的信度系数最好不低于 0.80 , 该经验法则与推论统计学的传统做法以及一些测试发布者提供的测试指南不谋而合。

## 4.8 差异分的信度

有时相比单个分值, 我们可能对成对分值之间的关系更感兴趣。我们可能会关注一组小学生的学习能力和阅读理解能力之间有何差异, 又或是想调查从 10 月份进行的第一次测试到来年的 5 月份进行第二次测试这期间测试对象阅读理解水平的增长。上述示例中, 每一个体的成绩只有在与其他人进行比较时才有意义。我们必须思考对这些差异性的推断结果有多大的信度, 了解两项组合测试各有什么特点。

虽然无可奈何, 但这是无可争辩的事实, 即与两项独立的测试相比, 有关两个测试分数之间差异性评估结果的信度比通常要低得多。导致其信度如此之低的原因主要有两个: (1) 由于两项测试中会有诸多不同的分值, 因此其中的测量误差会不断累积; (2) 单独考察每一个具体分值时, 不再具有测试的整体性和协同性。图 4-2 所示的简图对上述情形进行了说明。



阅读测试



图 4-2 差异分数的本质



图 4-2 中所示的每一个横向的方形条代表受试者在一项测试中的成绩 (更准确地说是成绩方差), 该方形条又分成若干个部分, 分别表示取得该得分的各种因素。 从上往下看, 第一个横条代表的是阅读测试, 第二个是学业能力倾向测试。注意受试者在阅读测试中的成绩被分成了三个部分, 标示 “一般因素” 的部分包括个人的综合智力以及有关上述两项测试的应试技巧等。在计算这两项测试的相关系数时可能会考察到这一点。另一个标示“具体阅读因素”的部分仅指阅读测试中表现出来的能力和技巧。个人在该因素上的差异相对稳定, 但其中的原因与学业能力倾向测试有所不同。第三部分为“误差”, 即该阅读测试的标准测量误差所反映的测量误差的偶然性。能力倾向测试也被分成了类似的三个模块。这两项测试各自的信度系数都是综合考虑其一般因素和特殊因素的结果。

现在来看看第三个横条 (以及第四个, 即将第三个横条中间的空白部分去掉后所得)。该横条表示的是分数差, 即以某种标准分值单位表示的阅读成绩与以相同单位表示的能力倾向测试成绩之间的差。从图中可以看到, 该横条中没有表示一般因素的部分。该部分在阅读测试中为正, 在能力倾向测试中为负, 故相互抵消了, 只有特殊因素和测量误差仍然存在。特殊因素指的是个人能力方面相对稳定的部分。在第四个横条中, 测量误差占很大比重, 说明分数差异上的稳定性会比其中任意一项测试的稳定性更低。例如,如果误差在这两项测试中均占 \( {25}\% \) (即测试信度 \( = {0.75} \) ),特殊因素分别也占 \( {25}\% \) ,那么由第四个横条可知,分数差异中测量误差则占到了 \( {50}\% \) , 另外 \( {50}\% \) 为有关个人能力的特殊因素。因此,有关分数差异测量值的信度要远低于任意一项原测试的测量结果信度。如果两项测试考察的能力特征完全一样, 以致只需要考察一般因素和测量误差, 那么最后在有关分数差异的比较中就只剩测量误差了, 因为一般因素相互抵消了, 即这些分数完全不具有信度。通过使用相同的或平行形式的测试对学生进行重复测量的方法评估其在相关教学目标上能力水平的增长时, 该问题的体现尤为明显, 因为在该情形中一般因素占的比重最大。

两次测量结果之间差异的信度可通过标准分数简单表示如下:

\[{r}_{\text{diff }} = \frac{\frac{1}{2}\left( {{r}_{AA} + {r}_{BB}}\right)  - {r}_{AB}}{1 - {r}_{AB}}\]

其中 \( {r}_{\text{diff }} \) 为差异分数的信度, \( {r}_{AA} \) 为 \( A \) 测试的信度, \( {r}_{BB} \) 为 \( B \) 测试的信度, \( {r}_{AB} \) 为这两项测试之间的相关系数。

因此,如已知 \( \mathrm{A} \) 测试信度值为 \( {0.80},\mathrm{\;B} \) 测试信度值为 \( {0.90},\mathrm{\;A} \) 测试和 \( \mathrm{B} \) 测试之间的相关系数值为 0.60 , 那么可得两项测试差异分数的信度值为:

\[{r}_{\text{diff }} = \left\lbrack  {1/2\left( {{0.80} + {0.90}}\right)  - {0.60}}\right\rbrack  /\left( {1 - {0.60}}\right)  = {0.25}/{0.40} = {0.62}\]

表 4-6 所示为将各种不同组合的 \( 1/2\left( {{r}_{AA} + {r}_{BB}}\right) \) 和 \( {r}_{AB} \) 的值代入上述公式所得的 \( {r}_{\text{diff }} \) 值。若两项测试信度的平均值为 0.80,当二者相关系数值为零时,所得分数差异的信度为 0.80 , 反之当二者相关系数值为 0.80 时, 所得分数差异的信度为零。很显然, 随着这两项测试的相关系数往二者信度的平均值靠近, 其分数差异的信度也会急剧下降。



表 4-6 差异分数的信度系数

<table><tr><td rowspan="2">两项测试之间的相关系数 \( \left( {r}_{AB}\right) \)</td><td colspan="6">两项测试信度的平均值 \( \left\lbrack  {1/2\left( {{r}_{AA} + {r}_{BB}}\right) }\right\rbrack \)</td></tr><tr><td>0.50</td><td>0.60</td><td>0.70</td><td>0.80</td><td>0.90</td><td>0.95</td></tr><tr><td>0.00</td><td>0.50</td><td>0.60</td><td>0.70</td><td>0.80</td><td>0.90</td><td>0.95</td></tr><tr><td>0.40</td><td>0.17</td><td>0.33</td><td>0.50</td><td>0.67</td><td>0.83</td><td>0.92</td></tr><tr><td>0.50</td><td>0.00</td><td>0.20</td><td>0.40</td><td>0.60</td><td>0.80</td><td>0.90</td></tr><tr><td>0.60</td><td/><td>0.00</td><td>0.25</td><td>0.50</td><td>0.75</td><td>0.88</td></tr><tr><td>0.70</td><td/><td/><td>0.00</td><td>0.33</td><td>0.67</td><td>0.83</td></tr><tr><td>0.80</td><td/><td/><td/><td>0.00</td><td>0.50</td><td>0.75</td></tr><tr><td>0.90</td><td/><td/><td/><td/><td>0.00</td><td>0.50</td></tr><tr><td>0.95</td><td/><td/><td/><td/><td/><td>0.00</td></tr></table>



心理学家和教育者必须时刻对因分数差异较大导致测试的信度偏低这一现象保持警惕。无论何时在使用测试模板对测试对象做出相关推测或判断时都会在一定程度上受到信度偏低带来的影响。因此, 与单独评价赫伯特在能力倾向测试或阅读测试中的表现相比, 在做出有关他在后一项测试上的成绩不如前一项的判断时必须加倍小心。同样地, 相比判断玛丽的阅读水平比简高 (或低), 在做出有关玛丽阅读水平的增长幅度比简大这样的论断时也需要更加谨慎。解析任何的分值差异时都需要从该差异性的标准测量误差出发, 该标准误差值约为这两项测试的标准测量误差平均值的 1.4 倍。这一点尤其适用于根据对个人成绩提高或进步所做的相关评估结果将学生分配到相应的年级。

许多差异性相对于该测试的标准误差而言都非常小, 因此信度也不高。这一点在分析分组组合或分数的涨幅时尤其明显 (近期有关增长模式的研究表明, 有关测量方法或程序不稳定的问题, 可以通过在两个以上不同的时间点进行测量来解决。然而, 解析分数组合中分值之间的差异性时, 仍然会存在上述问题。详见 Willett, 1988 和 Kaufman, 1990。其中说明了如何在标准化样本中利用差异分数的分布帮助解析分数组合)。

## 4.9 不可靠性对变量之间相关系数的影响

说到测量误差, 这里还有一点需要稍加注意, 因为它会影响我们对不同测量程序之间的相关性的理解和分析。以对比一套有关阅读理解的测量程序和一套有关数学推理的测量程序为例。在这两项测试中, 个体的成绩差异部分来自个人能力的真实差异, 还有一部分来自测量误差的偶然性。但如果这些测量误差真的是随机的, 那阅读测试中分值的测量误差与数学推理测试中的误差则是完全不相关的。这些没有相关性的误差是每位受试者得分中的一部分, 因而也存在于这两项测试各自的总方差中。也就是说, 它们会削弱受试者在阅读上和在数学推理上所得真实成绩值之间的任何相关性。这是因为测量值由真实值和测量误差组成, 测量值之间的相关性实际上是潜在的真实值之间的相关性 (所测量的特征本身之间的实际关联性) 和这两项测试中测量误差值之间的零相关性, 是这二者的折中值。

图 4-3 中阐述了测量误差对两项测试之间相关性的影响, 分别为阅读理解测试 (第一个横条) 和数学推理测试 (第二个横条)。与图 4-2 中所示类似, 每项测试由一些一般因素 (使二者具有相关性)、一些与特定测试相关的具体因素和误差组成。很显然, 不同测试之间的具体因素和测量误差是没有相关性的。第三个横条表示所考察变量之间的相关性。每一个方块代表相应比例的相关度, 等量排列在一般因素的两边。从第四个反映无误差的真实分值之间相互关系的横条可知, 一般因素占据更大的比例, 相应的相关系数值也更高。

我们常常希望根据所得的测试结果求取潜在的真实值之间相关性的推测值, 以便更好地理解所涉及的这些函数的共同点。幸运的是, 这一点可以通过一个相当简单的方法实现, 而该过程就叫作校正不可靠性引起的弱化。该推测值可用如下公式表示:

\[{\widehat{r}}_{{T}_{1}{T}_{2}} = \frac{{r}_{12}}{\sqrt{{r}_{11}{r}_{22}}}\]

其中 \( {\widehat{r}}_{{T}_{1}{T}_{2}} \) 为真实值之间相关性的推测值, \( {r}_{12} \) 为测量值之间的相关系数值, \( {r}_{11} \) 和 \( {r}_{22} \) 分别为这两次测量所得结果的信度系数值。

举个例子, 已知阅读测试和数学推理测试之间的相关系数值为 0.56 , 两项测试的信度系数分别为 0.71 和 0.90 , 那么由此推断出的关于二者零误差真实值之间的相关性系数值则为:

\[{\widehat{r}}_{{T}_{1}{T}_{2}} = {0.56}/\sqrt{{0.71} \times  {0.90}} = {0.56}/{0.799} = {0.70}\]





图 4-3 为什么真实值之间的相关性高于测量值之间的相关性?



考察上述两种函数时, 以相关系数值为 0.70 而非 0.56 的角度去考虑更佳, 尽管这两项测试之间的相关度只有 0.56 。

## 4.10 标准参照测试的信度

到目前为止, 有关信度的探讨都是假设测试为延续性的且没有上限或 “天花板” 的变量, 而通常在常模参照框架下设计的测试也是如此。我们知道在一般的测试中不可能是大批的受试者都取得满分或接近满分的成绩。但标准参照测试通常是专门针对少数有限种类的能力或特征设计的, 这些能力或特征涉及的内容都在教学大纲范围。因此在这类测试中, 绝大部分学生都可能取得满分或接近满分的成绩就不足为奇了。传统测量信度的方法不太适用于这类测试, 因为所得的整组分值之间几乎没有什么差异性。另外, 如前所述, 这种缺乏差异性的现象会导致由此推测出的信度相关系数值偏低。

分析标准参照测试分值的方法有三种。一是掌握/没掌握所测量的特定技能或知识体系。由此, 测试对象将被分成两个部分, 若得分超过了提前设定的分数线则为已掌握者 (达到了该测试材料所要求的必需水平), 反之得分低于该分数线的则为未掌握者。界线分明而没有中间区域, 且所有掌握者具有相同的性质。

第二, 从掌握程度分析标准参照测试分值。在该方法中, 我们也会将每个人的成绩与提前设定好的标准进行比较, 但与刚刚过线的测试对象相比, 那些得分远在分数线之上的人则被认为其掌握程度更高。同样地, 与只差几分就过线的测试对象相比, 那些得分与分数线相差甚远的人则被认为其掌握程度更低。

第三种分析标准参照测试的方法是将测试题目当作从某一内容领域抽取的样题。受试者在该套试题中的得分即为有关其相应领域水平的推测值, 也就是其在一项包含了该领域所有题目的测试中可能取得的分数。这里所面临的问题就变成了我们对该领域水平所做的推测准确度有多高?

在标准参照测试信度的评估方面, 我们已经取得了巨大的进步。虽然每种解析标准参照测试分值的方法在具体操作上会有少许差异性, 但所有的方法都遵循内部一致性的概念。接下来我们将详细介绍掌握/非掌握方法中会涉及的有关一致性的问题。然后简单阐述其他分析方法中会遇到的一些问题。伯克(Berk,1984)、布伦南 (Brennan, 1984) 和萨博柯维雅克 (Subkoviak, 1984) 对上述三种解析方法的可行性操作程序进行了系统的论述。

掌握/非掌握方法将受试者分成两个类别。我们通常根据在不同的时间点使用同一测试进行两次测量或者使用一对替代形式的测试所得的两次分类结果的一致性对该解析方法的信度进行评估 (还有与 KR-20 类似的单词测量方法)。例如, 假设有一项专门考察学习英语的留学生 \( {}^{\text{①}} \) 对一些具体英语句子结构的掌握情况。在此测试中, 布拉奇福德 (Blatchford, 1970) 使用了 10 种英语句子结构来评估每个人的掌握情况, 每种结构有四道题。他共设计了两套相似形式的题, 在第一次测试完成后一周进行了第二次测试。测试中, 学生们被要求选出符合英语语法的句子结构。图 4-4 所示为有关其中两种句子结构的多项选择题。每道题下面都有一个表格, 分别是所有学生在两次测试中关于这两种句子结构答对 0 题、 1 题、 2 题、 3 题或 4 题所对应的比例。例如,第 6 题下方的表格内,第一行第一列中的数字表示该测试群体中有 \( 2\% \) 的对象在 \( \mathrm{A} \) 测试中一道题也没答对,在 \( \mathrm{B} \) 测试中答对了 4 道题。

首先来看图 4-4 中的第六题。注意在这两次测试中的该句子结构上有 \( {36}\% \) 的学生得了满分 4 分, \( {21}\% \) 的学生得了零分。该群组中这 \( {57}\% \) 的对象在此四题小型测试上的两次表现完全一致且清晰明了。一组 \( \left( {{36}\% }\right) \) 似乎已经完全掌握了正确的用法, 而另一组 \( \left( {{21}\% }\right) \) 似乎完全不懂该句子结构的使用规则。还有另外 \( {43}\% \) 的学生在一项测试中的不同题目上或在这两次测试中表现出一些不一致性。我们应该如何表述这种不同程度的不一致性或不可靠性呢?

---

<!-- Footnote -->

① 在讲英语的地区或国家留学的非英语母语学生。一译者注

<!-- Footnote -->

---

Set 6. The use of "but" after an "although" clause.

(1) Because he was late, he still attended the meeting.

* (2) Although he was late, he still attended the meeting.

(3) Although he was late, but he still attended the meeting.

(4) Because he was late, but he still attended the meeting.



<table><tr><td rowspan="2">答对的题目数——B 测试</td><td colspan="5">答对的题目数——A 测试</td><td rowspan="2">总数</td></tr><tr><td>2</td><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td>4</td><td>2</td><td>1</td><td>2</td><td>6</td><td>36</td><td>47</td></tr><tr><td>3</td><td>1</td><td>1</td><td>1</td><td>1</td><td>7</td><td>14</td></tr><tr><td>2</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>5</td></tr><tr><td>2</td><td>3</td><td>1</td><td>1</td><td>1</td><td>1</td><td>7</td></tr><tr><td>2</td><td>21</td><td>3</td><td>1</td><td>1</td><td>1</td><td>27</td></tr><tr><td>总数</td><td>28</td><td>7</td><td>6</td><td>13</td><td>46</td><td/></tr></table>



Set 10. The use of "most" with plural nouns.

(1) The most of the students must study three hours every night.

* (2) Most students must study three hours every night.

(3) Most student must study three hours every night.

(4) Most of the student must study three hours every night.



<table><tr><td rowspan="2">答对的题目数——B 测试</td><td colspan="5">答对的题目数——A 测试</td><td rowspan="2">总数</td></tr><tr><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td>2</td><td>21</td><td>3</td><td>1</td><td>12</td><td>18</td><td>38</td></tr><tr><td>3</td><td>1</td><td>2</td><td>3</td><td>5</td><td>5</td><td>16</td></tr><tr><td>2</td><td>2</td><td>3</td><td>1</td><td>3</td><td>12</td><td>10</td></tr><tr><td>3</td><td>4</td><td>4</td><td>1</td><td>5</td><td>1</td><td>11</td></tr><tr><td>0</td><td>15</td><td>5</td><td>1</td><td>3</td><td>1</td><td>25</td></tr><tr><td>总数</td><td>23</td><td>16</td><td>10</td><td>24</td><td>27</td><td/></tr></table>

图 4-4 掌握情况测试中的两道有关英语句子结构的样题,

星号表示正确答案 (表中的数字均为百分数)



需要谨记的一点是, 这种类型的测试主要是用来判断每名学生是否掌握了某一具体技能。或许我们可以设定一个严格的标准, 只有得满分, 即答对全部四道题, 才算掌握了相关技能。或者设定的标准也可以稍微宽松一点, 即四题中答对三题或以上就算合格, 唯一那道答错的题可能是由于测试对象的粗心或一些外界因素所致. 不论使用哪种标准, 我们需要探究的重点问题仍在于 “在第一项测试中成绩排名在第二项测试出现变化甚至逆转的概率是多少?”或者“在第一项测试中成绩合格而在第二项测试中又不合格或反过来在第一项测试中成绩不合格而在第二项测试中又合格的概率有多大?”

如下为两种不同标准下所有学生在上述第六题上的通过率:



<table><tr><td colspan="3">严格标准 (答对所有四道题) A 测试</td><td colspan="3">宽松标准 (四题中答对三题) A 测试</td></tr><tr><td>B 测试</td><td>不合格</td><td>合格</td><td>B 测试</td><td>不合格</td><td>合格</td></tr><tr><td>合格</td><td>11</td><td>36</td><td>合格</td><td>8</td><td>53</td></tr><tr><td>不合格</td><td>43</td><td>10</td><td>不合格</td><td>33</td><td>6</td></tr></table>



若按照严格标准,则要么都合格要么都不合格的学生共占 \( {79}\% \) ,在任意一项测试中不合格的学生占 \( {21}\% \) 。在相对宽松的标准下,相应的比例分别为 \( {86}\% \) 和 \( {14}\% \) 。

关于第十题的测试结果可用同样方式表示如下:



<table><tr><td colspan="3">严格标准 (答对所有四道题) A 测试</td><td colspan="3">宽松标准 (四题中答对三题) A 测试</td></tr><tr><td>B 测试</td><td>不合格</td><td>合格</td><td>B 测试</td><td>不合格</td><td>合格</td></tr><tr><td>合格</td><td>20</td><td>18</td><td>合格</td><td>14</td><td>40</td></tr><tr><td>不合格</td><td>53</td><td>9</td><td>不合格</td><td>35</td><td>11</td></tr></table>



很显然, 在第十题上得分相反的群体所占比例大于第六题。在严格标准和宽松标准下,得分相反的群体所占比例分别为 \( {29}\% \) 和 \( {25}\% \) 。有关这道题测试结果的信度对于我们推断最核心的问题: “某个学生是否掌握了这项技能?”来说并没有上一道题高。

对于一项用于简单地判断测试对象对某项技能的掌握程度 “合格/不合格” 的测试来说, 重复测试时测量结果的一致性似乎就是一个相对合理的有关该测试信度的指数。但遗憾的是, 该指数只能用于说明该受试群体以及该项测试的特征。若许多学生的成绩刚达到掌握或合格的门槛 (即学会了一项特定技能, 但刚刚才勉强学会它), 那么重复测试时很可能也会有大量学生成绩发生逆转, 即再次测试时表现为不合格。反之, 若许多学生对该技能的掌握程度远在合格分数线之上或者许多人从未学习过该技能, 那么重复测试时的逆转率也会相对较低。同样地, 如果是在针对该技能进行一段时间的有效教学之后再去评估两次测量结果的一致性, 那学生在两次测试中从完全的未掌握者转变为完全的掌握者都是有可能的, 这样就会造成一种所做出的相关评估表面上的不可靠性。因此, 评估一项旨在针对在所测量技能上刚达到合格水平的学生群体进行掌握/非掌握判断的测试信度十分重要, 因为该测试最终也会用来对他们进行测试。另外, 在两项测试的间隔期间没有进行相关积极教学的情况下研究测试的信度也十分重要。

现在我们需要了解如何判断在重复测试中成绩具有一致性的学生所占比例以保证该测试得出的测量结果达到令人满意的水平。在一种极端情形下, 会有两种选择 (即掌握者或未掌握者),这时纯靠运气答题所得测量结果的一致性则为 \( {50}\% \) 。若该测试所得结果的一致性完全就像是靠抛硬币决定的, 那计算出的值显然没有任何意义和价值。在另一种极端情形下,这两种形式的测试所得结果表现出 \( {100}\% \) 的一致性, 那么该测量结果的信度显然也会达到其相应的最高值。因此, 主要是中间部分的分值出现频率最高, 且最值得评估。重复测试时, 在上述这两种合格标准下, 学生在这两项四题小型测试上成绩的一致性分别达到了 \( {79}\% \text{、}{86}\% \text{、}{71}\% \) 和 \( {75}\% \) ,该结果是良好、勉强可接受还是不尽如人意?

对上述问题我们很难简单地回答是或不是。其答案一方面取决于该测试的长度, 另一方面取决于根据测量结果所做判断的重要性和不可逆性。测试越短, 学生成绩发生逆转的频率就越大。所做决定或推断的重要性越低, 我们能接受的结果的可逆性程度就越大。假设所分析的测试仅由四道题组成, 那测量结果的一致性大约在 \( {70}\% \) 到 \( {85}\% \) 之间,这很可能是我们预期范围内较好的结果。若测试的结果只是用于学生在复习或补课方面的指导, 那该一致性水平就是完全可接受的, 因为第一次测试中的误差在后续测试中通常就能得到纠正。

我们之前已经阐述过, 这些结论或说明所依据的数据来自在一周的间隔时间内使用可替代形式的测试得出的测量结果。当然, 也可以将一项测试进一步细分, 然后通过单次测量方法获得两个分值。接着可以把这些分数制成表格来分析有关学生的掌握判断发生逆转的频率。但是, 对于那些刚刚过线的学生而言, 似乎其在不同测试中表现的不稳定性要比在单次测量的同一项测试所划分成的不同子测试中高得多。 布拉奇福德 (Blatchford, 1970) 发现一项单次测量的四题测试, 其稳定性系数的中值为 0.80 , 而时隔一周进行的两项不同形式的测试之间的相关系数中值却只有 0.61 。 该结果表明, 若受试学生仍处在有关某项特定技能的教学期间, 与使用相对较长的测试进行单次测量相比, 根据在不同的时间进行两项简短测试所得的数据进行有关掌握/未掌握判断可能会稳妥得多, 且很有可能会更加全面可靠。

有些方法需要用到更为复杂的统计学理论, 比如推断有关掌握程度的测量结果的信度, 以及评价对个人在某领域内水平的推测是否准确等, 我们会在这本书中对这些理论进行系统全面的介绍。伯克 (Berk,1984) 和布伦南 (Brennan,1984) 对相关可用的方法也进行了详细的阐述。但这本书中将主要说明这些方法背后更深层次的逻辑关系。164

上述例子中, 这些推断信度的方法都会涉及方差分量, 这是它们的基本特征。如第二章定义的, 方差即为标准差的平方 (更准确地说, 方差是在开平方求取相应标准差之前的那个数值)。任何一组分值的方差大小都在一定程度上取决于影响这些分数之间差异性的因素。例如, 对一组十岁的、来自堪萨斯州某个农村的中产阶级白人女孩进行有关美洲大平原的地理知识测试, 然后随机从整个美国人口中抽出一组数量相同的测试对象, 并对他们进行有关美国地理概况的测试, 前者成绩的方差可能会比后者要小得多。存在该差异性的原因主要在于, 后一种情形中的测试分数可能会受到种族或民族背景 (种族、社会经济地位、地理位置等因素)、性别、年龄差异的影响, 以及在更大程度上还有测试题目本身差异性的影响。

通过系统地控制其他差异性来源, 以每组测试分数的方差来评估上述每个影响因素 (还有一些其他可能涉及的因素) 的效果是有可能的。比如, 使用测试一再测试程序和其他平行形式测试的方法对信度所做推断的差异性可看作是有关该套样题方差的推测值, 因为在第一种情形中测试题目相同, 而在后一种情形中不同。有关性别、 年龄以及许多其他变量的影响可以通过对比测量分数的方差进行评估, 比如保持一组测试对象的这些特征不变化, 另一组有变化, 以对比这两组测量结果的方差。有关评估个人在某领域水平推测值的信度和测量掌握程度的方法程序也需要用到方差, 且该方差不仅要能反映所有受试者在测试中的每道题上的差异性, 还要能体现每个对象在不同测试中的不同题目上表现的不一致性。对哪种类型数据的一致性进行评估决定了我们所使用的方差分量。最终所得的比率结果表示的是根据不同测量方法所得测试分数的方差所占的比例, 其中一部分为个人表现较稳定的方面。对于上述问题以及其他有关信度推断的更高阶的问题, 费尔特和布伦南 (Feldt and Brennan, 1989) 在其书中进行了相当详细的讲解。

## 4.11 计算机自适应测试的信度

计算机自适应测试主要是根据标准测量误差来评估测量程序的信度。换句话说,其关注的是在完成了测量之后有关该个体真实值的不确定性 \( \left( {S{D}_{\mathrm{c}}}\right) \) ,而不是受试者在某一群体中排名的一致性 \( \left( {r}_{XX}\right) \) 。至于必须使用该方法的原因则在于不同的受试者参加的测试各不相同。实际上, 每一对受试者与测试组合都是独一无二的。因此, 某一个体在该项测试上的成绩, 浅显地说即答对了多少道题, 是无法直接与另一个人的成绩直接进行比较的。若要进行对比, 则必须将二者的测试分数转换为该潜在特征的一般量表。但是, 若将每道题当作一项迷你测试, 我们可以基于每一位受试者在这道题上的表现得出相应的标准测量误差。

在对某位测试对象毫不了解的情况下, 我们能对其在一项测试中可能取得的成绩的最佳估计就是该测试常模组的平均值, 因为平均值是该分值量表上平均平方误差最小的分值。也就是说,对有关任何既定群组在测试 \( X \) 上的测量结果而言, \( {M}_{X} \) 是我们能够对该群组中任一个体的得分做出的最佳猜测。几乎对每一位受试者来说, 该猜测值都会存在一定的误差, 个人成绩相对于平均值的差即为我们所做推测中的误差值。标准差是一种衡量平均误差大小的方法。因此, 在使用韦氏儿童智力量表对约书亚进行测试之前, 我们对他真实成绩的最佳猜测就是 100 分 (该测试常模组的平均值), 对其中标准差的推测即为 15 (该测试常模组的标准差)。在对他进行了此项测试之后, 我们对其真实成绩的最佳猜测就是有关其在测试中的表现的测量值, 而标准测量误差则为多次重复操作该测试程序得到的误差值的标准差 (参见费尔特和布伦南, 1989, 第 121 页, 有关真实分值推断的详细介绍)。

使用计算机自适应测试程序时, 每道题都被看作是一项独立的迷你测试。我们用一道题对约书亚进行测试, 他的回答会不断改变我们对其真实分值的推测。如果他答对了这道题, 我们对其真实成绩的推测值就会升高; 反之, 若回答错误则会相应地降低。在此过程中, 我们不断地出更多更难的题直到他无法再回答正确, 或出更多更简单的题直到他能够回答正确。他每答对一道题, 都会相应提高我们对其能力的推测值, 同时降低我们对其真实成绩的不确定性。但问题是 “我们要怎样表示这种不确定性呢?”

回想第三章中有关项目反应理论和计算机自适应测试的介绍, 每道题都有一条对应的题目特征曲线或说轨迹曲线, 该曲线揭示的是某一个体的能力水平与其答对该道题的概率之间的关系。对于一些主观作答类题目, 比如填空题, 答对的概率则可能从 0 到 1 波动, 其中 0 表示某对象在该道题上相关能力水平极低, 而 1 表示在该道题上相关能力水平极高。当题目属于客观选择类时, 能力水平较低的受试者选中正确答案的概率等于 1 除以该道题的选项数目。以有五个选项的多项选择题为例, 纯靠运气 (在项目反应理论术语中叫作 \( c \) 参数) 答对的概率为 \( 1/5 \) ,或者 0.2 。我们将会以一些主观作答类题目为例阐明其中的基本原则, 因此此处无须考虑全凭猜测作答的问题。若想了解如何推测客观选择类测试标准测量误差 \( \left( {S{D}_{\mathrm{e}}}\right) \) ,可参考泰森 (Thissen,1990)。

第三章中说到, 唯一能够从中获取有关受试者能力水平信息的题即为那些我们无法提前预知其是否能够答对的题。由这道题得出的有关受试者能力水平的信息叫作题目信息, 是表示答对某道题的概率的变化速率的函数, 而该变化率本身也是表示该道题对应的轨迹曲线上特定点斜率的函数。答对的概率变化越快 (曲线越陡峭), 由该道题得出的有关受试者的信息量就越大。图 4-5 所示即为此特征。在项目反应理论术语中,我们通常以第八个希腊字母 \( \left( \theta \right) \) 表示个人能力水平。如图 4-5 中,对于能力水平范围处于 \( {\theta }_{1} \) 和 \( {\theta }_{2} \) 之间的测试对象而言,答对题目的概率几乎没有变化; 这一区间内的概率值为零。因此, 该道题反映不出任何有关处于这段能力水平范围内测试对象的差异性,我们从中获得的有关该 \( \theta \) 水平范围内受试者的信息量为零。在 \( {\theta }_{3} \) 到 \( {\theta }_{4} \) 之间那段能力水平相对较高的范围内,最高点对应的对象回答正确的概率 (约 0.12) 高于这段曲线的最低点对应的对象 (约 0.05)。有关该 \( \theta \) 水平范围内测试对象的信息量大于零, 但仍然不算太高。





图 4-5 反映答对题日概率的变化速率与能力连续体上若干个不同能力水平之间关系的题目轨迹曲线



接下来看看能力水平范围处于 \( {\theta }_{5} \) 和 \( {\theta }_{6} \) 之间的对象,二者之间的距离与前两段相同。这里,正确率的变化率达到了其最大值 (此时曲线的斜率等于题目曲线斜率, \( \alpha \) 系数)。这段范围内正确率的变化率约为 0.35 到 0.65 。此能力水平范围能够获得的题目信息量最大。该范围也是受试者的能力水平 \( \left( \theta \right) \) 与题目难度 (即 \( b \) 参数) 最匹配的阶段。即当 \( \theta  = b \) 时,能够从题目中提取到有关受试者能力水平的信息量最大。随着能力水平继续增长到超过该范围, 题目信息量又开始减少, 直至回归到零,即到达约为 \( {\theta }_{7} \) 所对应的能力水平。该能力水平以上,所有受试者都能答对此道题。

项目反应理论测试研发者常常也会绘制一种曲线图, 叫作题目信息函数。它表示不同 \( \theta \) 水平所对应的题目信息的变化率。图 4-6 所示为两个典型的信息函数。它们从零开始,在 \( \theta  = b \) 时达到其最高值,然后在 \( \theta \) 水平远低于 \( b \) 时又回归到零。在 \( \theta \) 到 \( b \) 之间的水平轴上的单位不是均匀分布的。题目难度与个人的能力水平越接近,从这道题中能提取出的有关该个体的信息就越多。同一测试题目可能对有些测试对象而言反映不出任何相关信息, 而对另一些却能够从中提取出很多有效信息 (若想了解如何计算题目参数和题目信息, 可参考 Wainer and Mislevy, 1990。)





图 4-6 两条信息曲线。区分度更高的题目对应的函数覆盖的能力量表范围相对更窄



图 4-6 中所示为难度相同而区分度不同的两道题对应的两条函数曲线。表示 A 题目的曲线比表示 \( \mathrm{B} \) 题目的曲线相对更窄且峰值更高。从这两条曲线可知, \( \mathrm{A} \) 题的区分度 (其轨迹曲线的倾斜度更陡,并且在 \( \theta  - b = 0 \) 这段范围附近提供的信息量更大) 比 \( \mathrm{B} \) 题更高。但在该测量特征上 \( \mathrm{B} \) 题能够在更广泛的范围内提供一些与其有关的信息。

对任意一个既定测试对象 (更准确地说是能力水平为 \( {\theta }_{i} \) 的人, \( {\theta }_{i} \) 即为该个体的能力水平) 而言, 我们所提取的有关这些对象的信息是他们完成的所有题目相应的题目信息的总和。因此, 回想约书亚参加的那项特定测试, 我们从每道他解答的题中都能提取到相关信息, 而从这些单个题目中提取到的信息的综合即为从该项测试中得到的有关他整体水平的信息 (测试信息)。使用如下关系式可以将测试信息转化为标准测量误差的十进制当量:

\[S{D}_{e} = \sqrt{1/\text{ 测试信息 }}\]

也就是说, 通过计算机自适应测试测量得出关于我们对个人真实分值不确定性的值等于测试信息值的倒数开平方。而对解析该值的方法与传统分析测量误差的方法完全一样。

计算机自适应测试程序的其中一个优点是, 假设题库里的题目数量充足, 在有关每道题的测试完成之后,就可以计算出测试讯息和标准测量误差 \( \left( {S{D}_{e}}\right) \) ,因此测试可以一直持续直到达到我们满意的精确度水平。而在传统测试中, 大部分题目都属于中等难度水平,得分位于处于中间水平的那些测试对象的 \( S{D}_{e} \) 值往往最小,而成绩分布在两端的对象的 \( S{D}_{e} \) 值则偏大,因为更多的题目反映的是有关中间水平范围内受试者的信息。参考该题目信息, 该测试者能够继续对实验对象进行测试, 直到达到满意的精确度水平。在此准确度下对学生测试分数做出的判断能够达到一定的信度水平。

## 4.12 总 结

信度或一致性是任何测量程序必备的特征或属性。测量方法揭示出的个人表面上的差异应该尽可能在最大程度上反映出所测量特征的真实差异。因为任何测量过程都存在一定的误差, 对测量工具而言, 或许只有信度是相对独立于误差之外的一种属性。

对任何测量方法或工具而言, 不存在某一个所谓的正确信度值。测量所得的信度只可能是函数, 它可以表示该潜在特征、测试本身、该受试群体以及获得有关该信度信息的条件等的一系列属性。推测一项测试的信度度时须将所有这些因素考虑在内。

测试的目的决定一项测试的信度。若需要根据测试分数做出的决定相对难以改变, 我们会希望对自己从测量结果中提取到的信息有相当的把握, 且要求尽可能达到信度的最高值。另一方面, 如果是以此为参考做出一些短期且很容易改变的决定, 一个相对低得多的信度值或许就足够了。此外, 测试分数的预期用途也会影响所需信度的类型。若要评估个人当前的能力水平, 则需要能够反映该测试内部一致性或短期稳定性的信度系数。相反地, 若是用于预测未来的成绩水平, 则需要反映在相同跨度的时间内这些分数稳定性的信度指数。在上述任意一种情形中, 当涉及描述个人的成绩或表现时, 合理设计测试所得的标准测量误差是推断这些个人分值一致性的最佳指数。较好的测试发布者们会针对自己设计的测试给出好几种不同类型的信度系数, 以便测试者能在充分了解相关信息或情况的基础上做出决定。

计算机自适应测试的信度往往通过该测试的标准测量误差值表示, 标准测量误差是表示从该测试每道题中所提取的有关受试者信息的函数。使用计算机自适应测试程序进行测试可以一直持续直到达到满意的精确度水平。

## 4.13 习 题

1. 查看两套或三套测试手册中有关信度系数的证据。这些证据是否足够充分? 有哪些不足之处? 它们适合哪种类型的测试? 每种类型的证据分别会反映出哪个或哪些差异性来源?

2. 请列举两种情形说明需要以标准测量误差作为个人表现稳定性的指标。

3. \( \mathrm{X} \) 测试的发布者表示,该测试可用于评估测试对象当前的阅读成绩水平以及预测其接受另外一年的教学之后的阅读成绩水平。对于该测试的这两种用途, 此发布者需要提供什么样的证据证明其信度?

4. T 测试手册中所给出的信度系数是基于以下三种情况: (1) 使用同一测试于两周后进行再测试; (2) 阿尔法系数; (3) 两种不同形式的测试 \( \mathrm{A} \) 和测试 \( \mathrm{B} \) 之间相关, 且这两项测试之间有两周的时间间隔。你觉得上述哪项操作程序得出的信度系数值最低? 为什么? 哪项得出的系数推测值最有用? 要回答上述两个问题还需要什么额外信息?

5. 指出下述情形中的变化是否会提高或降低相应的信度:

(1)将小学所有年级的学生作为一个整体而非对每个年级单独进行测试所得测量结果的信度。

(2) 使用一套含有 25 道题而非 100 道的测试。

(3)取四位裁判评分的均值, 而非采用某一位裁判的评分。

(4)使用库德一理查森公式 20 而不是使用等效形式的测试所得分数之间的相关系数计算信度。

6. 在一名学生的整个学业生涯中使用韦氏儿童智力量表对其进行四次测试, 累积所得如下这些智商数值: \( {98}\text{、}{107}\text{、}{101} \) 和 95 。这些数值的波动有什么显著性?

7. 一所学校计划在九月份进行一项 \( \mathrm{R} \) 形式的阅读测试,在来年 5 月份再进行一次 \( \mathrm{S} \) 形式的阅读测试,以考察在这一年内个人阅读能力水平增长上的差异。对该年级群组进行的这两种形式的测试中, 所得测量结果的信度大约都在 0.85 。使用不同形式的测试在两个不同的时间点进行测量的结果之间的相关系数值为 0.80 。那么测量所得的个人阅读能力水平的增量有多可靠? 除了个人学习能力的真实差异之外, 还有哪些因素会导致在此期间个人能力水平增长上的差异?

## 推 荐 阅 读

American Educational Research Association, American Psychological Association, & National Council on Measurement in Education. (1999). Standards for educational and psychological testing. Washington, DC: American Psychological Association.

Belk, M. S., LoBello, S. G., Ray, G. E., & Zachar, P. (2002). WISC-III administration, clerical, and scoring errors made by student examiners. Journal of Psychoeducational Assessment, 20, 290-300.

Blixt, S. L., & Shama, D. B. (1986). An empirical investigation of the standard error of measurement at different ability levels. Educational and Psychological Measurement, 45, 545-550.

Brennan, R. L. (1984). Estimating the dependability of the scores. In R. A. Berk (Ed.), A guide to criterion-referenced test construction (pp. 292-334). Baltimore: Johns Hopkins University Press.

Feldt, L. S., & Brennan, R. L. (1989). Reliability. In R. L. Linn (Ed.), Educational measurement (3rd ed., pp. 105-146). New York: Macmillan.

Hacrtel, E. H. (2006). Refiability. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 65-110). Westport, CT: Praeger.

Jarjoura, D. (1985). Tolerance intervals for true scores. Journal of Educational Measurement, 10,1-17.

Kane, M. T., & Wilson, J. (1984). Errors of measurement and standard setting in mastery testing. Applied Psychological Measurement, 4, 107-115.

Kaufman, A. S. (1990). Assessing adolescent and adult intelligence. Boston: Allyn & Bacon.

Lord, F. M. (1984). Standard errors of measurement at different score levels. Journal of Educational Measurement, 21, 239-243.

Lord, F. M., & Novick, M. R. (1968). Statistical theories of mental test scores. Reading, MA: Addison-Wesley.

Rogosa, D. R., & Willett, J. B. (1983). Demonstrating the reliability of the difference score in the measurement of change. Journal of Educational Measurement, 20, 335-343.

Thissen, D. (1990). Reliability and measurement precision. In H. Wainer (Ed.), Computer adaptive testing: A primer (pp. 161-186). Mahwah, NJ: Erlbaum.

Thorndike, R. L., & Thorndike, R. M. (1994). Reliability in educational and psychological measurement. In T. Husen & N. Postlethwaite (Eds.), International encyclopedia of education (2nd ed., pp. 4981-4995). New York: Pergamon Press.

Thorndike, R. M. (2001). Reliability. In B. Bolton (Ed.), Handbook of measurement and evaluation in rehabilitation (3rd ed., pp. 29-48). Gaithersburg, MD: Aspen.

Wainer, H., & Mislevy, R. J. (1990). Item response theory, item calibration and proficiency estimation. In H. Wainer (Ed.), Computer adaptive testing: A primer (pp. 65-102). Mahwah, NJ: Erlbaum.

## 第5章 测量程序应有特性: 效度

## 5.1 引 言

对于决策, 一项测试的信度是不可或缺的, 却不是最重要的。一项测试也许信度非常高, 却和我们要测量的对象没什么关系。比如说, 头围的测量, 信度虽然很高, 却不能测量阅读能力。在教育学及心理学等领域, 对于任何测量程序, 首先要关注的问题是, “它的效度有多高?” 提出这个问题是要弄清楚一项测试是否可以测量我们想测量的对象, 只测量我们想测量的对象。这里引用《教育学与心理学测试标准》中的一句话: “效度是指在运用测试时, 对于测试分数的解读可得到证据和理论支持的程度。” (美国教育研究协会、美国心理协会及国家教育测量委员会, 1999, 第 9 页)。所以, 测试的效度是相对的。在某些用途上, 测试得出的分数是有效的, 而其他用途或解读也许就是无效的。

如果拿出一把卷尺测量桌子的长度, 毫无疑问卷尺的确可以测量桌子的长度。 我们可以直接依据卷尺的读数来决定是否可以把这张桌子放在房间里两个窗户之间。大家都很熟悉这种测量, 经验也告诉我们用卷尺测量长度是有效的。但是如果用卷尺来测量头围, 然后来决定大学的录取结果, 就很有问题了。注意如果用头围来决定买多大的帽子, 卷尺测量头围就是有效的测量。

现在假设我们对一群孩子进行阅读能力测试。这项测试要求孩子们阅读文章回答问题, 选择正确的选项, 并在答题纸上用铅笔标出选项。根据答题纸上答对的题目数量, 计算出得分。测试得分衡量了他们的阅读理解能力。但是分数本身并不是阅读理解, 只是在某个特定时间对于某个样本行为的记录。任何对于阅读能力的评价都是基于答对题目数量做出的推论。对分数进行解读的效度并不是理所当然的, 必须要通过充分的证据来得到证明。

还有一个例子是测量 “情绪适应能力” 的性格测试。在这类测试中, 受试者阅读一些关于情绪或行为的表述, 选择自己是否符合这些表述。某些反应被视作是情绪适应性差的表现, 并依据个人选择计算出一个分数。但是在纸上勾选几个选项就能测量出一个人的情绪躁动吗? 还得想办法知道在测试中的表现在多大程度上可以对应某种特定的行为表现。问题在于确立这种测量的效度。

上述三种测量方式, 卷尺、阅读理解测试以及性格测试, 都需要证据证明其测量出的数值对于预期目标是有用的。这些测量方式的不同体现在两个重要方面: 一是从测量到解读的推导长度; 二是可能带来的社会影响。在卷尺的例子中, 推导长度很短, 社会影响可忽略不计 (用来决定有毒废料的埋放地点等情况除外)。在心理测量中, 这两个方面就得好好考虑了。要建立阅读理解能力测试与受试者阅读能力之间的关系, 则需要仔细考虑行为的含义, 而这样的分析还是比较直接的。在这种情况下, 测试分数应用到受试者的教育中可以起到较为积极的社会影响, 但是如果应用不合理, 比如如果对受试者来说, 英语是第二语言, 虽然测试成绩可以准确评估其英语阅读能力, 也许会带来决策失误。决策带来的影响和测试成绩的使用密切相关, 所以和测试的效度也密切相关。这类应用不当越来越少见了, 但是应用测试的人必须意识到可能的后果。性格测试的推论过程会更长也可能带来负面影响。

一项测试可以在以下任意一方面与人类行为的某些方面相对应。有一些专门的术语来描述这几个方面: (1) 内容相关效度, (2) 标准相关效度, (3) 建构相关效度。我们会逐一介绍来了解每一类及与其相关的测试和情况。在章末我们会介绍过去 20 年来有关效度的一些综合看法。

## 5.2 内容相关效度证据

假如有一项测量英语语言运用能力的测试, 如何判断该测试真的测量了此项能力呢? 首先, 我们要确定正确有效的英语运用能力包括哪些知识和技能。如果该测试是要评估课堂教学的效果, 那么必须要明确教学目标里包含了哪些知识和技能。 然后检查该项测试考察了哪些知识技能, 最后将测试内容与课程内容以及教学目标进行比较, 来看测试内容和后者的吻合度。如果吻合, 那么该测试是有效的。在制定工业和军事项目测试或者驾照等资格证书考试时, 过程与之类似。

因为这样的分析是合理的, 符合逻辑的, 所以有时被称作合理的或逻辑的效度。 又因为这样的分析主要基于测试内容, 所以通常又被称作内容效度。然而, 这里的内容不仅是简单的事实性内容, 还可以包括认知过程。比如在英语表达领域, 一方面要考虑字母大小写、标点使用、拼写规则等内容, 另一方面也要考虑如何组织符合逻辑的想法、写出表达统一思想的句子、找到合适的词汇表达自己的思想等技能。总的来说, 内容是受试者直接接触到的东西, 而过程是他们处理内容的方法。内容相关效度是指衡量某项测试是否包含合适的内容并且要求在处理测试内容时运用合适的方法。

要衡量一项测试的内容效度或者制定一项新的测试, 需要明确其具体内容和方法。有关明确一项测试测量目标的说明被称为命题蓝图。命题蓝图与测量对象的吻合度就是该测试的内容效度, 命题人和测试使用者的责任就是确保测试含有合适的内容并需要运用到合适的认知过程。

## 1. 设计命题蓝图

命题蓝图 (又名测试规格表) 是一项明确的测试命题计划。命题蓝图的基本构成包括认知过程的具体说明及测试内容的描述。两方面需要对应起来, 每部分内容有相对应的认知过程, 以便测试的制定。命题人在准备每一单元的测试时, 需要建立一个命题蓝图, 不仅包括测试的内容和认知过程, 还应当包括衡量学生学习进展的方法。本节所用的范例是教师或命题者可以为本地学生制定成绩测试而使用的指南。 制定标准化成绩测试的过程是相同的, 只是对应更为广泛的课程。在衡量一项测试的内容效度时, 领域定义的步骤是一样的, 但是与效度问题相关的是测试是否与领域相关, 而不是去指导命题。在第九章, 我们会介绍专家们用来制定效度教育测量的命题原则和分析方法。

表 5-1 提供了对八年级学生进行健康课程测试的命题蓝图。该测试有 60 项内容, 采取简答客观题的形式。每个单元标题下的条目说明了每部分包含的认知过程。 整个蓝图明确了重点内容和测量方式。大多数标准化测试会包含更为广泛的内容, 但是内容的定义和测试的结构是类似的。

在美国一些州, 大多数课程的命题蓝图是集中制定的。商业化测试出版者依据这些蓝图进行命题。制作考试的二维大纲是一件费时费力的工作, 但是完整的命题蓝图可以用到课程更改为止。

仔细看一下命题蓝图就能知道测试不过是学生行为的样本, 原因有以下四点:

① 蓝图只包含纸笔作答类考试中适合进行衡量的对象 (第十章中将简要提及衡量其他目标的操作步骤)。

② 表格中每项说明条目只能列举测试内容, 而不能穷举。

③ 依据蓝图所指可以设计出无数道题目。

④ 考试时间是有限的, 所以考试只能包括蓝图中所指的部分内容。

如果要满足本地的测量目标, 则要谨慎选择考试题目。在制定考试和评估考试时可以考虑以下四个方面。

① 在考试中, 需要重视的考试内容和认知过程是哪些? 换句话说, 每部分内容和认知过程所占比例分别是多少?

② 考试要包括什么类型的题目?

③ 考试时间是多少? 考试总题目数量是多少? 蓝图里的每部分应该占多少题?

④ 题目的难度应该怎样?



表 5-1 八年级健康课程期末考试命题蓝图

<table><tr><td rowspan="2">认知过程目标</td><td>内容领域</td></tr><tr><td>A. 营养, \( {40}\% \)</td></tr><tr><td rowspan="5">1. 认识术语和词汇 20 %</td><td>营养物 不完全蛋白质 维生素完全蛋白质</td></tr><tr><td>酶氨基酸</td></tr><tr><td>代谢糖原</td></tr><tr><td>氧化碳水化合物</td></tr><tr><td>4 或 5 题</td></tr><tr><td rowspan="5">2. 辨认具体事实</td><td>营养物对身体健康至关重要</td></tr><tr><td>营养物的优质食物来源</td></tr><tr><td>消化系统器官</td></tr><tr><td>每类营养物质的消化过程</td></tr><tr><td>关于食物和营养物的信息来源</td></tr><tr><td>30 % 预计消化系统中酶变化带来的影响</td><td>7 或 8 题</td></tr><tr><td>3. 了解原则、概念和概括</td><td>平衡饮食的基础</td></tr><tr><td/><td>酶反应 细胞间的物质运输</td></tr><tr><td/><td>细胞代谢</td></tr><tr><td>30%</td><td>体内营养物的功能 7 或 8 题</td></tr><tr><td>4. 判断健康信息和广告</td><td>分析食物和饮食广告</td></tr><tr><td/><td>解读食物标签</td></tr><tr><td/><td>分辨有关食物和饮食的信息来源是否可靠</td></tr><tr><td>10 %</td><td>2 或 3 题</td></tr><tr><td>5. 在新情境下运用所学原理</td><td>判断饮食是否平衡 计算增重和减肥饮食所含的卡路里</td></tr><tr><td/><td>认识美国联邦食品药品法提供的服务和保护措施</td></tr><tr><td>10 %</td><td>2 或 3 题</td></tr><tr><td>题目总数量</td><td>24</td></tr><tr><td>考试总时间: 90 分钟</td><td/></tr></table>

续表

<table><tr><td colspan="2">内容领域</td><td rowspan="2">题目数量</td></tr><tr><td>B. 传染病,40%</td><td>C. 非传染病, \( {20}\% \)</td></tr><tr><td>免疫 流行病 病毒 病原体 携带者 地方流行病 抗体 原生生物 潜伏期 4 或 5 题</td><td>甲状腺肿大 缺乏性疾病 糖尿病 心血管疾病 龋齿 2 或 3 题</td><td>12</td></tr><tr><td>常见传染病 各种疾病发病率 传染方式 几种免疫方式 常见传染病症状 7 或 8 题</td><td>维生素缺乏引起的特定疾病 激素失调引起的特定疾病 非传染病的发病率 青少年及年轻人群中常见的非传染病 3 或 4 题</td><td>18</td></tr><tr><td>疾病控制的基本原则 抗生素的效用 人体对疾病的免疫 人体内的免疫反应 7 或 8 题</td><td>心血管系统内的血压 糖尿病的控制 异常特征的遗传 细胞的非正常生长 3 或 4 题</td><td>18</td></tr><tr><td>区分药物的充分证据和证据不足 辨别误导性医药广告 2 或 3 题</td><td>辨别健康信息中的错误和误导性信息 辨别健康信息来源的可信度 1 或 2 题</td><td>6</td></tr><tr><td>认识哪些条件可能增加传染病的发病 概率 辨别对物体进行消毒的正确做法 对相关规定、程序或治疗进行合理解释 2 或 3 题</td><td>预测特定激素分泌发生改变后的影响 预测某些异常特征遗传的可能性 1 或 2 题</td><td>6</td></tr><tr><td>24</td><td>12</td><td>60</td></tr><tr><td/><td>题目总数: 60</td><td/></tr></table>



(1)考试内容与认知过程目标的相对重要性

每个内容领域和认知过程的题目比重应与其重要程度相对应。决策过程是主观的, 但是测试使用者应该确保测试中各内容重要性的平衡。为不同部分的知识点和认知过程分配不同数量的题目可以体现各部分的重要性。

在考虑各内容领域和认知过程的比重时,首先可以以 \( {100}\% \) 为基准,为各部分分配占比。如表 5-1 蓝图所示,测试设计者决定 \( \mathrm{A} \) . 营养部分占比 \( {40}\% \) ; B. 传染病部分也占比 \( {40}\% ;\mathrm{C} \) . 非传染病部分占比 \( {20}\% \) 。如果课程指南要求 \( \mathrm{A} \) 部分和 \( \mathrm{B} \) 部分的教学时间均为四周, C 部分为两周, 那么考试比重正好与教学时间大致对应。176

关于表 5-1 中的认知过程,测试设计者决定过程 1 占 \( {20}\% \) 的题目,过程 2 和 3 分别占 \( {30}\% ,4 \) 和 5 分别占 \( {10}\% \) 。这样的分布表明此课程设计强调术语、事实、原理和概念的记忆, 这门课主要注重增加学生的知识量, 而非新情境下对知识的运用能力。 如果测试中的题目分配反应了课程设计的这一特点, 那么分配就是合理的。也许这样的课程设计有问题, 但测试中的题目分配是合理的。

## (2)使用的题目类型

测试中可用的题目类型可分为两类: (1) 要求受试者自己写出答案的题目, 有时称作结构式答复类题目; (2) 要求学生从所给选项中选出正确答案的题目, 又称选择类题目。结构性答复类题目可以是要求学生写长答案的论述题, 要求一两句答案的简答题, 或者只需填写一个词和词组的填空题。选择类题目可以是判断题、单项选择题和连线配对题。选择哪种题型取决于需要考察的认知能力, 每种题型的长短和考试的记分方式。

(3)测试的题量

如果决定采用论述题, 因为时间有限, 所以只能有几道题。对答案的要求越细致, 题目的数量越少。比如, 高中一项 40 分钟的测试也许有 3 或 4 道论述题, 每题答案长度约为一页纸。而如果是选择题和简答题, 题量会更大。

一项测试应该有足够题目, 以收集学生在各内容和认知能力方面足够多的样本。 测试所考察的内容和认知能力越多, 测量时间越长。

测试时长是制约题目数量的一个因素。能力测试考察的是能力而不是速度, 所以应该为学生提供充分答题时间,至少要让 \( {80}\% \) 的学生有时间答完所有题。在有些科目中, 答题速度也是测试的考察内容。在一段时间内要求答完的题目数量取决于以下几个因素:

① 测试中的题目类型。简答题需要学生自己写答案, 相比判断题和单项选择题, 会需要更多的时间。要求更为详细作答的题目要求的时间更长。

② 受试者的年龄和教育水平。小学生的阅读能力和写作能力还处在起步阶段, 相较高年级学生, 需要更多时间。年纪小的学生不能长时间专注一项任务, 所以考试时间应当缩短, 题目数量应当减少, 考试应当划分为块分几天进行。除了第一次考试这样的极少数情况, 学生和成年人则反应更快, 可以更长时间保持专注。

③ 学生的能力水平。和低水平学生比, 高水平学生的阅读和写作能力更高。他们对学习内容和解决问题能力的掌握也更好。高水平学生与同年级同年龄低水平学生相比, 每个单位时间内可以回答更多问题。所以, 为高水平学生设计的测试可以有更多题目, 为低水平学生设计的测试题目可以少一些。

④ 测试的长度和题目的复杂度。如果题目需要阅读文章、表格材料、地图和图表, 应该提供充分阅读和检查的时间。这类材料越多, 题目的数量应该越少。

⑤ 测试的认知类型。知识点回忆类题目相比情境应用题要求的时间短。如果测试要考察高级认知能力, 在相等时间下, 题目数量应该减少。

6 题目的计算量或心算量。大多数人在处理需要计算的材料时, 相比纯文字材料, 需要更多时间, 所以如果测试需要数学计算, 则应设置更长的时间。

(4)关于测试题量的一些总结

在给定的时间内, 应该有多少题量? 这里不可能给出一个明确无误的答案。一个基本规律是, 一个成年人在阅读并回答一个简单的事实性单项选择或判断题时, 所需的时间大概是 30 秒到 45 秒, 如果是相对复杂, 需要解决问题的题目, 需要 75 秒到 100 秒。

需要注意的是, 在给定时间内能完成多少问题, 受试者在这方面的差异性很大, 而且差异不仅与阅读能力和知识掌握程度有关, 有时也和其他因素有关, 比如个人的学习风格和考试技巧。有些人考试的时候遇到一个不会的题, 会在这一题上耗很多时间, 而没有时间回答其他题。如果考生慌乱答题, 没时间仔细看题审题, 出现失误的概率会增加, 测试的信度和效度都会大打折扣。

要涵盖命题蓝图中的所有内容可能需要大量题目, 而单次考试的时间可能不够。 最好的解决办法就是把测试分为连续几天进行的几个小测试。在第十三章中, 我们会了解到这是标准化成绩测试中常见的做法。

(5)决定题目的分布

如表 5-1 所示, 命题人决定八年级的健康课考试包括 60 道题。命题蓝图中还规定了每个部分有几题。第一步要决定每部分有几道题。表 5-1 中明确了 A 部分占比 \( {40}\% \) ,有 24 道题 \( \left( {{0.40} \times  {60}}\right) ,\mathrm{\;B} \) 部分有 24 题 \( \left( {{0.40} \times  {60}}\right) ,\mathrm{C} \) 部分 12 题 \( \left( {{0.20} \times  {60}}\right) \) 。 这些数字被记在 “题目数量”一栏。每个认知过程所占题目数量的计算原理同上所述。计算完成后, 将数字记录在最右一列。

计算命题蓝图中每个格子里的题目数量, 将内容区的题目数量乘以每行认知过程的占比。比如,要计算 \( \mathrm{A} \) 部分第一格里的题目数量,将 \( {24} \times  {0.2}\left( {{20}\% }\right) \) ,得到 4.8 题。因为 4.8 位于 4 到 5 之间, 可以决定是 4 题或 5 题。其他格子的题目数量依此类推。值得注意的是, 有些认知过程与某些知识内容是紧密相关的, 比如在社会学科的考试中, 地图理解相关的认知能力主要通过对自然资源相关知识点的考察而得以衡量, 而不是人力资源相关知识点。有时候需要对格子里的内容进行修改, 保证内容和认知过程的一致。另外, 最好能在每个格子里写明一系列范围来保证灵活性。

## (6) 合适的题目难度

对于论述题、简答题以及客观题, 难度的含义是不同的。对于论述题, 适当的难度意味着班里的学生能给出可信的回答, 学生的作答在完成度、思想性和想法组织能力等方面有区分度。

对于客观题, 可以从每道题或整个测试的角度来考虑难度。在衡量每道题难度时, 最常见的做法是用答对题目的学生数除以所有参与测试的学生数 (通常我们假定所有学生都有答题的机会)。衡量整个测试的难度时, 用答对的平均题目数除以总题数。例如,如果在某项测试中所有受试学生答对了 \( {40}\% \) 的题目,那么此项测试的难度系数为 \( {40}\% \) ,如果学生答对了 \( {75}\% \) ,那么难度为 0.75 (这样的计算方式有时会产生误解, 因为难度系数越大, 题目越简单。这样计算出来的数值应该被称作“简单系数”。整个测试的难度系数是每道题难度系数的平均值。

对于常模参照测试和标准参照测试, 合适的难度系数和难度分布有所不同。大体来说, 标准参照测试题目要简单一些 (从平均题目难度来说)。如果测试的目的是要知道哪些学生有特殊困难, 那么大多数学生应该可以得到满分或接近满分, 只有少数分数特别低。如果测试是为了了解学生在课前对某个话题是否有掌握的知识, 那很有可能出现不少得零分或低分的情况, 因为相关内容还没有教过。

对于标准参照测试、诊断测试及课前测试, 并不需要最大化差异性。即使所有学生都得满分或者零分, 我们也可以提取所需信息。但是如果测试是为了区别一个班级中学生之间的不同水平, 那么测试分数应呈现一定分布, 区分出水平最高的学生, 水平次之的学生以及水平非常差的学生。理想状态下, 最好每个学生的分数都不一样, 这样可以突出差异性, 进行排名。如果任何人 (或是超过一个人) 都可以拿到满分, 那么测试成绩的差异性会降低, 排名也会更困难。这样也表明这项测试没有一个合理的顶点, 不能让学生充分展现掌握知识的限度。同样, 测试中最好不出现零分或者仅靠运气得来的超低分数, 因为这意味着学生不能回答任何问题, 这项测试不能衡量这名学生的水平。所以, 测试中最好不要出现一道所有人都能答对的题和一道所有人都不能答对的题, 因为这样的题不能区分学生之间的水平差异 (用项目反应理论的术语来说,对于受试者,项目难度参数 \( b \) 的数值范围超过 \( \theta \) 值的数值范围)。

一个粗略的经验法则是, 一项测试的难度系数应当处在靠纯粹猜能答对的题目比例到 \( {100}\% \) 之间。由于猜测的成分会增加考试分数的差异性,通常测试应当稍微简单一些而非难一些。对于四个选项的单项选择题, 比较好的难度系数是 0.65 到 0.70 ; 对于判断题, 较好的难度系数应该是 0.75 到 0.80 。因为靠运气得到正确答案的概率是 1 除以选项数量, 所以一道有 5 个选项的题, 平均难度系数为 0.60 到 0.65 (运气带来的偶然性差异为 \( {20}\% \) ,而 \( {20}\% \) 和满分 \( {100}\% \) 的中间值为 \( {60}\% \) )。

接着来谈一下表 5-1 中的例子, 假设健康课程测试中的 60 道题均为填空题, 测试的目的是根据知识掌握程度对学生进行排名。比较理想的状况是全班平均得分为答对 30 道题 \( \left( {{0.50} \times  {60}}\right) \) ,因为这种作答题,仅靠猜测答对的可能性为零。如果这 60 道题是有 5 个选项的选择题,那么均分为答对 36 道题比较好 \( \left( {{0.60} \times  {60}}\right) \) 。

这种程度的难度有时让老师和学生感到困扰, 因为他们通常只是想着在考试中答对多少题算及格, 多少算不及格, 而上述的建议无关考试通过与否, 基于测试而做出的决定, 比如给学生判分和划等级, 完全是另一个问题, 和学生能答对多少题无关。 这里给出的比例建议是为了最好地区分学生的成绩水平, 所以制定标准化成绩测试的人通常运用这里列出的建议。

要达到理想的平均难度,老师可能会出一些比较难的题,只有 \( {30}\% \) 到 \( {40}\% \) 的学生可以答对 (假设题目是有四个选项的单选题),一些比较简单的题,有 \( {80}\% \) 到 \( {90}\% \) 的学生可以答对。但是需要注意的是, 达到最适合的难度水平虽重要, 更为重要的是题目要合理涵盖所学内容, 水平高的学生和水平低的相比答对每道题目的可能性应该更高。要建立内容效度, 必须确保题目可以对所学内容和认知过程进行合理测量。

评估内容效度的问题和制定命题蓝图, 制定对应测试的问题相似。保证测试的内容效度在于在命题蓝图中仔细分析课程教学目标, 在制定命题时要仔细, 运用适当技巧和智慧, 符合命题蓝图的规划。一项面对某一特定学校或课程的标准化测试要保证效度, 即确保它能反映该学校或课程制定的教学目标。

对于学生成绩测试来说内容效度至关重要。尤其是对于考察多项教学目标的正式测试 (内容参照测试) 来说, 效度的高低在于试题是否很好地反映了测量目标。而对于常模参照测试来说 (比如课程结束后的标准化测试), 考虑的重点即它是否反映了该领域比较重要的知识技能, 这决定了测试效度的高低。

设计一项具有广泛适用性的测试需要花费很大心血来了解相关领域的教学目标。命题人经常要参考很多资料, 资料来源通常有这些:

① 常用的各种教材。

② 各州、各郡和城市学校的近期课程。

③ 各教育协会年鉴里关于特别学习小组的报告。

④ 进行相关教学的教师。

⑤ 关注业内教师培训和监督的各部门专家。

从这些来源获取信息资料, 然后制定命题蓝图, 依据命题蓝图制定测试题目。因为不同地区之间存在差异, 所以全国性的命题不可能完全适用每个地区的课程内容和目标。从这点来说, 全国性测试的效度可能还比不上专门依据地方教育目标制定的测试。但是商业出版的全国性试卷可以依据全国各地通用的内容制定测试题目, 这样就能反映核心课程要求。商业性试卷通常由测试专家编写, 他们经验丰富, 受过专门训练, 试卷会经过严格的审核, 排除措辞或内容方面的偏见。这些测试题目通常质量很高, 尽管可能不完全适合地区的教学目标, 但是却值得一用。

前面所说的内容应该清楚说明了教学和测试之间的密切关系。测试内容反映了教学或计划教学内容, 教学课程设置就是学业测试的原材料。有时测试的内容会比地区的课程计划超前, 因为专家们可能会应对教育界的新趋势进行新的测试设计。 有时也会因为依据既定教材和相对传统的教学目标而显落后。但是通常来说, 测试内容和课堂教学紧密相连, 测试的质量高低在于能否如实反映主要教学目标。

要检验测试分数的效度是否能反映课程目标成绩, 只有仔细检查实际的测试题日。名为 “数学概念” 的测试也许只是考察一些概念的定义, 名为 “阅读理解” 的测试只是要求对文章里的一些细节问题进行回答。测试里的问题决定其测量的内容, 要检验针对某项课程制定的测试的效度, 必须要仔细查看测试中的每道题。

## 2. 测量能力倾向与典型表现的内容效度

对于学业测试, 内容效度及其衡量的重要性相对直观, 但对于倾向性测试和测量性格与兴趣的测试也同样重要。然而对于后者, 相关定义更为复杂。假如我们想制定一项测量个人总体认知功能水平的测试, 也就是通常所说的智商测试, 要如何定义所测内容呢? 要回答这个问题, 就得首先考虑什么是智商, 那就得牵扯到相关理论了。所用理论给出关于智商的定义, 说明什么样的行为可用来衡量智商。这个理论在这里的作用相当于前面学业测试中所用的课程计划。在明确理论之后, 就可以依据理论开始制定测试对相关内容和认知过程进行测量。我们将在第十二章中介绍一些有关智商的主要理论和相关测试。

对于典型表现测试来说, 内容效度同样重要, 但是有所不同, 因为与人格建构相关的行为通常不可穷举。我们可以判断某个试题是否是典型的 “社交性”, 但是要列出所有善于社交的情景和行为表现是不可能的。出于这一原因, 很难说哪项性格或兴趣测试的内容效度最高, 在衡量内容效度时, 关于其是否符合相关理论的要求, 经常要带上个人的主观判断。我们将在后面介绍测试题目是否符合行为理论, 这是建立效度的关键。

## 5.3 标准相关效度证据

我们经常需要通过一项测试来做出影响未来结果的决定。通过学业能力倾向测试来预测一名高中生在进入某所大学后的表现, 而测试分数代表了其大致的成绩水平。在录取员工时, 通过测试来挑选那些可能表现优秀的员工, 他们生产效率高、出错率低、转职率低。为了达到这样的目标, 测试形式不重要, 重要的是它能否考察到相关职位的要求。一些其他要求 (虽然不一定必需, 但是可能在以后会需要) 也被视作是达到 “成功” 的要求, 我们在衡量测试时要看它与相关要求的相关系数, 关联度越高, 测试的质量就越高。

## 1. 表面效度

前面说测试形式不重要并不完全准确, 对于受试者来说, 测试的可接受度和合理度还是很重要的。对于准飞行员来说, 考数学的话, 计算气流和油耗比要求计算烤面包要用多少面粉和配料更加合适。这种合理度常被称作表面效度, 虽然对于测试的应用来说算不上一个多决定性的条件, 但是如果受试者的自愿合作很重要, 可以成为一个必要条件。只有试题与考试用途相符, 参加考试者才会尽力真诚作答。如同萨基特、施密特、艾灵森和卡宾 (Sackett, Schmitt, Ellingson, and Kabin, 2001) 所说: “当试题看起来的确在预期表现能力方面对受试者进行了合理考察时, 受试者的表现会更加积极……同样重要的是, 受试者感觉自己受到了公正的对待” (第 315-316 页)。

## 2. 实证效度

运用测试评估来进行预测主要是实证和统计评估, 这方面的效度有时被称作实证或统计效度。基本操作步骤是对一组申请工作或培训项目的人员进行测试, 随后跟进, 对每人在随后工作或培训中的某方面指标进行评估, 称作效标, 接下来计算测试分数与效标之间的关联, 相关系数越高, 说明测试的预测越有效, 标准相关效度越高。

依据测试与效标之间的时间关系, 效标效度有两大分类。如果测试结果用来预测未来的表现, 比如用于人员选择, 就是预测效度。如果测试是用来代替更为复杂昂贵的操作, 比如使用成组的智商测试来代替个体测试, 需要注意的问题则是两组测试产生的信息是否有足够的关联, 更为经济的测试是否可以用来代替昂贵的测试。如果是这种情况, 那么我们需要知道这项测试产生的分数是否与另一项同时产生的分数有高度的关联性。当测试和效标分数是基本同时产生时, 就是共时效度。预测与共时这两个术语, 更多是与测试目的相关, 而不是时间关系, 但是名称来源就是如此。 预测效度使用更为广泛, 所以在接下来的讨论中主要讲预测效度, 但是这两种实证效度的操作和相关问题是类似的。

可以通过不同的方式来呈现预测和效标之间的关系。例如图 5-1 中的条形图呈现了在飞行技能倾向测试中各九个得分段候选人通过空军飞行员训练的不同比例。 如图所示, 从低分段到高分段, 通过率上升了, 所以成功完成训练与倾向测试相关。 我们可以绘制出类似的条形图, 来呈现大学入学考试成绩与进入大学后的成绩之间的关系, 以及文秘倾向测试成绩与文秘培训中成功率之间的关系。图中显示相关系数为 0.49 , 如果相关系数更高那么不同分段之间通过率的差异会更大。





图 5-1 倾向测试中各得分段完成空军飞行培训项目的学员, 相关系数为 0.49



## (1)关于标准相关效度中的效标问题

前面讲到要估算实证效度, 可以计算测试分数与合理效标之间的相关系数。问题是 “合理效标” 这个词, 对于选择测试的人来说, 最大的挑战是如何选择验证测试效度的合理效标。无论是在职场还是在教学领域, 这都是件麻烦事。也许可以直接使用工作效率或上级主管的评价作为效标, 并且直接采用一种简单直接的标准, 但是找到一种令人满意的效标并不容易, 进行考核测试的人需要进行很多工作。

每种可能的效标都有自己的问题。使用实际业绩作为效标——比如制作了多少件机械, 收银时的正确率, 卖出去多少份保险一一也许很好, 但是很多职业, 比如医生、教师、秘书、接待员, 并没有这样可以对工作表现进行量化的标准。即使有这样的标准, 工作中也可能会被很多非控因素影响。机床工人的生产效率不仅取决于个人技艺, 还要受到其他因素影响, 比如设备质量, 工作环境中的照明是否充分, 以及加工材料。保险销售也不仅是销售员个人效率的问题, 也受到地域、监管、协助等因素影响。

因为常常缺乏客观指标或者指标有缺陷, 相关心理学家通常将上级评价作为效标。这种评价是公司中人事部门的惯例, 每位雇员会有一个半年期的效率评价, 或者专门搜集评价用于人员筛选研究。在这种情况下, 评价的高低通常不仅在于受到评价的人, 也在于给出评价的人。这样的评价通常不稳定, 受到很多非个人表现之外的其他因素影响, 第十章和第十一章将对涉及人员评价的相关问题和操作进行介绍。

多种效标标准可以用来为选拔测试建立信度。除了量化的工作表现记录和主观评价, 也可以采用能力测试。比如衡量大学入学考试数学考试的信度高低, 可以看它是否可以预测大学数学综合性考试中的成绩, 在这里大学数学综合性考试就是一种效标。另一种常用的效标是在某种教育或培训项目中的平均成绩。衡量工程师选拔考试的效度, 可以看在工程学校里的课程成绩。

所有效标都是有偏向性的, 因其只衡量了实际工作表现或者学业成绩中的一方面。比如刚才提到的工程学校课程成绩, 虽然很直观, 却也只是衡量了工程师成功的某一个标准。要达到完全的客观, 则要看在某个职业中一生的成就情况。但是这种完全客观的衡量是不可能的, 所以要找到尽可能让人满意的替代标准, 这些替代标准也不可能完全让人满意, 能做的就是找到最好的标准, 或者使用几种标准达到满意的程度。那么接下来的问题就是找到最满意的标准, 怎样知道标准是否令人满意呢?

(2)标准测量所需特性

效标最好符合四个标准, 依照重要度排名, 依次是: ① 相关系数, ② 没有偏向, ③ 信度, ④ 可用性。

效标的相关性是指与我们所想预测的对象相对应, 在衡量效标的相关性时, 可以运用理性的思考, 比如, 要判断大学新生的平均成绩是否达到大学的要求目标, 并没有什么可用的实证性证据。对于成绩测试来说, 就需要依赖尽可能精准的专业知识来判断测试内容是否准确反映了教学目标的要求。同样, 我们也需要专业判断来衡量所选效标是否准确。效标的相关系数可以说和效标的内容效度相关, 相关系数高的效标与有关行为有密切关联。

对于效标来说, 第二重要的是没有偏向。这是指每个人在这一标准下得高分的机会是一样的, 也就是每个水平相等的人, 不管在哪个组, 可以得到一样的分数 (除了测量上的错误)。前面所举例子里保险销售人员如果分配到不同地区, 不同地区之间财富的差异就是一种偏向; 对工厂工人来说, 设备的差异就是偏向; 对于秘书来说, 老184板在员工评价上的宽松程度是偏向; 对学生来说, 不同班级之间教学水平的差异也是偏向。如果效标得分取决于非相关因素, 比如工作环境、工作评估、个人性格特点, 而非测量目标情况, 那么测试结果与效标得分之间的相关性就失去了真实意义。如果效标存在强烈的偏向, 则无法揭示人与人之间在某项特征上的相对差异。有关对偏向问题以及测试公平性问题的详细讨论, 参见卡米利 (Camilli, 2006)。

第三个因素是效标的信度。要使用测试来预测和测量职位成就, 测试必须稳定、 可重复。如果效标得分每天都在变化, 比如某人在某个星期工作表现得分很高, 下个星期又很低, 或者这个上级主管给的评分很高, 另一个主管给的分却很低, 那就没法找到可以预测得分的测试。没有测试可以预测不稳定的测量结果。

最后, 在选择效标时, 经常会遇到和便利性及可用性相关的实际问题。要为每个个人找到效标需要多久? 金钱成本或者其他成本是多少? 虽然在人事研究项目中通常允许为了找到好的效标数据而花费较大代价, 但也总是有限制的。在选择效标时必须考虑到实际限制。

(3)预测

在第二章中, 我们了解到可以使用回归线进行最接近的预测, 依据某个得分变量预测另一个得分变量。在效标变量中, 同样的回归线可以对得分进行最为准确、有效的预测。两个变量之间的相关性可以说明两者关系的紧密程度, 具体来说, 效标变量的变化有多少可以通过预测一方进行预测。我们稍后会了解到如何使用效标得分来表达其余不确定性。

(4)解析效度相关系数

假设我们收集了一组个人的测试和效度得分, 并计算出它们之间的相关系数。 学生倾向测试就为进行预测的指标, 而效标就是大学新生平均成绩。如何知道这项测试是一个好的预测指标?

显然, 其余条件保持不变, 相关系数越高越好。从某种程度来说, 衡量预测指标就是将它与其他预测方法进行比较。比如, 皮特的完美人格预测指标 (作者虚构的例子) 和其他测试相比, 效度相关系数更高还是更低? 和高中成绩或者学校校长评价这样的其他类信息相比, 效度相关系数更高还是更低? 我们会更青睐比之前测试在某项效标上效度更高的测试, 即使这项并不完美。

表 5-2 列出了一些有代表性的效度相关系数。这些数据说明了各类测试相关系数的大致情况。当然, 某特定研究或工作中的研究者, 则需要了解这些专门测试效标的效度相关系数是什么样的。



表 5-2 一些教育与职业标准中部分测试的预测效度

<table><tr><td>预测性测试 \( {}^{a} \)</td><td>效标变量 \( {}^{b} \)</td><td>效度相 关系数</td></tr><tr><td>认知能力测试 (CogAT)</td><td>成绩与能力测试 (TAP) 阅读 (12 年级)</td><td>0.79</td></tr><tr><td>语义</td><td>成绩与能力测试社会科学 (12 年级)</td><td>0.78</td></tr><tr><td>数学</td><td>成绩与能力测试数学 (12 年级)</td><td>0.79</td></tr><tr><td rowspan="3">爱荷华州教育发展测试 (ITED) 综合 (9 年级)</td><td>高中累积缋点 (GPA)</td><td>0.49</td></tr><tr><td>大学一年级绩点</td><td>.0.41</td></tr><tr><td>学业能力倾向测试 (SAT) 总分</td><td>0.84</td></tr><tr><td>爱荷华州基础技能测试 (ITBS) 综合 (6 年级)</td><td>大学最终绩点</td><td>0.44</td></tr><tr><td>西肖尔音调记忆测试</td><td>弦乐器演奏表现测试</td><td>0.28</td></tr><tr><td>短期就业测试 词汇知识得分</td><td>生产量一记账操作员</td><td>0.10</td></tr><tr><td>算术得分</td><td>生产量一记账操作员</td><td>0.26</td></tr></table>

注: \( \operatorname{CogAt} = \) 认知能力测试; ITED \( = \) 爱荷华州教育发展测试; ITBS \( = \) 爱荷华州基础技能测试。

TAP=成绩与能力测试; GPA \( = \) 平均最高分; SAT \( = \) 学业能力倾向测试。



测试作为预测标准的有用程度不仅在于与效标测量的相关系数大小, 还在于能提供多少新信息。比如, 成绩与能力测试中的社会科学测试与九年级社会科学成绩的平均相关系数为 0.51 , 而阅读理解测试的相关系数为 0.51 。但是两项测试之间的相关系数为 0.77 。两项测试至少有部分内容是重合的, 两项测试可提供的部分信息是一样的。从两项测试中将信息进行整合, 可以得到的相关系数不超过 0.53 。如果两项测试之间无相关联系, 每项测试提供的信息是完全独立的, 两者相加的相关系数可达 0.70。用数据处理方法可以帮助我们决定怎样考量两项或多项测试的权重, 计算回归方程和相加后的相关系数 (计算多项预测测试相加的权重以及相关系数属于专门的统计学问题。在中级统计学教材中可以看到对此类方法的详细介绍, 可参考 Cohen, Cohen, West & Aiken, 2003; McClendon, 1994; Tabachnick & Fidell, 2007)。

显然, 测试或预测和效标测量之间的相关系数越高越好。但是, 除了这一相对性标准, 还有某个绝对标准。效度相关系数要达到多少, 测试才是有用的? “令人满意的”效度是什么样的? 最后一个问题类似于问 “多高才算高?” 我们可以尝试找找答案。

如果一个机构需要用一项测试来决定是否雇用某个人, 录用某个学生, 最显然的问题是 “使用这项测试, 和纯粹碰运气, 或者使用现有的效度偏低一些的测试相比, 选对人的概率会大多少?”要回答这一问题, 很大程度上取决于招收比例是多少, 我们称之为选择比, 以及总体样本 “成功” 的可能性, 叫作基本比。如果我们在每十个候选人中只选择一个最好的人, 而不是必须要选九个人, 筛选程序会更加有用。不过, 让我们来看一个具体例子,假设招收比例为 \( {50}\% \) 即一半。让我们来看表 5-3 。



表 5-3 测试与工作成就 \( 2 \times  2 \) 表

<table><tr><td colspan="6">工作表现</td></tr><tr><td colspan="3">下面一半——“失败”</td><td colspan="3">上而一半——“成功”合计</td></tr><tr><td rowspan="3">选拔测试得分</td><td>上面一半 (录用)</td><td colspan="2"/><td/><td>100</td></tr><tr><td>下而一半 (淘汰)</td><td colspan="2"/><td/><td>100</td></tr><tr><td>合计</td><td colspan="2">100</td><td>100</td><td>200</td></tr></table>



表 5-3 中有 200 人, 测试和工作表现中分别被分为两半, 每一半为 100 人。如果测试结果与工作表现之间完全没有关系, 那么表格中四个空栏中都应该是 50 人。如果 “成功” 的定义为工作表现排名前一半 (基本比为 0.50), 那么对被录用者以及被拒者成功率都为 50 比 100 。两者成功率没有差别, 选拔考试和工作表现之间的相关系数为零。

表 5-4 中列出了选择比为 \( {50}\% \) 时各种数值的相关系数,以及这 \( {50}\% \) 被录用人中决定正确的比例 (“成功”)。在 \( {50}\% \) 的被拒人中淘汰为正确决定的比例与此类似。 随着相关系数提高, “决定正确”的比例会逐渐高于平均值。相关系数为 0.40 时, 做出正确决定的比例为 \( {63.1}\% \) ,出错的比例为 \( {36.9}\% \) ; 相关系数达到 0.80 时,决定正确的比例是 \( {79.5}\% \) ,依此类推。



表 5-4 必须录用半数人时做出正确决定的比例

<table><tr><td>效度系数</td><td>选择正确的百分比 (%)</td></tr><tr><td>0.00</td><td>50.0</td></tr><tr><td>0.20</td><td>56.4</td></tr><tr><td>0.40</td><td>63.1</td></tr><tr><td>0.50</td><td>66.7</td></tr><tr><td>0.60</td><td>70.5</td></tr><tr><td>0.70</td><td>74.7</td></tr><tr><td>0.80</td><td>79.5</td></tr><tr><td>0.90</td><td>85.6</td></tr></table>



表 5-4 不仅说明了相关系数为某值时决定为正确的比例, 还显示了预测测试效度提高后, 决定的正确率提高了多少。如果用效度 0.60 的测试取代效度为 0.40 的测试, 决定的正确率从 63.1 提高到 70.5 。这一表格中百分比计算的前提是从候选人中选拔测试中成绩最好的 \( {50}\% \) ,而且200人中有 \( {50}\% \) 的人可以在工作表现中达到 “成功”水平。虽然如此, 表 5-4 可以让我们比较直观地了解到对于雇用方或录取方来说筛选测试的效果是怎样的。

在很多筛选程序中, 更高的效度可以换来资金方面的获利。如果一家公司雇用和培训新员工上岗时需要花费 500 美元,将成功率从 \( {56.4}\% \) 提升到 \( {63.1}\% \) 的筛选程序可以节省大笔花费, 仅培训费每 100 人中可以节省 3350 美元。如果被录用员工在完成培训后工作效率更高, 带来的收益就更多了。当然这笔收益还得减去采用新筛选程序时的增加成本。如果筛选程序要每人花费 5000 美元, 那就不值得了。

表 5-5 介绍了另一种评估相关系数实用性的方法, 可能对参与选拔测试的一方更为有意义。表中横行代表申请人、待选学生或应聘人员在测试中的表现, 按照排名分成四等份, 而纵列数字代表达到每个效度值的样本数量。请注意看 5-5 表中效度相关系数为 0.50 的部分。注意 1000 人中有 480 人 (48.0%) 在四栏中的最后一栏, 27.9%处在倒数第二,16.8%在倒数第三,7.3%在第一栏。在前面提到的例子中,我们将工作表现的 “成功”定义为排名位于前一半, 可以将这种方法用到这里来理解两者之间的关系。在预测测试中每四个人中大约只有一人位于最低一栏的人才是“成功”雇员 (1000 人中有 \( {168} + {73} = {241} \) 人)。表格中加粗的条目代表在预测测试和效标中排名一致的情况。距离加粗条目越远, 预测和实际表现之间的差异越大。接近加粗项说明预测准确, 离加粗项特别远说明预测完全错误。



表 5-5 相关系数(r)取不同数值时预测的准确性

<table><tr><td colspan="5">\( r = {0.00} \)</td><td colspan="5">\( r = {0.60} \)</td></tr><tr><td rowspan="2">预测测试 四分情况</td><td colspan="4">效标四分情况</td><td rowspan="2">预测测试 四分情况</td><td colspan="4">效标四分情况</td></tr><tr><td>第 4</td><td>第 3</td><td>第 2</td><td>第 1</td><td>第 4</td><td>第 3</td><td>第 2</td><td>第 1</td></tr><tr><td>第 1</td><td>250</td><td>250</td><td>250</td><td>250</td><td>第 1</td><td>45</td><td>141</td><td>277</td><td>537</td></tr><tr><td>第 2</td><td>250</td><td>250</td><td>250</td><td>250</td><td>第 2</td><td>141</td><td>264</td><td>318</td><td>277</td></tr><tr><td>第 3</td><td>250</td><td>250</td><td>250</td><td>250</td><td>第 3</td><td>277</td><td>318</td><td>264</td><td>141</td></tr><tr><td>第 4</td><td>250</td><td>250</td><td>250</td><td>250</td><td>第 4</td><td>537</td><td>277</td><td>141</td><td>45</td></tr><tr><td colspan="5">\( r = {0.40} \)</td><td colspan="5">\( r = {0.70} \)</td></tr><tr><td rowspan="2">预测测试 四分情况</td><td colspan="4">效标四分情况</td><td rowspan="2">预测测试 四分情况</td><td colspan="4">效标四分情况</td></tr><tr><td>第 4</td><td>第 3</td><td>第 2</td><td>第 1</td><td>第 4</td><td>第 3</td><td>第 2</td><td>第 1</td></tr><tr><td>第 1</td><td>104</td><td>191</td><td>277</td><td>428</td><td>第 1</td><td>22</td><td>107</td><td>270</td><td>601</td></tr><tr><td>第 2</td><td>191</td><td>255</td><td>277</td><td>277</td><td>第 2</td><td>107</td><td>270</td><td>353</td><td>270</td></tr><tr><td>第 3</td><td>277</td><td>277</td><td>255</td><td>191</td><td>第 3</td><td>270</td><td>353</td><td>270</td><td>107</td></tr><tr><td>第 4</td><td>428</td><td>277</td><td>191</td><td>104</td><td>第 4</td><td>601</td><td>270</td><td>107</td><td>22</td></tr><tr><td colspan="5">\( r = {0.50} \)</td><td colspan="5">\( r = {0.80} \)</td></tr></table>

续表

<table><tr><td rowspan="2">预测测试 四分情况</td><td colspan="4">效标四分情况</td><td rowspan="2">预测测试 四分情况</td><td colspan="4">效标四分情况</td></tr><tr><td>第 4</td><td>第 3</td><td>第 2</td><td>第 1</td><td>第 4</td><td>第 3</td><td>第 2</td><td>第 1</td></tr><tr><td>第 1</td><td>73</td><td>168</td><td>279</td><td>480</td><td>第 1</td><td>6</td><td>66</td><td>253</td><td>675</td></tr><tr><td>第 2</td><td>168</td><td>258</td><td>295</td><td>279</td><td>第 2</td><td>66</td><td>271</td><td>410</td><td>253</td></tr><tr><td>第 3</td><td>279</td><td>295</td><td>258</td><td>168</td><td>第 3</td><td>253</td><td>410</td><td>271</td><td>66</td></tr><tr><td>第 4</td><td>480</td><td>279</td><td>168</td><td>73</td><td>第 4</td><td>675</td><td>253</td><td>66</td><td>6</td></tr></table>

注: 每行每列样本数为 1000 。



表 5-6 通过一个实例呈现了在同一项预测测试中得分相同的人在效标中的表现分布。该表呈现了在阅读理解能力测试中有不同表现的 260 名 11 年级学生在学业能力倾向测试中的得分分布情况。很清楚, TAP 得分越高, SAT 得分也会增加。但是我们还能看到有些 TAP 得分 200 分的学生比一些 TAP 得分 250 的学生在 SAT 中的得分更高。



表 5-6 学业与能力测试 (TAP) 阅读理解测试得分与学业能力倾向测试 (SAT) 中语文测试得分的概率关系

<table><tr><td rowspan="2">TAP 标准分数区间</td><td colspan="6">SAT 语文分数区间</td></tr><tr><td>200—250</td><td>251 — 350</td><td>351—450</td><td>451—550</td><td>551—650</td><td>651 +</td></tr><tr><td>251 +</td><td/><td/><td>10</td><td>40</td><td>40</td><td>10</td></tr><tr><td>241---250</td><td/><td>6</td><td>19</td><td>44</td><td>25</td><td>6</td></tr><tr><td>231—240</td><td/><td/><td>11</td><td>53</td><td>28</td><td>4</td></tr><tr><td>221—230</td><td/><td/><td>20</td><td>44</td><td>28</td><td>8</td></tr><tr><td>211---220</td><td/><td/><td>31</td><td>48</td><td>21</td><td/></tr><tr><td>201—210</td><td/><td>11</td><td>36</td><td>40</td><td>3</td><td/></tr><tr><td>191—200</td><td/><td>14</td><td>43</td><td>40</td><td/><td/></tr><tr><td>181—190</td><td/><td>20</td><td>56</td><td>21</td><td/><td/></tr><tr><td>171—180</td><td>11</td><td>22</td><td>61</td><td/><td>3</td><td/></tr><tr><td>低于 171</td><td>23</td><td>54</td><td>19</td><td/><td>4</td><td/></tr></table>

注: 此表格中的数据代表 TAP 阅读理解测试与 SAT 语文测试之间的相关系数为 0.61 。



表 5-5 和表 5-6 不仅说明了使用预测测试的好处, 还说明虽然测试成绩差不多, 在效标标准方面表现却会不同。对于学校和招聘方来说, 最重要的是提高做出正确决定的概率。如果涉及人员数量很大, 采用比现有测试效度更高的测试可以带来收益。从个人角度来看, 表 5-5 和表 5-6 中显示的预测与实际表现之间偶尔的不相符, 也许没那么重要。参加测试的候选人更愿意觉得自己是个例外。虽然在测试中成绩较差, 但是在实际培训和工作中会有很好的表现, 而不愿相信自己不能胜任这一职位。

(5)基本比与预测

在介绍表 5-3 时, 我们提到如果只需要从候选人中录取很小一部分, 筛选过程会比较有用。尽管如此, 表 5-5 与表 5-6 表明如果我们只录用候选人中测试成绩最好的 \( {10}\% \) 或 \( {20}\% \) ,可能会错失一些非常优秀的潜在人才。筛选过程的总体价值在于几个因素, 包括: ①对于 “成功” 的定义, ② 采用什么样的筛选规则, ③ 成功的 “价值”, ④ 录用者在随后 “失败” 会有什么样的 “代价”, ⑤ 错过具有成功潜质的候选人会有什么“代价”。

某组申请者全部录用后在工作中达到 “成功” 的比例被称作成功基本比。如果在效标标准中排名处于前一半为成功,那么成功基本比为 \( {50}\% \) 。预测测试中的选拔标准被称为分数线, 在决定是否录取申请人时, 分数线是被录用人中最低的得分。

在使用某个分数线时, 有些决定是正确的, 有些不正确。一种极端是, 如果录用了所有候选人, 会录用所有有成功潜能的人, 但是有一半人会失败。另一个极端是, 淘汰所有候选人, 不会录用到会失败的人, 但是会错失所有可能成功的候选人。筛选机制下做出正确决定的比例, 录取正确的人比例加上淘汰该拒绝的人的比例, 被称作分数线的命中率。每个分数线的命中率取决于成功基本比及预测测试和效标之间的相关系数。表 5-4 呈现了基本比为 \( {50}\% \) ,分数线为录用一半人时的命中率。

基本比离 \( {50}\% \) 越远 (高于或者低于),筛选机制的潜在命中率会越低。如果 “成功”的定义是在效标标准下排名前 \( {25}\% \) (就是基本比为 0.25),并且测试与效标的相关系数为 0.60 , 采用四个不同分数线的结果如下:



<table><tr><td>分数线</td><td>命中率</td></tr><tr><td>录用所有人</td><td>0.25</td></tr><tr><td>录用前 \( {75}\% \)</td><td>0.37</td></tr><tr><td>录用前 \( {50}\% \)</td><td>0.66</td></tr><tr><td>录用前 \( {25}\% \)</td><td>0.77</td></tr></table>



基于预测测试成绩划定分数线,录用 \( {50}\% \) 候选人的命中率为 0.66,与表 5-4 中的 \( {70.5}\% \) 相比稍微偏低 (那里的基本比为 \( {50}\% \) ),也比基本比降低后的命中率低。在基本比数值偏向极端值时, 使用预测测试的好处会明显下降。在效标标准下达到成功标准的人接近 \( {50}\% \) 时,使用筛选程序可带来的好处是最大的。

(6) 预测标准误差

当预测测试与效标之间的关系达不到理想状态, 在预测测试中得分一样的人会在效标中表现不同。在预测测试中得分分布在前四分之一的人不一定在效标中排名前四分之一。如图 2-12 (即这里的图 5-2) 所示, 预测测试中的得分都会有对应的实际效标表现分布。某个人在预测测试中的得分会有对应的平均实际表现, 也会有围绕平均值的波动。回归线可以帮助找到所有得分同一水平的人在效标中实际表现的平均值 (回归线中的 \( \widehat{\mathrm{Y}} \) 是申请人得分为 \( \mathrm{X} \) 值时对应的效标平均表现值)。预测标准误差反映了效标中实际表现围绕平均值的分布情况。估计标准误差就是效标中实际表现偏离预测表现的标准差分布。换种方式来说, 估计标准误差是在预测变量中得分相同的人效标得分的标准差。





图 5-2 效标变量(SAT) 中的预测得分为预测测试 (TAP) 中得分在同一分数段的人在标准变量中的平均得分, 预测标准误差是观测值围绕该平均得分波动的标准差



图 5-2 用图示呈现了表 5-6 中的数据。左侧的大面积正态分布图是所有 SAT 分数的分布情况, 平均值为 500 , 标准差为 100 。椭圆中是 SAT 测试和 TAP 测试的散点图, 两个较小的分布图分别为 SAT 得分在 191 到 200 之间以及 TAP 得分在 221 到 230 之间的分数分布情况。第一个分布图的平均值为 470 , 这也是对这一组人 SAT 成绩的预测得分, 第二个分布图的平均值为 530 , 也是对这组 TAP 得分为 221 到 230 的人 SAT 成绩的预测得分。这些分布的标准差就是依据 TAP 得分预测 SAT 得分的估计标准误差。

图中有两点需要特别注意。第一, 因为两个变量之间有中等程度的正相关关系, 所以右边一组的预测得分比左边高。TAP 得分更高的人 SAT 预测得分也会更高。 第二, 对大多数人的预测会有较小误差, 对一些人的预测会有较大误差。实际分数与预测得分之间的标准差就是估计标准误差。可以通过以下公式计算出大致的估计标准误差:

\[S{D}_{Y \cdot  X} = S{D}_{Y}\sqrt{1 - {r}_{YX}^{2}} \tag{5.1}\]

\( S{D}_{Y \cdot  X} \) 代表估计标准误差 (下标读作 “ \( X \) 对应的 \( Y \) 值”)

\( S{D}_{Y} \) 代表所有效标得分分布的标准差。

\( {r}_{YX}^{2} \) 代表预测测试在预测此效标时效度相关系数的平方。

注意这个公式和第四章中计算标准测量误差的公式 4.5 很像。标准测量误差衡量的是单一测试中成绩的不稳定系数。它通过测试的可信度来估算个人在不同测试中得分的变化情况。而估计标准误差计算的是使用某种测量去预测另一种测量成绩时的误差。它通过预测测试与效标之间的相关系数来估算预测分数距离效标中实际得分的误差是多少。测量标准误差和估计标准误差都很重要, 但是对于与效标相关的效度来说, 标准测量误差可以由试题出版商来控制, 而每种效标的估计标准误差都是不同的, 必须由地方自行决定。

让我们再来看下依据 TAP 得分对 SAT 的预测得分。表 5-6 中测试与效标之间有 0.61 的相关系数, 而 SAT 分数的标准差为 100 分。使用公式 (5.1), 可以得到

\[S{D}_{Y \cdot  X} = {100}\sqrt{1 - {0.61}^{2}} = {100}\sqrt{0.63} = {79}\]

依据 TAP 得分预测 SAT 得分的估计标准误差为 79 。

标准测量误差可以用来说明某人真实得分的不确定性, 而估计标准误差可以说明对某人的预测得分的不确定性和预测波动范围。假设预测误差存在正态分布, 大概三名学生中会有两人的 SAT 得分和预测得分相比估计标准误差在 1 个标准差以内,有 \( {95}\% \) 的人估计标准误差在 2 个以内。在表 5-3 的例子中, \( {68}\% \) 预测得分为530 分的学生实际 SAT 得分在 450 到 610 之间 (SAT 计分为 10 的倍数), 而大约 95 %的人在效标中的成绩为 370 分到 690 分之间。

估计标准误差清楚说明在预测人类行为时面临的限制。即使有最好的测量方法, 在教育和心理学领域的预测充其量也只能是接近。使用回归法可以预测出如同图 5-3 中的 SAT 分数 530 。如果要考虑到估计标准误差, 教师、咨询师以及相关人员会对目前的预测能力感到些许悲观, 但是这并不表明要停止预测或者测试是错的, 相反, 基于测试分数做出的预测在平均水平上正确的。但是, 应当保持合理的怀疑, 在对个人进行预测时, 不要对测试结果进行过分解读。

还有另外两个因素会影响效度相关系数和解读。第一个因素是预测测试和预测对象效标的不可靠。在第四章中我们谈到过这一减弱影响。第二个因素是由于提前筛选而使测试对象能力有限, 信度偏低或者提前筛选都会使实际的效度相关系数降低, 所以真实的效度通常要比效度研究中的所得值要高。





图 5-3 三名学生中有两人的 SAT 得分和预测得分相比估计标准误差 \( \left( {S{D}_{Y \cdot  X}}\right) \) 在 1 个标准差以内, 20 人中会有 9 人的误差在 2 个标偏差以内



预测测试分数范围如果受到限制, 可以对测试的预测效度产生明显影响。这里有一个例子, 最近某公立大学的申请人数量急剧上涨。因为申请人数量是先前的三倍, 学校改变了处理申请的程序, 原先是按照申请时间, 先申请者先录取, 现在是按照高中成绩和学术能力测试成绩进行录取。最后一批按照原先录取程序录取的学生, 大学成绩和高中学习成绩之间的相关系数为 0.61 . 采用新的录取程序, 只算在新程序下可被录取的学生, 相关系数下降到 0.47。使用高中成绩来预测大学成绩, 预测的效度有明显下降, 只是因为所选学生水平范围更小了。

再强调另外一点。对于特定课程和特定工作来说可能有特定的效度。虽然在接下来讨论总体效度概念时, 会说到有些测试对于很多职位都是有效的, 但是如果作者或者出版商宣称测试有效, 应该问一问 “对于什么来说是有效的?” 比如, 用于社会研究的成绩测试可以准确涵盖某项教育项目的内容和目标, 但是也许对另一个地方的教育项目来说就不适用。学业测试必须经过仔细衡量, 看是否与某特定教育项目的目标吻合。一项测试, 也许在挑选对顾客友善、熟悉产品、善于处理交易的商场销售员时效度很高, 但是对于挑选擅长外出寻找新商机的保险推销员则完全没用。在衡量效度时, 必须考虑到测试的情境是否与实际应用相符。

用来预测有清晰效标测量的结果时, 测试的效标相关效度最为重要。这句话里有两个要点: 预测和清楚效标测量。在预测时采用效标相关效度的主要局限在于可用的效标测量通常有限。如果能找到准确代表预测目标表现的效标, 就可以依据测试和效标之间的相关系数来决定是否使用测试分数。

## 5.4 建构相关的效度证据

有时, 对于一项教育测试或心理测试, 我们不会问 “这项测试预测将来表现的能力如何?”也不问 “这项测试反映了课程要求吗?” 而是问 “这项测试的得分意味着什么?”测试分数反映了这个人的哪些方面? 是否与某项有意义的特征对应, 有助于我们来了解这个人? 要回答这样的问题, 就要用到建构效度 (在心理学和教育学中, 建构一词指由研究者构建出来的不可观察的事物, 用以总结或解释可观察行为之间的规律或联系。所以, 很多特征的名称是指建构。我们谈到某人的 “社交性”, 就是以此来总结一个人过去行为表现中一种可观察到的行为模式, 以此来预测这个人在将来情境下的行为表现。建构来自观察, 但是建构实际上可以预测在新情境下我们会观察到的东西。在接下来要说到的研究项目中就是这样的情况)。

让我们来看一下某具体测量程序中的经典案例, 看看在测量一项心理特征或建构时是如何研究其效度的。麦克莱兰、阿特金森、克拉克和洛厄尔 (McClelland, Atkinson, Clark, and Lowell, 1953) 设计出一套测试程序, 衡量个人成绩 (取得成功和好的表现) 的需求和动力。这项测试使用了各类情境下有含糊意义的图片。要求受试者根据每幅图编造故事, 说明图片上发生了什么事, 结果如何。针对这些故事制定评分标准, 评分依据故事中有关成绩、成功等主题出现的频率。这样, 每人得到一个分数, 代表其得分的动力强度 (所有被试均为男性)。这里的建构效度问题就是这项测试在真实呈现个人某项有意义特征方面是否具备效度? 测试可以衡量个人得分的需求和动力吗? 麦克莱兰 (McClelland) 及其同事们的研究步骤如下。

研究人员首先提出了一个问题: “我们所构想的成就动力测试应该与什么相关?” 他们写出了一系列预测, 这里列出一部分:

① 成就动力测量中得分高的学生在大学的表现会更好, 学业能力会更强。那么, 他们在大学中的成绩应该比基于 SAT 得分进行的预测更好。

② 告诉学生测试测量的是智商, 在完成这样的测试后, 学生的成就动力应该会更高。

③ 成就动力得分高的学生在限时测试中会完成更多题目。

④ 强调早日实现独立的家庭出来的孩子, 成就动力应会更高。

这些预测均基于 “人类行为理论”。比如, 学业成绩是能力和努力的结果。所以, 成就动力越高的人会更加努力, 在能力相当的情况下, 成绩表现会更佳。每项预测背后的逻辑道理都是类似的。

大致来说, 麦克莱兰等 (McClelland et al., 1953) 发现大多数预测都与实验结果相符。对测试所测量特征进行合理分析后进行预测, 测试与预测相关联, 那么在测量一项有意义的特征或者建构时是有效的。“成就动力”这个标签很好地总结了该项特质的主要特征。如果测试的建构效度得到一系列研究的支持, 那么推导出该项建构的理论也得到了支持。

很多心理测试以及一部分教育测试是为了测量个人的总体特征或者某些特征。 一般智力、语言推理、空间想象、社交性、内向性以及对机械的兴趣都是特征或者建构的各种名称。如果测试得分与建构理论的预测相符, 那么测试就是有建构效度的。 关于某项特征的理论可以推导出以下类型的预测, 这些预测都可以通过测试来核实。

## 1. 相关性的预测

某项特征以及测量该特征的有效测试, 都表明它们应该与一些其他测量有正相关关系, 或无关, 或负相关。这些其他测量可以是已经被接受的相关测量。很多群体智力测试, 通过计算与其他更早的测试, 比如斯坦福一比奈智力量表之间的相关系数, 来证明其效度。其他测试也许是与所测特征有逻辑关联。所以, 智力测试有些可以通过与学校的表现之间的相关度来证明其效度, 技术测试可以看它们与工作中的熟练度之间的相关关系。

研究测试测量特征的一个方式是考察不同测试之间的相关度。由此可知哪些测试测量的维度和特征是共同的。如果有多项测试测量某个单一特征, 则可更清楚地了解该特征的性质和含义以及该项测试。研究测试建构的方式叫作因素分析。然而, 如果因素应具有实质内容、重要性或科学与教育的效用这种内在结构或者 “因素” 效度的确立需要从测试之外的实际生活中去寻找证据。

对建构 \( \mathrm{X} \) 的测量也许和其他特征的测量之间几乎没有关联; 这样的话,这个建构和其他测试的测量对象是不同的。一项用来测量机械理解的测试和语言测试之间的相关系数应该是比较弱的。如果两项测试测量的建构特性是完全不同的, 那么就不可能有太高的相关系数, 比如对社交性的测试和对果敢性的测试之间相关系数就不会太高。对关联度不大的建构特征进行的测试, 如果相关系数很高, 要么是对这些建构特征进行测量的测试有问题, 要么这几项建构特征并不是有区分的人类心理功能, 或者二者兼而有之。

(1)多特质多元方法分析

研究多项测试之间相关系数高低不同的各种模式的一种方式是由坎贝尔和菲斯克 (Campbell and Fiske, 1959) 提出的。他们将其操作步骤称作多特质多元方法相关系数矩阵 (简称 MTMM), 要求对每种不同特质采用几种不同的方法进行测量。 图 5-4 就是一例。图 5-4 中的条目是字母形式的, 而实际研究中的结果可能是数值。



<table><tr><td colspan="2" rowspan="2"/><td colspan="3">自我评价</td><td colspan="3">朋友评价</td><td colspan="3">观察</td></tr><tr><td>A</td><td>S</td><td>T</td><td>A</td><td>S</td><td>T</td><td>A</td><td>S</td><td>T</td></tr><tr><td rowspan="3">自我</td><td>支配件</td><td>a</td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>社交性</td><td>b</td><td>a</td><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>可信赖度</td><td>b</td><td>b</td><td>a</td><td/><td/><td/><td/><td/><td/></tr><tr><td rowspan="3">朋发</td><td>支配性</td><td>c</td><td>d</td><td>d</td><td>a</td><td/><td/><td/><td/><td/></tr><tr><td>社交性</td><td>d</td><td>b</td><td>d</td><td>b</td><td/><td/><td/><td/><td/></tr><tr><td>可信赖度</td><td>d</td><td>d</td><td>d</td><td>b</td><td>b</td><td/><td/><td/><td/></tr><tr><td rowspan="3">观察</td><td>支配性</td><td>c</td><td>d</td><td>d</td><td>c</td><td>d</td><td>d</td><td>a</td><td/><td/></tr><tr><td>社交性</td><td>d</td><td>c</td><td>d</td><td>d</td><td>c</td><td>d</td><td>b</td><td>a</td><td/></tr><tr><td>可信赖度</td><td>d</td><td>d</td><td>c</td><td>d</td><td>d</td><td>c</td><td>b</td><td>b</td><td>a</td></tr><tr><td/><td/><td/><td>\( \mathrm{A} = \) 支配性</td><td colspan="2">\( \mathrm{S} = \) 社交性</td><td colspan="5">\( \mathrm{T} = \) 可信赖度</td></tr></table>

图 5-4 多特质多元方法相关系数矩阵 (MTMM)



如图 5-4 所示, 我们可以对三项特质中的每一项一支配性、社交性和可信赖度一一采取三种测量方式: 自我评价、朋友打分, 以及在可控环境下进行观察。所以, 每个人都可以有九项得分 (三项特质中的每一项都采用进行三种方法测量), 所以 MTMM 矩阵包含了九个变量之间的相关系数。用这个方法来评估建构效度的核心就是对于同一个特质进行测量得出的分数之间算出相关系数, 而用同样的方法对不同的特质进行测量得出的分数之间算出相关系数, 前者相关系数应该比后者高。

包含字母 \( \alpha \) 的单元格叫作信度对角值。它们代表使用同样测量方法对同一特质进行测量的两项测量结果之间的相关系数 (我们所谓的信度就是指测试与其自身之间的相关系数)。这些变量的数值越高越好, 并且应该是矩阵中数值最高的。用术语来说, 这些叫作单一特质、单一方法相关系数。

在含字母 \( b \) 的单元格中的值是通过同一种测量方法对不同特质进行测量得出的结果之间的相关系数 (异质特质、单一方法相关系数)。这些相关系数代表由于建构特质本身的自然联系以及测量方法相同造成的相似性。应该比信度值小很多。

对于建构效度来说,应该关注字母 \( c \) 所在单元格 (叫作效度对角值)。这些数值代表对同一项特质采用不同测量方式产生的数值 (单一特质、异类方法相关系数)。 如果在测量支配性上有两三种好的测量方法, 即使测量方式不同, 结果也应该是吻合的。这有点像信度问题: 测试中抽出不同的试题部分, 能得出同样的测量结果吗? 如果测试很清楚, 对其特质也定义清楚, 那么答案应该是肯定的。如果用不同的方式测量同一个特质, 相关系数很高, 那么该建构特质和测量方法体现了聚合效度。不同测量方法在这一特质上聚合。

最后,来谈谈含 \( d \) 的单元格。这些数值是对不同特质采用不同测量方法得出的 (异质特质、相异方法相关系数)。这些数值是显示不同特质之间联系的最纯指标, 也应该是矩阵中数值最小的, 因为只代表不同特质之间的相关系数。

如果 \( b \) 单元格中的数值比 \( d \) 单元格的数值大,我们称之为存在方法协方差。也就是说, 个体在得分上的持续差异不仅是因为特质上的差异, 还在于测量方式。存在方法协方差会降低测量的建构效度, 因为测量得出的分数不仅是因为个人在特质上的表现, 还有其他因素影响。方法协方差越小, 对于特质进行的测量就越纯, 称作区别效度。但是, 请注意, 要证明有聚合效度和区别效度, 不一定必须要让方法协方差接近零。阅读测试和一般性认知能力测试之间会有高度相关性, 因为这些特质本来就有密切的自然联系, 但是交叉特质之间的相关系数应该比特质内相关系数持续性偏低。主要的问题是不同的相关系数是否出现 MTMM 方法预测的模式。

## 2. 对群体差异的预测

常有理论说某些群体在某些特质上会特别突出或者特别低, 所以在有关该特质的测试中会表现出特别高的分数或者特别低的分数。一组成功的销售人员很有可能在支配性和果敢性上有很强的表现, 而图书馆员的表现会比较差。而专业人士和商人的孩子和那些做书记员和半技能工作的人的孩子相比, 在这两方面的表现也很可能会差一些。对于任何特质来说, 根据我们对于社会和人群的了解, 可以推断不同人群之间是存在差异的。对不同的群体进行测试, 研究人员发现差异一直都存在。当然,一些预测也许是错的, 因为一方面来说, 测试可能对特质没有进行有效的测量, 另一方面, 现实世界的情况并不总是符合理论的预测。如果预测是错的, 我们也无法判断哪种情况是存在的, 或是正确的。

## 3. 对有关实验或干预反应的预测

有理论可能认为在一些实验条件和治疗之下, 人类特征的表达是可以得到修正的。比如, 我们可以预测一个人在进行小手术之前, 焦虑感会增加。闪光融合的频率可作为焦虑程度的指标 (闪光融合的频率是指黑白交互刺激融合成为稳定灰色的频率)。一项测试 (Buhler,1953) 发现, 如预料的那样, 在手术前闪光融合的阈值比手术后低, 手术后, 焦虑有所缓解。其他研究使用激起焦虑的刺激物, 比如牙科座椅, 也有类似发现, 这样就让焦虑这项建构特质以及对其进行测量的测试有了可信度。

关于测量特质和特点的测试, 可以建构一个理论网络, 产生可进行验证的明确预测。如果预测是对的, 该项测试及其建构特质的效度就得到了支持。如果预期是错的, 那么就要对测试的效度或者理论产生怀疑了。

## 5.5 效度的统一定义

大概从 1980 年开始, 逐渐出现了一种新的统一效度观。其实我们已经提到了这一新概念的某些方面, 不过现在要详细探讨。根据这一观点, 测试的效度, 甚至是测试的验证, 都是用词不当, 因为验证的对象, 是对于测试分数及其用途的解读, 而不是测试本身 (Cronbach, 1988; Messick, 1989; Shepard, 1993)。如果我们设计一项测试但是不去实施, 效度就不是问题。如果我们对一组受试者进行测量, 收集一些分数, 但是把分数锁在阁楼, 效度也不是问题。但是, 一旦我们从阁楼中取出这些数据进行使用, 不管是什么用途, 就得弄清楚对这些分数的使用是否合理。需要验证的推论主要有两类一解释性推论或行动推论。对测试分数意义的说明叫作解释性推论, 对将测试分数作为某种行动 (如决策) 的基础的合理性或实用性的说明叫作行动推论。

测试验证就是收集证据支持基于测试分数进行的推论。对解释性推论进行效度验证就是收集各类证据支持对测试分数的解读, 同时, 证明其他的解释不如这种解释好。对行动推论进行效度验证要求有分数解读的证据支持, 以及将测试分数用于某种用途的合理性和有用性。对测试效度进行验证的目的就是为我们所做的推论找到最好的证据支持。

日前我们的讨论主要集中在搜集资料支持行动推论。梅西克 (Messick, 1989) 则扩充了效度的含义, 不仅包括分数的意义, 还包括分数解读背后的价值观以及测试使用的效度、相关性以及社会影响。他认为效度验证必须不仅要关注与分数解读相关的证据, 还得包括分数解读和使用带来的实际和潜在影响。

赋予测试分数意义会涉及价值观判断。价值观会在各个层面影响对分数含义的解读, 比如测试对测量特质建构的命名以及建构的理论基础就含有价值观判断 (比如 “智商测试”这个名称常常会带有一些社会含义, 而“一般性认知能力”测试则没有那么多其他含义)。没有哪种解读是完全不带价值观判断的, 所以在讨论效度时必须涉及对价值观的判断。依据测试分数做出的每种决定都会带来影响, 也许有些是意料之外的。要看测试是否符合我们的期望, 在应用情景下发挥合适的作用, 需要搜集测试分数在应用时的相关性和有用性证据, 以及考虑到应用可能产生的预期和非预期198后果。在依据分数做出与人相关的决定时, 会产生一些社会影响。判断测试的使用是否合理必须考虑到各种可能。不仅要证明测试的使用符合预期目标, 还要综合考虑到各类社会影响。

## 1. 效度验证作为一项科学追求

依据安哥夫 (Angoff,1988)、梅西克 (Messick,1980,1988,1989) 和其他学者的观点, 我们在为基于分数的推论进行证据的搜集、组织和总结的过程, 其意图和目的都属于一种科学方法。科学与非科学的区别就是, 对于研究现象的本质是什么, 科学敢于接受外界的质疑。社区在测试中采取科学的方法, 测试以及对测试效度的验证就是科学的。在 1980 年, 梅西克说验证涉及 “对理论相关关系的合理假设进行验证” (第 1015 页)。十年后, 他称基于测试的 “推论就是假设, 而对推论的验证就是对假设进行验证” (梅西克, 1989, 第 14 页)。沙迪什、库克和坎贝尔 (Shadish, Cook, and Campbell, 2002) 对于效度、因果推论已经对科学假设进行验证之间的大致关系进行了详细说明。

对假设进行检验的大致过程是, 对于相关现象的本质提出一些论断, 然后看这个论断是否和证据相符。最好是依据一个相关理论框架来得出一些有意义的具体预测, 这样预测的相关数据也会变得有意义。如果得出的观察不符合预期, 数据和预期不一致, 论断的可能性就被驳倒了。如果观察结果符合预期推测, 假设仍是站得住脚的, 对该现象的这种解释就得到了一点证据支持。重要的一点是对假设进行清楚描述, 让质疑和证伪是可能的。仅仅进行证实是不够的, 还必须寻找可以对观点进行质疑和挑战的证据。

验证过程, 或者理论检验的第一步, 就是清楚说明各类预期推论是什么, 想对测试结果做出怎样的解读, 进行怎样的应用。第二步是决定采用什么样的证据对推论进行支持或质疑。最后, 依据搜集到的证据, 对推论的合理与否做出最后判断。

针对任何现象, 我们都能给出多种解释。在检验依据分数做出的推论时, 最好考虑或者排除一下其他矛盾的理论。将假设置于可推翻的可能性中, 可以表明假设的可证性, 但是即使假设没有被推翻, 也不能说明其他矛盾的解释是不可能的。所以, 除了直接对我们提出的假设进行检验, 还可以通过证明矛盾解释缺乏证据来说明假设的可行性。

如果基于分数得出的推论有强大的理论支撑, 验证推论的过程也是理论检测的过程。如果一个理论说会出现某个结果, 但是没有出现, 说明理论或者测量操作有问题。测试分数及其理论框架基础之间会一直有相互联系。数据和理论会相互修正。 另外, 找出相反的假设进行检验可以发现建构理论的缺点。对于假设检验来说, 理论支持既包括对预测结果的确认也包括对其他解释可能性的排除。

依据测试分数采取行动, 对这类行动推论进行验证通常会涉及有着矛盾诉求的社会政治环境。在政治环境下进行的科学项目, 按照定义来说就是一种应用科学。 所以, 如果对应用型的假设和理论进行检验, 有关测试分数的相关性、实用性和社会影响就是应用型的科学事业。

科学曾经被看作是非政治性的, 不带价值判断的, 但是现在科学界承认事实并非如此。最近的科学哲学家, 以及测试理论学家指出, 数据常常带有理论印记, 而理论反映了价值观 (Shadish et al., 2002)。考虑到测试实际使用中要涉及带有价值观的政治现实, 这样的意识是有潜在好处的。克龙巴赫 (Cronbach, 1988) 指出相互矛盾的不同观点会促使我们去仔细思考测试分数的不同用途背后存在哪些价值观。梅西克 (Messick,1989) 认为承认不同视角的存在可以抵消“先入为主的价值判断” (第 87 页)。另外, 意识到和考虑到那些影响我们立场的因素, 实际上可以让我们在试图支持某个推论时更有说服力。

## 2. 作为整体效度的建构效度

梅西克 (1989) 认为建构效度 “从对测试表现与其他变量之间的关系进行解释的概念这方面来说, 建构效度包含了所有证明测试分数解读可信度的证据和依据 ” (第 34 页)。对建构效度进行验证的一个重要特征是对分数进行解读时要依据一些有组织的理论或概念框架 (梅西克的 “解释性概念”)。

(1)支持依据分数得出推论的证据

效度不是要么有要么没有 (“有效”或 “无效”) 的概念, 而是具有不同程度。在对测试分数进行某种解读或运用时也许会得到很多证据支持, 也许只有很少证据。另外, 在对推论进行效度验证时, 常常会用到各种类型的证据。对于任何推论来说, 要有效支持建构效度, 需要包括合理证据和经验证据 (Shepard, 1993), 少一种都不行。 分数解读的合理性和准确性与否, 测试分数用于某种用途的效度与否, 如果得到了强有力的实证证据支持, 有令人信服的理论依据, 那么这些推论就比那些证据支持很弱的更有说服力。如果同时还可以证明其他假设得到的证据支持更弱, 那么预期推论就更有说服力了。

要让推论有充分的合理性, 要求既要从理论框架的角度进行思考, 又要考虑相关数据。必须将论断和实际进行对比。然而, 数据需要在理论情景下进行解读才会有意义, 自己是不会说话的。另外, 虽然相关行为理论是推论的最好来源, 但在对推论进行效度验证时并没有多大用处, 除非进行有关理论建构的测量。建构效度验证的过程, 就是要证明测试分数的确对拟测的建构特质进行了反映, 分数的应用是有效的, 既涉及理性也涉及经验。

验证效度的过程就是要不断搜集和评估证据, 来决定依据分数做出的推论是否可靠。既然我们永远不可能有 “所有证据”, 验证效度的过程永远不会彻底完成。未来的发现也许会加强或削弱现有的效度证据。可以将效度验证看作是一个不断为现有解释性推论和行动推论找到最合理证据支持的过程。

(2)建构效度面临的威胁

测试分数并不是对建构特质的完美反映。部分原因是测量中存在随机误差, 还因为测试分数并不能对目标建构特质进行恰当的测量。测试分数可以说是 “打入” 建构特质内部, 或者是这些建构特质的 “指标”, 但并不是直接的 “测量” (Borsboom & Mellenbergh, 2002)。这样小心翼翼的措辞承认了测试分数在反映建构特质时的局限。

测试分数在这方面的局限主要有两个方面: 测试有时候会将理论上应该包含的内容遗漏掉, 或者会混入一些不相干应该排除掉的东西。这两个对建构效度的威胁分别被称作建构的代表不足, 和无关建构的测试变异。如果测试的范围太狭隘, 不能包括建构特质的重要方面, 就会出现建构代表不足的情况。无关建构的测试变异是指出现与量化建构特质之外的变异。注意这两个概念和内容效度部分提到的内容很相似。

无关建构的测试变异有两大类: (1) 无关建构测试的难度, (2) 无关建构测试的容易度。前一种是指和建构效度无关的因素让测试对于某些人和群体难度加大了。比如, 高度考试焦虑感, 相比以论文写作和家庭作业的方式来对知识技能进行检测, 会对测试成绩有负面影响。这种情况下, 焦虑的受试者和实际水平相比会偏低, 测试分数的效度会降低。无关建构测试容易度是指测试的某些因素会让某些人表现更好, 而更好的表现却与建构特质无关。在学业方面, 会考试现象, 比如对试题类型、时间安排技巧, 知道正确答案是什么样的模式, 可以让有些人的分数得到提高, 这就是无关建构的测试变异的典型例子。对这样的受试者来说, 测试分数受到了影响, 偏高得分的效度也是有问题的。

建构的代表不足和无关建构的测试变异是建构效度降低的原因。每种情况都会削弱解释性推论的合理性, 因为分数解读时, 对建构特质的代表是错误的。在设计测试时谨慎一些, 保证测试内容和建构特质的范围是吻合的, 这样可以降低建构代表不足的程度。只使用一个指标的时候, 会更容易对建构特质代表不足, 或是让无关变异对测试造成影响, 所以在进行建构验证的时候, 推荐对每个建构特质采用多项指标。 沙迪什等 (Shadish et al., 2002) 将使用单一指标而可能造成的误导效果称作单一操作偏差。

## (3)建构效度的统一看法与传统效度验证证据类型的关系

如果说建构效度是 “整体效度”, 那么其他两类传统效度验证证据又处于什么地位呢? 原来称作建构证据的一直对于基于分数做出的推论提供建构效度支持, 只是在更为有限的意义上, 但是为什么现在内容和效标相关证据也构成建构效度呢? 在所有测试效度验证的过程中, 问题的答案都在于测试分数的意义如何。建构效度现在被看作是一个统一、多面的概念, 涉及对测试分数做出特定解释的原因。所以, 关于测试内容、测试分数与标准之间的关系, 在探讨测量目标所蕴含建构特质时找出的证据, 这些会影响到我们对于测试分数的理解的信息都可以看作是建构相关证据。

前面提到建构效度验证的过程涉及整合所有可能的证据来支持分数解读。要支持对测试分数进行某种解读或某种应用时, 必须要通过建构效度验证来说明测量的意义。内容证据会通过说明测试中包含了什么样的特质和行为来影响分数的含义。 同时, 建构理论能帮我们测试内容对于预期解释性推论和行动推论的相关性和代表性。测试与效标之间的实证关系为针对特质之间或者行为之间的理论关系而做出的推论提供了效度验证证据。对于任何观察到的测试与效标关系, 建构理论都可以提供一个合理解释, 这样就可以反过来说明测试使用的合理性。测试分数和效标测量可以看作是潜在特质和行为领域的指标。传统或者狭义的建构效度观是要找到证据支持这样的论断, 那就是测试分数和效标测量真的像宣称的那样对建构特质进行了测量。

现在每类证据, 包括传统内容、建构或者效标相关类的证据, 在证明基于分数所做推论的合理性时被视作 “必要但不充分”。这些证据加在一起可以为解释性推论和行动推论的效度提供更强大的证明。

每类效度验证的主要特点就是通过陈述和验证假设来证明基于分数所做推论的合理性。在这一过程中, 应该将建构之间的结构关系以及相互关系作为提出假设、解释现象的根源依据。在所有的效度验证中, 应该综合采用经验分析和理性分析。

除了这个关键特点, 其他几个重要问题也需要进行强调。第一, 和测试分数意义相关的任何证据, 无论来源是什么, 对于推论的效度验证可能是促进作用也可能是削弱作用。第二, 通过对建构效度进行彻底检查, 可以了解测试的内部结构, 测试分数之间的关系, 以及建构理论中其他变量之间的关系。最后, 基于分数的推论要得到强有力支持, 既需要有确认性证据又要对竞争理论进行排除。 (4)内部和外部因素

每种建构都是基于每种理论或者一组理论的, 这些理论描述了对某一感兴趣现象的理解。这个理论框架包含了一个内部模式, 说明了建构特质内部相连的各个层面和维度, 还包括外部模式, 对于一个建构和其他建构之间的关系进行了详细说明。 对基于分数得出的推论进行建构效度验证传统上会包含这两个成分。

建构特质的内部模式包括所有对建构特质进行定义的理论的所有必要元素。包括建构特质的维度、组织结构、对在特质测试中的表现涉及的一系列过程进行的描述。特别是, 理论得来的建构特征可以转化为可验证的假设, 然后利用经验进行肯定或否决。

对建构的内部结构进行评估的方法越来越复杂。建构效度验证的内部成分不仅包括传统意义上测试内部结构的心理测量问题, 测试题目之间的相互关联关系等等。 一些概念问题, 比如对于多维度 (或者按等级分布的) 建构之间各个方面占比的考量, 以及不同题目形式对于测量目标是否合适, 更加广义上的内部结构还包括这些问题。 这些问题不是进行简单的相关系数计算就可以进行检验的。测试理论学家现在依赖试题反应理论中的复杂数学方法来对理论上的复杂内部关系进行评估。

建构的外部模型详细说明了某建构与其他建构之间的预期关系。建构所处的概念框架中包括其他建构, 及其之间的关系。建构理论具体说明了几对建构之间的联系方向和程度, 或者是有些情况下和其他建构缺乏联系的情况。可以将对外部模型的具体说明作为可进行验证的假设。对建构的外部模型进行评估需要收集与建构相关的趋同性证据和区别性证据。针对某一建构得出的测试分数, 对同一建构采取不同的指标, 采用同一种测量方式对其他建构进行测量, 测试分数和前者的相关系数应该更高。

有关与测试使用相关的建构效度验证, 谢泼德 (Shepard, 1993) 认为建构的概念网络应该包含更加宽泛的外在部分。在讨论效标相关证据时, 我们了解到预测测试和效标之间的关系对于测试意义来说是很重要的, 所以也是部分建构效度。谢泼德提倡外部模式不仅要包括传统的趋同证据和区别证据, 还应该包括多种效标测量相关领域的理论概念, 相关建构之间的关系, 以及理论。梅西克 (Messick, 1989) 也认为必须将预测测试和效标测量在概念上 (不仅仅是经验上) 进行联系, 这样才能说明测试具体用途的合理性。

(5)可能的对立假设

科学与非科学之间的区别就是科学实践者愿意让自己的观点接受挑战。科学研究不仅需要对个人的解释找到支持性证据。如果我们只去寻找和我们的观点一致的证据, 找到的可能性还是很大的。但是这种方法只能证明我们的解释和实际观察是吻合的, 但却不是对该现象唯一或最好的合理解释。要证明某个解释比其他解释更好, 必须得设计研究对其他解释进行验证。对于一般性的假设检验以及建构效度验证来说, 都是如此。

日前很多效度研究都是为了解决测试中的偏差问题。如果群体在某项测试中的表现不同, 首先要问的问题是 “为什么?” 通常, 一种可能的解释要涉及公平问题。测试的批评者会想知道测试表现上的差异是否和测试构建或者表现领域差异有关, 或者其他不相干的因素有关。比如, 我们发现在英语分班考试中, 女生的表现会比男生好, 为此可以提出几种解释。我们可以这样推测, 女生的平均语言能力要更高 (如测试所测)。如果测试还是论文写作形式的, 还可以这样猜测, 女生在写作能力、作文质量、整洁度或者手写清晰度方面存在优势, 这些可以通过性别差异来解释。其他因素, 比如兴趣程度也许也是原因。在评估偏差的时候, 需要判断这些原因造成的差异是否和建构相关。在证明某项推论构建效度的合理性时, 需要记住总是存在很多反方面的解释, 那些对立性的理论也需要好好探讨。

## 3. 梅西克的扩大效度理论

塞缪尔。梅西克 (Samuel Messick, 1989) 在《教育测量》第三版中所撰写的一章内容是目前有关效度最为权威、引用最为广泛的著作, 虽然凯恩 (Kane, 2006) 在第四版中写的内容也许会最终替代梅西克的内容。梅西克这章内容里有两个方面和测量领域相关。第一, 将构建效度清楚确立为一个单一集中的效度概念。这并不是什么新想法, 实际上谢泼德 (1993) 指出在几十年前就有这种看法了, 但是梅西克在这一章中正式阐明了测量界的共识。梅西克的第二个贡献是扩展了效度的含义, 使其不仅包括测试分数的含义, 还有测试相关性和实用性的证据, 以及测试解读和使用的后果考量。虽然,要让测量界所有人完全接受用理性和经验方法来分析测试应用的后果, 作为构建效度验证的一部分, 还要等些时间, 但在效度理论发展史上这也算一个里程碑了。梅西克的模型是一个统一而多层面的效度概念。

梅西克 (1989) 通过一个四联表来呈现其效度框架, 详见表 5-7 (他的原书中是表 2-1)。204

“建立一个统一的效度框架……可以将统一的效度概念中两个相连的层面进行区分。一个层面是证明测试合理性的基础, 基于对结果证据的评估。另一层面是测试的功能或结果, 可以是解读或应用。将第一个层面 (证据基础或者结果基础) 与另一层面 (测试的解读或使用) 交叉, 就出现了表 2-1 这样的情况 (梅西克, 1980)。

如表 2-1 所示, 测试解读的证据基础是建构效度。测试使用的证据基础也是建构基础, 但是需要在应用测试时有相关性和效度证据的支持。测试解读的结果基础是对建构中蕴含价值观的评估, 以及解读之后的理论依据和理论蕴含的意识形态。一个核心问题是理论内含和价值观含义是否相符, 因为价值观含义并不只是辅助部分, 对测试分数的意义至关重要。最后, 测试使用的结果基础是对测试应用潜在和实际社会后果的评估。” (第 20 页)



表 5-7 效度层面

<table><tr><td/><td>测试解读</td><td>测试使用</td></tr><tr><td>证据基础</td><td>构建效度</td><td>构建效度十相关实用性</td></tr><tr><td>结果基础</td><td>价值观含义</td><td>社会影响</td></tr></table>

资料来源: 经梅西克 (1989) 许可后复制。效度, 选自林 (Linn) (编), 《心理测量》 (第三版, 13---103 页), 细约: 麦克米伦。版权 (C) 1989 美国教育协会。



我们已经讨论了和测试解读与测试使用证据基础相关的主要问题, 也就是表 5-7 中的“建构效度”和“建构效度十相关实用性”。现在我们来介绍梅西克关于测试解读和使用中的结果基础的思想: 价值观含义和社会影响。

(1)测试解读的结果基础: 价值观含义

科学中是否应该涉及价值观, 关于这个问题已经没有什么可争论的。肯定是有的。科学判断也是价值观判断。比如, 在 20 世纪 50 年代之前, 在进行效度验证时, 人们主要依赖经验, 而现在我们主要使用建构作为检验假设的基础。这是依据在现在看来什么是重要的有价值的而做出的选择。另外, 采用验证假设的方式本来就是一种选择。科学中肯定是要涉及价值观的, 问题是在科学研究中如何考虑价值观问题。

梅西克 (1989) 在效度概念中包括了测试解读的影响, 要求在效度验证过程中明确建构中隐含的价值观。他认为价值观对于效度考虑至关重要, 他们通过测试分数的建构解读影响分数的意义。对于任何事件或行为的解读都会涉及将它与更大的价值观维度进行匹配。任何单一的事件和行为可以看作其所属种类中的一个样本, 所以符合那个类别的特点。而每一个种类同时属于更宽泛概念中的一个子类, 也是附带另一层价值观的。在效度验证时, 价值观会在三个层面对分数含义产生影响: 第一, 对建构赋予的标签; 第二, 为建构赋予含义的理论; 第三, 理论中的意识形态。

要了解建构标签中蕴含的价值观, 可以来看这个例子, 如果某个测量尺度端点的分数解释含义被称作 “灵活对刻板”, 而不是 “混乱对一致”, 那么这两种叫法有什么不同呢? (Messick,1989) “个人危机”这个标签之下蕴含了怎样的价值观? 如果这个概念被称为 “个人成长机会” 呢? 如果我们对一件事有了先人为主的 “好” 、 “坏” 判断, 这样的价值判断常常会通过建构标签反映出来, 也会让我们对分数做出符合原来设想的解读。我们必须要谨慎, 让建构表现能够准确反映理论概念和经验推论所蕴含的全部价值观。

理论是比建构更为宽泛的范畴, 有自己的附带价值观和假设。建构因为其在更宽泛理论框架中的位置才有意义。所以我们也许会发现对相同的分数有不同的解读, 是因为通过不同的理论角度来看建构和指标。用不同的对立理论来看同一个现象就能理解这一效应了。比如对同样的倾向测试分数会有不同的解读, 从某个理论视角来看, 这个建构特质是相对稳固不变的, 从另一个理论来看, 却可以通过练习进行提升。从第一种视角来解读分数, 可以认为受试者在某特征方面的水平是不受个人控制的。从第二种视角来解读分数, 受试者在构建特质上的得分是可塑的, 所有个人要对自己的现有水平负责, 也是有进步空间的。很明显, 解读的不同对测试的实际应用会带来很大的影响。

最后, 第三类价值观的来源是理论内含的意识形态。意识形态是指“由共同的价值观、情感和信仰等构成的复杂建构, 为解读世界提供一个存在框架” (Messick, 1989, 第 62 页)。鲁宾 (Rubin, 1988) 认为意识形态是一个人的 “现实的隐含模型” (第 243 页)。在效度验证等科学研究中, 意识形态会对各方面产生影响, 比如提出什么样的问题, 寻找什么样的答案, 在研究中对观察到的东西赋予什么样的含义。人们对共性和差异性就有不同的看法, 有些理论学家认为在真正重要的方面, 人类的共性大于差异性, 这些理论反映了对于人类特征和经历共同之处的关注 (比如人类有超过 \( {98}\% \) 的相同基因)。而这个理论框架不能用来解释人类个体的差异,会认为这是不可解释的 “错误”。其他理论学家则认为每个人都是一个独特的个体, 研究人与人之间的差异比研究共性更为重要。这些理论学家会提出理论来解释我们之间的不同, 涉及基因的个体差异、情景、文化、个人体验等方面。因为意识形态是认识和解释世界的重要方式, 不同的意识形态对世界的体验是不同的。虽然很难站在另一个意识形态的角度来看待事情, 不同的意识形态可以引发有价值的辩论, 应该怎么样看待问题, 怎么处理价值观问题。处理价值观的一大难点是这些价值观常常是隐含的, 在考虑其影响之前首先要发现他们。

## (2)测试使用的结果基础: 社会影响

考虑测试使用的影响可以让我们判断测试在某个应用情境下的功能价值。梅西克 (1989) 认为在建构效度验证中应该考虑到测试实际和潜在的社会影响。首先, 依据建构理论对潜在的后果进行合理预测。要对测试使用后可能出现的预期和意外结果进行合理预测, 对测试分数与效标之间的关系提出假设解释时, 都需要知道分数的建构意义。另外, 实际结果对预测进行肯定或否决, 可以让分数有意义, 为其提供经验证据。前面提到的所有建构效度层面、分数解读、分数具体应用中的相关性和实用性, 以及和分数意义相关的隐含价值观, 都汇总在梅西克的表格中。

原来测试使用中的中心问题是, “测试是否发挥了预期效果? 是否符合预期目标?”梅西克 (1989) 则认为测试的预期结果并不能说明测试的使用就是合理的。要考虑到测试在特定情况下的应用价值需要, 包括预期结果和意外结果、积极影响和消极影响, 这样才能判断测试使用是否合理。如果测试的消极后果是因为效度低, 情况尤其如此。

对测试使用中的以分数为基础的推论进行效度验证, 需要对积极或消极影响的原因进行评估。如果两组人在同一项选拔考试中有不同的分数分布, 那么得分高的一组人被选中的比例会更高, 而得分低的一组会受到负面影响。如果测试分数上的差异和建构差异不匹配, 那么测试用于选拔人才的效度就降低了。前面我们提到影响建构效度的两个威胁,一个是建构代表不足,二是无关建构的测试变异。如果测试分数或者效标测量受到这两个因素的影响, 尤其是对不同的群体有不同的影响, 基于分数的推论就有问题了。所以, 测试若无效并不是因为负面的影响, 而是因为分数并不能代表测试建构。另一方面, 如果能排除这些造成无效的因素, 群体在测试上的表现差异可以视作在建构方面存在真实的差异。如果是这样, 测试使用就是有效的, 群体差异有分数上的意义。如果负面结果的原因不能追溯到测试的效度上, 即使某些个人和群体得分偏低, 仍要继续使用, 这就是一个政治或社会政策问题了, 与效度无关。

测试使用的副作用不仅会对个人和群体产生影响, 还会影响到整个机构和社会。 大多数美国州规定学校必须进行能力测试。进行这样的测试是为了确保所有从高中毕业的学生能够达到标准要求, 他们在社会中有足够的能力。这类测试的意外副作用也开始显现。为了确保所有的学生通过考试, 老师把大量的教学时间花费在测试特点、考试技巧和考试内容上。如果测试为单项选择的形式, 那考试重点就是对知识点和细节的记忆, 而不是思维技巧。这类“关键考试”的副作用, 我们会在第七章进行详细讨论。

梅西克 (1989) 表示对测试后果进行评估还有一个重要原因: 对测试应用的价值进行判断经常会成为社会行动的依据。比如, 要决定如何配置有限资源 (比如竞争激烈的学术项目职位或者工作机会), 需要依据一定的选择标准。那些未被录取的人常常会对选拔程序的公平性提出疑问。前面讨论过的所有效度问题都涉及公平性问题。但是, 不仅要证明测试是公平的, 还要证明整个选拔程序的公平性。公平性考虑中一个核心问题是: 如果采用不同的决策规则, 使用其他测试分数, 或者不看分数, 资源分配会更加公平吗, 会对另一人群造成不公吗?

实际情况很可能是后一种。决定谁可以得到稀缺资源要看个人的立场, 实际上也是一个价值判断问题。比如, 依据预期效标表现进行人员选拔这种常见做法, 蕴含的价值观就是机构的效率和经济性是最为重要的。在决策中, 这种价值观到处可见, 却不是唯一的一种。效率和经济性无疑非常重要, 有时候是最为重要的, 但是没有哪种价值观是理所当然最为重要的。不管筛选的标准是什么, 对于那些弱势的人和倾向其他价值观的人来说, 可能会不公平。

很多情况下, 不同的价值取向是相互矛盾的, 没有办法同时考虑到多种视角。在学业决策中最常用的四种价值基础是能力、努力程度、成绩和需求。但是实际上, 不能同时满足所有四种价值取向, 因为 “需求最多的不一定是能力最强的, 努力程度最高的不一定是成绩最好的” (Deutsch, 1975, 第 140 页)。我们要判断在应用情境下, 相互冲突的价值观中哪些是最为重要的。梅西克 (1989) 和克龙巴赫 (1988) 推荐特定情况下, 在决定哪种价值基础最为重要之前, 充分考虑多种价值观以及采用每种价值观可能带来的后果。

## 4. 对梅西克思想的修正及关注点的变化

效度概念一直有新的进步。虽然梅西克的模型代表了效度理念的一次重大转变, 今天依然是测试理论的核心, 但是其他理论家也提出了自己的看法。 1993 年, 谢泼德对梅西克的模型进行了修正。她并不是说梅西克的模型没能准确反映效度理论的现有情况, 也没有否定他的论证, 谢泼德的主要关注点是如何表达这些问题。梅西克的那章内容特别复杂, 足有一百多页。谢泼德认为这样很难进行实际应用。她注意到梅西克希望通过四联表来解构极其复杂的模型, 然后在文章中分为四个部分, 这会鼓励测量界延续一直以来将效度验证措施分为不同类型的传统做法。谢泼德认为这并非梅西克的初衷, 但是对他的模型进行这样的解读会有损效度概念的整体统一性。谢泼德担心将效度验证分为几个部分会误导测试使用者只关注效度验证的某些方面 (证据), 而忽略其他方面 (结果)。现在的共识是建构效度验证是一个不间断的过程 (科隆巴赫, 1971, 1988; 梅西克, 1988, 1989), 这使谢泼德更为担心测试发布者和使用者的实际操作和效度理论之间会有出入。如果建构的证据、分析和论点永远都不是完善的, 有些使用者会在证据不足或未充分评估结果的情况下解读和使用测试。

谢泼德 (1993) 引用科隆巴赫 (1988) 提到的建构效度验证过程概念, 与她自己的观点很接近。科隆巴赫强调了梅西克文章中提到的问题的不同方面, 把效度验证过程看作是一种评估论证。和梅西克的模型一样, 科隆巴赫认为全面的效度验证论点需要将 “理念、证据、社会和个人影响” 联系在一起 (第 4 页)。科隆巴赫和梅西克、谢泼德一样, 强调采取一种统一完整的方式来对待效度验证。然而, 不同于很多人对于梅西克著作的误解, 科隆巴赫的理念清楚呈现了一种同时考虑到各种问题的效度验证过程。

科隆巴赫 (1988) 提到现在效度验证主要是在公众领域进行, 公众会对测试应用的各个方面很感兴趣, 非常关注, 甚至产生怀疑。测试在决策过程中的应用, 尤其是聘用、资格认证和高等教育中的关键测试, 现在引发了很多激烈的辩论 (Sackett, Schmitt, Ellingson, & Kabin, 2001)。科隆巴赫认为, 根据任何分数得出的推论, 其效度如何, 应该允许公开的辩论, 那些参与测试解读和应用的人应该阐明自己的决定。 他还推荐进行效度验证的人员、测试发布者或使用者, 在验证效度时应该像针对某一话题进行辩论的人那样。一个好的辩论者首先应该仔细考虑问题的各个方面, 随后从任何一个角度进行有效的论证。对于任何辩题, 在论证特定分数解读和应用时, 若可以考虑到相反论点, 则可以加强原论点的说服力。

测试会含有价值观, 涉及政治。所以科隆巴赫 (1988) 强调, 在为我们想要提出的推论辩护时, 应该要考虑到多种视角。公众被某种论点说服之后, 会决定接受或者否决某种测试应用。他们的判断结果主要取决于提议是否和主流的信仰体系相符 (有关价值观冲突的例子、主流价值观及其引发的热情, 详见 Rushton and Jensen, 2005, 或者 Roue, 2005, 以及对这两篇文章的评论)。更为复杂的是, 不同地区意识形态常常有很大不同。在提出效度验证的论据时要考虑到这些不同的价值观, 在向公众传达观点时, 要充分考虑到这些不同的观念。如果专业人员不能进行合理引导, 非专业人员则会对测试的解读和应用提出自己的论点。

## 5.6 效度理论和测试偏见

自从 20 世纪 20 年代以来, 测试中的偏见就一直是教育和心理测量关注的主题。 其后几十年来, 很多研究都在关注如何在试题和测试应用的决策中发现和消除偏见。 测试偏见是很复杂的问题, 要解决也不简单, 部分原因是那些关注这个问题的人会带有不同的视角。不管决策是否涉及测试分数, 不同的人都对于决策中应该采用什么样的价值观有不同的看法。我们反复强调所有测试分数应用都带有价值观, 测试应用也会引来对公平性和负面影响的担忧。对测试分数的某种解读和使用也许在心理测量层面来说是“无偏差”的, 但是那些对分数含义和应用结果附带的价值观不满的人会认为是“有偏见的”。

事实上, 测试偏见有多种定义方式。在这一部分, 我们采用技术上的、心理测量领域的定义, 这一定义和效度理论是有联系的。从效度上来说, “有偏见”或者 “无偏见” 是基于测试分数的推论, 而不是针对测试 (或题目) 本身。我们已经详细讨论过了, 如果有充分理性和经验证据支持, 而冲突性的推论缺乏证据支持, 该推论就是有效的。如果对不同的群体, 效度有差异, 就是有偏见的。如果测试分数不能在不同群体和情境下反映建构水平, (或者对不同的人群反映的建构是不同的), 那么分数解读就是有偏见的。如果测试分数对不同的人群进行的效标表现预测有差异, 那么测试分数用于决策就是有偏差的。

在相同语境下会经常提到 “偏见” 和 “公平” 这两个词, 但是在测量领域常常代表不同的概念 (Murphy & Davidshofer, 2001)。偏见通常由经验证据显现出来, 比如测试分数高估了某个群体的效标表现, 却低估了另一个效标群体, 所有这主要是个统计概念。这种情况下, 偏见可以通过科学方法揭示出来。在题目层面, 可以查看群体和题目的反应和互动, 在题目上的表现是否存在差异模式。在预测层面, 可以通过查看不同群体的回归方程来发现偏见。在斜率和截距上的差异说明可能存在效度的不同 (见 Camilli, 2006 和 Kane, 2006)。

公平, 则是指判断决策和基于测试分数采取的行动是否合理, 是一种价值判断。 这是一个哲学或政治概念, 而不是一个经验和科学问题, 没办法用数据来衡量决策是否公平。要判断是否公平,需要将已采取的行动和 “应该采取的行动” 进行对比。人们通常会倾向于觉得和自己的价值观和信仰一致的决策是 “公平的”, 而与其他价值观相符的决定是 “不公平的”, 而不会考虑对个人的后果是怎样的。因此, 从心理测量角度来说完全没有偏见的放之四海皆有效的推论,一些人甚至许多人却可能认为它不公平。经常有人会因为对测试的效果不满意而指责测试有偏见 (有时候甚至觉得测试设计者有不良企图), 而不会想到这是因为自己的意识形态不同。

## 5.7 信度和效度的重合

要衡量一项测试的用处, 一个方法是问在何种程度上可以从测试分数得出一些普遍结论。如果同一天进行两种形式的测试, 两项测试的相关系数可以告诉我们, 依据一组测试题目对另一组测试进行概括总结, 或者依据分数对于两组测试所测内容范围进行概括总结时, 能有多大信心。如果测试的方式不同, 可以收集不同情况下的证据。如果测试的方式、时间都不同, 可以针对不同测试题目和情况收集可得出普遍原理的证据。如果是两项相似但不同的测试, 而测量目标都是同一个建构或特征, 就可以得出测试之间可概括性的证据。现在考虑的范围会更广, 不仅是某个命题蓝图或设计中的试题样本, 而是不同作者制定的不同命题蓝图。那么这就不仅是信度的范畴, 而是效度的范畴了。当然, 可以将测试与相同特征的其他指标相比, 来考虑可概括性, 比如自我描述, 同学、上级或老师的评价。我们可以依据测试分数来预测这些评价吗?

普遍适用性这个概念既涉及信度又涉及效度, 说明这两个概念的区别只在于总结归纳时范畴的广度。也许最终普遍适用性这个概念会替代这章和前一章中谈到的几类信度和效度。图 5-5 就是对普遍适应性概念的说明。可以看到这很像一个洋葱, 有好几层, 可以知道离中心越来越远时, 结论的适用性如何。对于普遍适用性的详细讨论可以参考哈特尔 (Haertel, 2006) 的著作。





图 5-5 从测试分数进行概括的不同层次



## 5.8 标准参照测试的效度

标准参照测试关注的是具体的、范畴比较小的教学目标。所以, 评估标准参照测试的效度最重要的是内容相关证据。教学目标包括两个元素: 教学范畴内的信息内容以及学生应能如何处理这些内容。在试题中应该包括目标中的这两个元素, 这样试题才是对于目标达成程度的有效指标。

测试内容中经常被忽视的一个部分是受试者出现某种表现的条件。如果测试时间太短, 大多数受试者不能完成所有题目, 那么完成测试的速度也是测试内容的一部分。如果测试实施的条件比较差, 对受试者来说这些条件就是测试内容的一部分。 因为这些因素在不同群体间有不同表现, 测试的内容也很发生变化, 所有测试实施的标准化相当重要。内容效度和测试分数有关, 和各种影响也有关系, 包括说明是否清楚, 评分过程是否准确。如果内容对于测试的使用十分重要, 那么必须仔细考虑到各种影响测试内容的因素。

我们知道, 对于老师和相关科目专家来说, 内容效度主要是一种专业判断问题。 但是, 要评估标准参照测试的效度, 可以采用一种有用的经验或统计证据。这种方法主要依据贝克 (Berk,1980) 提出的观点, 他认为标准参照测试应该尽可能区分出已经掌握和未掌握教学目标的群体。理想化的测试应该将受试者分成两组同质化的群组: 已掌握教学目标的人和还没有掌握的人。

问题当然就在于怎么定义掌握这个概念了。一种常见做法是让老师找出哪些学生已经掌握了教学目标, 哪些还没有。这种方法可以产生两种区别很大的学生, 但是处在中间的学生会被忽略。第二种方法是将已经接受教学的学生和还没有接受教学的学生进行对比。还有一种方法是将学生接受教学之前和之后的水平进行对比。每种方法都有缺点, 所有方法都面临差异、变化和分数的不稳定问题。但是每种方法都为实现教学目标的教学活动的综合效度提供了一些证据, 也为测试是否能够测量这些目标的掌握程度提供了判断依据。

效度验证过程和第九章提到的题目分析很类似。将受试者分为两组: 掌握者和未掌握者或者已接受教学者和未接受教学者。然后计算出每组人答对题目的比例。 掌握者一组或者已接受教学者一组答对题目的比例显著更高的题目就是有效的。在极端情况下,掌握者一组答对的比例应该是 \( {100}\% \) ,而未掌握组答对的比例应该是纯猜测可能答对的比例。整个测试应该将受试者分为两组, 掌握组应该达到满分或者接近满分的程度, 而未掌握者应该接近随机水平, 不应该出现分组错误。

对教学内容的掌握很少是有或没有那么简单的事情。在任何班级中, 都会有掌握程度的差异性存在。事实上, 掌握程度这个问题在于如何定义掌握。效标测试关于掌握程度的一个好处是, 理论上来说, 学生达到掌握程度后可以解决课堂上的问题并完成任务。这类知识是形成性评估的重要组成部分。但是, 很多情况下, 在学校及其他地方, 这其实是一个相关程度问题。总结性评估通常需要常模参照测试, 明确关注相对性的表现水平。

## 5.9 元分析和效度的泛化

在心理学和教育学领域, 研究的样本通常比较小, 代表性低, 所以不同研究常常会产生不同的结果。过去 30 年来, 研究者在寻找更好的方法, 从一堆看似矛盾的研究结果中提炼出事实。对就同一种现象进行的各种不同研究进行结果的系统整合的方法,叫作元分析 (Glass,1977)。

对于从不同群体不同来源的测试效度数据进行整合就是元分析的一个例子。有了能力测试之后, 研究人员立刻开始收集教育和职业标准之下的测试效度数据。任何一种测试, 同样的课程, 相似的职位, 效度相关系数差别很大。比如, 通过鉴别能力倾向测试 (DAT) 中语言推理能力部分的得分预测英语成绩, 效度相关系数, 不同群体的数值不同, 从 0.07 到 0.76 。

人们通常认为, 效度必须在特定情况下才成立, 尤其是职业预测。然而, 最近, 施密特 (Schmidt) 及其同事 (Hunter & Schmidt, 1996; Schmidt, Hunter, Pearlman, & Hirsh, 1985) 证明研究结果之间的差异可能是统计数据的原因, 小样本取样误差, 效标可信度低, 或者研究样本中限制程度的差异。他们建议对搜集的数据进行元分析, 对不同研究的结果进行汇总分析, 取平均值, 可以对测试效度进行更为稳定、更适用的预测, 这样得出的数值比对当地较小样本进行研究得出的数值更接近实际数值。 所以,除非某个学校 \( \mathrm{X} \) 的英语课程和大多数学校的课程区别特别大,那么通过对很多学校的结果进行分析得出的效度相关系数中位数 0.49 会更为准确。学校 \( \mathrm{X} \) 在考虑使用区分性的能力倾测试下的语言能力推理成绩预测英语成绩是否有效时, 采用这个中位数值会比有限的局部研究得出的数值更为准确。施密特和亨特 (Hunter) 将这种元分析应用称作效度泛化。

元分析和效度泛化的步骤现在还很有争议, 但是在教育和职业心理学领域对这种方法的使用越来越广泛。我们可以预测在未来的十年或二十年里, 会对过去五十年的效度研究进行系统化的整合, 这样就可以对测试效标关系进行更为稳定的、一般性的估计。我们希望这样的关系可以被均等就业机会委员会以及其他政府和法院机构采纳, 取代原来基于局部小规模样本进行的研究, 客观测试程序会成为评估求职者的实用程序。

## 5.10 总 结

对于测试来说最为重要的就是效度。但是, 要证明测试分数在使用时具备效度, 是测试开发者和使用者共同的责任, 因为效度是指对测试分数的使用和解读。在某种情况下, 对测试分数进行的某种解读是合理的, 在另一种情况和目的下, 同样的解读可能就是不合理的。

关于某项测试是否具备使用效度, 有三类相关证据。第一, 内容相关效度证据揭示测试内容和预期解读之间的关系。如果二者之间有很好的相关性 (这一点需要专业人士来判断), 那么测试的使用则可以得到支持。第二, 效标相关或者实证相关证据, 这样的证据来自于测试分数与其他相关变量, 尤其是职业和教育成绩之间的关系。测试分数与在某项任务中的表现之间如果有很高的相关系数, 使用测试进行预测, 筛选以及人事变动就是合理的。最后, 建构相关效度证据主要看测试分数与理论推论之间的相关性。内容和校标相关证据可以帮助判断依据理论进行的预测是否合理。但是对实验干预的反应, 与其他变量之间的关系是否符合预期模型同样重要。

## 5.11 习 题

1. 如果美国高等教育测试中心要为高三学生制定理科普通摸底测试, 制定者要为此确定测试的效度证据,需要哪些步骤?

2. 测试指南中, 以下陈述提到来什么样的效度证据?

a. 学校态度问卷中的得分与教师的适应性评分之间相关系数为 +0.43 。

b. 有 150 名教师认为某阅读测试的目标是重要的。

c. 奇才编程倾向测试与就职 6 个月上级的评价相关系数为 +0.57 。

d. 聪慧因素测试产生的得分与韦氏智力量表得分相关系数为 +0.69 。

e. 精准学业组合考试基于对 50 种广泛使用的教材以及全美各地 100 种课程的分析。

3. 请对以下表述进行评论: 课堂上的老师是唯一能对其所教班级进行的标准化学业考试的效度进行评判的人。

4. 查看两到三项不同测试的指南。这些指南中提供了什么样的效度证据? 这些证据充分吗?

5. 查看表 5-5 , 如果筛选过程中使用测试的效度为 0.50 , 并且申请人中只有分数最高的四分之一被录用, 被录用人中工作表现高于平均水平的占多少百分比? 如果分数排名前四分之三的人被录用, 百分比是多少? 如果效度只有 0.40 , 两种情况下的两个百分比分别是多少? 将这四个百分比数值进行对比, 说明了什么?

6. 如果海军中的人事心理学家在研究筛选直升机维护培训员的测试, 针对这一专门职位, 他们会使用什么样的效标来衡量在职位上的成功程度? 可能的效标都有哪些优缺点?

7. 采用新生平均绩点作为衡量大学入学考试的效标有哪些优点? 哪些缺点?

8. 一项测试指南中有如下表述: \( \mathrm{Q} \) 测试的效度在于它与斯坦福一比奈智力量表的相关系数达到 0.80 。还需要什么其他证据来判断这个表述是否正确?

9. 有三项阅读测试可供你所在学校使用。在你看来, 它们的效度是相等的, 每项测试的信度都为 0.90 。你还需要其他什么信息来决定使用哪项测试?

10. 研究适合你所教班级的能力倾向或学业测试。为每项测试写一份评估, 可以使用本章最后一部分中的指南。

11. 从统一效度的角度考虑你在第 10 题中所研究的测试。测试中有哪些隐含的理论建构? 使用测试会有哪些可能的积极和消极影响? 除了测试作者所预想的目的, 测试还可以有哪些其他用途? 滥用测试会带来哪些后果?

## 推荐阅读

American Educational Research Association, American Psychological Association, & National Council on Measurement in Education. (1999). Standards for educational and psychological testing. Washington, DC: American Educational Research Association.

Ames, C., & Archer, J. (1988). Achievement goals in the classroom: Students' learning strategies and motivation processes. Journal of Educational Psychology, 80, 260-267.

Anastasi, A. (1986). Evolving concepts of test validation. Annual Review of Psychology, 37, 1- 15.

Angoff, W. H. (1988). Validity: An evolving concept. In H. Wainer & H. Braun (Eds.), Test validity (pp. 19-32). Mahwah, NJ: Erlbaum.

Borsboom, D., & Mellenbergh, G. H. (2002). True scores, latent variables and constructs; A comment on Schmidt and Hunter. Intelligence, 30, 505-514.

Camilli, G. (2006). Test fairness. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 221-256). Westport, CT: Greenwood.

Cook, T. D., & Campbell, D. T. (1979). Quasi-experimentation: Design and analysis issues for field settings. Chicago: Rand McNally.

Cronbach, L. J. (1971). Test validation. In R. L. Thorndike (Ed.), Educational measurement (2nd ed., pp. 443-507). Washington, DC: American Council on Education.

Cronbach, L. J. (1988). Five perspectives on validation argument. In H. Wainer & H. Braun (Eds.), Test validity (pp. 3-17). Mahwah, NJ: Erlbaum.

Deutsch, M. (1975). Equity, equality and need: What determines which value will be used as the basis of distributive justice. Journal of Social Issues, 31, 137-149.

Ebel, R. L. (1983). The practical validation of tests of ability. Educational Measurement: Issues and Practices, 2(2), 7-10.

Embretson (Whitely), S. (1983). Construct validity: Construct representation versus nomothetic span. Psychological Bulletin, 93, 179-197.

Fredericksen, N. (1986). Construct validity and construct similarity: Methods for use in test development and test validation. Multivariate Behavioral Research, 21, 3-28.

Gardner, E. F. (1983). Intrinsic rational validity: Necessary but not sufficient. Educational Measurement: Issues and Practices, 2(2), 13.

Haertel, E. (1985). Construct validity and criterion-referenced testing. Review of Educational Research, 55, 23-46.

Hambleton, R. K. (1984). Validating the test scores. In R. A. Berk (Ed.), A guide to criterion-referenced test construction (pp. 199-230). Baltimore: Johns Hopkins University Press.

Messick, S. (1980). Test validity and the ethics of assessment. American Psychologist, 35, 1012- 1027.

Messick, S. (1988). The once and future issues of validity: Assessing the meaning and consequences of measurement. In H. Wainer & H. Braun (Eds.), Test validity (pp. 33-45). Mahwah, NJ: Erlbaum.

Messick, S. (1989). Validity. In R. L. Linn (Ed.), Educational measurement (3rd ed., pp. 13- 103). New York; Macmillan.

Rubin, D. B. (1988). Discussion. In H. Wainer & H. Braun (Eds.), Test Validity (pp. 241- 256). Mahwah, NJ: Erlbaum.

Sackett, P. R., Schmitt, N., Ellingson, J. E., & Kabin, M. B. (2001). High-stakes testing in employment, credentialing, and higher education. American Psychologist, 56, 302-318.

Schmidt, F. L. (1988). Validity generalization and the future of criterion-related validity. In H. Wainer & H. Braun (Eds.), Test validity (pp. 173-189). Mahwah, NJ: Erlbaum.

Schmidt, F. L., Hunter, J. E., Pearlman, K., & Hirsh, H. R. (1985). Forty questions about validity generalization and meta-analysis. Personnel Psychology, 32, 697-798.

Shepard, L. A. (1993). Evaluating test validity. In L. Darling-Hammond (Ed.), Review of research in education (Vol. 19, pp. 405-450). Washington, DC: American Educational Research Association.

## 第6章 测试的实际应用问题

## 6.1 例行测试的使用中与实际应用相关的一些因素

虽然对于心理与教育测量来说, 效度和信度至关重要, 但要在全校或整个学校教育体系或政府部分和某个行业推行某项测试, 则必须考虑到一些实际操作的问题。 对于考试主管机构来说, 它们更注重如何节省开支、合理安排时间, 不改变日程安排也能将某项考试纳入标准学期安排。另外, 其他因素如考试的准备情况, 如何打分, 如何解读分数, 对于考试的实施来说也很重要, 它们对于测试的用途和解读有很大的影响。

## 1. 经济性

在当下教育部门和企业经费紧张的环境下, 省钱的重要性毋庸赘言。对于教育部门及其他行业来说, 资金真的很重要, 研究人员必须注意花费情况。测试的经济性一部分在于每个受试者所需测试材料的费用, 批改测试的费用, 以及是否有可能重新使用测试。比如, 在小学高年级测试中, 可以使用分开的考试册和答题纸, 这样考试册就可以循环使用。如果测试可以连续使用几年, 或者不同的班级和学校可以在不同日期考试, 可以节省不少费用。所以出版商会将考试册和答题纸分开。

经济性的另一方面在于考试安排, 但是通常却不能做到。在第四章中, 我们了解到测试信度很大程度上取决于于其长度。考试需要有足够的时间才能产生准确的结果, 可以对某些测试进行高效率设计, 使其每分钟能产生更为可靠的测量结果, 但是通常来说缩短时间意味着测试的准确性和涵盖范围也会下降, 除非可以使用计算机自适应测试。但是这需要有足够的合适计算机, 同时应试者应能够适应这种形式的考试。

经济性的第三个方面是评分的简易程度。如果需要本来就很忙碌的教师或者心理学家来手动评分, 或者需要专门请人来评分, 那么这个工作量就会很大, 所以需要依赖机械化评分, 相关出版商也正开发可以通过精密设备来批量处理的测试。一些商业化测试, 比如学术能力倾向测试以及斯特朗职业兴趣量表, 就需要使用出版商指定的专门机构进行评分。其他测试, 比如为个人制定的斯坦福-比奈智力量表和韦氏智力量表, 只能手动判分, 但是大多数测试可选择手动判分、自行设置机械判分系统或将试卷交给专门机构处理。

(1) 计算机评分

一些考试出版商经营的考试评分机构提供高效的判分报分服务, 处理周期为 24 小时, 就是在收到完整答题纸 24 小时内可以完成评分并用邮件回复结果。同时, 评分机器的成本越来越低, 很多学校、校区和人事机构可以设置自己的评分系统。最基本的设备包括一台光电文件阅读器和一台计算机。阅读器对答题纸上的答案进行识别 (至少有三家公司的扫描设备的售价低于 5000 美元, 会对很多校区和中型公司来说完全可以承受)。

对于大多数美国大学生来说, 分开的答题纸再平常不过, 不过对于小孩子来说却不方便。在试题册上找出正确答案, 记住选项, 然后将选项在答题纸上相关位置填涂, 这对于小学生来说很是麻烦。但是现在的设备可以让小学生也能使用分开的答题纸。学生直接在试题册上选择答案, 在判分过程中, 试卷边缘一册的回答可以撕开, 由扫描器对答案部分进行扫描, 或者测试材料可以设计为可供扫描仪扫描的可折叠型。现代扫描设备可以一次处理 50 多种不同的答题纸。

随后将扫描仪的结果存入计算机, 与计算机存储的答案进行对比, 计算出分数存入计算机以备下一步分析, 或者按照记录形式打印出来, 比如在第三章中提到的例子。计算机还可以生成一系列数据, 比如平均数、标准差, 以及关于班级、学校和教育系统的种种百分比数据。所以, 评分系统通常不仅可以用来评分, 还可以生成有关测试结果的一系列数据信息, 对于当地老师或者学校可能很有用。一些评分系统还可以保留几年的成绩记录, 生成地方测试的长期纵向数据。对于当地学校来说, 有自己的评分设备的一个好处是便于分析当地试题 (见第九章), 还可以收集当地长期的数据。

可能最令人意想不到的一个发展是现在有那种可以对论述题进行评分的软件, 使用评分标准和参考答案就可以做到 (Page,1994)。评分标准就是设定一系列标准, 说明如何与标准答案进行对比, 如何对语法和拼写进行评分。佩奇 (Page) 和他的助手表示他们设计的程序和六名评分人产生的评分可信度一样, 当然, 评分结果主要看评分标准的准确度, 但是随着计算机评分系统的经验不断完善, 使用这种标准测试评分的趋势会越来越明显。

大规模测试中使用的经济型测试适用于不同的扫描仪和评分系统, 几乎所有答题纸可以使用模板, 使手动批改更高效, 一些出版商也会提供塑料模板。一些测试使用特殊答题纸, 由两张纸订在一起, 背面覆盖一层炭, 或可以感压, 答案印在第一张纸的背面, 当批阅者批阅正面时, 覆有炭层或者可以感压的材料将回答印到背面, 那样就可以算出与正确答案重合的部分。

购买测试的一方会考虑什么样的作答形式和评分系统适用于可能采用的测试。 如果要在当地进行评分, 那么就要知道可供使用的扫描仪有哪些限制。可供当地进行评分的相应出版商会提供常用扫描仪可适用的答题纸, 一些通用的测试可以提供相应软件包, 可以生成有关分数的分析和各种报告, 如第三章中介绍的例子。

(2)计算机辅助测试分析

测试制定者和出版商越来越依赖计算机为用户生成分数解读报告。在计算机存储设备里存储一系列表述, 如果分数落在某个给定区间内, 或者出现某种分数组合, 或者对某些特定问题产生了特定回答, 计算机会依照设定程序生成一些表述。报告中的表述也许非常直接简单, 只是与得分有关, 比如 “亨利在计算题中的得分略低于平均分”, 或者是第十四章中介绍的人格分析。报告也许只注重某个的分数, 或是对整个测试进行宽泛的讨论。比如, CPP 关于斯特朗职业兴趣量表产生的报告会介绍解读受试者分数的基准, 整个测试的大致原理和产生不同分数的原因, 以及要进一步了解与受试者兴趣相对应职位信息需要阅读的参考资料, 还有九页长的个人化深度分析报告。如在第三章中所介绍, 评分系统还可以为班级和学校生成总结报告。

计算机报告也许比不上长期的经验智慧, 但是它们可以从专业人员那里汲取经验, 也能防止个人偏见和经验不足, 也能节省时间, 不用花费精力来写报告。计算机的使用可以保证报告不会忽略结果的哪个部分, 也能保证解读的连贯和一致性。报告的确还需要了解受试者的专业人士来进行评估, 但是计算机报告本身就非常有用。

## 2. 有助测试实施的因素

在衡量一项测试的实际可用性时, 需要考虑的一个因素是实施的难易度。仅需日常教学教师, 仅需耗时一段时间的测试实施起来很方便, 而需要专门训练人员, 需要占用很长时间的测试则比较麻烦。以下几个因素可以影响到测试实施的难易度。

① 有清楚完备说明的测试比较容易实施。测试施行的说明应当完整, 受试者必须阅读并遵守。说明应一字不差包括所有测试制定者要对受试者说的内容, 最好使用显眼的颜色或者加粗字体。除了说明完整, 还应当包括适当练习题, 练习题的数量在于题目的新颖程度。如果题目很常见, 说明直截了当, 一两道例题就够了。如果题目比较新颖, 不太常见, 较为复杂, 那么就需要更多例子。好的出版商会设置练习题, 让学生熟悉测试中包含的题型。

受试者对测试中题型的熟悉度不同可能会成为不相干的影响因素。家境不好的孩子和家境好的孩子相比会对测试环境更为陌生, 足够的练习题可以有效消除这一影响, 对家境较差的孩子进行更为准确的测试。有关如何进行测试的说明 (通过模拟测试) 甚至可以作为低年级的教育活动之一, 因为可以消除 “会考试” 这一不相关因素造成的个体差异。

② 不同部分有不同时限, 计时准确性并不至关重要的测试更易实施。对每个测试部分进行计时并精确到几秒十分无聊, 而且除非每个人都可以用计时器, 否则计时很可能不准确。有些测试也许会有八个或十个部分, 每部分两到三分钟。但是有三到四个部分, 每部分五到十分钟的测试会更容易施行, 测试的部分少一点, 每个部分延长, 这样可能造成误差的计时错误出现的可能性会减少。如果使用计算机进行计时, 也许可以解决这样的问题。

③ 测试题目的布局与考试的难易度有很大关系。如果回答题目时, 选项挤在同一行, 又小又难以辨识的图形和图表都挤在一起, 会增加答题的难度。试题的难度应在于内容和思考过程, 而不是题目形式。印刷文字和图案应该够大够清晰, 选项和回答应该分开, 一道完整题目, 关于同一个图表问题的说明及一篇阅读文章应该包含在同一页或者双开页。如果题目的布局让受试者难以作答, 得分就会低于他们的应有水准, 这会减弱测试的效度, 这对于效标测试可以有很大的影响。

## 3. 有助解读和应用测试分数的因素

有时候这一点会被人们忽略, 但是测试的目的就是为了运用其结果。要应用测试得分, 必须对其进行解读, 赋予其含义。测试制定者和出版商的一个责任就是提供相关信息让使用者可以对每个参与测试者的得分进行合理解释, 根据其相关需求, 对测试结果进行评估。测试制定者和出版商主要通过附赠的测试指南和其他材料来履行这项责任, 在指南和附加材料中, 使用测试的人可以找到哪些信息呢? 以下是一些举例。

① 关于测试测量目的的功能性说明和测试的基本制定过程。在说明中, 测试制定者会说明怎样应用测试分数是合理的, 并提供相关证据, 证明推荐的解读方法是经过合理步骤验证过的。对于成绩测试来说, 最重要的是测试内容和认知过程是否得到了测量, 测试指南中应该说明测试内容是如何选出来的以及是如何测量认知功能的。如果作者不愿意公开自己的思路, 接受质疑和检查, 那么他的思路很可能不够全面彻底。220

说明中, 不仅要包括选择测试目的和内容时经过的理性程序, 还要包括对测试题目的检查、实验和审核时的经验程序。说明中应该包括评审小组的成员构成和检查测试偏差时采用的统计程序。测试的效度、分数的解读、解读分数时的注意事项以及分数应该怎么使用, 对测试来说是最为重要的元素。测试制定者的计划和具体步骤是构成测试效度最重要的步骤, 必须清楚写出来以便使用者可以判断每一步的质量。

② 实施测试的具体说明。在这一部分的前面我们讨论了这点的重要性, 对于教师或者其他需要使用测试的人,需要这样的说明来统一实施测试。要取得符合使用者需求有效度的成绩,需要合理的实施, 如果实施过程有违说明, 那么测试的效度也会打折扣。

③ 评分要点和关于评分的具体说明。评分的问题已经讨论过了, 如果能在或必须在当地进行评分, 指南和附加材料中应该包括如何记分、错误点怎么算、每部分分数如何相加得出总分的具体说明。如果需要当地使用者进行手动评分, 评分要点和模板应该可以尽可能协助这一繁重的任务, 同时还应当对电子评分提供详细说明。

④ 设置合适的常模参照组。指南或者其他资料中应包括关于常模的说明, 即所用的参照常模是如何获取的以及应当如何使用。对于测试常模及其使用已在第三章中进行了详细介绍, 所以这里仅对测试设计者选取合适的常模组的责任稍加说明。 一般常模是必需的, 而适于特定类型的群体、特殊职业人群以及其他限定范围更窄的人群的常模在很多情况下也会十分有用。

⑤ 测试信度的证据。相关证据应包括关于测试信度的简单数据, 还得说明得出估算信度所用的方法步骤, 以及计算信度时每组人的描述性和统计性特征。如果测试的形式不止一种, 制定者应当说明两种形式之间的关系, 以及单次测试中产生的数据。如果测试可以得出各部分的得分, 并且需要应用各部分得分, 还应当对每部分得分的信度进行说明。比较好的步骤是对测量的标准误差和信度相关系数进行说明。 建议测试制定者最好说明每个分数段的标准测量误差, 因为这可以说明测试在哪个分数级别是准确的。

⑥ 测试的不同部分分数之间相关性的证据。如果测试对不同部分分别记分, 指南中应说明不同部分得分之间的关系。这部分信息对于解读各部分得分, 评判各部分之间的差异性十分重要, 如果相关度表明各部分的信度相似, 说明他们测量的内容类似, 各部分的不同没有什么意义。各部分得分的信度, 以及之间的关联, 可以更为准确地衡量得分不同的含义。有些出版商会提供信息来衡量在标准样本中分数差异在某种量表上出现的频率。比较好的情况是分数差异的模式有特定的含义。应该对不同部分之间的关联进行的因素分析加以说明, 所以对于不同部分得分相加的结果可以对某个共同方面进行测量。这样的分析可以衡量内容效度和建构效度。

⑦ 关于测试和其他变量关系的证据。既然测试是用来进行预测的, 那么与相关标准之间的关系直接反映了测试的实际预测能力。应该充分说明相关标准变量的实质信息, 小组数据来源情况, 以及数据采集的条件。只有这样测试使用者才能判断测试预测能力的效度。

在衡量测试的构建效度时, 最好说明其与其他相同功能测量之间的关系, 作为边缘性证据。例如, 在测量一组人的智商时, 可以说明其与个人智商测量之间的关系。

最后, 说明测试得分与年龄、性别、社区类型、社会经济阶层, 以及其他与个人或一组人有关因素之间的关系, 通常会很有用。这些信息可以有助于了解测试与受试者的背景、生活状况、教育背景之间的联系。这类证据也可以有助于了解出版商开发测试时的目标人群是否与当地人群相符。

⑧ 应用测试及解读测试结果的指南。测试制定者应该知道测试如何使用才是合适的, 如何解读才是合理的, 他们是这方面的专家。要让测试可以为他人所用, 尤其是让未受专门培训的教师正确应用测试结果, 需要详细的建议, 这样可以正确应用测试结果来对个体或者一组人的优缺点进行判断, 来进行班级分组, 进行补习课程, 与个体进行面谈, 或者其他需要依据测试结果进行的活动。使用计算机进行测试结果解读在这种情况下会十分有用。

最后需要记住的一点是在准备测试指南时所花费的心血通常可以预测测试制定时所花的心血。如果测试制定者细致说明测试是如何制定的, 充分列出测试信度和效度的相关证据, 那么他们肯定会尽最大努力制定高质量的测试, 在制定过程中会非常用心, 表现出专业水准。

## 4. 电子化测试

最近有一种操作简单但是有一些缺点的新型测试形式, 那就是通过网络进行测试。美国心理协会开发了一个叫作心理协会测试 (http://www.PsychCorpCenter.com) 的网站, 网站上有资质的专业人士可以为客户进行一系列测试。客户通过电子邮件得知为他们准备好了某项测试, 可以登录网站, 很方便地完成测试。计算机软件会计算出得分, 生成相关报告, 计算得分平均花费三分钟。接下来, 预订测试评估的人被告知测试已经完成,可以下载报告了。在写作这本书时,心理协会网站上有 32 种测试可以以这种形式进行。另一家大型考试出版商——咨询心理学家出版社 (CPP) - 有五种网络测试工具, 以后其他大型出版商可能会很快效仿这一形式。

心理协会采取多项细致措施来确保测试制定者和使用者的身份、测试结果及测试报告等信息的安全。对于测试使用来说, 这点至关重要, 可以减少关于测试安全性的担忧。但是对于网络测试来说, 还是有两点警告。第一点是关于测试环境控制和测试规范可行性的潜在问题, 这倒不是什么大问题。测试规范在特定环境下施行, 来确保受试者认真对待测试, 并且认真诚实作答。除非有研究表明网络测试中的回答和传统测试作答一致, 对网络测试的得分进行解读时必须谨慎。

第二点问题更为严重。如果测试的地点是某人家里的私人空间, 我们没办法确定到底是谁在作答。心理学会要求受试者在登录时提供预约人的身份信息, 以控制这类问题的发生, 但是这不能完全确保作答人的真实身份。心理协会提供的一些测试会用来帮助公司筛选人才, 渴望得到工作职位的人可能会在作答时寻求朋友或亲戚的帮助, 甚至可以让别人来代替自己作答。唯一可靠的解决办法是让受试者来可被监控的制定地点参加测试, 但是这样一来网络测试的很多优势就没有了 (最近, Petrill, Rempell, Oliver, and Plomin, 2002, 表明可以通过电话来测量认知能力, 但是受试者是孩子, 有一名家长协助实施测试)。

## 6.2 测试评估指南

为了帮助潜在测试使用者, 在最后部分我们介绍一下评估测试的指南。这项指南包括一系列问题, 主要选自《教育学与心理学测试标准》(美国教育研究协会、美国心理协会及全国教育测量委员会, 1999)。仔细研究《标准》全文可以让你成为一个非常在行的测试使用者 (最新版本的《标准》和前面的版本有所不同, 前者更侧重如何正确解读和使用测试结果, 而非如何制定测试。测试分数的效度主要 (或者有人会说完全) 取决于所应用的具体情况, 测试使用者有责任确保基于测试分数做出的推论和决策应该得到合理证据的支持)。

也许你会注意到这一指南中的许多问题和测试中可提供说明的准确性相关。这一指南中的许多部分, 尤其是和信度及效度相关的部分, 隐含着没有清楚说出来的另一个问题。这个问题是: “根据已有信息, 测试的满意度如何? 和其他测试相比如何? 按照绝对标准来看, 是否可以达到我想要的目的? "确保测试的效度, 很大一部分责任在于使用测试的人。使用者必须评估出版商给出的证据, 以及所了解受试者的信息, 以及测试结果的用途。在评估相关信息时, 必须判断相关证据是否支持测试的用途。

这一指南中的一些问题还与标准的合理性及分数转换相关。读到这里, 或许可以再回顾一下第三章的相关内容。

## 1. 基本信息

① 测试的名称是什么?

② 测试的设计者有哪些人? 他们姓名及职位各是什么? (应当包括此类相关信息)

③ 测试由谁出版? 什么时候出版的?

④ 测试形式不止一种吗? 如果是, 有多少种?

⑤ 测试费用是多少?

⑥ 实施测试需要多长时间?

## 2. 关于测试的信息

① 有指导潜在使用者施行测试, 合理解读结果的测试指南吗? (或者其他包含类似信息的材料, 比如期刊中的文章。)

② 测试、指南以及标准最近有过修订吗? (对于大型商业化测试, 测试以及指南通常会至少每十年进行一次修订, 同时增加新的标准。)

## 3. 解析测试结果的辅助方法

① 指南中是否清楚说明测试的预期目的和应用?

② 指南中是否清楚说明正确实施测试及解读结果所需的资格要求?

③ 测试、指南、记录表格, 以及附带材料是否可以指导使用者对测试结果进行合理正确的解读?

④ 指南是否量化性地清楚说明了变量之间的关系, 所以读者得以知道其准确性大小? (比如,“测试与变量 \( \mathrm{X} \) 之间的相关系数为0.55”的表述比“测试与变量 \( \mathrm{X} \) 相关系数很大”更准确。)

## 4. 效度

① 测试指南是否对测试的效度提供了支持证据?

② 指南是否避免了引用测试题和测试总分之间的相关系数来作为支持效度的证据?

③ 如果测试设计是一些特定行为样本 (比如成绩测试), 指南中是否对行为类型进行了清楚定义, 并且说明了采样步骤?

④ 如果涉及效标效度, 指南中是否清楚描述了效标变量, 说明其合理性, 以及有哪些表现是这些效标不能测量的?

⑤ 在估算效标效度时, 是否充分描述了所用样本? 样本是否合理? 使用更为多样的样本可以产生高效度的假象, 是否避免了这样的小伎俩?

⑥ 对于效标效度的数据分析是否得以合理呈现, 让使用者可以判断对个人情况的推论准确性有多高?

⑦ 如果测试是为了测量理论构建 (比如某种能力、性格或态度), 是否清楚说明了建议的解读及其与其他理论解读的区别? 支持进行此种解读的证据是否清楚充分?

⑧ 是否提到可能影响测试分数有效使用的因素, 比如语言障碍、学习障碍, 以及一些需要注意的因素? 指南是否考虑到滥用测试结果可能带来的后果?

总之, 指南中推荐的应用方法以及你计划的应用是否得到现有证据的支持? 记住, 如果你打算将测试用于测试研发者未计划使用的方面, 那你就需要自己承担起证明测试用作此用途效度的责任。

## 5. 信度

① 指南中是否提供了充分的数据, 可以让读者判断测试分数对于推荐的用途是否可靠? (或用于读者自己设想的与推荐用途不同的用途?)

② 是否详细说明了计算信度数据时所用的样本情况, 好让使用者判断此数据是否适用自身情况? 和效度一样, 使用更加多样的样本可以造成信度虚高, 而实际使用时信度会降低。这种情况是否已避免?

③ 有关信度的数据, 是否通过皮尔森积矩相关系数及标准测量误差的统计方式进行了呈现? 不同表现水平是否提供了不同的标准误差?

④ 如果测试形式不止一种, 是否提供数据以便对比?

⑤ 如果测试是为了测量某种大致的同质特征, 是否提供了组成测试不同部分之间内部一致性的证据 (不同题目或者不同部分之间的相关系数)?

6 测试指南是否提供了数据, 说明测试表现随时间推移的稳定性?

总之, 指南中有关测试信度的数据在多大程度上支持制定者推荐的测试用途, 以及读者设想的测试结果用途?

## 6. 测试的实施与评分

① 关于测试实施的说明是否清楚充分, 使实施者可以复制制定标准和确立信度与效度数据的相关环境?

② 如果测试通过计算机进行, 或者需要计算机辅助, 是否具备所需的相关计算机程序? 是否具备相关技术支持?

③ 如果测试可以在当地进行评分, 评分的具体步骤是否具体清楚, 从而提高评分效率和减少评分中的误差? 关于各部分的评分标准是否清楚? 如果有评分程序, 有相关技术支持吗?

④ 如果测试可以通过出版商或者商业评分机构来评分, 评分机构是否能够累积测试结果, 以便协助制定符合当地情况的标准, 保证当地情况下的效度?

## 7. 量表和常模

① 用来呈现测试结果的量表表述是否清楚, 使解读结果的人可以完全理解并且向受试者说明?

② 指南中关于常模组的表述是否合理? 通常来说应该是标准分数或者合理参照组内的百分位排名。

③ 是否清楚定义并且描述了与常模对应的参照样本? 这些样本和受试者是否具有可比性?

④ 如果包括修订版在内, 测试形式不止一种, 是否提供了对不同形式的测试得分进行换算的表格?

⑤ 指南中是否提到地方常模的潜在价值? 是否可以帮助制定适合地方的标准?

⑥ 是否有计算机程序辅助解读测试和生成报告? 如果是, 那么该程序是否是互动式的? 其生成的报告是否基于测试结果给出建议而不是得出定论式的结果?

总之, 在选择测试时有很多需要考虑的因素, 没有一种因素能一以概之。作为测量方面的专业人士, 在使用特定测试达到特定目标时, 应该尽责任搜集相关证据。没有哪项测试是完美的, 选择测试时, 需要衡量每一项测试的优点, 考虑到相关代价和可能后果。只有你觉得益处肯定大于风险时, 才能决定使用这项测试。

## 6.3 了解具体的测试

2006 年, 公开出版并销售的以英语为试题语言的测试共 2846 项, 和 4 年前相比增加了 66 项。另外, 更多的测试已经绝版, 或者只在特定地方出版, 或者只是为了特定的研究项目。可以通过某种渠道来获得这些资源。仅仅一篇文章不足以列出所有你感兴趣的测试, 更别说介绍它们了。一些非常知名, 使用广泛的测试会在接下来的章节中进行介绍, 作为不同类型测试的范例。至于其他的, 在这章接下来的部分我们会尽可能提供一些方法, 可以帮助你找到你需要的测试及有用的信息。我们将你可226能有的疑问进行了分块, 按照可能的顺序进行介绍, 并尽力提供了一些有用的方法, 希望可以帮助你解答这些疑问。

## 1. 现存测试有哪些?

什么样的阅读理解测试适合四年级学生? 哪些职业兴趣测试适合高中高年级学生? 有哪些测量人们对待核能的态度的测试? 首先需要了解的是有哪些测试是存在的? 如果有一系列测试目录, 就可以开始进行选择了。如果没有什么令人满意的测试目录, 我们可以自行编。可以去哪里找到这样的测试目录呢?

第一个来源是《在印测试 VI 》(Murphy, Spies, & Blake, 2006)。这个目录 (又称 "TIP-W") 每 5 年修订一次, 对 2846 项商业出版商出版的现有测试按照字母进行排序, 并提供出版商信息和出版时间。还有 18 类按主题分类的索引, 帮助读者找到想找的类别。在《心理测量年鉴》(见下) 的某些版本中, 可以看到一些已经不再印发的测试, 并且有出版商的索引、测试名称缩写、作者姓名及分数标签列表。《在印测试》 是《心理测量年鉴》系列的副刊, 我们随后将进行介绍。《在印测试》包含《心理测量年鉴》中对应测试条目的参考文献, 以及更新的参考文献。每一版《测试在印》会对目录进行更新, 删掉不在印的测试条目跟新新的参考文献, 条目中包括测试名称、目的、适用人群、出版日期、缩写 (如果有的话)、提供的分数、实施方法 (个人或者群体)、价格、 时间、作者姓名、出版商, 以及《心理测量年鉴》的交叉索引。

除了《在印测试》, 还可以参考的两种资料是《心理、教育与商业测试评估索引大全》(下面简称《测试》) (Maddox,1997) 以及《行为测量技术词典》(下面简称《词典》) (Hersen & Bellack, 1988)。这两本资料中的内容分主题按字母排序, 与《在印测试》 相比, 每个条目包含了简短介绍, 以及出版商和价格信息。这些描述不是主观评判式的, 而是来自测试制定者以及出版商的说明。而《在印测试》中的信息比较粗糙, 没有列出测试制定者以及出版时间等信息。《在印测试》中有 2500 条现存测试的条目, 以及不在印测试及出版商的索引。《词典》中有 288 项临床量表和问卷, 且给出了信息来源的名称和出处。

《在印测试》、《词典》及《测试》对于寻找测试十分有用, 但是在如下两方面美中不足。它们没有有关最新测试的信息, 除了《词典》和 “TIP-VII” 中的一些条目, 它们都不含不在印测试条目 (未出版的测试是指不供出售的测试。在书中或者文章中全文介绍的倾向性测试在这里就是未出版测试,除非作者意欲对其进行销售)。

要找到最新出版的测试, 需要拿到测试出版商最新的出版目录。目录中会介绍出版商最近推行或者将要发行的测试及服务。很多出版商会偶尔发行一些测试, 但是很少有出版商会经常发行大批量的测试。在《在印测试 Ⅷ》中可以找到出版商的完整名单和地址, 通常还有电子邮件地址和网址。从你所在大学的测量机构或者当地学校的测试机构, 有时也可以找到最新的测试目录。如果没有这样的资源, 可以给相关出版商写信, 索求一份他们的最新目录。一些专业期刊如美国心理学协会的《美国心理学协会通讯》会附带测试出版商的广告。大多大型出版商还有网站介绍其发行物。如果你知道测试的名称但是没有找到相关信息, 可以使用谷歌搜索引擎搜索出版商网站,找到介绍测试信息的文章或者书籍。

要找到某地区制定的未出版测试或者只在研究中用到的测试十分困难。但是一些原始资料和指南比较有用, 最有用的可能是教育考试服务中心 (ETS) 编的测试合集《测试集缩微》。从 1975 年起, 教育考试服务中心开始发行未出版测试的索引及测试的缩微版复印件。2004 年这项服务终止时, 这系列合集收录了一万多份测试。很多大学订购了这份合集, 你所在的学校图书馆可能还有这些资料。但是, 订购有以下限制 (引自《合集》):

购买者可以复制本缩微集中的材料供自己使用。将材料用作其他用途时, 比如修改材料、进行销售或者传播, 则必须直接与原作者联系取得授权。(第 iii 页)

本书写作时, 内布拉斯加一林肯大学布鲁斯心理测量中心在其网站上提供了轻松访问 ETS 合集的链接, 其地址为: http://buros.unl.edu/buros/jsp/search.jsp, 使用谷歌搜索 “ETS 测试合集” (ETS Test Collection) 就能找到。教育考试服务中心网站上是这样介绍此合集的:

教育考试服务中心的测试合集收录了 25000 份测试及其他测量工具, 并为研究者、研究生和教师提供有关标准化测试以及研究工具的信息。此合集从 20 世纪初直到现在, 是世界上此类合集中规模最大的。

对于寻找与未出版测试相关信息的人, 这是一个非常宝贵的资料来源。

不少其他资料 (现在来看年代有些久远) 也收录了未出版测试的一些信息。《未出版实验心理测量名录》(Goldman & Busch, 1978, 1982; Goldman & Mitchell, 1990; Goldman & Osborne, 1985; Goldman & Sanders, 1974) 中收录了相关 3000 多条目,而《儿童发展测量手册 II 》(Johnson,1976) 以及《儿童发展测量手册》(Johnson & Bommarito, 1971) 则包含了其他适用于青少年的测试资料。《教育与社会科学测量手册》(Lester & Bishop, 1997) 中列出了主要与教育有关的 80 类使用较少的测试。

还有一些其他资料涵盖倾向性测试并且引用了实际使用的记分量表 (Robinson, Athanasion, & Head, 1969; Robinson, Rusk, & Head, 1968; Robinson & Shaver, 1973; Shaw & Wright, 1967)。最近, 奥布莱恩 (O'Brien, 1988) 出版了一份书目, 涵盖了一些有关测试的参考条目, 教育考试服务中心也出版了六卷本的《测试合集目录》, 其中包括: ① 学业测试, ② 职业测试, ③ 特殊人群测试, ④认知、倾向和智力测试, ⑤ 态度测试和 ⑥ 情感测试和人格测试。除了上述资料, 在本章结尾列出的《测试信息资源》列表中也包括某些领域的一些参考资料。

三卷本的《家庭测量技术》是比较新的资料, 介绍了家庭治疗与研究领域中使用的各种测试。第一卷 (Touliatos, Perlmutter, & Straus, 2001) 和第二卷 (Touliatos, Perlmutter, & Holden, 2001) 收录了使用 168 项测试的研究报告摘要。第三卷 (Perlmutter, Touliatos, & Holden, 2001) 收录了测试的副本、评分指南, 以及首次介绍测试时的原始文章。如果你需要在家庭治疗中使用到测试, 这些资料会非常有用。

《全国测试项目选日》(教育考试服务中心测试集, 1987)。该三卷本系列涵盖了很多全国性测试的名称、出版商、出版社、出处以及总体介绍等信息。第一卷涵盖部分中学、政府部门、研究机构、专业机构以及医学机构招生时所用测试。第二卷包括学分测试和预修项目测试, 第三卷包含专业认证和资格考试。这一系列中的测试通常是不公示的。

## 2. \( X \) 测试到底是什么样的?

当你找到了打算考虑的阅读测试、兴趣量表或测试 (比如叫作 \( \mathrm{X} \) 测试),想要了解更多。这时应该去哪里了解呢?

有关这项测试的部分信息可以在《心理测量年鉴》中列出的测试和评估中找到。 但是最重要的是审阅测试本身。所以, 如果可以的话拿到测试的复印本好好看一看。 一般可以在大学的图书馆、咨询中心或者放置出版测试的测量文件区拿到一套测试样本, 通常包括测试复印本、答题纸和测试指南。或者学校的测试部门也许可以提供这样的资料。也可通过查阅《学术、专业和研究型图书馆测试合集》(Fehrmann & O'Brien, 2001) 找到测试复印本。这本书中列出了 77 家可供外部专业人士使用其设施的图书馆, 收藏有至少一百种测试。如果通过这些方法也找不到, 也许你可以从出版商那里预订一份样本, 目录中会标明价格。

有些出版商可能会要求出示身份证明以确定你有资格查看这些测试材料。学校教师或者公司上级的介绍信应该就足够了。但是, 有些测试, 比如人格测试量表和个人认知能力测试, 需要有专门训练和技能, 则会有进一步的限制, 也许会需要填表确认你是否有资格。有些少数情况下, 可能还需要有专业资格的人为你订购测试并进行监督。

本章结束部分所附的列表中提到的一些手册中收录了很多未出版测试的完整副本, 尤其是《微缩测试集》。一些其他测试, 还有完整的文章对其制定过程和使用进行了详细介绍。如果这些资料中找不到你想看的未出版测试, 你可以试着从作者那里要一份。

当你有了测试或者量表的复印件时, 你要从中获取哪些信息呢? 答案在于测试的类型。如果是学校的学业测试, 你应该审阅测试中的题目, 确认测试涵盖的内容是否与教学目标, 或者学校和地区的教学大纲相符。不管是哪种测试, 都要确认测试中的题目表述是否清楚, 是否有正确的选项, 说明是否清楚, 以及页面排版是否整洁清晰。如果是未出版的测试, 测试材料的质量就在于你自己了, 因为在取得授权后可能得自己印制新的副本。

除了测试本身, 同等重要的是那些附带材料, 它们要说明心理测量的特点, 测试结果的报告形式, 以及如何辅助测试的使用和解读。如果测试由商业出版商出版, 那么这些信息应包括在给测试实施者或监考者的测试指南中, 技术指南中应该提供关于此心理测量特征的详细细节。你应该仔细查看这些指南。

对于未出版的测试, 可以在使用这些测试的相关研究文章和报告中找到相关技术材料。这类信息的质量和商业出版测试指南中的信息相比, 质量可能要差一些。 对于比较新还未广泛使用的测试, 通常需要与作者进行联系。可能会经常遇到只在某项研究中使用的测试, 其效度和信度的来源只有一项研究。有时候, 甚至没有可验证测试质量的证据, 这样的测试只可以用作研究, 并且需要谨慎使用。

大多数商业出版测试会提供附带的评分和报告服务。有些只是批改答题纸答案, 计算得分和百分比或者标准分数, 有些还可以对每个人的测试结果进行解读。在第三章中有这样的例子。测试样本应该对可提供的报告进行说明或者提供示例, 这样就可以判断这些服务是否符合你的需求。

要格外仔细审阅关于测试信度和效度的证据。测试样本主要是用作宣传的, 出版商可能会有些夸大, 所以不要被天花乱坠的辞藻蒙蔽, 专注基本证据, 如果证据不充分或者措辞模糊, 要谨慎起来。第四章、第五章及本章提到的测试评估部分介绍了需要关注的证据。

## 3. 评审们如何评价 \( X \) 测试?

测试出版商提供的材料关注怎么推销测试 (有些非常明显, 有些则隐晦一些), 所以最好了解一下胜任而无相关利益的评审有什么意见。首先要推荐的是《心理测量年鉴》系列, 这一系列由已逝的奥斯卡 - 布鲁斯先生于 1936 年发起, 直到 1978 年由他出版。随后的几卷由内布拉斯加大学布鲁斯心理测量中心负责。在写作本书时, 《心理测量年鉴第 17 卷》(Geisinger, Spies, Carlson, & Plake, 2007) 已经出版, 《心理测量年鉴第 18 卷》也即将出版。《心理测量年鉴》中每项重要的出版测试都有专业的无利益相关人士撰写评论。在最新版的《心理测量年鉴》中, 出版者为每项新测试附加了至少两份独立评论 (见桑代克,1999b,内有对《心理测量年鉴第 12 卷》的详细介绍和分析及一些注意事项)。

这一系列年鉴的内容是累加的, 如果某项测试在刚推出时进行了审核评论, 通常不会进行再次审核评论, 除非测试或者相关材料有了较大的改动, 或者测试意外地得到了广泛应用。《在印测试 Ⅷ》有一份索引, 列出了前十六卷《心理测量年鉴》中对仍然在印测试的评论所在卷数和页码。

1988 年, 布鲁斯心理测量中心开始了编写《心理测量年鉴》的新日程, 出版了《心理测量年鉴第 9 卷增刊 (Conoley, Kramer, & Mitchell, 1998), 增加了白 1985 年以来出版的 89 项新测试。《心理测量年鉴第 10 卷》出版于 1989 年, 其增刊于 1990 年出版。布鲁斯中心的工作人员宣布会在随后隔一年发行完整的卷本, 并在两年中间发行增刊。但《心理测量年鉴第 11 卷》在 1992 年才出版, 1994 年增刊出版。《心理测量年鉴第 12 卷》于 1995 年出版; 《心理测量年鉴第 13 卷》于 1998 年出版, 此卷的增刊于 1999 年出版; 《心理测量年鉴第 14 卷》于 2001 年出版; 《心理测量年鉴第 15 卷》 出版于 2003 年, 而《心理测量年鉴第 16 卷》在 2005 年出版, 看来布鲁斯中心的目标达成了。从《心理测量年鉴第 11 卷》起, 年鉴有了光盘版。这种形式的优点是可以进行自动搜索, 但是这样就不能迅速回看对几种感兴趣的测试进行直接比较, 除非读者将自己感兴趣的评论打印出来。最近, 网上测试评估取代了两年一期的《心理测量年鉴增刊》, 布鲁斯中心在完成对新测试的评估和编辑之后会立即在网络上发布。

布鲁斯中心还有一个网站, 地址为: http://www.unl.edu/buros/。这个网站链接到其他测试相关网站, 包括教育资源信息中心测试与评估系统 (ERIC/AE) 的测试搜索网站和美国心理学协会官网。此网站还可以搜索《心理测量年鉴》和《测试》中已发表的测试评论文章。1985 年 (《心理测量年鉴第 9 卷》) 之后的所有测试评论按照 19 类主题进行分类, 分类的索引包含所有条目。这个网站上没有评论的副本, 但是你可以知道是否有对某项测试的评论, 然后可以去购买或者找到评论。

每卷《心理测量年鉴》及其增刊都包含了各种测试。在大学图书馆、大型公共图书馆和很多学校的测试部门的咨询台应该可以找到《心理测量年鉴》及《在印测试》。 布鲁斯中心的网站上有链接可以访问银盘公司的数据库, 付费后可获得评论的复印件, 或者可以直接从布鲁斯中心付费订购每份评论的传真复印件。《心理测量年鉴》 是获取测试评论最重要的资料来源, 其中还有关于测试的书评和专评、出版商列表, 每项测试出版资料几乎都含有完整的参考文献。

另一个资料来源是十卷本的《测试批评》(Keyser & Sweetland, 1984)。每卷收录了对几百项测试的评论, 通常比年鉴系列的评论更长更细致, 但是缺少不同观点。 后八卷中有前面所有内容的主题索引, 但在每一个单卷本中, 测试是按标题字母排序的, 没有按主题分类。要找一项具体的测试可能会比较难。但是, 访问网址 http:// infotree. library. ohiou. edu/single-records/2535. html, 可以进行搜索。

在《教育测试批评集》(Levy & Goldstein, 1984) 中可以找到对某些美国测试及很多在英国出版测试的评论。这些测试分为六大类: 早期发展、语言、数学、成套学业考试、基础能力、性格以及咨询。

在一些类似《心理教育评估杂志》的心理学和教育学期刊中有时可以找到一些新的或者重要的测试及书评。但是通常只是间隔出现, 而且只有一位评论人的观点。 现在还没有一份对新出版测试进行定期系统评论的期刊。现在最好的评论资料就是 《心理测试年鉴》及其增刊, 而且还会定期有纸质版和数据库的更新。

哈米尔、布朗和布莱恩特 (Hammill, Brown, and Bryant, 1992) 在《在印测试用户指南》中提供了另一种测试评估途径。这一卷中收录了一些在版测试在七个技术维度上的质量评分, 以及对其非技术方面的评价, 还有综合质量评分。如同韦氏智力量表和斯坦福-比奈智力量表一样, 不同部分有不同评分量表, 格式如下: A. 强烈推荐; B. 推荐; F. 不推荐。这种表格形式很紧凑, 但是按功能进行评分导致各部分的评分是分开的, 所以得多翻看几页内容才能知道某项测试的大致情况。而且这份材料已经比较过时了。

一些大学图书馆也有可以用来搜索感兴趣测试的网站。有个网站涵盖了我们提到过的一些资料, 可以直接访问位于加利福尼亚州立大学萨克拉门托分校图书馆的有用数据库, 网址是: http://library.csus.edu/guides/rogenmoserd/educ/ttests.htm。

## 4. 前人对 \( \mathrm{X} \) 测试做过哪些研究?

对于这项测试的信度进行过哪些研究? 对其作为 \( \mathrm{Z} \) 的预测考试的效度进行过哪些研究? 一对一培训会对测试分数带来什么影响? 和 \( \mathrm{Y} \) 有什么联系?

大多数商业出版测试, 在测试的技术指南中可以找到一些材料。不同的指南会提供不同量的数据和研究信息,一些比较好的指南会像一本书, 对测试的信度与其他测试的相关性, 在学术或工作标准方面的预测信度等各种方面进行说明。指南通常还会包括参考书目, 引用相关研究。但是, 很多广泛使用的测试指南并没有提供全部信息。在其 95 年的历史里, 有 1 万多项研究用到了斯坦福一比奈智力量表, 而明尼苏达多项人格问卷和韦氏智力量表虽然只有 70 年历史, 但其涉及的研究更多。指南中很难收录最新的研究, 而当出版商对指南进行修订时, 通常测试本身也需要修订, 所以即使是最好的商业测试指南也只有五到十年的寿命。

前面已经提到, 在《心理测量年鉴》和《在印测试》中有关于出版测试的详细参考书目。和测试评论类似, 这些参考资料只包括最新版的出版文章和书目。但是对于一些使用广泛的测试, 参考书目会很长, 有几百个条目, 但是你可以迅速浏览标题, 也许可以找到自己感兴趣的。

另一种查找有关测试研究的方式是查找月刊或者年刊的索引和摘要。可能最有用的几本资料是《国际论文摘要》、《教育学索引》和《心理学摘要》。另一种资料是《教育学论文中使用的测试索引》(Fabiano,1989)。从 1980 年开始,《国际论文摘要》就有了在线搜索服务, 最近内容进行了扩充, 包括自 1861 年以来的美国论文! 这份资料对 5 万多份测试按照其名称进行字母分类。每项测试的条目中包括测试对象、摘要的卷数和页码及作者姓名。

其他有关测试的综合性数据库有学位论文数据库 (ProQuest Education) 及社会科学期刊数据库, 教育资源信息中心测试与评估系统 (ERIC/AE), 以及心理学研究数据库 (PsychInfo)。ERIC/AE 包含教育及相关领域的文献信息, 通常是未出版或者比较少见的资料, 而心理学研究数据库则包含 《心理学摘要》中的大部分电子版材料, 还有如何获取复印件的指示。学位论文数据库则可以直接获取文本格式或者便携式电子文档 (pdf) 格式的全文。很多图书馆都有相关服务。教育资源信息中心测试与评估系统和心理学研究数据库数据库中每篇文章都有完整引用, 有研究的关键词和摘要。这些数据库有一个优点, 就是可以用关键词或词组搜索每个条目的完整内容。如果搜索某测试的名称, 可以看到一系列包含此名称的所有条目, 包括题目、 摘要或者关键词。也可以搜索作者姓名或科目主题, 绝对值得花上半个小时来熟悉这些用途。

最后就是日益丰富的互联网了。很难说将来的一两年会怎么样, 但是将来肯定可以搜索所有的网页、数据库, 以及教育资源信息中心测试与评估系统、美国心理协会、布鲁斯中心以及大多数大型图书馆的资料。大多数心理学和教育学期刊都有网页版, 专业测试中心也是。专业机构的期刊和通讯中会经常刊登相关网页地址。谷歌搜索尤其有用, 只是搜索结果太多, 如果搜索内容不够具体或者目标网站并不太知名, 从中找到有用信息会比较耗时 (搜索 “教育信息中心测试合集” 有 110 万条结果, 但是想找的网站就在最前面)。

在使用数据库时, 有效的搜索在于使用合适的关键词, 引导搜索引擎找到相关条日。有时, 数据库的搭建者会提供计算机可识别的术语词汇表。而如何从词汇表中选择合适的词找到相关条目则要靠用户自己了。虽然测试的题目不太可能会出现在关键词和摘要中, 但可以通过测试的大致测量目标来找到相关文献。

通常来说, 如果想搜索某个数据库, 最好浏览学校或者公共图书馆的分类索引。 图书馆可能有一个计算机终端直接访问需要的数据资源。如果没有, 相关图书馆员也许可以帮忙访问。搜索也许需要付费, 所以在使用搜索服务之前最好估算一下价格。而谷歌则可以供所有有网络连接的人免费使用, 也许将来会代替那些数据库。

## 6.4 总 结

测试不仅需要得出有用有效度的信息, 还得有实用性。测试费用、实施和评分的难易度, 依据测试分数进行合理推论的难易度, 包括是否可以进行常模参照和标准参照解读等问题都是实用性问题。

在评估测试时, 需要考虑到所有影响测试质量的因素。测试指南及其他资料应当说明测试的目的、信度和效度, 标准规范以及测试应该如何实施和评分。在考虑使用哪些测试时, 还得了解有关分数解读的信息。

在《在印测试 ¶》、《测试》及《行为评估技术词典》等出版资料中可以找到关于具体测试的信息。在《缩微测试集》和《未出版实验心理测量》等资料中可以找到未出版测试的复印本。在几个版本的《心理测量年鉴》以及多卷本《测试批评集》, 还有各种专业期刊和通讯中可以找到有关测试的评论。

## 6.5 习 题

1. 使用文中列出的资源, 准备一份目的明确的现有标准测试的较完整清单 (比如一年级法语课测试, 阅读测试, 大学生活适应程度问卷)。

2. 针对你感兴趣的一些特性 (比如自我认识、对污染问题的态度、创新性), 通过文中提到的文献和参考书目, 找到现有可用的研究测试。

3. 你对哪项测试感兴趣? 查阅《心理测量年鉴》, 评论者是如何评价该测试的? 评论者之间有不同意见吗?

4. 回答下列问题需要查找哪些资料? 哪些资料先找? 每份材料会有什么样的有用信息?

a. 要了解两个初级西班牙语课程班级的进度, 应该使用哪种测试?

b. 都市学业考试 (the Metropolitan Achievement Tests) 有哪些现有规范标准?

c. 罗夏墨迹测试 (the Rorchach Tests) 对预测大学学业成功与否有价值吗?

d. 最新版儿童韦氏智力量表是什么?

e. 有哪些已出版的盲人语言能力测试?

f. 爱荷华州基本能力测试和都市学业考试有哪些显著不同点?

g. 认知能力测试的费用是多少?

h. 测试人员如何看待职业偏好性体系?

5. 查阅两到三家出版商的出版目录。对比对同类型测试的介绍。其提供的信息是否充足? 在介绍测试的价值和局限时是否客观?

## 测试信息参考资料

## 通用资料

Buros, O. K. (Ed.). (1978). The eighth mental measurements yearbook. Highland Park, NJ: The Gryphon Press. (This volume is now handled by the Buros Institute of Mental Measurementsat the University of Nebraska, Lincoln, NE.)

Conoley, J. C., & Impara, J. C. ( Eds.). (1994). Supplement to the eleventh mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Conoley, J. C., & Impara, J. C. (Eds.). (1995). The twelfth mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Conoley, J. C., & Kramer, J. J. (Eds.). (1989). The tenth mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Conoley, J. C., Kramer, J. J., & Mitchell, J. V., Jr. (Eds.). (1988). Supplement to the ninth mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Fabiano, E. (1989). Index to tests used in educational dissertations. Phoenix, AZ: Oryx Press.

Fehrmann, P. G., & O' Brien, N. P. (2001). Directory of test collections in academic, professional, and research libraries. Chicago: Association of College and Research Libraries.

Geisinger, K. F., Spies, R. A., Carlson, J. F., & Plake, B. S. (2007). The seventeenth mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Goldman, B. A., & Busch, J. C. (1978). Directory of unpublished experimental mental

measures: Vol. 2. New York: Human Sciences Press.

Goldman, B. A., & Busch, J. C. (1982). Directory of unpublished experimental mental measures: Vol. 3. New York: Human Sciences Press.

Goldman, B. A., & Mitchell, D. F. (1990). Directory of unpublished experimental mental measures: Vol. 5. Dubuque, IA: Wm. C. Brown.

Goldman, B. A., & Osborne, W. L. (1985). Directory of unpublished experimental mental measures: Vol. 4. New York: Human Sciences Press.

Goldman, B. A., & Sanders, J. L. (1974). Directory of unpublished experimental mental measures: Vol. 1. New York: Bchavioral Publications.

Hammill, D. D., Brown, L., 8. Bryant, B. R. (1992). A consumer's guide to tests in print (2nd ed.). Austin, TX: PRO-ED.

Hepner, J. C. (1988). ETS test collection cumulative index to tests in microfiche, 1975-1987. Princeton, NJ: Educational Testing Service.

Hersen, M., & Bellack, A. S. (Eds.). (1988). Dictionary of behavioral assessment techniques. New York: Pergamon.

Impara, J. C., & Plake, B. S. (1998). The thirteenth mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Johnson, O. G. (1976). Tests and measurements in child development: Handbook II. San Francisco: Jossey-Bass.

Johnson, O. G., & Bommarito, J. W. (1971). Tests and measurements in child development: A handbook. San Francisco: Jossey-Bass.

Keyser, D. J., 8. Sweetland, R. C. (1984). Test critiques. Kansas City, MO: Test Corporation of America.

Kramer, J. J., & Conoley, J. C. (Eds.). (1992). The eleventh mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Krug, S. E. (Ed.). (1988). Psychware sourcebook (3rd ed.). Kansas City, MO: Test Corporation of America.

Lake, D. G., Miles, M. B., & Earle, R. B. (1973). Measuring human behavior: Tools for the assessment of social functioning. New York: Teachers College Press.

Lester, P. A., & Bishop, L. K. (1997). Handbook of tests and measurement in education and the social sciences. Lancaster, PA: Technomic.

Levy, P., & Goldstein, H. (1984). Tests in education: A book of critical reviews. London: Academic Press.

Mauser, A. J. (1977). Assessing the learning disabled: Selected instruments (2nd ed.). Novato, CA: Academic Therapy Publications.

Miller, D. C. (1983). Handbook of research design and social measurements (4th ed.). New York: Longman.

Mitchell, J. V., Jr. (Ed.). (1985). The ninth mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Murphy, L. L., Plake, B. S., Impara, J. C., & Spies, R. A. (2002). Tests in print (6th ed.). Lincoln, NE: Buros Institute of Mental Measurements.

Murphy, L. L., Spies, R. A., & Plake, B. S. (2006). Tests in print (7th ed.). Lincoln, NE: 236

Buros Institute of Mental Measurements.

(   )' Brien, N. P. (1988). Test construction: A bibliography of selected resources. New York: Greenwood.

Perlmutter, B. F., Touliatos, J., & Holden, G. W. (Eds.). (2001). Handbook of family measurement techniques, Vol. 3: Instruments & index. Thousand Oaks, CA: Sage.

Plakc, B. S., & Impara, J. C. (1999). Supplement to the thirteenth mental measurement. yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Plake, B. S., & Impara, J. C. (2001). The fourteenth mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Plake, B. S., Impara, J. C., & Spies, R. A. (2003). The fifteenth mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Robinson, J. P., Athanasion, R., 8. Head, K. B. (1969). Measures of occupational attitudes and occupational characteristics. Ann Arbor: University of Michigan.

Robinson, J. P., Rusk, J. G., & Head, K. B. (1968). Measures of political attitudes. Ann Arbor: University of Michigan.

Robinson, J. P., & Shaver, P. R. (1973). Measures of social psychological attitudes ( rev. ed.). Ann Arbor: University of Michigan.

Shaw, M. E., & Wright, J. W. (1967). Scales for the measurement of attitudes. New York: McGraw-Hill.

Spies, R. A., & Plake, B. S. (2005). The sixteenth mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Sweetland, R. C., & Keyser, D. J. (Eds.). (1986). Tests: A comprehensive reference for assessments in psychology, education and business (2nd ed.). Kansas City, MO: Test Corporation of America.

Touliatos, J., Perlmutter, B. F., & Holden, G. W. (Eds.). (2001). Handbook of family measurement techniques: Vol. 2, Abstracts. Thousand Oaks, CA: Sage.

Touliatos, J., Perlmutter, B. F., & Straus, M. A. (Eds.). (2001). Handbook of family measurement techniques, Vol. 1: Abstracts. Thousand Oaks, CA: Sage.

教育考试服务中心的出版物及资料集。有关测试集数据库, 《缩微测试集》及其注释索引, 测试集参考书目, 请访问 ERIC/AE 网站, 网址为: http://www.ericae.net.

## 其他与测试集相关的出版物

Educational Testing Service Test Collection. (1986). The ETS test collection catalog (6 vols.). Phoenix, AZ: Oryx Press.

Educational Testing Service Test Collection. (1987). Directory of selected national testing programs. Phoenix, AZ: Oryx Press.

## 特定主题领域参考资料

Becre, C. A. (1990). Gender roles: A handbook of tests and measures. Westport, CT: Greenwood.

Beere, C. A. (1990). Sex and gender issues: A handbook of tests and measures. Westport, CT: Greenwood.

Braswell, J. S. (compiler). (1981). Mathematics tests available in the United States and Canada. Reston, VA: National Council of Teachers of Mathematics.

Grommon, A. H. (Ed.). (1976). Reviews of selected published tests in English. Urbana, IL: National Council of Teachers of English.

Johnson, T. F., & Hess, R. J. (1970). Tests in the arts. St. Ann, MO: Central Midwestern Regional Education Laboratory.

Mangen, D. J., & Peterson, W. A. (Eds.). (1982). Research instruments in social gerontology. Minneapolis, MN: University of Minnesota Press.

Northwest Regional Educational Laboratory, Center for Bilingual Education. (1978). Assessment instruments in bilingual education: A descriptive catalog of 342 oral and written tests. Los Angeles: National Dissemination and Assessment Center.

Ostrow, A. C. (1990). Directory of psychological tests in the sport and exercise sciences. Morgantown, WV: Fitness Information Technology.

Savard, J. -G. (1969). Analytical bibliography of language tests. Quebec: International Center for Research on Bilingualism.

Scholl, G., & Schnur, R. (1976). Measures of psychological, vocational and educational functioning in the blind and visually handicapped. New York: American Foundation for the Blind.

Valette, R. M. (1977). Modern language testing (2nd ed.). New York: Harcourt Brace Jovanovich.

Wall, J. (1981). Compendium of standardized science tests. Washington, DC: National Science Teachers Association.

## 第2部分 测试的应用

## 第7章 教育决策与评估

## 7.1 引 言

现在你可能已经意识到本书的一大主题就是测量与决策之间的关系。在教育领域, 教学者、学生和家长需要做出一系列决定, 这些决定会对学生的教育体验产生影响。以教师为例, 他们必须要决定如何评估学生的学习进展, 同时还要考虑如何制定符合学生个体要求的课程标准。随着教育程度的提升, 学生也要为自己的将来做决定, 包括课程选择和职业规划。家长需要和自己的孩子还有孩子所在学校进行合作, 同时也会做出一些决定, 影响到学生的教育规划。最后, 政府机构会根据测试数据来做出决策, 不仅影响到每个学生的升学和资格证书取得, 还会影响到学校、教师和相关人员帮助学生达到学业成就标准的效率。

要做出正确的决定, 每个决策者都需要信息, 具体来说, 决策者必须知道需要什么样的信息来理解和分析问题, 去哪里获取信息, 如何评估信息, 以及如何有效使用这些信息来进行决策。很多情况下可以通过教育测试和测量获取一些信息。

## 7.2 价值观与决策

决策过程涉及价值观。在教育方面, 在做某项决定时, 决策者必须确定什么样的信息是相关的, 什么样的教学目标最为重要, 还有要达成这些目标有哪些可行可靠的方法。通常来说, 并没有一个完全客观的答案, 这些是价值观问题。个人价值观和社会价值观都很难量化。虽然理论上可以通过测量来衡量某人对某一价值观的认同程度, 但是并没有测量程序可以告诉我们个人、学校或机构应当有怎样的价值观, 在进行某项决策时什么样的价值观是最为重要的。在一个社区中, 各类人会有不同的价值观, 什么样的价值观应当优先, 个人和机构中通常会有很多不同意见。决策中有关测试和评估使用的争议, 尤其是涉及人员筛选和人事变动问题时, 主要是因为价值观的不同。有些价值观已经被写入美国各州法令和联邦法令中。比如, 1965 年的《初等与中等教育法案》(ESEA) 和 1975 年的《残障儿童教育法》(AHCA) 都是为了确保低收入和残疾学生享受免费合理的公立教育权, 其价值观是贫困儿童和残障儿童与其他富裕家庭的健全儿童应当享受同等的教育权。在有些情况下, 需要通过州法院或者联邦法院来解决价值观上的冲突, 法院会做出判决来推行教育领域的社会目标。 还有一些情况下, 州立巡回机构、当地教育委员会和学校人员会就决策采用什么样的价值观达成一致。但是在大多数情况下, 总是会有价值观的冲突。

## 7.3 《有教无类法案》

2002 年 1 月 8 日, 乔治 - W. 布什总统签署《有教无类法案》, 使其上升为法律。 该法案是一项复杂的综合性教育法案, 包括十个部分, 体现了联邦政府对公共教育前所未有的干预。虽然宪法规定公共教育权在于州政府, 但是很多联邦法都试图对公共教育进行某些程度的控制。这一法案建立在以往联邦立法的基础之上, 最主要的是 1965 年出台 1994 年重新实施的《初等与中等教育法案》, 以及《提升美国学校法案》(IASA)。《初等与中等教育法案》的第一条款, 可以说是最为著名和最有影响的部分, 规定筹集联邦资金用于帮助各州为贫困儿童增加教育机会。《提升美国学习法案》则扩大了第一条款中联邦对学校的资助范围, 专门划分资源用于地区教育改革。 《有教无类法案》中的很多规定在《提升美国学习法案》中就已提到。和之前的法令相比, 最大的变化就是它提高了测试与报告的要求, 对学生达不到学业测试标准的学校和校区实施处罚,并且要求学校关注教师的质量。

## 1. 《有教无类法案》总览

《有教无类法案》的主要目标是“确保公立学校的每一个学生能在安全的教室里接受合格教师的教学, 达成重要的学习目标。” (Yell & Drasgow, 2005, 第 8 页)。为了达到这一目标, 该法案制定了一系列宏伟目标。批评该法及其实施的一些人认为这些目标都不现实, 不过读者可以自行判断。该法案的主要目标如下:

- 到 2014 年, 所有公立学校学生在阅读和数学上达到符合严格学术标准的高水平能力。有望在 2008 年或 2009 年重新实施该法案时, 国会会考虑到将科学科目的 \( {100}\% \) 掌握程度纳入其中。这意味着熟练程度的普遍化,是指所有的学生, 包括残障学生以及刚到美国英语还不熟练的新移民。

- 到 2005-2006 学年, 每一个公立学校的教室里会有高水平的教师 (拥有学士学位, 取得其任教领域的完全资质, 在测试中表现出对所教科目的掌握能

力)。(注: 在本书英文版刊印时, 离该目标还很远。)

- 所有学生能在学习氛围浓厚的安全环境中学习。

- 所有英语能力不足的学生能熟练掌握英语。

- 所有学生从高中毕业。

这些目标及其所限定时间对于各州、各区和学校都是很大的挑战。迄今为止, 只有前两个目标受到了较大的关注。为了协助和激励当地教育者和官员达到这些目标,2002 年国会增加了 \( {25}\% \) 的联邦资助。然而评论者认为这项资金投入远低于法案中的要求, 虽然有一些帮助, 但是远不足以支持各州达成目标所需的资金花费。

这项法案中的每一部分都体现了四大主题或原则: (a) 当地问责制, (b) 教学方法以研究为依托, (c) 当地对联邦资金的使用有更多掌控和弹性 (d) 家长选择。第一个主题即在提升学生成就及表现差学校的基本运转方面的问责制度, 与测试最直接相关。各州需要针对语言阅读能力、数学和科学等学科内容制定标准, 并进行测试评估学生的水平。每年需要汇报成绩, 所以教育相关人员 (比如家长、教师、政策制定者和公众) 可以了解学校在学生教学方面的效果。另外, 考试数据在汇报时必须分块, 就是所有数据要分为一个个部分, 以便对每部分数据进行分析。这样的话, 就可以了解不同族裔学生的表现, 分别对残障学生、贫困学生、英语不熟练学生的成绩进行分析。 这样的要求是为了对学校提升所有学生学业成绩的情况进行问责, 而不只是局限于健全学生、中产白人和以英语为母语的学生。

除了进行当地问责, 该法案还要求学校实施经过严格科学研究证实有效的课程和教学标准。前教育部长罗德・佩奇 (Rod Paige) 曾说学生的表现差, 部分原因是老师会使用一些“自己感觉良好”的方式, 而不是 “真正有效” 的方法。为了推行使用有研究依据的教学方式, 法案规定联邦基金只能用于有严格科学证据的项目。不幸的是, 在教育方面, 这样的研究还不够, 所以这部分法令的执行比较困难。

法案的第三个指导原则是允许州政府和学校有使用联邦教育资金的弹性。通常,学校有大约 \( {10}\% \) 的资金来自于联邦资金,这些钱必须按规定用于特定学生人群。 比如, 第一条款资金用于低收入学生, 但是当地可以决定怎么用, 用来干什么。让州和地方官员决定如何使用联邦资金是因为当地政府对当地的学生和学校情况有更好的了解。最后, 该法案规定, 如果学生在一个长期表现差的学校就学, 家长可以就提升孩子的教育进行选择。依据所在学校表现差的时间长度, 家长可以选择让孩子转学到一个更好的学校, 或者使用附加教育资源, 比如请家教, 相关费用由当地承担。 如果学校有流失学生的危险, 表现差的学校就有了提升的动力。

## 2. 标准和评估

如上所述, 《有教无类法案》的一大主要原则就是要对当地进行问责。据法案规定, 各州需要向美国教育部提交责任计划, 这样才能拿到联邦教育基金。每个州需要制定自己在语言阅读能力、数学和科学等科目的学习内容和成绩标准, 并且实施评估项目来测量学生在这些核心学业方面的成绩水平。该法案同时鼓励各州在其他课程内容如社会科学与艺术等方面制定标准, 但不强制。

各州制定的学业成绩标准必须清楚描述学生在高中毕业之后应该知道哪些知识, 有哪些能力。另外, 各州必须制定至少三个成绩水平来衡量学生的掌握程度。至少有一个高级水平或是 “超出预期水平”, 一个熟练水平或是 “达到预期水平”, 还有一个基本水平或是 “接近预期水平”。法案规定各州标准必须连贯严谨, 鼓励更高水平的教学。然而, 法案没有对学生实际表现做出清楚定义。因此, 各州在制定标准、划分水平和进行评估时通常有很大的自主空间。所以, 各州对学生的预期要求并不一致。

标准实施后, 各州则着手制定与标准对应的测试以评估学生的成绩水平, 追踪学生的学习进度。法案要求各州测试必须可信、有效且尽可能适用于所有学生。各州会规定分数线, 区分从基本到熟练等不同成绩水平。学生的得分必须达到或者超出这些分数线才算“通过”考试。很多州会和专业的测试研发公司协作进行测试制定。 要求所有公立学校的测试项目必须对全体学生中 \( {95}\% \) 以上的学生进行测试,测试还要涵盖每一个上述表现较差的特定学生群体的 \( {95}\% \) 。残障学生或者英语能力有限的学生需要参加所在年级的州立考试, 但是可以适当调整。可调整程度由各州决定, 但是可以包括考试流程调整, 比如延长考试时间、考试期间休息, 或者单独考试。因为严重障碍而受特殊教育的学生, 可以参加其他替代考试来提升测试与学生的预期目标之间的适切性。同样, 英语能力比较差的学生可以使用母语参加考试, 直到接受连续三年的教育, 这时候语言理解能力考试必须使用英语。我们会在第八章中详细介绍针对特殊需求学生的测试。

各州必须在三年级到八年级之间每年对所有学生进行一次阅读和数学测试, 从十年级到十二年级之间进行一次测试。科学学科测试在这些年级段也是必须的, 但不要求每年都测。按照这些要求, 公立学校需要进行大量的测试。每年春天, 公立学校三年级到八年级的学生都会参加一些标准测试。在此期间, 学生、老师、教务管理者和家长们都专注于考试, 教学和课外活动会暂停。

## 3. 问责制

《有教无类法案》最具争议性的方面之一就是问责制了。该法案的首要目标是到 2014 年在阅读和数学科目上达到 \( {100}\% \) 的熟练掌握程度。要达到这一目标,各州必须确保所有学生按照其所制定的学业标准不断进步, 对当地学校和校区按照学生的长期成绩进步报告进行问责。要求向家长和学校汇报学生的个人成绩, 向联邦政府汇报各部分分组数据, 向公众公布年度报告。每个州必须为所有学生制定年度成绩目标。如果达到了这些目标, 则说明取得了应达年度进步 (AYP) 就达到了。

应达年度进步基于所有学生从 2001-2002 年开始的基础水平到 12 年以后的 \( {100}\% \) 熟练掌握水平之间的进步情况。在州级考试中达到熟练水平或以上的学生比例为基准线。每年学校应该让更多学生达到熟练水平, 比例应定期增长, 以确保在 2013-2014 年达到 \( {100}\% \) 的目标。比如,如果 2002 年学校里有 \( {40}\% \) 的学生在州级标准测试中成绩达到熟练水平,而在 2014 年要达到 \( {100}\% \) ,这之间就有 \( {60}\% \) 的差距。 州政府、学区和学校有 12 年的时间达到这一目标, 用 60 % 除以 12 , 每年的提升率大约是 \( 5\% \) 。每年,所有学生必须达到这一增长目标,否则学校就没能实现应达年度进步。显然, 那些原本达到熟练水平的学生数量较少的学校离目标就有更大的差距, 就要完成更多的应达年度进步。

连续两年没能完成应达年度进步的学校会被要求进行整改。一旦学校或者学区没能完成进步要求, 会立刻实施法案中规定的处罚。首先, 州政府会提供教学援助来分析未能达标的原因并解决问题。学校、家长和其他专家必须制定计划提升核心科目的成绩。另外, 如果学生在被认定进行整改的学校入学, 学生可以选择转到该学区更好的学校。如果学校连续第三年不能达到进步要求, 则必须为学生提供额外教学帮助。第四年和第五年则会实施整改措施, 比如撤换学校的核心人员, 实施新的课程标准, 对学校进行整改时, 必须对学校的管理结构进行改革, 比如将学校交给州政府管理, 或者由另外的独立机构来运转学校。这些措施会对学区产生很大影响, 但是必须注意, 这些措施只适用于接受联邦教育资金的学校, 各州可以不接受联邦资金, 这样就可以避过处罚措施。通过这样的 “胡萝卜加大棒” 激励措施, 联邦政府可以影响到各州各地方的教育政策和措施。

该法案有关不能达到每年进步要求则进行强制惩罚的规定招到不少批评。一些人认为并没有充分证据说明未能达标后进行强制的整改措施会对提高学校水平、提升学生成绩有效, 这些惩罚措施反而会惩罚到制定高学业标准的学校。即使有证据表明这些强制措施有一些效果, 措施的具体实施以及对于家长和学生的保护措施也是有很多实际问题的。比如, 很多学区能达到标准的学校很少, 学生和家长并没有多少选择余地, 所以进行合理择校几乎不可能。而表现良好的学校也不太愿意接受成绩差的学生, 因为会影响到它们的年度达标情况。甚至有这样的担忧, 学校会 “排斥” 拖后腿的学生。理论上说, 家长可以为学生要求额外的帮助, 但是缺乏对额外教学服务的评估和监督。如果额外教学不是由有能力的教学人员进行, 或者与学校的课程要求不符, 那么可能反而带来坏处。

一些人认为联邦政府应该只限于挑出表现差的学校, 而如何进行提升则应该由当地来决定。这样的建议实际上与联邦和州宪法有关联邦政府和州政府在公共教育上的规定更加吻合, 以及和该法案对于当地进行问责和管理的原则更加契合。

其他批评者认为这种对于学生熟练水平的统一要求注定会让一些学校甚至大多数学校不能达到要求。他们认为一些学生 (比如有严重残障的学生) 不可能达到该年级的预期成绩要求, 即使对测试进行适当调整。另外, 那些需要另外分组进行成绩汇报的学生, 包括残障学生和英语不熟练的学生, 实际上就说明了他们的表现会比较差。这些类别的学生一旦达到了熟练要求, 则不再属于这一类别了。所以, 这些类学生不可能达到 \( {100}\% \) 的熟练水平。这类学生越多,学校不能达到年度进步要求的可能性就会越高。这就意味着为这类学生进行教育的学校受到惩罚的可能性更大。

《有教无类法案》是一项十分复杂的法案, 对美国的教育政策和措施有深远的影响。现在, 它是教育人士十分关心的法案, 至少在进行教育决策时需要考虑到它。接下来我们来了解一下其他的教育决策。

## 7.4 人员安置决策

课堂教师一般会将班级尤其是小学阶段的班级分为更小的小组来进行教学。进行分组的主要目的是为了让有类似教学需求的小组学生得到更为高效的教学。将学生分为相对同质性的同班小组就是一种主要由教师来决定的安置决策。这样的决策主要依据每个学生对于教育目标的掌握情况。

有时候一些学生的教育需求会很特殊, 与其他学生有很大的区别, 教师不能够在课堂上进行合适的调整。通常有两类这样的学生。一个极端是, 有些学生特别有天赋, 学习成绩和学习速度远超过其他学生。在中学阶段通常会依据成绩水平将这类学生安排在另外的班级里。分轨制度就是让水平类似的学生分到一个班级中, 这样可以让教师针对学生的需求更有效地实施教学。这项措施对成绩好的学生十分有效, 他们可以快速进步。但对成绩差的学生却有特别坏的影响 (比如说每天重复单调低质量的教学, 教师的期望会很低, 学习动力也会下降) (Woolfolk, 2008)。在普通教育中无法掌握阅读等基本学习技能的学生可能会不适应课堂要求, 破坏课堂秩序, 影响其他学生的学习, 对这样的学生可由教师或学校的心理专家和咨询师进行评估, 进行另外的安排。第八章会介绍针对这类学生的相关测试。

人员安排应当考虑到被安排人以及这样的安排会对其产生怎样的影响。然而, 一些安排对于课堂教师和其他学生也有好处。比如, 如果决定将日常教学中一名破坏课堂教学的学生安排走, 安排专门的老师来应对这样的学生, 对其他学生也是有好处的。在一些情况下, 最好的解决办法是让老师安排一名助手专门照看有特殊问题的学生。在进行这样的决定时要考虑到每位学生的情况, 什么样的决定对该学生和其他同学是最好的。

在教育方面, 关于人员安排也有很多争议。然而, 由于学生之间存在成绩差异, 而且随着学习推进, 差异通常会越来越大, 而不是缩小, 所以需要经常进行这样的决定。学生之前的学习基础、学习动力以及最为合适的教学方式等方面都有很大差异, 他们将之前学习经验在新情境下应用的能力也不同。某种对某些学生的学习和进步有帮助的教学项目可能对另一个学生来说就是阻碍。课堂教师以及其他教育工作者都意识到需要根据学生之间的差异调整教学方法、学习材料及课程标准, 将学生安排在最合适的学习环境之下。

## 1. 残障学生的主流化问题

1975 年出台的《残障儿童教育法》, 又称《公法》(PL) 94-142 (见第八章), 保障残疾学生有和其他健全学生一起接受教育的权利。这项法案最近经过修订重新实施, 是为 2004 年的《残障人员教育促进法案》(IDEA 2004), 规定公立学校应为有残障的儿童提供有利其发展的低限制教育环境。这一规定通常被称作主流化。

在 PL94-142 法案出台之前, 常规教育与特殊教育之间的差距令人沮丧。对特殊教育与常规教育学生的学业成就进行严格的对比研究后发现特殊教育的影响主要是负面。另外, 我们发现特殊教育的教室中, 老师没有经过很好的训练, 课程也只是普通教育的缩水版, 而课堂中也大多是少数族裔的孩子。这项发现督促立法方面调整对有特殊需求学生的教学方式。

现在对于有特殊需求学生的教育既有完全纳入正常教学的, 也就是学生全程都在常规教室中学习, 也有完全接受特殊教育的, 即完全不参加常规教育。接受彻底的特殊教育曾经是常规, 但是现在只适用于有严重残障问题的孩子。大多数特殊儿童至少会有部分时间在正常教室中学习, 所以至少是进行了部分的主流化。根据教学系统的安排、学生障碍的严重程度, 以及当地可提供的设施和资源, 可以由常规老师或者特殊教育人员来照顾学生的特殊教育需求。

符合《残障人员教育促进法案》的每个儿童必须有一个为其个人定制的教育项目 (IEP), 详细说明该儿童可获得的特殊服务和教育经历, 以及如何评估这些措施的效度。每名学生的个人定制教育项目需每年进行修改, 包括个人的目标、时间表, 并对该学生目前的学习成绩水平进行说明。

直接受该法案影响的学生在法律上被列为智力障碍、情感障碍或学习能力障碍者, 他们是特别同质化的人群。将学生划分在合适的类别之下, 便于学校的资金分配及教育资金配置, 同时也能保证学生得到的教育和资源能够满足他们的需求。研究表明教学的一些特点, 相比学生的课堂环境, 对于特殊学生的学业表现和成绩更为重要 (Shepard, 1989)。

让残障学生回归正常课堂对很多老师来说有不少挑战, 因为他们大多没有受过训练, 常常不能应对特殊学生的需求。因为教育资金是有限的, 如何在学校内分配财政资源也会涉及一些政治和价值观的问题。《残障者教育改进法案》反映了社会对于残障学生进行正常化教育的相对重要性。但是, 社会对于另一极端特别有天赋的学生的需求却缺乏关注。因为这些能力超强的学生不需要特殊的关注和设施就可去和特别好的成绩,所以没有为他们提供充分发展的机会。

## 2. 人员安排决定是如何做出的

要决定什么样的安排对学生是最好的, 主要考虑的是学生的需求和教育资源之间是否吻合。安排到甲 (比如某项课程、学校部门, 或者特殊教育) 而不是乙也许会更好, 因为两者在教学目标上或多或少有些不同, 因为其采取的教学方式是不同的。比如说, 大学里的英文作文修改课的教学目标是为了教学生如何写出没有语病的简单文章,而创意写作课的首要目标是为了培养叙述诗歌和诗歌写作中原创性和戏剧性。 对两组学生来说有不同的目标。另外, 高中普通数学课和高级数学课的共同目标是为了让学生掌握 “数学分析”, 但是两者所教内容的深度和广度不同, 教学速度也不一样。在后面的例子中, 我们会提到一些测量每组学生学习进度的测量方法。

使用测试来进行人员安排也很普遍。在进行课程安排和教学安排之前, 可以对学生的原有水平进行测试。如果能达到以下标准, 那么这些测试对于人员安排是很有帮助的: 第一, 对于特定科目的特定人门知识进行测试; 第二, 不同的教学在方法、 内容和进度方面有很大不同。

如果是为了给特殊学生提供另外的特殊服务, 测试就会有些不同。如果学生符合《残障人员教育促进法》的规定可享受特殊服务, 则需要有相关测试分数作为法律证明。不同的州对于残障证明的要求有不同规定, 但是通常会对以下方面进行测试: (1) 一般智力水平; (2) 学业成绩; (3) 与特定障碍有关的表现。比如, 智力障碍评定需要对个人进行斯坦福一比奈智力量表或者韦氏智力量表测试。智力有限, 无法应对学校及其他环境的要求是评定智力障碍的主要指标, 所以必须将成绩与全国同龄学生平均水平进行对比。

要对学习能力障碍进行评定则需要更加复杂的测试。智力测试通常会表明学生的一般性智力功能是正常的, 并不是非典型地低。而标准化成就测试则可以确认学生在课堂上哪些方面有困难, 找出特定的障碍。智力测试中表现出来的智力差异, 以及在课堂和标准成就测试中表现出来的学习成绩差异, 是进行学习能力障碍评定的主要参照。

第三大类残障是情感障碍, 对此也需要进行评估测试。最主要的分类依据是行为评估。这类评估需要从家长、教师、学校心理专家、同学及该学生本人那里收集行为数据信息。在一些情况下, 还可以运用人格测量来评估情感障碍。对测试数据进行解读时, 必须要注意年龄情况和行为情景。儿童在社会行为和成熟方面会有很大差异, 只有测试得分处于同龄人中最低的百分之一或百分之二时才能评定为有障碍。

## 7.5 课堂教学决策

课堂教师最为重要的目标就是让学生达到教学目标。教师必须密切关注全班学生和个别学生的学习进展, 这样才能做出正确的决定。从哪里开始教? 什么时候进行下一单元的教学? 要复习这一单元? 或者是否有学生需要更多帮助? 这些决定会对课堂教学产生重大影响。

要确保教学效果, 必须通过正式和非正式的测试对学生的学习进展进行评估。 非正式性的测试包括提问, 在学生完成任务时进行观察, 让学生大声朗读, 或者说出数学题的解答方法。这些方法可以了解学生对于材料的理解情况, 以便教师制订更好的教学计划。如果学生已经准备好接受新的教学内容, 教师要知道是否需要进行另外的复习。非正式的测试也可以让老师对于教学方法的效度得到反馈。如果学生的学习没有达到预期, 老师则应该考虑是否改变教学方式。用来指导课程教学的测量方法被称作形成性评估。

要做出 “重大” 决定, 比如评分和进行安排变动, 则需要进行更为正式的总结性评估。总结性评估通常是采取考试的形式, 在教学之后进行, 对学生的学习进行评估。 这类评估包括教师进行的测试, 用来了解学生成绩进行教学决策, 还有标准化成就测试, 用来评估教学质量, 看哪些学生表现突出, 哪些学生表现较差。老师可以依据考试成绩让学生通过学校心理辅导老师和咨询师接受进一步的诊断, 找出学生在哪些方面做得好, 哪些方面有问题, 找出学习出现问题的潜在原因。如果要对学生进行额外安排, 比如对学生进行特殊教育或将其安排进尖子班, 则需要进行另外的测试。

对教师行为进行的调查表明老师更喜欢使用非正式评估方式, 比正式方式使用更加频繁。原因可能在于非正式的评估可以对教学进行及时反馈, 而且不需要花费精力和心思进行准备。然而, 实践表明在针对个体学生做出决策安排时, 最好配合两者使用。在使用测试时, 教师必须确保决策中测试的使用用途是可信有效的。在使用非正式评估时, 教师需要仔细记录下结果, 确保对于学生的表现掌握充分的信息。 如果教师因为时间和精力有限不能进行记录, 则建议他们采用更多正式性的评估, 这样更容易进行系统追踪。教师需要准确记录评估结果, 这样就可以和家长进行沟通, 也可以帮助他们进行决策。

## 1. 使用教学目标

通常, 课堂教师针对一个班级会有一系列广泛的教学目标。认知目标包括知识基础构建, 或者阅读和写作等认知能力的发展。情感目标包括态度、价值观、兴趣、个人属性和社会属性的发展。教学领域不同, 对这些目标完成情况的评估方式也不同, 可以是对表现和成果进行评估 (见第十章中的相关讨论), 也可以是对获得的认知能力和信息进行评估。

要了解学生是否达到了不同的教学目标, 需要进行不同的测试。然而, 不管测试方式如何, 最重要的是收集的信息必须准确可靠。如果收集到的信息不客观或质量差, 那么基于这些信息做出的决策很可能是有问题的。

## 2. 评估方法的类型

## (1)标准化成就测试

学年伊始, 教师可以依据学生在标准化成就测试中的得分为新班级学生制订教学安排。比如, 可以依据测试分数来选择适合学生现有水平的阅读材料, 安排数学或者语文教学的进度。然而, 在教学实际开始后, 教师需要及时了解学生在特定教学目标方面的完成情况。而标准化成就测试不能提供这类信息。因为这类测试必须关注全美国各学校共同的教学目标, 强调是一般性技能, 不能针对某个课堂上强调的特定250内容进行测试。另外, 它们只能测量可以通过书面测试进行测量的认知能力。需要进行口头交流或者动作表现的情感等方面的技能则无法进行测量。标准化测试同时还花费甚高, 需要好几个小时来实施。因为这些原因, 标准化测试无法针对特定目标经常使用。另外, 教师也许需要等很长时间才能知道测试结果, 所以不能在需要进行教学决策时及时得知成绩。

(2)课程材料中附带的评估资料

有些课堂教师, 尤其是教低年级的教师, 会使用课程材料附带的测试而不是自己设计测试。很多基础阅读和教科书会附带这样的测试。这些材料通常满足测试题和教学目标吻合的要求, 可能还会设定一个合格分数, 让教师知道哪些学生达到了教学要求, 哪些没有达到。虽然这些材料可以减少设计测试的负担, 但是在使用前应该仔细检查。很多情况下, 这些测试质量不高, 另外对每类教学目标进行测试的题目通常数量太少不能进行准确测量。虽然这些测试被称作标准参照测试, 但是通常定义并不清楚, 而且题目也许并不具备充分代表性。还需要强调的一点是这些测试不是标准化测试, 所以没有辅助分数解读的信息。参照第九章中提到的评估标准对测试进行评估, 进行合理修改, 可以保证对学生的成绩水平进行较为精准的评估。

(3)教师自创的测试方法

因为每天都需要进行教学安排, 为了获取相关信息, 课堂教师通常必须自己设计测试和考核。为了解教学目标的达成情况, 通常需要用到以下五种方法来收集数据:

① 笔试

② 口试

③ 成果评估

④ 表现测试

⑤ 情感测量

上述每种方法都有其优缺点, 只适用于某些特定种类的教学目标。

① 笔试。涉及掌握特定学科领域的知识点, 运用知识来解决问题, 或者诸如阅读等一般学习技能的教学目标可以通过教师自创的笔试进行可靠准确的评估。遗憾的是, 很多教师自创的测试质量较差。这类测试通常有两类问题。第一, 测试中的题目与课堂目标不吻合。第二, 测试的心理测量质量通常比较差, 因为题目设定欠佳。 对老师进行的调查显示常常连基本的数据分析都没有用到, 比如对集中趋势和变量进行分析。因为这些缺点, 这类测试所得的数据通常有问题, 对于教学决策没有太大价值。在第九章会介绍一些提高试题质量的指南。

② 口试。虽然对老师来说, 口试更耗时, 但是可以和笔试一样对多种教学目标进行检测。同时还可以包括很多其他目标, 尤其是语言课堂的教学目标, 可能口试对于语言教学来说是最为合适的测试方式了。口试还有其他优点, 可以对整体思想进行考查, 这样就减少了书面表达中技巧的影响。这种方式的主要缺点是测试会比较主观。

对学生进行口试的另一种用途是发现学习问题。比如, 老师让学生解答一系列两位数加减法问题, 让学生进行大声的口头解答, 说出得出答案的步骤, 这样就可以发现学习问题, 有时候虽然学生给出了正确答案, 可是解答过程却可能有问题。口试对于发现学生可能有的阅读问题就不那么有效了, 不过也许可以帮助老师发现一些复杂阅读过程中的小问题。对于有认知或运动障碍的学生, 口试有助于了解更多的信息。

③ 成果评估。某些教学目标, 比如书法、木工课搭建鸟屋, 或撰写商业信函, 则需要学生展示符合要求的合格成果。这样的目标不能直接通过笔试测量, 最好对成果本身进行考察。这类测试叫作成果评估。成果评估的主要问题是如何对成果进行相关质量评估, 如何判断哪些指标是和要求标准相关的。在第十章会详细介绍成果评估的方法。

④ 表现测试。有些教学目标要求学生进行口头汇报, 表演乐器或者在电脑上使用电子表格。这类表现要求通常没有实质性的成果, 即使有最终成果, 其中的操作过程也是非常重要的。要对这类目标进行检测, 只能分配任务让学生去完成, 比如让学生在课堂进行口头汇报, 然后对其表现进行评分。这类方式叫作表现测试。其主要问题有两个方面: 第一, 要确定表现的哪些方面是重要的; 第二, 找出对表现的不同水平进行评判的合适标准。在第十章会介绍提升表现测试质量的方法。

⑤ 情感测量。几乎所有教学项目, 尤其是中小学教学项目, 不仅有认知教学目标, 还有情感目标。情感目标主要是教学人员希望学生发展的个人特征和社会特征, 比如价值观、兴趣爱好、自我认知以及与他人的协作能力。对这些进行测试很困难, 因为这些涉及学生的内在感觉和动机, 不能进行直接测量。现在所能做的是对学生的行为进行观察, 通过观察推导行为的背后动机, 让同学和老师对学生进行评分, 或者让学生自己报告自己的感受和内在动机。在第十一章会介绍相关方法。但是这些情感评估测量都不是完美的。然而, 即使情感测量远不完美, 如果教师和学校认真对待, 对影响学生成绩的情感发展进行观察, 则可以在学生成绩不满意的情况下, 对课堂教学或学校组织管理进行调整。

## 7.6 日常教学决策

成就测试的一个重要目的就是帮助课堂教师决定教什么, 学生该学什么, 做什么练习。每周的拼写测试是一直以来的课堂传统, 而语法和数学测试也已经被老师们用了好多年, 这些测试可以帮他们安排下节课的教学, 了解学生的学习进度。

对使用测试来协助教学决策感兴趣的人越来越多, 也有越来越多人致力于设计测试了解学生知识技能的掌握情况。这些测试得出的信息可以帮助教师和学生决定在进行下一课的学习之前是否有必要巩固知识。对于层级结构的科目, 这样的信息尤其重要,因为要学习内容 \( \mathrm{B} \) 之前必须对内容 \( \mathrm{A} \) 有足够的了解。数学就是这样的例子,其他科目也有类似的结构要求。比如, 孩子们在学习单词拼写之前必须先认识字母。

对特定技能进行检测的测试通常非常具体。在应用这样的测试时, 老师通常会设立一些标准来代表掌握程度 (通常是比较随意的)。这样的标准有时候会被错误归类为标准参照测试 (标准参照测试的要求在第三章中已提到)。这类测试和标准参照测试的相同之处在于其代表题目来自比较狭隘的领域。因为领域比较狭隘, 所有题目针对的是类似的技能, 所以受试者要么几乎全部答对, 要么几乎全靠猜。

为便于理解, 图 7-1 中列举了两种教师自创的测试。第一项测试是为了测试五年级学生对于质数的理解 (也许有人已经忘了什么是质数。质数就是在大于 1 的自然数中,除了 1 和它本身以外不再有其他因数的数。比如 \( 2\text{、}3\text{、}5\text{、}7 \) 都是质数,但 9 不是)。第二项测试在第三章也出现过, 是为了测试学生如何对某些名词首字母进行大写的技能, 来看哪些学生对于这个技能的掌握有问题。

每项测试都很短, 第一项测试是让学生从 15 个数字中选出 6 个质数, 第二项测试中有 13 个单词需要划线。如果设定学生答对 \( {90}\% \) 算作有良好的掌握能力,则允许学生在每项测试中出现一次错误, 如果出现更多错误, 说明对概念或技能的掌握程度还不够。这些测试的测试范围是很具体的, 而且与学生的掌握情况明确相关。测试题目针对的是特别具体的小范围教学内容, 相对容易明确。

在教学中, 一整个单元的教学范围通常更为模糊, 该出哪些题也没那么容易搞清楚。比如, 某一个单元的教学内容是《权利法案》, 我们可以测试一个人对于前十条宪法修正案的掌握程度, 但是如果要考察这十条修正法案对于当代美国有什么样的意义和实际用处, 如何对这些知识范围进行合理定义呢? 在这种情况下, “掌握程度” 就不好把握了。



<table><tr><td>质数测试 题目: 你知道什么是质数吗? 请看下面的数字, 其中有 6 个是质数。判断各个数字是否为质数, 如果是 质数, 请画圈标出, 如不是, 不需要画任何标记。 \( \begin{array}{lll} {31} & {47} & {143} \end{array} \) \( \begin{array}{lll} {33} & {49} & {293} \end{array} \) \( \begin{array}{lll} {35} & {51} & {415} \end{array} \) \( \begin{array}{lll} {38} & {59} & {763} \end{array} \) 41 97 942 大写字母测试 请阅读以下段落。标点符号正确, 每句开头的单词首字母已大写。其余单词没有大写, 其中有些单词 的首字母应大写, 请在相应单词下划线。 We saw mary yesterday. She said she had gone to chicago, illinois, to see her aunt helen. Her aunt took her for a drive along the shore of lake michigan. On the way they passed the conrad hilton hotel where mary's uncle joseph works. Mary said that she had enjoyed the trip, but she was glad to be back home with her own friends.</td></tr></table>



图 7-1 教师自创测试示例

如果没法清楚定义知识范围, 就没法决定在测试中采用哪些有代表性的试题。 对类似的知识点进行考察的时候测试制定者常常会采用不同类的题目。对于一些不容易清楚定义的知识点, 设定一个达到掌握程度的清楚标准几乎不太可能。所以, 针对一些抽象材料而自创的测试虽然可以得到一些有用信息, 帮助教师进行决策, 但是对于老师自创的测试来说, 只有图 7-1 中所列的那种情况下才会得出比较准确的信息。现在教学界推行的教学标准改革的一大趋势就是为教师制定更为清楚明了的教学范围,教学目标 (见 Hambleton and Pitoniak, 2006)。如果课堂中的教学课程、教学方式和测试方式都符合统一的标准, 那么就能进行准确的效标参照分析。另外, 基于《有教无类法案》中对于教师资格的严格要求, 很多教师培训项目会让准教师接受更多提高测试有效度的培训。

## 7.7 汇报学业进展

确保学生、家长和学校了解学生的学习进展非常重要。对于学生来说, 知道自己的学习进步和成就是很好的激励, 知道学习中的特定困难情况也有助于学生及早寻求帮助。图 7-1 中所列的这种测试可以让学生、教师及时得到反馈, 了解知识和技能方面的不足, 以进一步学习和练习。

大多数家长对学校里孩子的学习进展也很关心。当然, 不同的家庭关注程度不同, 对于孩子的学习支持程度也不同。但是家长必须配合学校, 应该对孩子的进展有所了解。家长尤其要了解孩子在每门科目中的学习水平, 如果孩子有困难, 必须及时了解。各类测试结果可以帮助家长了解孩子的学习进展和困难, 与学校进行沟通。

按照传统, 对成绩进行效标参照分析, 将其与同年级学生或同校学生, 甚至整个地区或全国的大致水平进行对比。很多学校会定期向家长提供这样的数据信息。现在越来越多的教师和学校还会提供对学生学习进度进行的效标参照分析, 其中包括学生在哪些方面达到了熟练掌握的程度, 哪些特定方面还有问题。这些报告也许会参考州政府制定的预期学业成就标准。

在向家长汇报学生的学习进展时, 很有必要将学生表现与其他指标进行对比。 在确定学生的表现程度时通常有以下常用方法:

1. 和完美水平相比的表现。

2. 和同等水平相比的表现 (某些预期水平或者平均水平)。

3. 和潜在水平相比的表现。

## 1. 相对于完美水平的表现

在将学生水平与完美水平相比时, 需要问这样一个问题, 即 “在这个测试中学生的成绩距离满分还差多少?”我们可能会倾向于将满分解读为 “完全掌握”, 但这样的解读是不对的, 因为有的测试涵盖范围很狭隘, 对于涵盖范围广的测试, 这样的解读也是完全不合适的。对于后一种情况来说, 总是还有更难的题目, 所以不能得出学生已经掌握所有知识点的结论。即使对于分辨哪些数字是质数这样如此清楚具体的题日, 也会有难度更大的情况。所以 “完美” 只是对于一些特定的代表性题目来说的。 在常用的教师自创测试中,将 “ \( {80}\% \) 正确” 解读为 “对该主题有 \( {80}\% \) 的了解” 是十分荒谬的,至多可以这样解读: “对于老师期待掌握的内容答对了 \( {80}\% \) ”。另一方面,老师的期待也是一个实质的标准, 对学生和家长也很重要。

## 2. 相对于同等水平的表现

相对于同等水平相比的表现通常是指对分数进行常模参照分析, 学生的表现是否好取决于其他学生的表现。对于一项教师自创的测试来说, 就是要将学生的成绩与同班水平进行对比。对于出版测试来说, 针对的对象范围更广, 通常是同年级或同龄的所有学生。

在第三章中, 我们提到了使用不同评分标准和参照指标对个人分数进行汇报的各种分数转换。将学生与所属群体进行对比时, 我们提到最好使用百分比或者标准分数来代表学生的水平表现。能够向一个不太懂测量的家长或其他人及时直接传达信息的一种分数转换方法就是通过相对排名体现学生的分数水平, 比如排在第 15 、 20 位或倒数第 25 位百分位处。

这样的报告可能会有两方面问题。一个问题是很有可能某个班级学生之间的水平差异太小,前 \( {25}\% \) 的学生和后 \( {25}\% \) 的学生之间并没有什么实质性的差异。这样的话, 进行差异分类就很勉强了。另一个问题是如果使用一组人作为标准, 一定会有 \( {50}\% \) 的人低于平均水平, \( {25}\% \) 的人排名垫底,意味着这部分学生“没有及格”。在语言使用方面也有一个问题。对于统计学家来说, 平均水平是指处于一组人的中游, 而对于大多数人来说却是 “可接受最低水平” 的意思, 所以哪怕是低于平均水平一点点, 也会有 “不可接受” 的含义。对于 “平均水平” 含义的两种解读必须进行区分, 所以那些排名位于受试群组中第 20 或 30 百分位数处的学生不会被认为是不及格。关于标准测试, 出版商会提供一个依据全国或地区群体制定的一般水平指标, 或者学校会制定一个系统标准。如果使用全国标准, 对于那些录取发达地区学生的高水平学校来说可以减轻一些压力, 因为学校的学生通常都超过全国标准。但是, 对于那些位于经济落后地区的学校来说就有压力了, 很容易有一种失败感。不分情况盲目实施全国标准, 对于学校或学生来说, 可能会带来不现实感和挫败感。

对于那些碰巧分在一个大多数学生都特别有天赋的班级的普通学生来说, 同样也会出现这种情况。一个水平完全“正常”的学生在这样的班级中很可能即使很努力还是每门课都排名倒数, 这样他会因为其他学生太过优秀而有特别强烈的挫败感。 全国标准测试可以让这样的学生了解自己的真实情况, 在更大的参照群体中找回信心。但是, 很多教育人士强烈批评在教室中进行常模参照解读, 他们认为老师的主要目标是帮助所有学生掌握需要掌握的内容, 学生的相对水平与此没有关系。

## 3. 相对于潜能水平的表现

在意识到按照统一不变的标准来进行测试可能不平等之后, 测试实施者和教育评估者希望可以以学生的潜能为参照了解学生的表现情况。其指导思想是并非所有人都是一成不变的, 统一的一般性参照水平不适用于所有人。这种方法又叫 “白我参照”, 在了解残障学生的学习进展时使用最多, 可以用来了解这些学生定制教育项目的完成情况。在汇报中采用这种方法时必须为每个孩子制定一个单独标准, 依据目前对该孩子的了解, “应该有怎样的合理预期水平?”

这个问题说起来容易, 但是如果仔细分析, 会发现很难进行回答, 涉及很多技术甚至道德问题。如何为个人制定一个合理的预期成就水平呢? 比如,要期待一个 8 岁的孩子和一个 12 岁的孩子跑得一样快, 达到一样的阅读能力, 解决同类水平的数学题, 是很不合理的。 8 岁孩子在体型上也会有差异, 要求体型偏小的学生和体型偏大的学生跳一样高也是不合理的。同样的道理, 孩子们在一般智力发育方面不同, 在相关测试中的得分肯定也是不同的。对于在学业能力倾向测试中得分不同的学生, 要求他们在阅读和数学中达到同样的水平也是不合理的。

对能力倾向测试与成绩测试之间关系进行的数据分析表明这两者之间相关系数很高。在一般性智力测试中得分低的学生, 其阅读和数学的得分也很低。从某种程度来说, 可以说他们在学术成就方面的潜能比较低。因为有这样的关系, 对分数进行分析时要做适当调整。不幸的是, 乍看完全合理的方式实际上没法操作。因为这两类测试的差异不仅是使用功能上的不同, 其所测的能力也是不同的。两者之间的相似之处意味着学生在两类测试中的表现应该差不多。当在这两类测试中得分有偏差时, 应该考虑测量是否出错了。在排除这个可能性之后, 如果 “天资” 超过 “成绩” 的话, 可以考虑学生是否在某项学习能力上有缺陷, 或者考虑是否有情感问题。

除了技术问题, 对不同学生采用不同的预期和标准可能会带来社会后果。人倾向于根据期待值而进行调整, 高的期待会鼓励高成就。另一方面, 能力更强的学生也许会质疑为什么要对自己有比别人更高的要求和期待。出于这个原因, 一些学校允许老师将学生的努力程度和成绩分开进行汇报。

## 4. 评定成绩

很多教师觉得给学生评定成绩是最为痛苦的任务之一。这项工作耗费很多时间, 使人产生焦虑和痛苦。也很少有学生喜欢被评定成绩的, 对老师来说评分耗时费力,但是得到的回报却是很多学生的不满意。

对学生成绩的评估主要是用一些集中的高度抽象符号进行表示。全国教育委员会在 1967 年开展的一项调查显示大约 \( {80}\% \) 的美国学校在使用数字或者字母表示学生的成绩,但是在一年级该比例为 \( {73}\% \) ,幼儿园为 \( {17}\% \) 。但是关于这方面没有什么新的研究 (Stiggins, Frisbie, & Griswold, 1989)。

近年来, 关于这种用抽象符号代表教师评估的做法遭到了很多批评, 理由接下来会进行介绍。然而,用来代替常规的 \( \mathrm{A}\text{、}\mathrm{\;B}\text{、}\mathrm{C}\text{、}\mathrm{D} \) 或 \( \mathrm{F} \) 评级的其他办法也有自己的毛病, 所以目前没有什么令人完全满意的替代评分方法。

## 5. 成绩的重要性

成绩一直深深植根于教育文化中。教育机构内部、教育机构之间, 以及教育机构和其他外部体系之间进行决策或采取措施, 或多或少都要看成绩。能否有资格申请到教育项目、专业院系、奖学金, 成为运动队成员或者上学深造, 常常要取决于学习成绩。是否能被大学或者研究生院录取, 之前的学习成绩至少占一部分因素。所以, 教育系统内的很多地方, 成绩和行政与教学一起对学生的发展产生影响。

很多学习方面的理论家, 包括行为学家、认知心理学家, 都强调在辅助学习的过程中反馈的重要性。一个人要想提高, 就得知道他们现在的水平是什么样的。成长发育的过程需要挑战极限, 孩子们得知道自己和其他孩子相比离目标有多远。如果反馈不准确, 这一过程就得受影响。教师的自然倾向是帮助学生、支持学生, 不喜欢给学生负面的反馈。但是, 老师应该避免为了做出正面反馈而扭曲事实, 因为这样反而适得其反, 导致学生的积极性下降, 影响学习成绩。如果学生需要提高, 他们要知道需要在哪方面进行提高,但是反馈不应该对学生的个人价值问题产生暗示。

家长也需要知道孩子在学校的进步。有很多途径可以满足这一需求, 比如可以看学校记录, 参加教师会议, 或者查看教学目标掌握情况的记录表。经验表明家长最为认同传统的评分方式。实施新的反馈方法需要对家长进行大量的教育说明。到目前为止, 采用新的形式来汇报学生进展的举措受到了很多家长的反对。大多数家长在了解孩子的学习目标达成情况时都会问孩子的得分情况。

另外, 家长有权要求学校以一种他们可以理解的方式对学生的学习进度进行准确汇报。为了避免造成痛苦而统统给高分是一种不负责的表现。误导家长以为自己的孩子没有学业上的问题会极大损伤家长和学校之间的信任。学校欺瞒的做法对谁都没好处。事实上, 最近有几个成功起诉学校的案例, 因为有些学生连六年级的作业都做不好,学校却给他们颁发高中毕业证书。

学校还有责任确认学生是否在指定科目中达到了最低水平要求。如果学生在某门课上得到了令人满意的成绩, 那么潜在雇主或者升学学校会认为该学生掌握了该课程的内容要求。显然, 对学生水平进行认证并不是学校的唯一或第一责任, 但的确是一项责任, 学校对学生的成就通过成绩进行准确汇报是雇主和其他人所期望的。 传统的评分系统历时悠久, 主要在于上述提到的几个原因, 还有就是目前还没有更好的替代方法能够满足需要获得此信息的众多人的需要。

## 7.8 影响未来教育的决策

随着学生在学校里成长, 他们需要为自己将来的教育计划做出决定。过去的成绩将会影响他们的决定。现在进行的测试是为未来表现进行预测的最好方式。一般性成就水平会影响孩子将来的教育决定, 而某门课的成绩会影响将来的专业选择。

学校的成绩是一个成就指标, 但是不同的教师、不同的学校, 其标准常常不同, 所以对于规划未来的学业来说参考价值有限。成绩常常是只具备个人和地区性的意义。因为这样, 标准化测试, 因其具备更为广泛的代表意义, 并且可以让不同地区之间具有可比性, 对于评估总体成绩水平来说具有更统一的广泛意义, 不过也有特定的优缺点。

在根据测试结果来进行计划时要注意避免两个误区。一是过早做决定。人是会变的, 现在的表现并不能对将来进行完美的预测。咨询师要避免过早排除一些选择, 比如说是否要上大学。另一个错误是将测试结果用于过于负面的用途。测试结果应该是用来开启新的可能而不是否定过去。测试可以用来发现学生的天赋, 鼓励进一步发展, 也可以让学生在进行学校和专业选择时不切实际。在大学录取时, 广泛使用标准化测试, 加上资助项目的应用, 带来的一个影响是对大多数美国年轻人来说教育机会在于学习能力,而不是支付能力。

## 1. 选拔性决策

选拔意在尝试为某个组织或机构选出有可能对其做出最大贡献的人。这意味筛选决策强调的是将机构或者社会的福利置于个人福利之上。这和人员安排决定很不同, 因为人员安排是为了让个人能在最有利于其发展的环境下接受教育。所以, 如果雇主想招聘键盘操作员, 看中的就是每个工作日输入文本时的错误率有多少, 而对于要招生的大学来说, 最重要的就是学生的平均绩点 (GPA)。简言之, 选拔机制的目标即找到能将机构利益最大化的人, 也就是那些最有可能取得成功的人。

价值这个概念其实挺模糊复杂的。一些很简单的指标, 比如可输入的字数, 或者成绩绩点, 充其量是雇主或者教学机构对于个人真正贡献的一个粗略简单估计。

过去的成绩和现在的表现对于预测将来都是很有效的。所以, 在预测大学成绩时, 高中的成绩常常是最好的预测指标。相关系数可达 0.5 几和 0.6 几。而招聘期间的工作技能对于将来工作上同等技能的表现情况也是最为理想的预测指标。在筛选过程中预测效度十分重要, 虽然录用决定注重为机构带来利益, 但对个人来说也是十分攸关的。

对一门或者多门科目使用客观学业成绩测试来代替或补充高中成绩, 作为对大学成绩的预测, 是因为这样的测试可以让所有受试者完成统一的试题, 可以弥补评分标准上的差异, 学生经济社会地位的差异, 学校对内容强调有所不同的差异。出于这一原因, 广泛使用的大学人学测试, 比如学业能力倾向测试及美国大学入学考试考的都是很基础的阅读、语文和数学技能。

对于职场来说, 学业能力倾向测试对于大多数职位来说都不合适。有些职位需要学习新的技能, 完成有难度的任务, 在这种情况下, 心智能力测试是适用的, 但是在大多数情况下, 对特定工作技能进行考查的测试才是最为合适的。适合进行这类测试的职位有木匠、机械师、电工及一些办公室职位, 比如键盘操作员、记账员和程序员。在采用职业技能测试时必须要小心。虽然可以对工作所必需的很多突出技能进行考察, 很多其他重要特征却是很个人化的, 比如和他人相处的能力、吸毒等, 这些都是很难进行测试的。

在依据测试结果进行人员筛选时, 无论何时, 进行决策的机构和组织必须记录下每种用途下测试的效度 (第八章中会对有关人员选拔测试的法律规定和法庭决议进行回顾)。比如, 学生在申请大学时常常提交自己的学业能力倾向测试成绩或者大学入学考试成绩, 这些分数可能还会用于奖学金申请, 帮助学生选择课程和专业, 根据学生需求安排补课。在用于这些额外用途时, 必须确认对分数的应用是有效而合适的。虽然一项测试对于预测大学新生的绩点很有效 (所以根据分数进行录取也是合理有效的), 但这不能表明将测试成绩进行其他用途的决定也是有效的。

## 2. 高风险决策

在美国教育系统改革中,高风险测试的问责是一大问题。高风险包括用于 \( \mathrm{K} - {12} \) 教育中对学生进行重大教育决策时使用的所有学业成就测试, 包括升学、留级和毕业 (Paris, 2000)。高风险测试也用作学校教育影响的指示 (Thorn & Mulvenon, 2002)。如果某学校的学生在测试中表现良好, 就可以得到更多的资金支持, 可以对外有一个高质量学校的好名声。一些州按照 \( \mathrm{A} \) 到 \( \mathrm{F} \) 的等级对学校评级,政府资助标准和学校评级挂钩。前面我们提到, 学生表现差的学校按照《有教无类法案》 会受到惩罚。

当前教育改革运动的一个特色叫作最低能力测试, 该测试是为了了解学生是否对必备技能有了最低的掌握程度, 达到完成某教育项目的要求。最低能力未必就是简单的意思, 实际上可能会非常严格。个人必须达到提前制定的标准。如果未能达到标准, 则可能需要补课或者留级, 有时候会拒绝发放毕业证书。这些测试的目的有三: ① 找出哪些学生需要补课; ② 保证毕业生毕业时, 或者学生进入下一个年级时, 对知识有基本掌握; ③ 让学生有提升学业成绩的动力。这个方式对于政治家及公众来说有很大吸引力,因为很直接地解决了一些公共教育的不足。

有关最低能力测试的合法性也有很多问题。问题不只是实施测试或者为升学和毕业制定标准那么简单。问题是要对谁能拿到毕业证书,需要进行多长时间的补课, 做出绝对的决定。虽然关于这方面的法律问题已经得到了解决, 通常倾向于支持最260低能力测试, 但是很有可能还会有问题出现。对不同族裔学生会有不同的影响, 少数族裔学生的失败率也更高, 这是一个大问题。法院已经判定, 如果测试分数的差异是过去种族隔离等歧视政策的结果, 没必要证明测试有歧视动机。

1979 年德布拉诉特林顿 (Debra P. V. Turlington)一案中, 法院重申了贯彻公平的警告, 要求最低能力测试不应延续种族隔离的影响, 上诉法院另外裁定测试的内容是有效的。麦克朗 (McClung, 1979) 表示最低能力测试的内容效度由两部分组成: 课程效度, 是指课程和测试之间的吻合度, 以及教学效度, 是指测试所测内容和课堂教学之间的吻合度。虽然这类判断对很多学校人员来说是有争议的, 因为所有的测试都可以这么说, 但法院还是采取了专业人士的观点和判断。

在最低能力测试刚刚开始实施时, 评论者普遍认为这类考试会招来官司, 因为对特殊教育学生不公平。但是法院在一系列裁决中裁决学校可以要求特殊教育学生参加这类考试, 如果不能通过, 可以不发毕业证。根据耶格 (Jaeger, 1989) 所记, 法院还裁定对于要求特殊教育学生参加测试的学校并不需要证明课程效度和教学效度。这些学校也不需要证明对特殊教育学生有不同影响, 这和法院对于少数族裔学生的态度很不同。

《有教无类法案》并未规定学生达到或未达到州政府测试要求会怎样。但是, 很多州还是决定使用测试中收集到的数据来完成法案的问责要求, 为确定学生的能力水平提供决策辅助。州立成就标准要和所教课程及测试相符, 所以课程效度和教学效度还是有些保证的。有些州在进行高风险决策时, 使用测试分数作为单一指标, 而其他州只将测试分数作为多种参考的一种。在《有教无类法案》规定下成立的测试项目会记录学校在帮助学生掌握州立标准时的情况, 虽然各州进行了心理测量研究来支持自己的解读分析, 使用测试分数针对学生个体进行教学决策时的效度很难进行确认。没有效度证据支持, 使用测试分数进行高风险决策很显然是不合适的。

如果要用测试来作为在校学生学习进展的唯一决定因素, 会出现很多棘手的问题。对于有视力障碍或者接受特殊教育的学生, 应该做出什么样的调整? 对于未通过考试的学生, 应该提供什么帮助? 老师们会为了考试而教学, 只关注如何帮助学生通过考试, 而忽略其他重要教学目标, 比如鼓励学生的创造力和兴趣? 有关高风险测试的担忧主要在于测试原则和教学实际之间的差距。《心理与教育测试标准》中提到了一些提高测试公平性, 避免意外后果的原则, 包括以下这些:

- 对学生的继续教育做出留级、追踪观察或毕业等重大决定, 不应该只看一项测试的成绩, 还应该参考其他相关有效信息。

- 如果关于学生升学或毕业的决定主要看测试成绩, 必须有证据证明测试考察的特定或一般性内容和技能是学生有机会学到的。如果测试要决定学生是否有资格升入下一年级, 或者高中毕业, 学生应该有多次参加同等测试的水平, 来证明对知识的掌握情况。

- 如果某学区、州政府或者其他权威机构要求考试, 应该清楚说明考试成绩的用途。要求考试的一方有责任对其影响进行监管, 尤其是对于少数族裔学生、社会经济情况较差学生的影响, 应尽可能减少这类测试的负面影响。

- 对于英语能力有限的学生应该做出合理调整安排, 以获得有效的考试分数。 如果这类学生要参加的是英文版的测试, 对测试分数进行解读的时候应考虑到他们有限的英语水平。

- 对于有残障的学生, 应该进行合理调整, 保证其测试分数的效度。

必须要记住没有哪项测试对所有学生都是有效的。采用测试的学校官员必须保证测试的内容是学生在课堂上平等学习机会下可以学到的, 确保某些群体, 比如少数族裔学生、残障学生或者英语能力有限的学生不会因为测试或者测试环境而受到排挤和歧视 (美国心理学会, 2001)。

## 7.9 其他教育决策

## 1. 有关课程设计的决策

有必要对成绩进行测试的一个目的是对其他课程材料和教学设计进行评估。在教学领域, 会经常有进行调整变化的提议, 比如课程重点、课程材料的变化, 或者教学方式的变化。如果需要进行理性的改革, 如果教学要提升效度, 而不仅是简单换个风格, 则需要对调整和改变的效果进行系统评估。针对拟进行的变革实施充分的研究是很难的, 但是不进行相关评估性研究就进行改变调整是盲目的, 全看支持者的说服力了。《有教无类法案》要求采用有研究支持的课程和教学实践。虽然这类研究现在还不是很普遍, 但如果对其进行认真规划和执行, 是完全可行的。

任何评估性研究的第一要求是说清楚拟进行的革新想达到什么样的目的。所以,需要对方案的完整目标进行详细说明, 说清楚新方案的所有目标, 取代原有方案的目的是什么。如果新修订的数学教学计划是为了提高学生对计数系统的了解, 而原有方案强调的是运算能力, 那么就得对两个方案在计数和运算两个方面进行评估比较。在提升对计数系统的了解时, 是否会牺牲学生的运算能力? 只有在弄清楚两种方案的目标达成情况才能进行合理抉择哪种更好。这种选择还得看我们对每种结果的重视程度。在进行这样的决策时, 我们得对成就不同方面的重要性进行判断, 对价值评判体系的各方面重要性进行判断, 然后进行综合考虑和选择。

如果对教学方案的各项目标进行了详细清楚的说明, 可以进行教学和评估, 那么需要了解这些目标是否可以通过现有测试进行合理测试。使用现有测试可以省钱省力, 也可以使用现有数据。很多测试在设计的时候经过了对于教学领域内规定内容和目标的详细分析。对现有测试来说, 相关分析在测试出版几年前就有了, 并且很可能依据的是不同学校通用的课程标准。对于阅读和数学课程中涵盖的基本技能, 这没什么问题, 因为对这几门课学校之间的教学内容没有太大差异。虽然在其他科目内容上也许会有一些差异, 大多数教育内容的变化是很慢的, 所以即使是在具体形式和内容上有区别, 很多教学方案在教学目标上还是有很多相同之处的。所以, 在花费时间、精力和金钱为当地的评估项目制定新的测试前, 不妨仔细研究现有测试, 这可能会有很多好处。

## 2. 公共决策和政治决策

每个社区都关心和关注当地的教育系统。每个社区和每个州, 教育支出占财政支出的一大部分, 公民们会想知道自己的钱花得值不值。他们还想知道自己所在州和其他州相比, 学校的质量怎么样, 以及本社区的孩子们有没有学习他们认为很重要的东西。公民们并不会经常做出有关学校的决定, 但是当他们做出决定时, 常常是负面的。他们也许会投票否决学校预算, 学校公债, 或者校委会成员, 甚至组织抗议活动反对某个人, 某个项目或者某项政策。相反, 他们也许会决定对学校予以金钱、时间上的认可和支持。采取什么样的行动全看他们对学校的看法, 而看法怎么样就要看对学校的了解了。

对学校的了解大概就是了解学校发生了什么? 有哪些活动、学习资源和新的想法? 对大多数人来说最为重要的就是孩子学得怎么样。每个学校系统都需要处理与公众的关系, 以及如何向公众展现学生的学习进度情况。

一种方式是对具体方面的成就进行汇报。比如, 学校可以汇报三年级结束后, \( {78}\% \) 的学生能准确说出 7562 的千位、百位、十位和个位上的数字。但是这样的报告对于公民来说没有传达多少含义。他们可能的反应是“那这是好是坏? 和去年相比怎么样? 应该有多少比例的学生达到这个水平? 和隔壁的森特维尔学校相比怎么样?” 如果对具体的成就进行汇报, 老师和公众很有可能会被各种细节搞晕。

在向公众汇报时, 很有必要进行一定的总结。总结常常意味着要进行一些对比, 包括和去年的成绩对比, 和类似学校和地区进行对比, 或者和州立标准进行对比。 《有教无类法案》要求汇报每年需要对州立能力测试的结果进行公布, 按照学校、地区和地理分区进行分别汇报。测试结果是向公众进行汇报的主要依据, 因为它们恰当呈现了各州制定的教学目标。但是如果将不同州的数据进行对比或者与全国水平进行对比却是不恰当的。我们在前面提到每个州都可以制定自己的标准, 在对学生进行评估时可以制定自己的评估机制。将一个州与另一个进行对比, 好比将苹果和橘子进行比较。如果需要将州与州进行对比, 或者进行全国性的比较, 需要实施全国标准的测试和标准, 将结果向公众进行公示。

## 7.10 总 结

本书的一大主题就是探究测量与决策之间的关系。从测试及评估过程中所获得的信息会用来帮助进行很多教育决策。因其对于教育政策以及实施的重大影响, 包括各类决策, 我们介绍了《有教无类法案》。测试在用来进行有关学生安排、教学、学生学习进展等方面决策时, 决策过程不可避免要涉及价值观判断。决策的本质及其所需的信息类型, 决定了什么样的评估是最为合适的。老师是否选择某项成就测试、 教学材料附带的评估材料、口头测试、产品评估、表现测试或是情感测试, 都要取决于其所做决策的类型。测试也用于人员筛选和职位安排决策, 指导每天的教学选择和课程评估, 以及向家长和公众汇报学业进展。

## 7.11 习 题

1. 价值观在决策中起到什么样的作用?

2. 《有教无类法案》的主要目标是什么? 它是如何影响教育决策的?

3. 《残障者教育促进法案》是什么? 讨论此法案对学校、学生及老师的潜在影响。

4. 如何利用测试进行人事安排? 使用这类测试需要什么样的证据支撑? 为什么?

5. 对五年级班级来说, 以下测试类型各自测量的目标分别是什么, 请举例子: 笔试、口试、成果评估、表现测量和情感特征评估。

6. 一项可以对过去成绩进行合理测量的测试为什么对于人员安排决策的价值有限?

7. 社区大学在给大学新生分组、安排英语必修课时需要经过哪些步骤? 分组的意义何在? 会有哪些好处? 哪些坏处?

8. 六年级 4 月份的时候, 海伦在爱荷华州基础能力测试中的阅读成绩对应的年级当量为 6.2 (相当于 6 年级的第 2 个月)。如果她在认知能力测试中非语言部分的得分为 85、115 或 135 , 应该如何解读该成绩?

9. 如果不将表现与潜能相比, 而是将表现与同等水平相比, 你对第 7 题的回答会有改变吗?

10. 针对电视机修理工, 在准备水平测试时需要包括哪些方面? 测试的形式应该是什么样的?

11. 对修订后的数学课程进行评估, 与对学生学习数学进行分班的测试相比, 会有哪些不同之处?

12. 有人认为虽然按照 A、B、C、D、F 五级评级是相对的, 但是这样的分级却是决定性的评估。对此有哪些赞成或反对观点? 评级系统是否基于绝对标准之上, 请列出证据支持你的观点。

13. 学校的评级制度和评分机制有哪些相似之处? 哪些不同? 哪些因素会让评级制度和评分机制的效度都受到影响?

14. 学生的自我评价在其教育生涯中应该扮演怎样的角色? 有哪些局限性?

15. 某大学将新生英语课分了十个班。可以采取哪些措施确保统一的评分标准, 以保证学生不会因为分在某个班级而受到惩罚性影响?

16. 有人提议学校应该放弃评级制度, 只区分合格或不合格。这样的方式有哪些好处? 哪些坏处? 原有成绩等级的功能要用什么来替代? 这些替代措施的合理度是多少?

17. 一位校长对教育委员会成员说: “我们学校比梅森高中的标准更高, 我们的及格分数线是 70 分, 他们只有 65 。”这句话里有哪些假设? 这些假设条件站得住脚吗?

18. 什么是高风险测试? 考虑到个人通不过测试的后果, 你觉得使用测试结果会有哪些潜在的问题?

## 推 荐 阅 读

Bloom, B. S., Hastings, J. T., & Madaus, C. F. (1971). Handbook on formative and summative evaluation of student learning. New York: McGraw-Hill.

Gullickson, A. R., & Hopkins, K. D. (1987). The context of educational measurement instruction for preservice teachers: Professor perspectives. Issues and Practices, 6 (3), 12-16.

Hambleton, R. K., & Pitoniak, M. J. (2006). Setting performance standards. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 433-470). Westport, CT: Praeger.

Hess, F. M., & Petrilli, M. J. (2007). No Child Left Behind. New York: Peter Lang.

Linn, R. L., & Gronlund, N. E. (2000). Measurement and assessment in teaching (8th ed.). Upper Saddle River, NJ: Merrill/Prentice Hall.

Meier, D., & Wood, G. (2004). Many children left behind. Boston, MA: Beacon Press.

Popham, W. J. (1990). Modern educational measurement: A practitioner's perspective. Upper Saddle River, NJ: Prentice Hall.

Slavin, R. E. (1987). Mastery learning reconsidered. Review of Educational Research, 57, 175-213.

Slavin, R. E. (1988). Educational psychology: Theory into practice. Upper Saddle River, NJ: Prentice Hall.

Stiggins, R. J., & Bridgeford, N. J. (1985). The ecology of classroom assessment. Journal of Educational Measurement, 22, 271-286.

Stiggins, R. J., Frisbie, D. A., & Griswold, P. A. (1989). Inside high school grading practices: Building a research agenda. Educational Measurement: Issues and Practices, 8(2), 5-14.

Terwilliger, J. S. (1989). Classroom standard setting and grading practices. Educational Measurement: Issues and Practices, 8(2), 15-19.

Woolfolk, A. (2008). Educational psychology: Active learning edition (10th ed.). Boston, MA: Pearson Education.

Yell, M. L., & Drasgow, E. (2005). No Child Left Behind: A guide for professionals. Upper Saddle River, NJ: Prentice Hall.

## 第8章 评估特殊人群:心理测量. 法律及道德问题

8.1 引 言

圣雄甘地有句话, 大意是说一个国家是否伟大要看它怎么对待其最弱势最脆弱的群体。在过去 50 年, 美国在保护之前受到边缘化对待的少数群体的公民权利方面已经有了很大进步。1964 年的《民权法案》认定学校和公共场所的种族隔离制度及基于种族、性别、宗教信仰及原国籍的雇佣歧视是非法的。1975 年的《残障儿童教育法案》, 以及后来 1990 年的《美国残疾人法案》扩充了《民权法案》, 将残疾人权利纳人保护范围。这些标志性的法案代表在公共教育人学机会方面的大幅度进步, 这些成果是值得美国骄傲的。然而, 除了人学机会, 对于每个孩子接受教育的质量还是有担忧的。通过 1965 年的《初等与中等教育法案》及其修正案 (第七章中有对于《有教无类法案》的讨论, 以及最新版本的介绍), 美国人承认要保证所有学生接受高质量教学, 单是有人学机会是不够的, 有些孩子由于童年时期的一些经历和特征, 在入学后如果要成功,需要更多的帮助。

通常要基于更广大人群的优先需求来决定为哪些人群提供特殊服务。对于残障儿童来说,基本假设就是他们无法控制自己的出生和成长环境 (Safford & Safford, 1996)。同样, 那些经济条件差和英语能力有限的学生在学校面临失败的风险, 也不是他们的错。上面简要提到的一些立法体现了美国人对于为所有学生提供良好教育的重视。

在这一章, 我们将探讨针对有特殊教育需求学生进行的测试有哪些重要组成部分。首先,我们大致看一下影响当前测试实践的立法和诉讼, 然后介绍针对残障学生的评估程序, 以及如何对美国公立学校越来越多的英语非母语学生进行测试的问题。 在本章的结尾, 我们会对测试中的一般道德问题进行讨论, 尤其是针对风险人群进行的测试。

## 8.2 重大立法与诉讼概览

对于教育与心理服务机构的活动, 法律系统监管最为严格的就是涉及标准化测试的活动 (Bersoff, 1981)。当前心理教育测量实践受到多方面的影响, 很多是为了保护原来受到不公平待遇群体而设定的司法和立法规定。依据美国联邦有关残障人群的最新规定, 以下学生从幼儿园到十二年级有资格接受特殊教育及其他相关服务: 有智力障碍; 听力障碍, 包括耳聋、言语和语言能力障碍; 视力障碍, 包括眼盲、情感或行为障碍; 畸形; 自闭症; 脑创伤; 其他健康问题, 比如注意力缺陷、学习障碍, 或者因此在学习上有困难的。(《残障人士教育促进法案》(IDEA), PL 108-446)。美国联邦立法对英语能力有限学生的需求进行了考虑, 这些学生在只提供英语教学的课堂里会遇到不少阻碍。

## 1. 影响重大的立法

现今大部分公立学校教学者工作的体系中会要求为有特殊需求的学生提供合理的教育机会。自从 1975 年《残障儿童教育法案》(PL 94-142) 出台后, 这是一个相对新的现象。正是这项法案确保了残障学生接受免费公共教育的权利, 并为相关教育树立了最初的标杆, 要求教育环境尽可能减少限制, 测试过程没有歧视性区分对待。 在这项法案通过之前, 公立学校可以拒绝接收有残疾的学生。即使学校接收了这些学生, 他们也不一定能接受符合个人需求的教学, 还经常和其他学生分开。在第七章中我们提到, 对很多提供特殊教育的课堂进行检查发现情况很不好, 老师没有接受充分的训练, 不能满足有特殊需求的学生的需求, 老师对他们的期望值很低, 课程也有很多水分。

1990 年的《残疾人教育法案》(PL 101-476), 1997 年的《残障人士教育促进法案修正案》(PL 105-17), 以及该法案 2004 年修正案对 PL 94-142 号法案进行了更新, 体现了更多现代式的思考和社会政策。与 PL 94-142 号法案的初衷一样, 《残疾人教育法案》保障儿童和青少年接受免费合理的公共教育的权利, 同时还为测试过程提供保证, 强调评估应该只包括可以为法律决策带来有意义信息的测试, 来决定个人是否有资格接受特殊服务, 或用来指导教学。在制定个人教育项目 (IEP) 的时候, 必须为每个孩子制定具体的教学目标, 说明会提供哪些特殊服务来满足学生的特定教育需求。另外, 这些服务应该尽可能不限制孩子的发展 (LRE)。理想情况下, 这些特殊儿童应该和正常儿童在一起接受通识教育。《残疾人教育法案》重要修正案的一个关注点是将个人教育项目和通识教育课程联系起来, 让残障学生参加全校考试; 要求在评估和课堂安排中有更高的家长参与程度; 支持除了正式的上诉外可以选择调解 (Dwyer,1997; McLoughlin & Lewis, 2008)。

对残障人士可享受的服务产生重大影响的另一项法案是 1990 年的《美国残疾人法案》(ADA; PL 101-335,42 U. S. C. § 12101)。如前所述, 这项法案依据的是以前的一些法案, 尤其是 1964 年的《民权法案》, 为残障人士提供特殊保护。虽然和测试相关问题没有直接联系, 但这项法案还是很重要, 因为在法律上确立了残障人士和其他以前受到歧视、被剥夺权利, 现在却得到法律特别保护的人的同等地位。1964 年 《民权法案》基于个人种族、宗教和性别对某些群体进行特殊保护。而这项法案将残疾人也纳入了保护范围。

1974 年的《家庭教育权利和隐私法案》(FERPA) (PL 93-380) 是第一项保护教育记录隐私的立法。因此, 它对于学生教育记录和心理记录的处理有重大影响。这一法案提供了以下保证: 第一, 家长和监护人有权查看和自己孩子有关的所有教育记录; 第二, 家长和监护人可以对记录提出质疑; 第三, 在公布正式记录之前确保得到相关人的书面同意。电子数据也应和传统纸质数据一样保存管理。另外, 教育和心理服务提供者不仅要保护所有人记录的隐私, 还应该帮助所有人了解记录的含义。《残疾人教育法案》中对于残障人员的相关权利保障进行了强调。

1965 年的《初等与中等教育法案》(ESEA) 及其修正案是影响美国从幼儿园到十二年级公共教育的主要法案。该法案原来的核心是第一条, 主要是为了帮助学校去服务经济困难学生。本法中不太知名的第七条授权实施一系列有竞争力的资助项目, 帮助母语非英语者掌握有效的双语能力。2001 年的《有教无类法案》是对该法案的重新实施, 将原来的第七条改为新法案的第三条。这个变化改变了原来实施双语教育的目的, 现在相关项目是为了帮助母语非英语者迅速掌握英语, 达到和英语为母语者一起学习的程度。第七章的相关讨论中, 我们提到《有教无类法案》的一大目标就是让所有美国公立学校学生掌握熟练的标准美国英语。对于很多学区来说, 尤其是很多大都市, 该法案促使对母语非英语学生教育项目的投资加大了。有了更多的投资, 对于还需要学习英语的学生来说, 提高英语熟练度, 提升学业成绩的期望也更大了。

## 2. 影响重大的诉讼

有关公共教育领域的法庭案例中, 最有影响力或奠基意义的当属布朗诉教育局 (Brown v. Board of Education, 1954 年) 一案。该案的判决依据是所有儿童属于公民, 所以他们在教育服务和机会方面应该得到平等待遇。尽管美国最高法院 1954 年判决的初衷是保护黑人儿童免受不公正待遇, 这项判决也作为一项判例, 为其他少数群体在教育方面提供了保护。和有色人种儿童一样, 残障儿童也不应当因为自己不可控的因素而被剥夺享受教育服务的权利。

在测试偏见方面, 也有一些很著名的案例。第一个案例是霍布森诉汉森 (Hobson v. Hansen, 1967)一案, 其重要性主要在两个方面。第一, 它质疑了依据单一群体认知能力测试对孩子进行能力分班的做法; 第二, 对于大部分贫困儿童和黑人儿童被分在能力较低班级中的做法, 法庭进行了谴责。在瓜达卢佩组织诉藤普校区 (Guadalupe Organization v. Tempe Elementary School District, 1972) 一案中, 法院裁定在进行测试之前, 必须对学生的母语和英语能力进行测试, 如果孩子的英语能力有限, 要另外进行合适的测试。这项案件中裁定在测试中测试执行者应该既懂英语又懂学生的母语, 有口译人员协助测试, 测试应该不强调口语能力, 用他们可以理解的语言向家长和监护人解释测试结果。

最后, 有两例特别针对智力测试的重要案例。拉里等人诉威尔逊。罗尔斯等人 (Larry P. et al. v. Wilson Riles et al., 1979) 是一项大多数教育学和心理学人士都知道的加州案例。基于个人智商测试来判定学生是否有残障, 这种做法在用于黑人儿童时, 其效度受到了质疑。在判决中, 法官认定原告胜诉, 认为这些标准化个人智商测试存在偏见, 对于其他文化的儿童不公正。很快, 伊利诺伊州有一起类似的案例, 特殊教育行动组织家长诉汉农 (PASE v. Hannon, 1980)), 法院的判决很不一样, 即韦氏儿童智力量表和斯坦福一比奈智力量表 (见十二章), 在一个更大的评估系统中进行时, 不会对其他文化背景的儿童有偏见。

## 8.3 特殊教育评估过程

## 项目实施和评估程序的移交

特殊教育评估需要系统收集信息, 对于如何满足学生特殊教育需求做出重大决定。首先,要判断学生是否出现了问题, 可能使该学生在学校的学习出现困难。一旦确定问题的确存在, 则进行测试, 根据测试数据进行法律决定, 判断是否符合接受特殊教育服务的条件。最后, 确定符合条件后, 需要进行一系列教学决策, 要制订和实施能满足学生特殊需求的项目, 并对其效果进行监测和评估。下面是特殊教育评估和决策过程的一个简要概览。

## 1. 识别和移交

要找出有障碍的学生, 需要进行两大类测试程序: 筛查和移交前策略。几乎所有公立学校学区都有一个机制, 用于发现那些无法在学校正常学习的三岁及以上儿童。 筛查包括对该校区所有学生进行大规模数据收集。通常, 筛查的内容包括简短的病史, 针对身体残障如视力、听力和言语困难进行基本医学评估。这些措施可以让医疗人员和学校人员在庞大的数据中进行有效的数据过滤, 找出那些存在学习困难风险的学生。经过筛选测试后, 如果发现有潜在问题, 则对学生进行更深度的评估。

学校人员然后采用符合学生年龄的测试题对学生的智力、社交能力和运动功能进行额外的评估。筛选评估和这些额外的深度评估不同, 前者通常是面向同一年级、 学校、学区或社区所有学生的, 是为了找出哪些学生存在学习困难风险。 筛选工具有高度敏感性, 所以很可能会将不需要特殊服务的学生认定为存在学习困难风险。错误认定存在风险对于家长来说会很有压力, 但是筛选评估必须要敏感, 这样可以早日发现潜在学习困难问题。与其错过了对困难学生的发现, 不如将后来证明没有困难的学生包括在内。早发现可以早干预, 对于教育项目来说这样可以做到收益最大化。 另外, 早期发现意味着学生在上学之前就可以进行干预调整, 提高了他们将来取得学业成功的可能性。

如果某个学生表现出学习问题, 通识教育教师可以向学校里的其他专业人士进行咨询, 判断学生的困难类型和程度, 进行合理干预, 帮学生解决问题。学校人员会组成一个转交之前的小组, 如果发现有学生存在早期学习困难, 可以采取相应行动帮助学生。这个小组的目标是协助通识教育课教师, 进行课堂内的支持和挑战, 很多学生的学业和行为需求, 不需要安排到特殊教育项目中, 就可以得到满足。在实施课堂干预后, 由课堂教师来对干预帮助的效度进行监测和记录。相关证据再由小组人员进行评估, 评估过后, 可能会做出以下三项选择中的一种: ① 终止课堂干预帮助; ② 继续进行和改变课堂干预; ③ 进行更深入的教育心理评估, 决定是否符合接受特殊教育服务的资格。

## 2. 资格认定

如果孩子出现了学习、社会情感、言语和语言, 或者运动障碍, 要认定是否符合移交特殊教育的资格, 可以由和孩子相关的人来进行 (家长、教师、特殊服务人员等等)。 在大多数情况下, 这是由家长或教师来进行的, 并且需要转交之前小组的意见。在移交的时候, 学校人员应该准备好详细的证明材料, 包括移交原因记录, 移交前干预小组采用的措施和结果。到这里, 孩子还不是特殊教育服务系统的一部分。在为孩子分配一名管理人员, 特殊教育员工取得家长同意可对孩子进行诊断测试之后, 孩子才进入特殊教育体系。

如果取得了评估许可, 由教师、家长、家长委托人和专家组成的跨学科评估组对孩子的主要相关障碍领域制订正式的个人评估计划。学校相关人员, 比如心理学人员、咨询师、医生、社会工作人员、生理和职业治疗师及言语/语言病理学家通常会来进行评估。进行这种跨学科评估主要有两个原因: 第一, 对于某方面的障碍, 可能需要不同学科的专业人员给出广泛的参考意见; 第二, 要进行全面评估, 一组人可能比一个人在操作合理性上更有保证。资格认定通常要依据常模参考标准测试。数据收集中测试的主要功能领域会在下面进行介绍。

跨学科小组在收集完测试信息, 进行整合之后, 就可以决定孩子是否有资格接受特殊教育服务。这项决定是一个法律决定, 依据两个互相关联的标准: 孩子必须在学校中表现出困难及造成困难的原因是某种障碍。

## 3. 项目计划、实施和评估

如果孩子有资格接受特殊教育服务, 跨学科评估小组要依据资格评估中收集到的数据及其他辅助材料制订个人化教育计划 (IEP)。计划中必须明确说明该儿童的现有功能水平; 这一年可测量的表现目标; 详细说明会提供什么样的特殊教育服务以及在哪里由谁来提供; 说明依据《有教无类法案》该儿童如何参加州立评估测试的规定。在计划中还要详细说明如何对学生的进展进行监测, 如何告知家长孩子的表现情况。可以通过正式和非正式测试来对学生的教育项目进行监管, 但是通常非正式测试更好。非正式测试的例子包括观察、作业分析、效标参照测试。如果该儿童没有达到计划中的目标, 家长可以要求修改孩子的教育项目。如果教育项目有效, 《残障人士教育促进法案》要求每年对个人计划进行检查。

《残疾人教育法案》对特殊教育学生和家庭的一项保护措施是, 要求每三年对每个学生进行重新评估, 决定其是否还需要继续接受特殊教育。个人计划制订组决定在重新评估中需要包括哪些内容。如果取得家长同意, 小组可以决定在重新评估中不需要增加新的测试数据。个人教育计划评估和每三年的重新评估会按时进行, 帮助家长和学校人员确定学生是否仍然需要额外关注和特殊服务才能在学校正常学习。

还有一个要求, 即在进行自己孩子有关的特殊教育项目会议的时候, 通知家长和法定监护人。最重要的是, 向家长提供的信息是进行诊断测试后得出的准确直接反馈信息。对评估过程完全不了解的家长看到各种数字和陌生的术语时可能会有些发慌, 应该帮助家长了解这些信息, 这也是重要的一部分。辛普森 (Simpson, 1990) 提出, 在一些方面, 家长和家庭成员可以对针对孩子的教育干预进行支持。对孩子进行支持, 参与个人计划制订, 进行家庭教育, 这些方面家长都可以加强参与度, 可以帮助孩子提升。

《残障人士教育促进法案》要求所有州立公共教育部门记录残障学生的教育成果。对特殊教育的成功性进行评估不只是要看学校在特殊教育系统中的学习进展 (学生问责制), 同时还得看整个服务提供系统的成功性 (系统问责制)。各州和地方的政策制定者需要了解学校质量和效率的相关信息, 教师也应知道学生的进展。教育仍然是主要的公共政策和政治问题, 依据结果进行评估的原则会越来越重要。在当前的教育评估测量领域, 依据结果进行的测量这一概念越来越重要。这种方法注重找出教育的重要成果, 然后设计出有利于学生达到这些成果的教学系统。如果学生没能达到要求, 应对教学项目进行检查, 看哪些方面可以进行提高 (见 Salvia & Ysseldyke, 2000)。另外, 作为一种新的有创新的测量方式, 在一个统一框架下测量学生、学校和整个系统的确很有潜力。

## 8.4 特殊教育评估涉及的主要领域

## 1. 智力和认知能力

在讨论障碍测量的时候, 首先必须要谈到智力建构, 否则无从谈起。不管是关注更为认知方面的障碍原因, 还是关注测量的实用方面, 智力的本质是什么, 对于学业表现和项目计划有什么影响, 这些问题必须好好考虑。

在大多数情况下, 州和地方规定, 在决定儿童是否满足移交特殊教育服务的标准时, 测试中应该包括个人智力功能测试。原因很直接, 智力测试是评估中最强大、广泛和稳定的测量指标。这样的测试可以用作诊断工具, 收集很多信息, 从最基本的信息回忆能力, 到对新刺激物的复杂处理能力。使用这些测试可以发现各类功能失调和障碍问题, 因为它们通过运动神经渠道体现出来。另外, 资格认定测试还能发现孩子的认知优缺点, 可以协助个人计划的制订。智力测试在这方面可以提供很多有用具体的信息。

在测量智力方面, 有两项主要的智力测试, 其历史最为悠久, 使用最为广泛: 斯坦福-比奈智力量表第五版 (Roid, 2003), 以及韦氏智力量表。如第十二章中所说, 韦氏儿童智力量表包括一系列类似且有关联的试题库, 年龄范围包括童年早期(韦氏学龄前和小学智力量表第三版, 2002)、童年 (韦氏儿童智力量表第四版, 2004) 到成年 (韦氏成年智力量表第四版, 2008)。关于学校测试, 还有两种测量工具一考夫曼儿童评估测试修订版(K-ABC-II ; Kaufman & Kaufman, 2004), 以及伍德科克-约翰逊儿童测试第三版 (WJ-III; Woodcock, McGrew, & Mather, 2001) 有时候也会用到。还有很多其他标准测量工具,但使用频度不是很高。

## 2. 适应性行为和自理能力

近年来, 适应性行为的概念经过大改。它原先是社会成熟度的一个组成部分, 现在是一个独立、多层面的建构, 原来只是行为观察中一个简单的系统, 现在则是一个复杂的心理测量概念 (McGrew, Ittenbach, Bruininks, & Hill, 1991)。最近, 适应性行为是指一个人在自己所处环境下有效运转的能力。1992 年以来, 美国智力障碍协会 (American Association on Mental Retardation, 1992) 试图将适应的焦点和责任从有障碍的个人转向社区, 通过明确社区生活需要得到哪些支持来达到这个目的。现在适应性行为被视作评估系统中非常重要的一部分, 尤其是对有障碍的儿童和年轻人进行的评估。

适应性行为的建构最近才上升到理论层面, 原来只是依据是否具备对日常生活重要的行为而归纳地发展。题目的制订原先是依据对特定行为的观察 (比如会系鞋带), 接着到量表 (将相似题日进行分类), 最后从量表到测量工具。有了这些测量工具, 才有了相关理论。一种理论是格林斯潘和格兰菲尔德 (Greenspan & Granfield, 1992) 的一般能力理论。这个理论认为一般能力由两类能力构成, 环境能力和社会能力。每一小类都有智力和非智力成分, 来源于更为细致的能力定义 (见图 8-1)。对这些维度进行实证效度验证还没有得到特别的证据支持。虽然对已出版量表进行的内容分析表明有十种不同内容区域 (Bruininks, Thurlow, & Gillman, 1987), 因素分析结果表明有一个根本的因素。

适应性行为测量通常和智力障碍联系在一起。法律规定要进行智力障碍诊断, 需要在智力测量中得分显著低于平均水平, 并在两个及以上适应性行为方面有对应的缺陷。这样的规定可以防止一个孩子可能仅仅因为智力测试的分数低, 但是在非学校环境下 (比如家里和社区中) 表现正常, 却被错误归类为智力障碍。

20 世纪 70 年代中期到 80 年代早期的法庭判例推动了适应性行为的有关研究。 在安排特殊教育项目的时候, 促使测试者减少对于单一智力测试指标的依赖, 采用多种能力倾向测试。采用这样的决定并得到广泛采用的原因是通过适应性行为能够了解在日常生活中应对紧急问题的能力, 这是智力测试没法做到的。测量适应性行为





图 8-1 一般能力综合模型

资料来源: 经许可, 改编自 Greenspan, S. R., & Granfield, J. M. (1992). Reconsidering the construct of Mental retardation: Imphications of a model of social competence. American Journal of Mental Retardation, 96,447. 版权所有(C) 1992, AAMR/ccc。



的四项常用测试有美国智力障碍协会的适用性行为量表 (居民和社区——Nihira, Leland, & Lambert, 1993; 学校一 Lambert Leland, & Nihira, 1993)、独立行为量表修订版 (Bruininks, Woodcock, Weatherman, & Hill, 1996) 和维兰德适应行为量表 (Sparrow, Cicchetti, & Balla, 2005)。

## 3. 行为和社会一情感能力

与智力和适应性行为相比, 对于行为和社会情感能力的测量更为困难。在第十四章中我们将介绍, 情感和行为失调障碍需要依据临床诊断进行判断, 因为建构本身的主观性特点, 这样的判断通常带有主观性。

依据美国《残疾人教育法案》, 有情感障碍的儿童在一段较长的时间内会表现出以下特征的一种或几种, 而且表现程度很明显:

- 用智力、感官或其他健康方面的原因无法进行解释的学习障碍;

- 不能和老师同学建立并维持令人满意的人际关系;

- 在正常情况下表现出不合理的行为或感受;

- 经常感到不开心或抑郁;

- 有产生和个人或学校问题相关的生理症状或恐惧的倾向。

关于人格和社会功能的理论有很多, 有存在争议的神经动力学模型, 还有具有高度行为倾向的模型 (见第四章)。理论不同, 对于行为异常的描述不同, 教育干预的目标和教育策略也不同。理论方向的巨大差异也会带来术语混乱等问题。比如, 《残疾人教育法案》把这类障碍叫作情感失调, 但是很多教育人士喜欢用行为失调这个词, 因为他们关注的是可见的行为, 而不是不能观察到的心理状态, 而且他们倾向于认为既然行为是可以学习的, 就可以进行矫正改变, 而心理特征就不一样了。不管是用什么术语, 要对孩子失调行为的本质、程度和持续时间有清楚了解, 大多数孩子虽然会出现行为异常, 但并不存在行为或心理问题, 所以并不适合在学校和社区接受特殊服务。

法律对情感障碍的划分, 只有孩子行为出现严重异常, 持续较长时间, 而且对孩子的学校表现和课堂教学环境产生负面影响, 才能采用。这样的儿童符合接受特殊教育服务的要求。要对情感和行为障碍进行诊断, 通常要在各种环境下观察孩子的行为表现, 并由家长和教师等人进行评估。在判断是否存在行为或社会情感障碍时, 即使有观察得出的数据, 还是需要参考很多专业人士的意见。有些作者担心专业人士的判断常常带有主观性, 但是证据表明专业人士判断的诊断结果一致性一直在提升, 而且一致性很高 (Matarazzo, 1990)。在专业临床人员的记录中有通过斯坦福或韦氏量表等认知能力测试来进行情感障碍诊断的例子, 但是不推荐这种做法。谢泼德 (Shepard,1989) 认为如果依据对能力倾向测试的反常反应来对临床症状做出诊断, 那么只通过行为观察就足够了。

如果老师和家长更加关注孩子的社会性功能,采用行为评估量表一 3 (McCarney & Arthuad, 2005), 伯克斯行为量表修订版 (Burks, 1996) 就能收集到需要的信息。但是, 如果更关注情感功能, 想深入了解心理病理, 最好加上儿童行为检查表 (Achenbach, 2001) 或者儿童行为评估 (BASC, Reynolds & Kamphaus, 1998)。这两项测试都包括家长、教师和自我评价表。如果是有严重行为问题的青少年, 可以使用明尼苏达多项人格问卷的青少年版 (见第十四章) 等工具, 但是这类工具要求有经过训练的临床心理学家参与。

## 4. 神经心理能力

对神经心理功能进行测量对于心理教育测量者来说是一个比较新的领域。神经心理学是心理学的一个分支, 依托临床、认知、校园心理学等方面的最新进展, 还从医学和神经学借鉴了很多成果。虽然早期的感知运动能力研究得出的结果不是很清晰, 但是神经心理学的新研究还是从这方面研究中进行了很多借鉴。

这一领域是人类功能的重要组成部分, 教学和心理学人士的长期投入和关注说明了感知运动和感觉运动功能的重要性, 也说明了推动心理诊断中交互功能新研究的重要性。威克斯和尤尔一琼斯 (Weeks & Ewer-Jones, 1991) 认为如果不能正确感知信息, 就不能为刺激物赋予有价值的意义。如果意义是扭曲的, 那么相关反应也会出现异常。这也是为什么如果怀疑孩子需要特殊教育帮助, 在第一阶段的评估中, 要对基本感知功能如视力、听力和简单运动功能进行测试。

有时候, 只需要提供简单的设备一一比如眼镜和助听器一一就能解决问题。但是很多情况下, 评估测量和干预不是进行视力量表测量和听力测量就行的。感知运动技能是否不仅要关注简单的感觉输入, 关于这个问题有不同的看法。虽然以前教育和心理学服务提供人员会采用视觉听觉处理、整合、区分测试, 现在有了更加现代化的测试方式, 包括对大脑一行为关系的测试, 会用到各种设备和测量方式, 比如脑电图 (CT), 磁共振成像 (MRI) 和正电子放射断层造影术 (PET)。所以, 和 20 年前相比, 神经心理学和知觉运动障碍的诊断和治疗有了很大进步。比如在阅读方面, 菲菲尔和迪菲娜 (Feifer & Defina, 2000) 提出, 使用神经心理测量加上神经成像技术可以更好地了解阅读障碍中大脑一行为之间的关系。同样, 肯纳德, 斯图尔特, 西尔弗和埃姆斯利 (Kennard, Stewart, Siluer, and Emslie, 2000) 发现评估中发现的某些神经心理功能模式和特定领域内学业成绩的提高有关联。

## 8.5 评估母语为非英语者

## 1. 简介

根据 2000 年的人口普查, 美国有 20% 的人在家不说英语。美国公立学校中母语为非英语背景的适龄儿童数量增长率超过了总人口增长率。预计在 2050 年, 美国学生中每 4 人中就有 1 人是拉美裔学生 (Woolfolk,2008)。拉美裔学生的比例已经超过了临近墨西哥的各州和佛罗里达州内拉美裔学生比例。公立学校在人口构成上的变化对于教学者来说是个挑战, 在教学和测试中, 很多在家不说英语的学生英语水平有限 (LEP)。更为复杂的是, 英语水平有限的学生中差异性也很大。虽然很多美国公立学校中英语水平有限的学生在家说的是西班牙语, 但是他们的文化背景有很大差异。比如, 虽然美国大部分说西班牙语的学生来自墨西哥, 但还有很多是来自美国中部和南部、古巴和波多黎各。另外, 很多来自美国中南部的人除了会西班牙语还会其他美洲语言, 也许他们更喜欢用这种语言。

虽然在美国学校英语为非母语的学生中, 西班牙语是最常见的, 但其他语言也很常见。就全美国来说, 排在英语和西班牙语之后最常见的语言是法语和汉语普通话。 但是, 全国不同语言的使用人群分布有很大差异性, 在很多地方, 有些人说的语言并不常见。比如, 华盛顿州西北部很少人说法语或汉语, 但是有很多公立学校的学生是俄罗斯移民后裔。美国 \( {80}\% \) 的老挝赫蒙族和中国苗族人在加利福尼亚、明尼苏达和威斯康星等州的都市定居, 迈阿密和芝加哥的公立学校里不少学生说海地克里奥尔语, 亚利桑那州和新墨西哥州有很多说纳瓦霍语的孩子。在城市里, 阿拉伯语也越来越普遍。纽约市的公立学校是全国最大的学区, 据估计, 学生在家里说的语言有 170 多种, \( {43}\% \) 的学生来自母语并不是主要语言的家庭。要满足如此多的多样化学生群体需求, 对于当地教育官员来说是个不小的挑战。

对母语为非英语学生进行测试要分为两个阶段。第一, 要判断学生英语及其母语的水平。这一步得出的信息可以决定如何对这些学生实施面向所有公立学校学生的学业能力测试, 而且在评估母语为非英语学生是否满足接受特殊教育要求的时候, 也需要参考这些信息。

## 2. 语言水平评估

语言水平是指个人接受信息和表达信息的沟通技能水平。接受技能主要涉及听力和阅读, 表达技能主要涉及口语和写作。这是语言功能的两大方面, 这些能力水平的发展速度可能会有很大不同。基本人际交流技能 (BICS) 是指在没有人进行正式教学的情况下, 社区所有成员都能掌握的口头语言技能, 包括口语和听力。认知/学术语言水平 (CALP) 则是在教学中掌握的阅读和写作技能, 是在学术环境下对语言进行更为正式和精准的应用, 比如特定科目的特定词汇。

需要主动习得的语言通常叫作“第二语言” (L2), 虽然学习者可能会说不止一种语言, 而个人掌握这门语言的速度会受到若干因素的影响。对于来到美国的移民来说, 第二语言就是英语了。这些因素包括学生的年龄、第二语言的浸入程度、母语 (L1) 和第二语言之间的相似度。然而, 相比掌握简单人际交流技能, 适应课堂教学的要求来掌握高级语言能力花的时间会更长。因为语言技能掌握的速度不同, 基本人际交流技能的水平不能证明学生学术语言使用能力的水平。认知/学术语言水平技能的发展需要经过正式教学, 学生的人学年龄会影响到由于这项技能的缺乏对学业成绩造成阻碍的程度。《有教无类法案》第三条款规定对新移民儿童和英语水平有限的公民进行英语语言教学。要判断是否有资格接受辅助英语语言发展服务, 需要进行英语水平测试。《有教无类法案》规定各州在语言阅读能力、数学和科学领域为所有学生制定内容标准和成绩测试, 法律同时还规定为英语水平有限的学生制定英语水平标准和测试。

虽然各州在英语水平标准和水平测量测试方面有很大不同, 但对外英语协会 (TESOL) 这一专业机构制定了综合性英语水平标准, 很多州都是根据这个标准来制定自己标准的。这些标志围绕四个语言使用层面: 听力、口语、阅读和写作。标准对口头和书面表达中的主要领域进行了详细描述, 包括音韵学 (发音)、词汇、句法规则 (语法)、语义学 (含义), 语用学 (语言使用情景)、辅助语言学 (非语言和其他沟通中的非语言元素) 以及话语 (思维模式)。另外, 对外英语教学协会使用五个水平等级来判定语言发展过程中的复杂程度和模式。通过对学生进行英语和母语语言水平测试, 可以将学生划分在符合其发展技能水平的等级; 将学生安置在适合语言能力发展的教学环境中; 在对学生进行其他技能测试的时候进行合适的调整安排。

在测量语言水平时会用到正式和非正式方法。有很多可用的商业测试工具, 但大多数都是为西班牙语学生制定的。伍德科克-穆尼奥斯语言调查修订版 (Woodcock, Munoz-Sandoval, Ruef, & Alvarado, 2005) 和思想水平测试 (IPI) 2008 年版中的口语水平测试 (2004) 就是两个这样的例子。林奇和路易斯 (Lynch & Lewis, 1987) 提到现在尤其需要开发针对亚洲语言的正式测试。

如果缺乏某门母语的正式测试, 只好选择非正式性测试。华瑞兹市 (Juarez, 1983) 认为非正式性测试对沟通技能和认知/学术语言水平测试可以进行很好的预测。非正式测试措施包括在语言使用情境下对学生进行观察, 对作业样本进行分析, 进行测量特定语言能力的效标参照测试。

## 3. 对母语为非英语者进行学业能力评估

《有教无类法案》要求英语能力有限的学生参加语言阅读、数学和科学等科目的所有州立学业考试。另外, 法律还规定测试必须符合心理测量标准。所以, 学校面临很大压力, 要为英语水平有限的学生提供有效的测试。对于不说英语的学生来说, 如果数学或科学测试是用英语写的, 测试并不能对这些科目的学业水平进行有效测量。 但是, 对于测量专家、心理学家和教育学家来说, 为各类非英语背景学生制定可靠的有效测试可是个不简单的任务。

要预测学生的成绩和能力, 不能因为英语水平而使结果受到偏差影响。在第五章我们提到, 这是一个效度问题, 因为这涉及测试分数中存在和测试特征不相干的变量。要解决这个效度问题, 有几个不同提议。一个办法是将学业技能测试翻译成学生的母语。这个做法很昂贵而且技术上也很困难。字面翻译也许会引起题目的歧义, 而且目标语言不同, 也许相同的题目难度会变得不一样。另外, 英语设计的心理功能评估也许用学生的母语来进行表述, 涉及的心理功能会不同。

翻译必须保留英语中的原有含义和维持任务的难度水平, 如果要对分数进行常模参照解读, 需要在和受试者有相似语言和文化背景的学生样本中进行参照。有人提出使用语言词汇能力要求最低的测试, 但要了解和解答题目还是需要语言和词汇, 而且这样会让测试任务中的认知要求不等同或者不可预测。

最后, 解决这些问题, 最常用的方法是使用翻译人员。但是, 对题目要求进行同声传译可能会不准确, 而且这和常规测试实施标准很不一样, 这样就没法采用既有的标准规范。但是既然没办法为所有语言制定测试, 通常必须用到翻译人员。不管是进行正式还是非正式测试, 对题目要求进行同声传译, 可以确保学生知道题目要求是什么。

## 4. 对母语为非英语者进行特殊教育评估

在特殊教育领域, 在安置学生的时候, 对于文化和语言多样化背景学生是否可能存在歧视,一直都有很大争议。和《有教无类法案》一样, 《残疾人教育法案》也要求在对学生是否需要接受特殊教育进行评估的时候, 不能因为英语水平而有偏见。梅西克 (Messick, 1984) 建议在对学生的能力进行测试之前, 先对学生的学习环境和课堂教育质量进行调查。只有确认学习环境很好, 对通识教育课堂中的教学进行适当调整之后, 学生还存在学习问题, 再对这个英语水平有限的学生进行测试, 判断是否需要特殊教育服务。如前所述, 对母语为非英语学生进行评估的时候, 首先要对学生的英语和母语能力水平进行评估, 完成这一步之后, 才能进行接下来的其他测试。

## 8.6 传统学业能力

## 1. 阅读、数学和书面语评估

任何儿童都有可能在学习中碰到困难。事实上, 大多数孩子在上学期间都会碰到这样那样的学习困难。然而, 接受特殊教育的孩子在通识教育中会出现特别的困难, 需要额外的支持和关注, 而且这仅凭普通课堂教师的努力实在是不能提供的。第十三章中要讨论的几种学业成绩测试经常用来评估学生对某个科目内容的掌握程度。学业倾向测试 (比如第十二章中提到的) 则可以测试和同龄人同年级相比, 学生的预期表现程度怎么样。组合使用、标准学业成绩测试和能力倾向测试可以使评估人了解学生在传统学业能力方面实际表现和预期表现之间的差距。对大多数接受特殊教育的学生来说, 这样的差距表现在基本阅读、写作 (书面语) 和/或数学能力方面的缺陷。对于年龄更大的学生来说, 这还可能包括其他内容, 比如科学或社会研究, 但是通常仍涉及阅读、写作或数学等重要技能。

接受阅读障碍评估的学生是最多的 (McLoughlin & Lewis, 2008)。也许是因为阅读是普通教育课程中影响最为必备的一种技能。阅读出现障碍会对各门课程造成影响, 因为阅读能力障碍会影响从书面材料中获取基本信息的能力。

在将有障碍的孩子移交特殊教育的时候, 数学能力常常是第二大因素。在现代社会, 数学能力对于量化思考十分重要, 但是和阅读能力相比, 对于课程学习的影响相对较小, 所以不是那么容易显现。在障碍领域中, 写作能力是最少进行评估的。良好的写作能力对于进行正常生活也很重要, 但是在诊断和干预方面的相关研究滞后于其他领域, 而且学区主管人员不太愿意因为孩子仅仅在书面语写作方面出现障碍就让孩子接受特殊教育。

基本学业能力测试可以从两种做法中选择一种。如果是因为通识教育出现障碍, 需要进行评估, 也就是在一门以上科目中出现了问题, 那么可以进行标准化成绩测试, 测试内容包括上述提到的所有三个领域。如果是某一内容方面出现了问题, 比如阅读能力, 则可以采用具体的诊断测试。这两种测试都可以让我们了解一个学生和全国其他学生相比, 能力水平如何, 但是只有针对特定能力进行深入的诊断测试, 才能对某项具体能力障碍进行深入了解。

很多测试可以对孩子的总体学业和相对学业水平进行了解。群体测试包括爱荷华州基本能力测试 (Riverside Publishing Company, 2001), 斯坦福成绩测试系列 (Harcourt Brace,2002) 和都市成绩测试 (Harcourt Brace,2000)。部分因为《残疾人教育法案》的规定, 很多学区甚至鼓励或要求残障学生也参加这类测试。但并非所有学生都能参加群体测试, 很多参加过的人表现很差。个人测试有时候在这些情况下是更好的选择。考夫曼教育成绩测试修订版 (K-TEA- II ; Kaufman & Kaufman, 1998)、皮博迪个人成绩测试修订版 (PIAT-R; Markwardt, 1997) 及伍德科克-约翰逊成绩测试 (Woodcock, McGrew, & Mather, 2001)都属于后一类测试。

除了这些测试组合, 还有很多个人测试可以用于诊断和项目计划。不难想象, 阅读测试是最多的。格雷口头阅读测试第三版 (Wiederholt & Bryant, 2001), 斯坦福阅读诊断测试 (The Psychological Corporation, 2003) 以及伍德科克阅读能力测试修订版 (Woodcock,1998) 就是这类例子。在数学测试方面, 恩莱特基本算术技能诊断试卷 (Enright, 1983)、关键数学诊断第三版 (Connolly, 2007), 以及数学能力测试第二版 (Brown, Cronin, & McEntire, 1994) 是最常使用的。最后, 书面语写作测试方面最常用的有书面语测第三版 (Hammill & Larsen, 1996) 和伍德科克语言水平测试修订版 (Woodcock,1991)。

## 2. 课程评估

课程评估 (CBA) 是另一种测试模式, 因为现在强调评估的各种表现模型的多样化, 所以 CBA 现在在教育界受到很多关注。课程评估的理念并不是近来才有的。教师很久以来经常针对课程的具体方面依据直接观察学生的表现来进行测试。教师会让学生在拼写课上直接根据学到的知识来拼写单词, 这就是课程评估。这种非正式测试可以对当地学校和课堂中学生的学习表现进行了解, 从中得出宝贵的信息, 这和全国性标准拼写测试得出的信息是不同的。后一种测试可以让教师将学生的表现和全州或者全国相似学生进行对比, 而前一种测试可以用来逐步改进学生在具体技能方面的水平。

要了解现有的表现评估模型, 课程测量 (CBM) 也是一个需要了解的重要术语。 虽然课程评估和课程测量这两个概念经常互换使用, 但是大多数学校心理人员会对这两个概念进行区分。课程评估是常规课堂中针对所有学生的非正式、个人化的测试总称。课程测量则是一种表现评估, 采用常规课程材料对特殊教育学生进行测试, 从而使相关专家判断学生在当地课程设置的具体领域和其他学生相比, 成绩表现如何。

对很多教育方面的心理学家来说, 课程测量是另一种评估模型。大多数传统培训项目比较注重常模参照的个人化智力测试, 最近也开始关注对人格、适应性行为和一般性发展等方面进行的测试。课程测量中, 一些很细微的技能, 比如一周中有一张设定的列表, 掌握表中内容的阅读、写作、拼写, 就可能是测量目标。对于有特殊障碍的学生, 比如智力障碍、言语和语言障碍的学生, 老师可以每天制定一个目标, 测试是否达成了目标, 然后将孩子的进度记录下来, 和其他几天或几周的进度进行对比。下面是依据马斯顿 (Marston,1989) 改编而来的课程测量例子:

- 让孩子朗读单词表中的单词, 记录下读对的数量, 时间为一分钟;

- 先讲一个故事, 然后让学生在三分钟内写下单词, 记下单词数量;

- 每七秒报一个单词, 总时间两分钟, 记录下孩子字母顺序拼写正确的单词数量。

对于很多教育和心理服务提供者来说, 课堂测试是另一种评估模型, 至于什么才是最好的做法, 也有一些说法。第一个期望是提供服务的一方愿意学习测量的新技能, 可以进行更快的干预。第二个观点在于评估的直接性和重复性。如果能对孩子进行持久重复评估, 就能发现孩子的实际表现趋势, 进行将来的计划。第三个观点是教师和心理服务提供者应负责判断当地测量 (比如每周拼写测试和数学测试) 的合理和可靠度。如果老师设计的测试不能准确反映某个学期的学习进度, 那就没有任何意义了 (Hasbrouck, Woldbeck, Ihnot, & Parker, 1999; Marston, 1989)。采用这类测试,一个意想不到的副产品是出现适于当地的规范。教育心理服务提供者可以衡量学生和当地学校与学区其他学生相比的学习进展情况。很多支持课程测量的人说采用课程测量的目的是课程测量可以体现学生每天的技能进步, 而不是与其他人和群体进行对比。然而, 如果教师及心理服务提供者想要进行个人和群体的对比, 也是可以做到的。

## 3. 生态评估

对于教师及心理服务提供者来说, 课程评估是另一种评估模型, 生态评估也是如此。生态评估中, 重点不是学生及其在内容上的障碍和困难, 而是课堂及其他学生进行活动的环境, 包括心理教育服务提供系统。生态评估的目的在于对所有影响到学习过程、学生和环境特点的因素进行评估 (McLoughlin & Lewis, 2008)。倡导对儿童与环境互动关系进行研究的理论并不是最近才有的 (比如布朗芬布伦纳的发展生态系统模型; Bronfenbrenner, 1989; Bronfenbrenner & Evans, 2000), 针对正常儿童的生态评估及针对残障儿童的生态评估模型都具有同样的效果。很多对孩子及环境进行评估的模型来源于针对特殊人群进行评估的模型, 因为残障儿童通常需要接受更多评估测量 (Browder, 2001)。

和其他新型评估模型一样, 生态评估模型通常比正式测量更加随意, 而且常常从调查者的个人视角出发。但是大多数模型都强调孩子和环境中其他人的互动关系, 也部分借鉴了心理健康模型, 其中融合了社区和社会干预。对于残障儿童, 韦特、伊利略特、克雷姆和格雷沙姆 (Witt, Elliott Kramer, and Gresham, 1994) 认为生态评估必须包括课堂教师。评估计划必须包括教师对学生的期望值、课堂物理环境, 以及当前的学习任务。另外, 布劳德 (Browder, 2001) 强调从不同环境下收集数据的重要性。学业行为功能评估 (FAAB; Ysseldyke & Christenson,2002) 是一项已经出版的测量体系, 可对不同环境进行评估。该方法中用于课堂的部分就是教学环境检查表, 包括课堂观察及与学生和教师的结构化访谈。良好的家庭学习氛围、家庭和学校的互动, 对语言和文化背景多样化的学生来说很重要, 也可以通过这项评估进行测量。 采用生态评估模型可以带来既积极又复杂的影响。首先, 生态评估扩大负责将残障因素转化为环境中的其他因素的范围, 很多方面和适应性行为评估的操作很像。第二, 评估的对象不是单一的, 如孩子、家庭, 甚至学业期望, 而是将这环境的所有要素之间的互动也纳入评估中。第三, 和传统评估方式相比, 可以采取新的有创新性的评估方式。该模型包含从传统的标准化测试到日常活动中最为主观、定性的结果。

采用生态模型的一大限制是收集必要信息需要花费大量时间和精力。现在市场上很少有测试能够有效衡量生态模型中涉及的大范围互动。注重儿童学习环境这一方面的评估通常会忽略其他同样重要的组成部分。伊塞尔代克和克里斯滕松 (Ysseldyke & Christenson, 1993) 设计了一种综合性生态评估工具, 即教学环境系统第二版, 对影响儿童学业表现的 17 项重要因素进行测量。 12 个因素和学校环境有关, 5 个因素和家庭支持有关。下面是教学环境系统第二版中测量的 17 个因素。

教学环境构成部分8.7 专业标准和道德规范



<table><tr><td>教学匹配性</td><td>认知关注</td></tr><tr><td>课堂环境</td><td>相关练习</td></tr><tr><td>教师期望</td><td>激励措施</td></tr><tr><td>教学展示</td><td>有用反馈</td></tr><tr><td>学习投入时间</td><td>适应性教学</td></tr><tr><td>进步评估</td><td>学生理解</td></tr><tr><td colspan="2">良好家庭学习氛围构成部分</td></tr><tr><td>期望和归因</td><td>纪律规正</td></tr><tr><td>有效家庭环境</td><td>家长参与</td></tr><tr><td>学习结构</td><td/></tr></table>



简介

教育和心理测量在这方面或那方面影响着大多数人的生活。由于很多依据这些测试结果所做的决定, 对受试者会产生重大影响, 所以为了促进教育和临床中的测试实践达到专业负责的标准, 制定了一系列专业标准和道德规范。道德规范指道德原则和行为规范, 对社会意义上什么是对什么是错进行了规定, 对专业职责和道德义务进行了详细规定。大多数专业组织都制定了道德规范, 帮助其成员在面临困难决定的时候进行决策, 通过组织成员施加的群体压力执行这些规范。虽然不同组织对于规范的措辞有差别, 但教育和心理服务机构之间具有共识, 为了确保测试的有效公正, 需要遵循一些共同的规范。很多专业机构制定了一些一般性的道德规范, 下面对284这些规范进行介绍, 包括: 1 . 专业训练和能力; 2 . 专业和科学责任; 3 . 对他人权利和尊严的尊重; 4 . 社会责任。

## 8.8 专业训练和专业能力

## 1. 专业训练

为了确保学生或客户的福祉和利益, 教育或心理测试使用者必须在测试和干预方面有相关技能。但是, 要能够胜任这些任务, 必须要对认知学习、人类生长发展、发展反常和心理病态, 以及一般性人际关系等内容有很深入的理解。换种说法, 测试信息必须放在教育和心理情景下来进行理解, 并和其他同等重要且与测试无关的信息进行衡量。有人认为, 测试采用者只要有测试相关技能就行, 而不需要其他人类功能和心理教育等方面知识。这种看法是错的。

实施测试和使用测试数据的熟练度主要在于个人将相关领域进行知识整合的能力, 以及是否能将人类功能的广泛基础与测量评估原理进行联系。这就是为什么资格评审委员会要求申请人有相关项目的大学毕业证书,并且还有相关课程经验。 全国教师教育认证协会 (面向特殊教育教师)、美国心理学会 (面向心理学家) 的研究训练项目认证, 以及咨询和相关教育项目资格认证委员会 (面向咨询师) 都有课程和经验时长要求, 要求学过和接触过各类失调症和障碍症的评估、诊断和治疗千预。

但是, 在正规教育中接受过良好训练, 并不是说在职业生涯中对领域内的最新研究进展都有了解。随着时间流逝, 进入行业以后, 一个有责任心的专业人员必须对领域内最新理论和操作进行了解。测试领域也是如此。测试使用者在评估的实施、下结论、进行干预决策的时候, 必须依据最新的信息。

如果教育和心理服务提供者缺乏充分训练, 或者不能及时掌握领域内和测量有关的最近理论和做法, 很可能会误用测试。针对测试和评估信息的误用, 1984 年教育界和心理学界的领袖成立了测试实践联合委员会 (JCTP)。这个组织的首要目标就是制定“一套确立测试使用者资质的经验实证方法, 为那些关注提升测试使用的人提供帮助” (Moreland, Eyde, Robertson, Primoff, & Most, 1995)。该组织列出了进行合理测试使用的 12 项最低能力要求。图 8-2 所示为可能出现误用的领域。

1. 在评分和记录中避免出错。

2. 避免基于没有完全效度的测试分数, 而给人贴上带有贬损意义的标签, 比如 “不诚实”。

3. 确保评分标准和测试资料的安全性。

4. 确保每位受试者遵循测试指示, 以保证测试分数的准确性。

5. 确保测试环境能够让受试者有最好发挥 (比如足够的空间)。

6. 不要对个人或群体就测试题目进行训练, 这会导致测试结果不能准确反映个人能力和水平。

7. 在咨询的情况下, 愿意对参加测试的人进行解释和引导。

8. 不要复印受版权保护的材料。

9. 不要采用和评分参考标准不吻合的自制答题纸。

10. 和受试者建立相互信任, 保证分数的准确性。

11. 在回答受试者提问的时候, 回答的详细程度不要超过测试指南允许的范围。

12. 不要想当然认为适合某种工作的规范对其他工作也适用 (也不要想当然认为适用于某个人群的规范也自然而然适用于另一个人群)。

图 8-2 合理使用测试的 12 项最低能力要求

资料来源: Moreland, K. L., Eyde, L. D., Robertson, G. J., Primoff, E. S., & Most, R. B. (1995). Assessment of test user qualifications: A research-based measurement Procedure. American Psychologist, 50,16. 版权所有(C) 1995, APA。

## 2. 专业能力

对于测试和相关服务的道德规范来说, 专业训练只是其中众多重要领域的一个方面。一旦个人离开了学校, 进入了专业行业, 我们往往默认这个人会遵守行业内的职业和法律行为规范, 包括合理使用心理测量工具与程序, 综合科学、法律和道德规范做出与测量有关的决定。

不难想象, 对于需要接受教育和心理帮助的人来说, 有很多服务可选。遗憾的是, 提供服务的专业人士能力水平也不尽相同。所以, 人们最好避开那些无法提供有效服务的相关人员。因为这些服务对象通常是很脆弱的人群 (比如儿童、年长者和残障人士), 在规范这些服务时须加倍注意和小心。

这部分介绍到的很多专业机构针对相关专业行为都制定了道德规范标准, 很多都与专业能力有关。比如美国咨询协会 (1995)、美国心理学会 (2002) 和全美学校心理工作者协会 (2000) 呼吁其所有会员遵守专业训练和经验限制, 不要从事自己不能胜任的专业实践。

## 8.9 专业责任和科学责任

## 教育测试与心理测试的标准

教育和心理测量会在很多不同背景和环境下进行。测试的起源、设计、结构和应用各不相同, 教育学和心理学的三大管理机构共同制定了一系列标准, 来 “推动测试的使用合理、符合道德规范, 为测试质量的评估提供依据” (美国教育研究机构 [AERA]、美国心理学会 (APA)、美国教育测量委员会 [NCME], 1999, 第 1 页)。这份文件的官方名称是《教育与心理测量标准》, 下文将其简称为《标准》手册, 自 1954 年以来出版了一系列帮助测试开发者和使用者评估教育与心理测量所使用的工具与规程技术性的手册, 这是第六版。《标准》的目的就是推动测试使用的合理性, 确保其符合道德规范, 为对测试、测试使用和使用影响的评估提供标准。与前几版不同的是, 1985 年版的标准将每个标准叫作 “首要标准” (所有测试在实施前必须满足标准要求), “次要标准” (最好可以达到, 但是在某些情况下可以不达到) 或 “有条件标准” (不同应用情况下, 重要程度不同)。现在的这一版 《标准》手册并没有延续上一版将重要程度进行区分的做法。相反, 它规定所有标准在对于其应用的条件和环境下同等重要。

这版修订版《标准》主要分为三大部分。另外, 其包含的介绍材料和以前的版本相比更为翔实。我建议经常和测试打交道的人, 不管是参与测试设计、实施还是评估中的哪个环节, 都应该有一本《标准》手册, 并熟悉其中的指导方针。

## 1. 测试结构、评估和记录

《标准》手册中的这部分内容包括各方面标准: 效度; 信度与测量误差; 测试开发和校订; 定量表、定常模、分数可比性; 测试实施、评分和汇报; 测试的辅助材料。依据 《标准》, “效度是测试开发和评估中最为重要的考虑” (美国教育研究协会等, 1999, 第 9 页)。《标准》中提到了支持测试使用时几类不同的效度证据。另外, 它还提到了保证测试分数一致性而制定的信度和测量误差标准。虽然《标准》手册支持标准化程序, 但是也提到了一些特殊情况, 须按照法律要求或应当对程序进行恰当的修改。比如“不同背景、年龄、测试熟悉程度的人也许需要不同标准的测试实施或者需要对测试过程进行更全面的引导” (美国教育研究协会等, 1999, 第 61 页)。一个常被忽视的领域是关于正规出版测试的编制和修订的标准, 它们对量表结构的重要标准进行了描述。

## 2. 测试和公平

《标准》手册的这部分内容包括公平和偏见的相关标准; 应试者的权利和义务; 对语言背景不同的人进行测试; 对残障人群进行测试。这部分强调了保证测试和评估各方面保持公平的重要性。“公平对待应试者不仅是平等问题, 同时还能改善基于测试做出推论的效度和信度” (美国教育研究协会等, 1999, 第 85 页)。在编制、实施、评分、解读测试以及依据测试得分做决定时, 若涉及不同语言环境或有残障的人群, 应该特别予以注意。

## 3. 测试应用

最后一部分标准包括测试使用者的一般责任; 心理测试与评估; 教育测试与评估; 就业和资格测试; 项目评估和公共政策方面的测试。除了强调测试使用者的道德义务, 《标准》手册还提到了和心理、教育、就业、项目评估及其他测试结果应用情况相关的具体问题。

## 8.10 尊重他人的权利和尊严

## 隐私和保密

对于教育和心理服务提供者来说, 涉及测试的时候, 学生或客户的利益应是其首要考虑因素。过去几年来, 对个人隐私的担忧越来越多。数据库的广泛使用甚至不负责任的滥用,使得个人信息可以快速存储和获得,这种可能对个人隐私造成侵犯的操作, 让很多人起了警觉。很多时候, 人们会使用访问医疗和个人记录的隐私权, 其中包括教育和心理测试信息, 来获取雇主保险公司的相关报销服务。教育和信息服务提供者应当区分隐私和保密这两个概念。“隐私”是指其他人可接触某人身体或行为的程度, 而 “保密” 是指其他人对某人自愿提供信息的可使用程度 (美国卫生及公共服务部, 1993 年)。从评估值的角度来说, 在什么样的情况下可以要求获取这类信息呢? 另外, 在什么样的情况下, 社会组织需要了解这些信息, 而且这种需要超越了个人保护自己秘密和隐私的权利呢? 有些信息会比其他信息更为私密, 但是对大多数人来说, 很多测试得出的信息, 他们不想让别人知道。在讨论测试道德时需时刻关注两个问题, 即谁会从所收集到的信息中获益? 怎么使用这些信息?

## 1. 谁会从收集到的信息中获益?

如果收集测试数据是为了给个人提供具体帮助, 尤其是经个人或者家长要求进行测试, 这时受到的反对应该是最小的。比如有时候通过课堂测试来找出需要进一步学业指导的学生, 或者在制订项目计划前进行诊断测试。这类测试的目标是针对学生的现有水平来进行教学, 这种情况下, 制订符合学生节奏的项目对学生的进步是有好处的。但是, 如果需要对学生进行分类安排, 则会有给学生打上标签之嫌。如果是这样, 应该对参加测试的学生和家长清楚说明项目的教育益处是什么。还有一些被测人可以直接从测试中获益的其他例子, 比如学生向学校咨询师寻求个人和就业上的帮助, 或者使用测量量表来让学生和咨询师了解更多信息, 这对咨询过程是有帮助的。

但是有时候测试并不能直接为受试者带来益处, 比如参加测试的个人只是一群人中的一员, 而测试的目的是为了获取群体数据。在第七章中我们提到了《有教无类法案》, 测试分数数据必须进行分组, 以更好了解不同族裔学生的表现情况, 表现不尽如人意人群的情况, 比如残障学生、贫困家庭学生或者英语能力有限的学生可以参加另外的测试。对数据进行分类指导学区进行资源的合理分配, 帮助学校人员更好地理解学生的特点和需求。

对专业从业人员进行的测试 (比如咨询师、医生、心理学家和老师) 对另外一个群体有益。虽然很多认证考试得出的信息并不会对受试者产生特别的好处, 但是测试可以衡量专业水平的高低, 对于服务型人员来说, 可以了解其服务水平的高低。如果专业人员可以从中直接受益的话, 那就是他们可以通过参加测试取得执业资格。最大的获益者应该是那些需要专业人员提供服务的人和整个社会。

## 2. 怎么使用这些信息?

在进行正式测试前, 应该确定信息具有相关性。一旦相关性确定之后, 必须有强有力的证据证明测试分数可以提供有效信息, 在提供相关服务时有助于进行正确的决策。即使测试的目标是有价值的, 如果带来的影响有问题或者太小, 就没有必要收集证据了。相反, 如果测试信息相关性越大, 就越有必要要求个人提供证据。

比如, 如果家长怀疑孩子有注意力障碍症, 打算带孩子去看咨询师或者去学校心理人员处进行评估, 那么提供相关服务的人员只需要收集对症状进行确认或否定的相关数据。如果在评估的时候有其他担心, 这种情况在有情感障碍或者学习困难的学生中也许会出现, 可以对相关担忧进行另外的测量评估。但是, 在任意一种情况下, 心理人员只应该收集进行重大决定需要用到的数据, 来决定学生是否需要接受特殊服务或定制项目。绝不能为了验证其他非正式的直觉而收集其他证据, 或者因为学生进行了其他测试而收集证据。

## 8.11 社会责任

测试的应用有其社会情境, 会产生特定的社会影响。如科尔和莫斯 (Cole & Moss, 1989) 及梅西克 (Messick, 1989) 所指出的, 测试也是社会政策的一种。测试可以提高教育和职业领域的效率和生产力, 这一点毋庸置疑, 但是采用这样的标准会有什么样的代价呢? 本书一直强调, 决策涉及价值观, 然而并没有什么客观标准可以对相互冲突的价值观进行评估。不同的人和群体对某项措施的社会价值会有不同的判断, 受到多种复杂因素的影响。采用某种价值观产生的代价是否可以通过它带来的益处得到补偿, 仅靠心理测量研究并不能判断, 必须由社会、社会成员和制定社会政策的人来进行判断。不管判断的结论是什么, 和测试相关的每项社会政策都需要回答两个问题: “测试公平吗?”, 以及 “测试对社会有益吗?”

## 1. 公平分配

现在让我们来看看测试的公平问题。制定测试的人和进行测试教学的人通常会认为测试的使用, 虽然不能保证, 但是至少可以使决策更好、更明智和具有社会合理性。虽然大多数情况下, 测试的目的是为了让个人和社会取得积极的结果, 但有时候公众很难理解为什么一个基于对人进行区分的体系 (即对能力不同的人和特征不同的人进行区分) 可以确保平等。在这一部分内容中, 我们将介绍一些积极结果。下一部分会介绍一些对测试的社会政治环境有更为微妙影响的因素。

分配社会公平这一概念, 在这里是指向人们、为人们和由人们提供的教育心理服务所产生的益处按照公平原则进行了平等公正的分配。很多教育和社会服务领域的成员都知道, 很多情况下都会存在社会不公正现象, 有些人几乎没有教育机会或者机会非常有限, 有人则可以享受特别好的教育 (Kozol, 1991), 而因为投保情况不同, 不同人得到的心理和医疗服务也不一样。一种常见的观点认为测试参照客观表现标准对个人进行评估可以提升公平原则 (见第七章)。人们通常会努力达到别人的期望。如果为所有学生设定学业标准的表现要求, 那些一开始不能达标的人会努力提高成绩来达到要求, 尤其是如果整个社会能够对他们进行支持。比如在佛罗里达州, 要从社区大学毕业, 必须通过客观学业测试, 原先有色学生群体的通过率更低。但是, 如果知识技能教学根据标准进行调整, 与测试内容相吻合, 那么原先不能通过测试的学生会提升测试要求内容的成绩, 显著提高通过率 (Gottfredson & Sharf,1988)。

## 2. 测试的社会效益

第二个问题“测试好吗?”, 如果要在所有情况下适用于所用人, 同样不容易回答。 对于那些制定测试的人, 最直接的反应是肯定的回答, 但仅限于由合格人员经手和指定用途。所以, 测试经常在很多涉及个人、社会和全国层面的社会问题上有且常有建设性的影响。依据梅西克 (Messick,1993) 的观点和统一效度的原则, 测试的价值和它的使用以及影响紧密相关, 测试过程中相关人员必须基于测试分数为社区提供合290理、有意义、有用的推论。

本章及前一章中, 我们提到测试在教育中有多种用途。教育是项很花钱的事业, 其效度和效率也不容易进行评估。学生在成绩测试中的表现可以是教育投入产出的一个指标, 这些数据至多只能说明学校效度的一部分情况。近年来对于教学标准和问责制有很多关注。不同州为了测量学生的水平, 进行问责而采用的测试在形式和质量上有很大差异。对于教育系统中其他重要指标的测试 (知识技能掌握程度之外的), 比如社会交往能力、协作性解决问题能力, 以及批判性思维能力, 还很缺乏。另外, 因为《有教无类法案》对于表现差的学校有惩罚措施, 大量资金用来弥补这些学校的不足之处, 但是是否有用却缺乏数据支持。所以, 让教育事业朝着高效的方向发展越来越重要。测试就是为了协助实现这一点。

测试的一个好处就是不会对任何受试者的能力提前做出判断, 即测试分数体现的是每个人作为个体的成绩和表现, 而不是群体的组成部分。测试并不会提前预设哪些人会表现好, 哪些人会表现差。虽然大多数教育和心理情境下, 完全依靠客观测试几乎不可能也不太理想, 人类总是自然地倾向于给不同的人设定模块化的成见, 而客观证据可以尽量避免这种倾向, 所以可以让所有人享受到公平的待遇 (见 Ryanen, 1988)。在这种情况下, 测试有助于为很多有才能的提供各种机会, 而不会因其所属的群体而失去机会。

测试的另一个积极社会影响是测试可以让我们了解人类的潜能。心理学和教育学就是要了解人类的成长发展, 什么能够激励他们, 是如何进行学习的, 以及生理、心理和社会等因素对他们的影响。如果要研究什么样的环境可以促进人类成长、发育及发掘人类的最大潜能, 则有必要通过一些测试对这些因素进行测量。如果要研究导致某个群体的人对另一个群体的人产生敌意的因素, 就必须找到测量该特征的方法, 或许可以通过测试或量表来实现。尽管测试都有缺点, 各种各样的测试仍然对研究人类成长、发展、动机和学习等方面发挥了重要作用。

## 3. 积极影响的最大化

前一部分我们提到虽然对于测试和测试成绩的使用有很多合理的担忧, 但是教育和心理测量的应用可以带来很多好处。但是很遗憾, 依据测量得出的结论并非全都是正确的。要基于最可靠的证据进行决定采取行动。决定采用这个选项通常意味着放弃另一个没那么好的。在进行决策时, 应该考虑到各种信息和所有因素, 否则会降低测试过程的重要性。要在应用测试成绩时产生有利影响, 这里我们列出六个能对决策产生微妙影响的准则。

## (1)检查且明确所有涉及的价值观

大多数决定, 无论有关个人、一个阶层或某一类人, 都会涉及相互影响的复杂价值观。如果决定将某个学生安排到高级物理课上, 对这个学生来说, 也许是可以进行更为高效的学习, 取得更好的物理成绩, 但是这样的决定在某种程度上会使这个学生和本校没能去高级班的主流学生隔离开来。一名学生决定申请法学院入学资格, 如果被录取, 自然是件很好的事, 比如可以收获个人名誉感和未来的经济前途, 但是如果未被录取, 则可能会带来一些负面后果, 比如自尊心降低, 错失其他项目的录取机会。人事筛选项目中也许会为雇主带来很多好处, 比如短时间的培训项目可以节省成本、降低人员流动率、提高工作效率, 但是对社会来说, 来自内地城市的年轻人工作机会却减少了。不管有没有测试, 个人和社会都要面对选择和决定, 无视测试提供的信息和数据也是一种选择。只有意识到其中相冲突的价值观, 进行充分考虑, 才能决定如何使用测试来进行更好决策。

(2)了解测试分数只是指标或符号

一次数学测试的成绩对个人数学能力仅起一个指示作用, 而不等于数学能力本身。学业能力倾向测试的分数也只是学生是否准备好进行学习的部分指标。符号充其量是对现实的不完美代表, 但是只有通过符号才能了解其背后的实际情况。通过温度计或者通过发烫发红的脸, 我们可以知道一个人是不是发烧了, 但是温度计或者身体外表本身并不是发烧。所有的测试在某种程度上来说都不是直接的, 但如果受到生理、文化或社会因素干扰, 指标的意义可能就会变得模糊。在对测量进行解读的时候需要对可能的干扰因素保持敏感。

(3)了解测试分数只是一类描述性信息

这句话的关键词是一和描述性。在任意一类决定中, 除了测试分数, 还涉及其他类的相关信息。斯坦福一比奈智力量表或者韦氏儿童智力量表也许可以为阅读有困难的学生提供一类有用信息, 来制订教学安排, 但是对视力进行评估, 对家庭情况和兴趣爱好进行调查, 这些信息也许同样有用。另外, 能力倾向测试只能衡量某人在某方面的现有水平。单单看分数, 没法知道为什么某个人会有这种表现或者测试表现和阅读障碍之间有什么样的相关关系。测试使用者必须要小心, 不要对测试分数进行过多推论。

(4)将测试分数与受试个体或群体的其他信息联系起来

测试分数并不是凭空存在的。只有将测试分数和这个人有关的其他信息结合来看, 才能最大程度了解它的意义。其他相关信息包括个人的文化背景、家庭背景、个人成长历史、身体和健康状态等。如果人数很多, 问题就很复杂, 学校和招聘方经常面临这样的问题。然而, 如果能对手头各方面证据进行考虑、衡量和应用就能做出最佳最明智的决策。

## (5)了解各类描述性信息中都可能存在误差

我们已经讨论过所有测试分数都存在测量误差。在测试实施、评分、解读和汇报的过程中都可能存在误差。测试分数使用者应该时刻意识到, 任何分数只是一个接近值, 为不确定性做好心理准备。同样关于某个人的其他类信息, 也存在误差的可能性, 只是可能没有那么明显。老师对学生的阅读能力, 与同学相处情况的印象, 以及学生家长对学生学业成就的关注等全部都是比较粗略的判断。医生对学生健康状况的评估, 社工对其家庭环境的表述, 都只是主观、接近但不完全的指标。在做决定的时候, 我们常常依赖有缺陷的片面信息, 测试分数也是不完美的。测试分数的好处在于它通常比其他信息更加客观, 其可靠性可以进行研究和量化。

(6) 承认人类智慧的有限性及保持对决策依据的怀疑性

虽然做决定常常要依据有缺陷的片面信息, 但是还是得做出决定。我们依靠自己具有的智慧和掌握的信息尽可能做出最好决定。对某个儿童进行教育的决定, 只需要暂时关注课程就可以了, 可以依据长期进程追踪项目的新信息来改变教学课程的方向。其他教学决定——比如学生决定上数学选修课, 因其想以后学工程专业——对未来会有一些影响。要意识到这些决定中的初探性, 新证据和信息的出现很可能会改变方向。某些决定就没那么容易更改了, 很可能会带来永久影响。对于所有决定, 无论做决定的时候参考了多少测试数据, 都有可能出现偏差。

## 8.12 总 结

对特殊人群进行测试的主要目的是找出哪些人群需要帮助, 判断什么样的课程安排可以满足他们的需求, 对帮助项目的效度进行监测。不同教育心理领域的很多测试措施都可以用来完成这些目标。一些标准测试, 比如智力、学业成绩、适应性行为和神经心理功能等测试可以为决策提供必要信息。一些新兴的测试方式, 比如基于课程的测试和生态评估, 体现了针对特殊人群测试的进步, 在心理教育领域为很多专业人士所采用。这些测试得出的数据可以用于各类和人有关的决策, 有时候会带来深远的影响, 所以在使用测试分数时, 要确保其有效而可靠, 提供相关服务的人要严格遵守相关标准。另外, 测试分数可以协助更好地进行决策, 造福个人和社会, 所以使用数据时要明智谨慎。

## 8.13 习 题

1. 请列出本章介绍的三项对特殊人群影响最大的立法, 并进行简要介绍。每项法案的主要特色有哪些?

2. 关于针对少数文化群体标准化测试的法律问题, 有两例非常著名的法庭案例: 拉里等诉威尔逊 - 罗宾等和特殊教育行动组织家长诉汉农。它们为什么重要以及二者结果有何不同?

3. 对于有残障的儿童和青少年, 为其提供特殊服务时, 从移交到项目的执行和评估, 请列出和简要解释其中的过程。评估测试位于其中的哪一步?

4. 在对母语非英语的学生进行评估时, 需要进行哪些步骤, 列出步骤并简要说明。对于这些学生群体来说, 要进行有效测试, 有哪些主要挑战?

5. 在多维度测试系统中, 标准质量测试扮演了什么样的角色? 请列出当前学校最常用的两种智力测试。

6. 对于可能存在情感障碍的儿童进行的多维度测试和针对传统学业障碍的测试有哪些区别?

7. 学生在学业成绩上最有可能在哪三种领域出现问题, 列出这三种领域并进行描述。本章提到的这三个领域, 哪一个是移交特殊教育最常见的原因? 你觉得为什么会这样?

8. 课程评估和生态评估之间有什么区别, 为什么课程评估是更为传统的测试措施? 课程评估和环境信息如何对常模参照测试结果进行补充?

## 推荐 阅 读

Browder, D. M. (2001). Curriculum and assessment for students with moderate and severe disabilities. New York: Guilford.

Flanagan, D. P., Andrews, T. J., & Genshaft, J. L. (1997). The functional utility of intelligence tests with special education populations. In D. P. Flanagan, J. L. Genshaft, & P. L. Harrison (Eds.), Contemporary intellectual assessment: Theories, tests, and issues. New York: Guilford.

McLoughlin, J. A., & Lewis, R. B. (2008). Assessing students with special needs, 7 th edition. Upper Saddle River, NJ: Pearson.

Merrell, K. W. (1999). Behavioral, social, and emotional assessment of children and 294

adolescents. Mahwah, NJ: Erlbaum.

Safford, P. L., & Safford, E. J. (1996). A history of childhood and disability. New York; Columbia University, Teachers' College Press.

Salvia, J., & Ysseldyke, J. E. (2000). Assessment (8th ed.). Boston, MA: Houghton Mifflin.

Sattler, J. M. (2001). Assessment of children: Cognitive applications (4th ed.). San Diego: Author.

Sattler, J. M. (2002). Assessment of children: Behavioral and clinical applications (4th ed.). San Diego: Author.

## 第9章 测试开发原则

## 9.1 引 言

前几章我们讨论过一个好的测试应具备的特征, 那么这些特征是如何实现的呢? 该怎样编写试题才能较好地测试出成绩或认知能力呢? 本章我们就来探讨一下编写衡量成就及能力的优秀测试题所需要的一些原则。这些原则既适用于教师为评估学生成绩准备的测试, 也适用于标准化测试, 而两者的唯一不同之处在于所用的资源。 第十、十一和十四章将介绍一些对于表现评估编制的建议, 态度及观点测量, 兴趣、个性及适应性测量。

在第五章介绍效度的一节中, 我们考察了测试应涵盖范围的定义。本章我们假设准备测试方案的任务已经达成, 且已知我们需要的试题类型及每一类型应该准备多少题目。我们的论述将集中于用第五章所给测试方案里的客观题来测试成绩, 不过一般性原则同样适用于编写第十二、十三章里阐述的认知能力测试。由于客观测试是标准化测试项目中最广泛使用的形式, 也是教师们喜欢的形式, 因而我们将关注编写及分析这些测试的题目, 即让考生从一些备选答案中选出最佳答案。本章结尾将提供一些编写优秀论述题的指南。

## 9.2 编写客观题的一些建议

## 1. 客观题的一般原则

本小节我们将讨论适用于编写所有类型客观试题的建议, 通常被称之为选择一回答题。这些原则中的许多也同样适用于论述题及其他题型, 考生在做这类题目时须自行作答。编写阐述一回答题的特殊事项将在本章末探讨。

① 测试题的阅读难度及词汇水平应尽量简单。最好避免出现复杂句子结构或不必要的生僻词汇, 不然学生就很难展现他们对试题内容的理解, 而这一点才是试题所要评估的对象。我的一位学生在一场大学课程考试中就因为不知道 “随后的”296(subsequent)一词的意思而丢了这一题的分。如果这门课强调专业词汇的学习, 且以掌握该词汇为教学目标之一, 那么出现该词汇也情有可原, 不过还是要避免一些晦涩的词汇。下面这个例子是为八年级学生编写的, 题目既冗长又复杂, 其中的一些词语, 如混杂的 (promiscuous)、恶毒的 (pernicious) 、有毒的 (deleterious) 等对该年级水平的学生而言完全超纲 (每个例子中标下划线的为正确答案, 判断正误题中字母: \( \mathrm{T} \) 表示正确,字母 \( \mathrm{F} \) 表示错误)。

例:

差题: 患急性感冒时, 混合使用鼻腔喷雾、润滑油及抗生素是危险的, 因为这会对(   ) 产生有害作用:

A. 鼻窦

B. 红细胞

C. 白细胞

D. 嗅觉神经

好题: 以下哪一项可能是由重感冒时频繁使用鼻腔喷雾、润滑油及抗生素导致的后果?

A. 鼻窦感染

B. 损害嗅觉神经

C. 破坏白细胞

D. 鼻腔黏膜充血

② 确保每一题都有专家认可的唯一正确答案或最佳答案。通常, 有争议的题目不是好的客观题, 尽管有时了解一下争议问题上存在的不同观点可能也很重要。在这种情况下, 题目就应该清楚阐明以哪种观点或哪种权威为基础产生答案。学生不应被迫支持某种观点为不容置疑的事实。如果测试目标是要求学生收集证据支持或反对一个有争议的话题, 那么合适的测试方式应该是论述题。

例:

差题: \( \underline{T}F \) 酗酒是一种病。

好题: \( \underline{T}\mathrm{\;F} \) 根据教材所述,酗酒是一种病

③ 确保每一题针对内容范围的一个重要方面, 而非全是细枝末节。有时老师和其他出题人会通过设置隐晦或琐碎的细节题来增加试题的难度, 比如脚注内容或图表中的孤立事实。下面第一个例子是八年级的卫生课考题, 要求答出细节, 而这种知识对八年级学生的卫生认识水平不可能产生什么影响。第二个例子是从教科书里搬来的, 几乎没什么重要性。任何学生不管熟不熟悉课程内容都会知道题目是正确的。 唯一一种选错的可能性就是觉得答案太明显了,肯定是道陷阱题。

例 1 :

差题: 2005 年, 所有类型事故死亡率中, 每 10 万人中 15-24 岁人群占多少比例?

A. \( {59.0}\% \)

B. \( {59.1}\% \)

C. \( {59.2}\% \)

D. \( {59.3}\% \)

好题: 2005 年, 15-24 岁人群中导致死亡的首要原因是:

A. 呼吸道疾病

B. 癌症

C. 事故

D. 风湿性心脏病

例 2 :

差题: \( \underline{T}F \) 处方药制药是一项高科技含量的行业。

④ 确保每一道题都是独立的。任一题的答案不应成为回答下一题的条件。每位学生在每一题上都应有公平的机会。在下面这个例子中, 不知道第一题答案的人就不太可能回答出第二题, 除非碰运气猜对。

例:

差题:

1. 坏血病是由于缺乏以下哪种东西导致的?

A. 维生素 A

B. 维生素 \( {\mathrm{B}}_{1} \)

C. 维生素 \( {\mathrm{B}}_{12} \)

D. 维生素 C

2. 这种维生素的丰富来源是:

A. 橙汁

B. 鱼肝油

C. 肝

D. 大米

同时还要确保一道题目中不含有另一道题目的答案。比如, 如果第二题的题干是“维生素 \( \mathrm{C} \) 的丰富来源是”,且两题顺序颠倒,那么很可能许多学生就会猜出坏血病病因的正确答案。如果一定要出这两题, 可以把它们放在不同页上, 以此减少其中一题对另一题的影响。如果一道题目需要一系列步骤来解答, 那么避免题目间影响, 同时仍然能使用 “选择一回答题”形式测出学生对步骤掌握的方法便是让学生答出第一步, 然后在另一处解答第二步或后面的几步。这样, 第二步的作答就不依赖于第一步回答正确了。

⑤ 避免使用陷阱题。当客观题要求学生从一个句子中选出一个与句意完全不同的单词或数字来, 它就成了陷阱题。在下面的差题中, 题目答案定为错误, 因为白喉的免疫剂不是类毒素就是抗毒素, 而不是疫苗。但是, 题目又包含了一层意义, 即考查学生对抗白喉免疫程序效度的了解。如果该题意在测试学生是否了解疫苗一词的正确用法, 那题目最好改成第一种好题, 而如果该题意在测试学生对上世纪白喉死亡率下降的了解, 那么最好改成第二种好题。陷阱题很有可能误导好学生, 因为他们关注整个题目的意义而不是核对每个单词的含义。

例 :

差题: \( \mathrm{T}\mathrm{F} \) 白喉疫苗的使用导致 20 世纪该病死亡率下降。

好题: \( \mathrm{T}\underline{\mathrm{F}} \) 用于防治白喉的免疫剂成为疫苗。

好题: \( {TF} \) 免疫措施导致 20 世纪白喉死亡率下降。

⑥ 确保题目清楚无歧义。这是一条一般性忠告, 就像“走吧, 从现在起不要再犯罪了”那样, 可能根本不起作用。但是, 题目及意义模棱两可是客观测试题中最普遍的错误, 这一点很明确。让我们看一下这个问题的两个例子。

例 1 :

差题: \( \underline{T}\mathrm{\;F} \) 糖尿病在 40 岁以后发病。

这一题参考答案为正确。然而, 这句话什么意思呢? 是说人只有在 40 岁以后才会得糖尿病还是 40 岁以后糖尿病发病率大呢? “发病”这个词在这里是什么意思呢? 你可以获得有关不同年龄的人被诊断出患糖尿病的相对频率数据, 但诊断出患病的时间和发病的时间并非同一回事。出题人又是指的哪一种糖尿病呢: 糖尿病? 尿崩症? 其他病症? 像这种题目很可能难住懂得多的好学生而不是懂得少的差学生。这一题没法修改, 不应该出现在测试中。

例 2 :

差题: 下面哪一种物质是人类最必需的?

A. 蛋白质

B. 水

C. 维生素

D. 矿物质

本题参考答案是 \( \mathrm{B} \) ,但上述所有物质都是人类必不可少的。回答这一题,考生应猜测出题人所写“最必需”的含义。在本题中, 出题人试图考查学生是否知道健康人没有食物可以活较长时间, 但不补充身体流失的水却只能活几天。修改后的试题就很清晰地对这一知识点进行了测试。

例 2 , 修改后

好题: 一个健康人被困在一座废弃的岛上, 为了生存, 这个人必须立即找到:

A. 维持体细胞的蛋白质

B. 饮用水

C. 维持身体新陈代谢的维生素

D. 提供能量的碳水化合物或脂肪

记住这六大基本点, 我们就可以转向客观测试常用的不同题型编写指导原则。

## 2. 编写判断正误题

判断正误题受欢迎的主要原因是评分客观、结构简单。在一张试卷中, 这种题型的数量也可比其他题型多。尽管有众多优点, 但判断正误题并不被测试专家视为评估学生成绩的理想方式, 因为很难编写出难易适当或不那么模棱两可、充满陷阱、測量效果差的题目。这种题型仅适合一小部分测试目标, 除非完全不重要, 不然没有哪种陈述是毫无疑义地正确或错误的。

判断正误题最适合考察确定型知识——比如, 细菌要么是病原菌要么是非病原菌, 疾病要么是可传染的要么是不传染的。围绕这种知识可以设计判断正误题。但任何领域只有一小部分知识是这种类型的, 且大多数完全符合的知识都不太重要。 由于这种题型的陈述通常独立出现, 没有参照系, 因而判断正误很困难。若要提供足够的语境消除歧义的话, 通常就会导致题目太长, 增加阅读负担。

另一个问题就是学生靠猜测也有 \( {50}\% \) 的回答正确率。因为这一点,该题型对学生知识的考查所获取的信息精确度就不如其他客观题高。因此就需要编写大量题目来对每个学生的能力做出精确的评估。

(1)好的判断正误题编写建议

尽管判断正误题型有很多限制, 且不建议出这种题, 但若坚持要出的话, 还是有些规则能用来编写出较好的判断正误题。判断正误题很少出现在专业性测试中 (但是, 注意第十三章描述的爱荷华州基础技能测试中的低水平阅读测试就是个例外)。

① 确保题目肯定非正即误。每个陈述应达到专家们一致同意的正确或错误程度。许多陈述就是因为知识丰富的学生能举例证明为什么该陈述是正确的或错误而导致问题出现。请看以下例子:

例 :

差题: \( {TF} \) 青霉素是治疗肺炎的有效药物。

好题: \( \underline{T}\mathrm{\;F} \) 青霉素是治疗链球菌性肺炎的有效药物。

尽管第一种出题的答案是正确, 但对青霉素了解很深的学生知道这种抗生素对治疗某些肺炎比对其他肺炎效果好。这样的学生可能会觉得这句话错误, 因为它并非在任何情况下都一样正确。修改后的句子就没有歧义。

② 避免使用某些限定词或描述性陈述。含有一切、从不、没有、总是及其他全包词语的句子体现的一般性很广泛, 因而有可能是错的。含有通常、有时、在某些情况下, 以及可能的限定性语句则有可能是正确的。善于考试的考生懂这个规律, 会利用这种线索得分, 尽管他们并未掌握所测试的知识, 因而降低了测试分数对于评估知识掌握情况的可信度。

例:

差题: \( \mathrm{T}\underline{\mathrm{F}} \) 所有细菌都会致病。

好题: \( \underline{T}F \) 病原菌是寄生菌。

③ 避免使用模糊不清的和非限定性的程度副词或量词。诸如经常、极大地、在很大程度上及在大多数情况下等表述在每个人看来具有的意义并不一样。当学生去猜测出题人心里的答案时, 测试结果就可能不准且令人失望了。在下面的差例中, 学生可能会因经常一词困惑, 因为干燥作为一种保存食物的方式如今只广泛用于某些水果的保存。

例:

差题: \( \underline{T}F \) 干燥经常用于保存食物。

好题: 工 F 水果可干燥保存。

④ 避免使用否定句, 尤其是双重否定句。回答一个否定句题目所需要的时间比回答同一个题目但用肯定句陈述的时间多, 这一点许多年来都是众所周知的事 (Wason,1961; Zern,1967)。另外,在回答否定形式的题目时犯错也会增多。也就是说,学生很可能因为不解措辞而不是因为没掌握相关知识而错失分数。

沃森 (Wason) 和塞恩 (Zern) 都使用了成对的句子, 比如 “36 不是偶数” 和 “36 是奇数”。否定句需要倒过来推理一下才能理解其中的意思, 句法上更难一点。此外, 学生在考试的时限压力下很容易忽略否定词。双重否定在理解上带来的问题更大。

例 1 :

差题: \( \mathrm{T}\mathrm{F} \) 通过接种天花疫苗获得对天花的抵御能力不叫主动免疫。

好题: \( \mathrm{T}\mathrm{F} \) 通过接种天花疫苗获得对天花的抵御能力叫作被动免疫。

例 2 :

差题: \( {TF} \) 肺结核不是非传染性疾病。

好题: \( {TF} \) 肺结核是传染性疾病。

⑤ 判断正误题的题目仅限表达一层意思。如果复杂的题目句包含不止一层意思则很难读懂。一句既包含正确意思又包含错误意思的句子通常不合适, 因为这很可能考验更多的是应试技巧而不是对目标知识的掌握。如果学生只需注意句子的一部分并判断正误, 那就可以用复杂句子。

例:

差题: \( \mathrm{T}\mathrm{F} \) 牙龈出血与牙龈炎有关,患者可通过每日刷牙治愈。

好题: \( \mathrm{T}\underline{\mathrm{F}} \) 每天刷牙可治愈牙龈炎。

⑥ 判断正误题的题目长度大致相当。正确的句子似乎总是倾向于比错误句长。 一般来说, 正确句子较长是因为出题人需要写明条件与限制来使句子毫无疑义地绝对正确。偶尔出现长的正确句子也没关系, 只要同时配上长的错误句, 或者两种句子在长度上并非总是不同。

⑦ 正确句与错误句的数量大致相同。老师有时会出更多正确句, 因为他们担心学生会记住错误句, 从而掌握了错误的知识。当学生发现这种规律并开始把自己存疑的句子都回答正确时, 问题就产生了。

(2)判断正误题型的变形

有些判断正误题型的变形是用来改进这种题型的。大多数变形意在达到以下一个或多个目标: 减少题目歧义; 减少猜题对得分的影响; 提供有关学生知识掌握情况更具体的信息。以下是四种最常使用的变形。

① 划出句中的一个单词或从句。这种变形是最简单的一种, 通过使考生集中注意句子中最重要的部分, 以减少歧义。

例:

1. \( {TF} \) 疟疾是通过按蚊叮咬传播的。

2. TF 食物冷冻后, 其中的有害细菌就会死亡。

题目应清楚指出学生应判断与句中其他成分有关的划线部分的正误。划线的方法也可以在复杂句中使用。

② 要求学生改正错误句。正确答出句子错误的学生很可能是碰巧猜对, 或是根据错误的信息选了正确的答案。比如, 这一句“胰岛素是由脑垂体分泌的”, 学生可能觉得是错的, 认为胰岛素是由肾上腺分泌的。在这种情况下, 错误的信息就导致了正确的答案。为确保学生知道错误句错误的原因——减少猜测影响——就得让考生改正所有他们认为是错误的句子。上述例子可通过把 “胰岛素” 改成一种脑垂体激素, 或把 “分泌” 改成 “不分泌”, 或把 “脑垂体” 改成 “内分泌腺” 或 “胰腺”。由于有很多方式把错误句子改对, 因而建议如果要用这种变形的话, 划出所有句子中的关键字词, 不管正确与否。划线部分应该是老师意在评估的特定内容。因此, 在本例中, 若老师想确定学生是否知道脑垂体分泌的激素名称, 就该在 “胰岛素”一词下划线。同样地, 若老师想确定学生是否知道分泌胰岛素的腺体, 就该在 “脑垂体”一词下划线。

③ 以学生专用的具体启发材料为基础设计判断正误题。判断正误题若以具体启发材料为基础会非常有效有用, 比如图表、地图、图形或阅读段落。在这种情况下, 考生根据给定材料答题, 能获得更明确的参照系。这种判断正误题可被有效利用来评估学生的理解、阐释、推算及逻辑推理能力, 只要使用合适的启发材料, 且设计的题目意在考查上述能力。举例如下:

例

说明:下列饼图显示了花在医疗保健上每一美元的具体情况。仔细查看此图, 回答后面的问题。







仔细阅读下面每一句话。若符合图中数据, 选 T; 若与图中数据矛盾或无关, 选 \( \mathrm{F} \)

(T) 1. 医生服务上花费的医疗保健费用比其他所有类别多。

(F) 2. 美国人很少有健康保险。

(F) 3. 美国人每一美元里有 24 美分花在医药及医疗仪器上。

(T) 4. 医院及医生服务加起来占所有医疗保健花费的一半多一点。

(T) 5. 牙医上花的钱比医生服务上花的钱少。

(T) 6. 约 \( {25}\% \) 的医疗保健花费用于医院服务。

这种题型有时会出得更复杂, 要求学生在四五种答案范围里面选, 比如绝对正确、可能正确、数据不足无法判断、可能错误及绝对错误。这种题型就成了选择题而非判断正误题。

④ 将多个短的判断正误题归在同一题干或问题下。以下是这种变形题的两个例子。

例:

说明: 在正确答案选项前写 \( \mathrm{T} \) ,错误答案选项前写 \( \mathrm{F} \) 。

A. 下面哪种病由病毒所致?

(T) 1 . 水痘 (T) 5 . 麻疹

(F) 2 . 白喉 (T) 6 . 腮腺炎

(T) 3 . 流感 (F) 7 . 肺结核

(F) 4 . 疟疾 (F) 8 . 伤寒

B. 一个 14 岁的女孩 24 小时内吃了以下食物:



<table><tr><td>早餐</td><td>午 餐</td><td>晚餐</td></tr><tr><td>一杯清咖啡</td><td>一杯可口可乐 (8 盎司)、小圆面包汉 堡 (4 盎司)、炸薯片 (20 片)</td><td>烤牛肉 (9 盎司)、土豆泥 (半杯)、 1 杯牛 奶 (8 盎司)、苹果派 (1 片)</td></tr></table>



请问她的膳食中缺乏下面哪些物质?

(T) 1 . 钙 (F) 5 . 烟酸

(F) 2 . 卡路里 (F) 6 . 蛋白质

(F) 3 . 碳水化合物 (T) 7 . 维生素 \( A \)

(T) 4 . 铁 (T) 8 . 维生素 C

这种变形题看起来像选择题, 但学生的任务是判断每项选择对于原问题来说正误与否; 因此, 这基本上还是判断正误题。这种变形题能有效测试简单的知识应用能力, 以及对分类或属性知识的掌握, 对深入测试一个题目的具体某方面尤为有效。该题型减少了学生的阅读负担, 问题作为判断正误的一个参照系, 消除了题干的歧义。304这种方法的另一种形式就是让学生在正确句子前打勾, 其余不做标记。

## 3. 编写多项选择题

选择题是最灵活的客观题型, 可用于评估用纸笔测试考查的任何教育目标类成绩, 但与书面表达、原创能力及组织答案能力技巧相关的成绩除外。聪明有才的出题人出的选择题不仅需要学生想起学过的知识, 还要求运用理解、阐释、应用、分析或综合能力来获得正确答案。遗憾的是, 并非所有选择题都很有质量, 因为写出好的选择题需要大量时间和技巧。选择题的一大重要特点是, 单一选项可以被改变或替换。 出题人可以通过改变干扰项来灵活调整试题难度。考试便可设置最佳难度水平, 从而最大程度地区分考生的知识水平。

选择题包含两方面: 呈现问题的题干及一列选项。标准的选择题中, 只有一个选项是正确的或最佳的答案, 其他都是陪衬或干扰项。题干可能以问题或不完整的句子呈现。题干形式似乎对题目的整体效度没有影响, 只要题干体现了一个清晰而具体的问题。

不同测试中选择题的选项数量不同, 也没有原因表明同一场测试的选择题不能有不同数量的选项。一道题必须有至少三个答案选项, 才能称之为选择题, 典型的选择题有四个或五个答案选项, 以减少猜中答案的可能性。选择题的选项数量与有效选项数量之间要有明显的区分。下面的差例选自八年级卫生测试, 说明了内容的效度问题。该题实际上是个二选题, 因为没人会选 A 或 D。修改后的题目仍然是四个选项,但却更符合四选题规范,因为 \( \mathrm{A} \) 和 \( \mathrm{D} \) 都更加合理。

例:

差题: 一个身高 157 厘米、体重 47 千克、中等活跃的 14 岁女孩每天建议摄入多少卡路里?

A. 0

B. 2000

C. 2500

D. 30000

好题: 一个身高 157 厘米、体重 47 千克、中等活跃的 14 岁女孩每天建议摄入多少卡路里?

A. 1500

B. 2000

C. 2500

D. 3000

修改后的题应该比原题更难, 因为选项数值更接近, 那些不知道答案的人就得在四个而不是两个选项里猜。

选择题的难度取决于题目所要求的认知过程, 以及选项的接近程度。看下面例子里的三道题, 都跟强化食品一词的意思有关。我们可以预测出第一个版本相对简单一点, 第二个版本有点难, 第三个版本更难。在第一版中, 题干直接照搬教科书中强化食品的定义, 干扰项也不是表明给食物增加营养的词语。第二版与第一版的差异在于, 第二版的题干将教科书里的定义改成一种新形式, 需要不同于第一版的思维过程。第三版与第二版之间的差异在于选项之间的接近程度不同。

例 :

1. 往天然食物里加入其原本没有的营养物质, 该食物便被称为:

A. 强化食品

B. 加工食品

C. 灭菌食品

D. 精制食品

2. 在供销售的加工牛奶中加入每 0.95 升至少 400U. S. P. 单位的维生素 D 浓缩物, 那么纸盒上就可以标明此牛奶是:

A. 强化食品

B. 加工食品

C. 灭菌食品

D. 精制食品

3. 在供销售的加工牛奶中加入每 0.95 升至少 400U. S. P. 单位的维生素 D 浓缩物, 那么纸盒上就可以标明此牛奶是:

A. 强化食品

B. 浓缩食品

C. 辐照食品

D. 再生食品

(1)改进多项选择题出题质量的建议

编写好的测试题需要足够的时间、适当的计划、遵守一套公认的出题规则, 以及多加练习。商业测试出版商有好多组经验丰富的出题人, 能编出大量高质量的测试题, 比如 ACT 测试和 SAT。但独立的教师和研究员经常需要自己准备选择题。我306们无法帮你及时编写或计划编写测试题, 但如果你使用下面这些好选择题编写规则, 那么就能改善你所编写的测试题。

① 确保题干清楚阐明问题。题干应让考生在阅读答案选项前清楚地明白所问的问题。看下面的差例。当你读完题干时只知道题目与胰腺的某一方面有关。直到读完选项后你才明白问题是什么。提供的答案选项内容也异质;一个与结构有关,一个与功能有关, 一个与持久性有关, 一个与位置有关。该差题只能说是四道判断正误题, 只不过有共同的题目短语 “胰岛细胞”。修改后的题目不仅题干清楚地呈现了问题, 而且答案选项的内容也同质。

例 :

差题: 胰岛细胞:

A. 含管道。

B. 产生胰岛素。

C. 随着年龄增大而消失。

D. 位于胰腺边缘。

好题: 胰岛细胞分泌的物质称为:

A. 胰蛋白酶。

B. 胰岛素。

C. 色氨酸。

D. 肾上腺素。

② 在题干中尽量包含更多信息, 选项尽量短。为了节省空间和阅读时间, 以及清楚地阐述问题, 尽量注意措辞及句式安排, 使答案选项相对短一点。如果同样的字词短语在所有或大部分选项里面重复了, 就像下面的差例中一样, 则改写题干使其包含重复内容。长的答案选项经常出现的原因就是没能在题干中清楚地阐述问题。

例:

差题: “空卡路里”的食物指的是:

A. 必需营养物质很少而热值很高的食物

B. 既无必需营养物质又无热值的食物

C. 营养价值和热值都很高的食物

D. 营养价值很高但热值很低的食物

好题: “空卡路里” 是指具有以下何种特征的食物:

A. 营养物质少, 热量高

B. 营养物质和热量都很低

C. 营养物质和热量都很高

D. 营养物质高, 热量低

③ 题干中只包含使问题清楚具体所需要的内容。用词很多而内容又与问题无关的长题干会降低测试的效度和效率。首先, 无关紧要的内容增加了阅读负担, 从而更难将阅读的一般技巧与对主题的了解分开。其次, 过多的内容增加了阅读时间、缩短了回答时间, 使测试效率低下, 因为在给定测试时间内, 可出的测试题就更少了。 下面例子里的前三句话很明显对于向考生明确问题是多余的。

例:

差题: 一种细胞属于具有某种特定功能的特殊小组。我们称这种细胞组为组织。 我们所有人体内都有不同种类的组织。下面哪一种组织称为上皮组织?

A. 肌腱

B. 腺样体和扁桃体

C. 黏膜

D. 软骨组织

好题: 下面哪一种组织称为上皮组织?

A. 肌腱

B. 腺样体和扁桃体

C. 黏膜

D. 软骨组织

如果测试目的在于评估考生是否能将解决问题或支持论点所必要的数据与无关紧要或不相关的数据区分开来, 那么出题人就得将额外数据添加进问题里面。在这种情况下, 额外内容就对测试过程很重要了, 因此便不是不相关内容。

④ 题目少用否定句。就像判断正误题一样, 否定形式的选择题增加阅读难度, 需要学生完成更难的推理任务。否定题对于考生知识掌握情况提供的信息也很少。

有时测试一下考生是否知道一般规则的特殊情况或是否能发现错误还是很重要的。为了达到这些目的, 题干中出现不或除了也情有可原, 尤其是当过度包含内容成为一种常见错误时。当题干中出现否定词时, 应该加下划线或大写以引起考生的注意。

下面的差例意在考量学生是否知道半规管的功能, 但题干并未考量学生这方面的知识。修改后的例子更直接地考量了这一目标。第二个好题否定形式用得好一308点, 原因有两个: 第一, 学生关于食品和药物管理局 (FDA) 的职责犯的最常见错误是把农业部的肉类检测职能归为 FDA 的职能; 第二, 如果题干用肯定陈述句, 就很难获得三个可行的误导选项。

例:

差题: 下面耳朵的何种构造与听力无关?

A. 鼓膜

B. 卵圆窗

C. 半规管

D. 耳蜗

好题: 1 . 下面哪个耳朵构造帮助保持平衡?

A. 鼓膜

B. 卵圆窗

C. 半规管

D. 耳蜗

2. 那面哪项活动不属于美国食品和药物管理局的职责?

A. 检查跨州运输的食品仓储情况

B. 检查跨州运输的肉类的屠宰场

C. 提起诉讼, 将不健康食品从市场上下架

D. 检测跨州销售的食品样本

⑤ 使用新材料设计问题, 考查学生对原则应用的理解或能力。大多数当地编写的测试太过重视死记硬背而忽视了考查信息应用的能力。选择题很好地考查了简单的知识回忆, 但若不仅仅需要死记硬背来回答问题的话, 就得向考生展示一个新的语境。前面评估强化食品知识的第二和第三个例子说明了如何摆脱材料原本的形式, 以测试考生的理解能力而非简单的回忆能力。下面所给两个例子, 意在说明如何设计题目以评估学生信息应用的能力。

例:

死记硬背 1 : 下面哪种食物在人体内新陈代谢时产生的卡路里最多?

A. 1 克脂肪

B. 1 克糖

C. 1 克淀粉

D. 1 克蛋白质

灵活应用: 下面哪项若从日常膳食中去掉导致的卡路里减少量最多?

A. 1 匙黄油

B. 1 匙白砂糖

C. 1 匙土豆泥

D. 1 个煮鸡蛋

死记硬背 2 : 肺炎和流感致死的情况最常见于:

A. 婴儿和老年人

B. 婴儿和小学生

C. 青少年和老年人

D. 青少年和青壮年

说明: 请看下图,图中显示的是不同年龄段 \( \mathrm{X} \) 疾病导致的死亡率。







下面哪种病可能是 \( \mathrm{X} \) 疾病?

A. 肺炎

B. 癌症

C. 肺结核

D. 心脏病

注意必须用一个不出现在答案选项中的字母指代这种疾病。

6 确保有且仅有一个正确或最佳答案。在典型的选择题里, 考生只能选一个答案。若要考生选择一个最佳答案, 出题人每一题只能提供有且仅有一个最佳答案。 尽管看起来很容易做到, 但某些地方编写的测试有很多选择题要么有两个或以上好的答案,要么一个答案也不好。在下面的例子中, \( \mathrm{B} \) 选项被定为正确答案,但 \( \mathrm{C} \) 和 \( \mathrm{E} \) 选项也有很大的正确性。修改后的版本则消除了这一缺陷,但题目可能就变得太简单了。

例 :

差题: 一个色盲症男孩的遗传基因来自:

A. 父亲

B. 母亲

C. 外祖父或外祖母

D. 祖父或祖母

E. 远祖

好题: 一个色盲症男孩的遗传基因最可能来自:

A. 父亲

B. 母亲

C. 父亲和母亲

D. 祖父

E. 祖母

除了要确保有且仅有一个正确答案, 出题人还应该确保标准答案毫无疑问是最佳的。出题人有责任运用其最好的学识及出题技巧来编写出业内专家一致认同的题日和答案。

⑦ 确保错误答案是合理可行的。选择题的一大主要优点在于要求考生从三个、 四个或五个选项中选出一个正确答案, 从而减少了猜中答案的概率。但是, 错误选项必须能引起缺乏所要考查知识的学生的注意。因此, 错误选项应该在逻辑上与题干一致, 且代表了特定年级或特定水平学生所犯的常见错误。

在下面的第一个差例中, \( \mathrm{A} \) 和 \( \mathrm{C} \) 选项是合成物,而不是元素,因而与题干不一致。第二个差例中, \( \mathrm{C} \) 和 \( \mathrm{D} \) 选项明显不合理。

例 :

差题: 下面哪种元素存在于蛋白质而非碳水化合物或脂肪中?

A. 二氧化碳

B. 氧

C. 水

D. 氮

差题: 食物氧化后在细胞中产生气体并被带入肺部排出的是:

A. 氧气

B. 二氧化碳

C. 氦气

D. 氯气

设计合理的干扰项, 尤其是在考查定量概念和技巧的题目中, 有一个好方法, 那便是明确学生在分析或解决问题过程中犯错误时可能会得到的答案。有时用这种方法可能发现学生在掌握知识或程序上的具体不足。

⑧ 确保不要无意识地透漏关于正确答案的线索。缺乏经验的出题人经常会透露正确答案, 或给出线索使考生能排除一个或多个错误选项。含有无关线索或特定限定词、比错误选项长的正确答案、或题干与选项的语法不一致的题目常常会比没有这些缺点的题目更简单。如果考生发现这些线索的能力有差异的话, 那么题目考查的东西就变了, 测试的效度也会打折扣。

下面是一些无意间给出的线索类型。第一题是 “谐音联想”, 即在给定答案和题干中重复单词词组或语音。第二题含有限定词 “从不” 和 “总是”, 效果和判断正误题相同。第三题的给定答案比其它选项长得多。第四题是语法不一致; 题干中的“一个”暗示了单数词,但 \( \mathrm{A} \) 和 \( \mathrm{C} \) 选项都是复数词。修改后的题目则显示了如何修改这些错误以使题目更有效地考查学生的知识而非应试能力。

例:

谐音联想

差题:

1. 血小板的功能是帮助:

A. 向细胞输送氧气。

B. 向细胞输送食物。

C. 使血液凝固。

D. 抵抗疾病。

好题:

1. 下面血液中的哪种结构有助于凝血?

A. 红细胞

B. 淋巴细胞

C. 血小板

D. 单核细胞

限定词

差题:

2. 下面哪项是厌氧细菌的特征?

A. 从不生活在土壤中。

B. 没有氧分子也能生存。

C. 总是会导致疾病。

D. 能进行光合作用。

好题:

2. 厌氧细菌不同于其他细菌的特征是它们能:

A. 忍受极端的温度变化。

B. 不需要氧分子存活。

C. 要么作为腐生菌, 要么作为寄生菌生存。

D. 在活细胞或无机培养基里繁殖。

长度线索

差题:

3. 药物的 “副作用”指的是:

A. 药物的额外好处。

B. 药物作用的连锁反应。

C. 药物对犯罪的影响。

D. 非医生希望药物所起作用之外的其他作用。

好题:

3. 一个患重感冒和低烧的人每 3 小时服用两片阿司匹林, 可能会产生以下哪种副作用?

A. 正常的体温

B. 咳嗽缓解

C. 呼吸通畅

D. 耳鸣

语法不一致

差题:

4. 青霉素提取于一个:

A. 细菌。

B. 霉菌。

C. 煤焦油。

D. 热带树木。

好题:

4. 青霉素提取于:

A. 细菌。

B. 霉菌。

C. 煤焦油。

D. 热带树木。

⑨ 只有当给定答案毫无疑问正确或错误时才能用 “这些全不对” 或 “以上全不对”。对于这种选项, 经验丰富的出题人可以用在拼写、算数及学习技巧测试上。在这些测试类型中可以给出绝对正确的答案。在其他测试类型中, 学生要选出最佳答案, 且给定答案是最佳答案, 但不一定要完全正确, 因而使用 “这些全不对” 或 “以上全不对” 是不合适的。

如果题干是一个问句而非不完整的句子, 那么使用选项 “以上全不对” 效果比较好。不完整的句子则不太可行, 因为 “以上全不对” 很少在语法上匹配题干。下面这个十年级生物测试题就说明了这一点。

例:

差题: 下面绝对不是植物茎部功能的是:

A. 传导。

B. 光合作用。

C. 支持。

D. 食物储存。

E. 以上全不对。

选项 “以上全不对”不仅在语法上与题干不一致, 而且逻辑上也不一致。选项 E 并没有说出植物的功能, 双重否定和题干中的 “绝不” 也使题目理解更困难。根本没有办法修改这一题, 因为有些植物中所有功能都是由茎部完成的。

如果在需要定量解答的题目或拼写测试中使用 “这些全不对” 的选项, 则用作正确选项与干扰项的频率应该相当, 且题干应为问句。在这种测试里, 该选项若作为正确选项出现在测试开始的简单题目里最有作用, 更加说明 “以上全不对” 有时是正确答案。

下面的例子反映了数值题目中不当使用 “以上全不对” 选项的情况, 因为选项只给了近似值而非确切值。选项 \( \mathrm{B} \) 是给定的正确答案,但选项 \( \mathrm{E} \) 更好,因为成年人的平均血容量预计在 4730 毫升到 7568 毫升之间。此外, 这一题评估的知识在大多数情况下是无关紧要的。

例:

差题: 一个一般体重的普通成年人有多少毫升血容量?

A. 1419 毫升

B. 6149 毫升

C. 14190 毫升

D. 23650 毫升

E. 以上全不对

好题: 一个健康成年人体重的多大比例是血液?

A. \( 3\%  - 5\% \)

B. \( 8\%  - 9\% \)

C. \( {12}\%  - {15}\% \)

D. \( {20}\%  - {25}\% \)

⑩ 避免在选择题里使用 “以上都是”。这种干扰项经常用在只能给出三个选项, 但又需要第四个选项时, 或很容易给出一系列特征, 但又很难想出三个不正确的干扰项时。在第二种情况中, 很容易列出三个特征再加上一个 “以上都是”。通常当 “以上都是”用于老师编写的试卷上, 那么它就是正确答案。用这个选项的题目通常很简单, 因为考生即使知识不全面也会选出正确答案。看下面的差例。假设考生只需选出一个答案, 而约翰知道年龄和体重都是用来计算基础能源需求, 但不知道身高也是计算的一部分,他就会选 \( \mathrm{D} \) 作答案; 因而,他尽管知识不全但还是得了分。在修改后的版本中, 考生必须掌握全面知识才能得出给定答案。选项 “以上都是” 若换个形式则更加有效, 这就是复杂选择题, 将在下一节讨论。

例:

差题: 下面哪个因素是计算基础能量需求必须考虑的?

A. 年龄

B. 身高

C. 体重

D. 以上都是

好题: 下面哪个因素是计算基础能量需求必须考虑的?

A. 仅体重

B. 仅年龄

C. 仅身高和体重

D. 仅年龄和体重

## E. 年龄、身高和体重

## (2)多项选择题的变形

标准多项选择题有很多变形题。一种常见的变形题是匹配题, 这将在另外一部分中讨论。本节中我们讨论两种有时会用到的变形题。

① 复杂多项选择题。这种变形题有时称为多选题, 得名于其形式及多个选项综合起来作答。它用来评估知识、应用能力或说明多种原因、影响、功能、作用时最有效。下面的例子阐述了复杂选择题的不当用法及出题上的几种错误。尽管有多种循环障碍的症状, 但选项都很短; 因此用平常的选择题型测试知识更有效。该题的技术性问题如下: 第一, 没有呈现给考生具体问题; 第二, 所有答案选项中都有症状 1、2、 3 , 学生只需决定迹象 4 和 5 是否正确; 第三, 呈现选项的方式 (选项 C、B、D 矛盾) 不同,给学生造成了不必要的困难; 第四,选项 \( \mathrm{B} \) 和 \( \mathrm{C} \) 是相同的。

例 :

差题: 如果手臂上的绷带或石膏太紧, 会影响手臂血液循环。循环受扰的症状包括:

1. 感冒。

2. 面色苍白。

3. 麻木。

4. 肿胀。

5. 活动不便。

A. 以上都是

B. \( 1\text{、}2\text{、}3\text{、}4 \)

C. 除了 5 都是

D. \( 1\text{、}2\text{、}3\text{、}5 \)

下面的例子说明了该题型的一种有效用法, 因为它要求考生区别食品与药物管理局管辖下的食品种类和商业种类。这种题型比传统的多项选择题更难, 也更能区分学生的水平。设计这种题型也更困难。

例:

看下面每种食物加工或生产活动。

1. 一位家庭主妇在家乡做果冻售卖。

2. 一位屠夫仅在马里兰州做玉米肉饼和猪肉肠售卖。

3. 一位食品加工商在加州做果冻, 却在纽约售卖。

4. 芝加哥一家屠宰场运肉至美国所有 50 个州。

5. 一位种柑橘的人在佛罗里达种植柑橘, 然后运至东部各州。

哪种活动要受到美国食品和药物管理局的管理和监督?

A. 仅 2 和 4

B. 仅 3 和 5

C. 仅 \( 3\text{、}4 \) 和 5

D. 仅 \( 1\text{、}3 \) 和 5

E. 所有

② 成对的句子作为启发。这种题型能有效考查考生对相对数量 (多于、少于或等于)、改变条件 (增加、减少或保持不变) 或时间顺序 (第一、第二或同时) 的相对影响的判断能力。第四种情况用来确定答案的信息不足。该题型占用版面小, 因为同一组句子的选项只需要列一次。这种题目应用于已有数量值的内容。比如, 成对句子的使用: (I) 一个 14 岁男孩需要的睡眠时间; (II) 一个 30 岁男人需要的睡眠时间。 这一对句子就比较理想, 因为对于任何年龄段的人没有确定的睡眠所需时间。

例 :

说明: 题 1 至题 3 都是成对的句子, 仔细读每句话, 在答题纸上标:

A. 若句 I 数量大于句 II 。

B. 若句 II 数量大于句 \( \mathrm{I} \) 。

C. 若句 \( \mathrm{I} \) 数量等于句 \( \mathrm{{II}} \) 。

D. 若信息不足, 无法判断哪一句数量较大。

(B) 1. I : 一匙蔗糖的热值。

II:一匙黄油的热值。

(A) 2. I : 一名身高 185 厘米、体重 86 千克的 25 岁男性伐木工人每天需要的热量。

II:一名身高 185 厘米、体重 86 千克的 25 岁男性办公室文员每天需要的热量。

(A) 3. I : 一个 16 岁女孩每天需要的铁。

II:一个 16 岁男孩每天需要的铁。

## 4. 编写匹配题

匹配题与一般的选择题不同的特征在于, 有许多问题的答案必须从同一列可能的答案中获取。匹配题更应该被视为一系列选择题, 只不过用一种更有效的方式呈现而已。比如, 一列题目列在试卷左栏, 一系列选项列在右栏。学生选择符合题目的选项。匹配题最常用于考查事实类信息, 如术语含义、事件日期、人物成就、化学元素符号、图书作者等。可通过图表、地图、简图或图画来建构有效的匹配题。可以给图形的特征编号, 让考生将名字、功能等与图形数字匹配起来。这种题目在测试学习技巧、科学或技术的测试中比较有用; 比如, 可以用这种题型考查生物系学生对细胞结构的辨认。

若需要评估学生建立联系的能力, 那么匹配题就比一系列选择题更有效。这种方式的主要不足在于, 它只适用于考查联系能力, 不适合评估更高层次的理解能力。 另一个缺点是, 这种测试不容易用机器评分, 因为选项数量通常超过了标准机器评分答题纸的 5 个选项。当然, 答题纸可以调整成这种题型, 扫描仪也可以进行编程, 能以非标准形式读取答案。

要想试题有用, 匹配题必须像其他试题类型一样仔细构思。构思不当的匹配题就会变成肤浅的测量工具, 给考生提出技巧要求很高的任务, 但又不在测试旨在考量的范围内。看下面的匹配练习, 这是 8 年级的健康卫生测试。



<table><tr><td>第 I 栏</td><td>第 II 栏</td></tr><tr><td>(p) 1 . 恒牙数量</td><td>a. 错位咬合</td></tr><tr><td>(i) 2 . 维生素 D</td><td>b. 撕咬食物</td></tr><tr><td>(n) 3 . 维生素 C</td><td>c. 战壕口炎</td></tr><tr><td>(k) 4 . 牙釉质</td><td>d. 矫正牙齿</td></tr><tr><td>(o) 5 . 牙龈出血</td><td>c. 下颌骨槽</td></tr><tr><td>(c) 6 . 奋森咽峡炎</td><td>f. 含神经和血管</td></tr><tr><td>(d) 7 . 畸齿矫正</td><td>g. 磨碎食物</td></tr><tr><td>(e) 8 . 肺泡</td><td>h. 牙冠</td></tr><tr><td>(a) 9 . 下颚突出</td><td>i. 阳光</td></tr><tr><td>(f) 10 . 牙髓</td><td>j. 清洁器</td></tr><tr><td>(m) 11 . 酸</td><td>k. 最硬的物质</td></tr><tr><td>(1) 12. 低衰变率 (b) 13 . 犬齿</td><td>1. 本原 m. 腐烂</td></tr><tr><td>(g) 14 . 臼齿</td><td>n. 柑橘类水果</td></tr><tr><td>(h) 15 . 牙齿可见部分</td><td>o. 牙龈炎</td></tr><tr><td>(j) 16 . 牙线</td><td>p. 32</td></tr></table>



注: “正确” 答案由出题人指定。

例:

差题

说明: 将正确项的字母填在左边每个数字前。每个字母只能用一次。

该例体现了编写匹配题容易出现的部分常见错误。首先, 题目说明很模糊, 没有具体说明匹配的基础。其次, 题目内容太异质, 不是好的匹配练习。第 II 栏有多少选项符合第 I 栏里第一条的情形呢? 还有第二条呢? 第 I 栏的表述之间几乎不相同, 除了它们总体上都与牙齿和牙健康有关。第三, 这一列太长了, 第 II 栏里的答案选项排列得也很不成体系。即使知道答案的考生也得在整列第 II 栏里搜寻答案, 实在很耗时。第四,有些条目太模糊,比如第 I 栏里的第 9、11 和 12 条, 以及第 II 栏里的 l 和 \( \mathrm{m} \) 。这种模糊性让考生很难回答出给定的正确答案; 此外,第 12 条的精确度也很令人质疑。第五, 第 I 栏有 16 道题, 第 II 栏有 16 个答案选项。如果学生知道 15 种, 那么就能自然而然猜出第 16 个答案。

(1)好的匹配题编写建议

由于匹配题可以被视为精简版的选择题, 因而两者的编写规则有许多共通之处。 本节讨论编写好的匹配题的具体规则。

① 同一道匹配题里的一系列表述应同质。若前一个例子所有选项都是牙齿的部分、牙齿及牙龈疾病或改善口腔健康的方式, 就会好很多。同质的选项能迫使学生通过其真正的区分能力来获得正确答案。如果需要测试几个不同的内容领域, 就要每个领域分别使用一套题目和答案。

② 题目应简短一点。将具体题日限制在五个或六个内, 就能很容易保证内容同质。而且, 少一点题目也能减少老师的负担及考生的阅读负担。

③ 让学生从较短表述栏里选择答案。原因在于学生会反复读答案栏, 表述短的就比表述长的耗时短。让学生从较短表述栏里选择答案能将阅读能力对测试的影响降低到最小化。

④ 每一栏用一个标题明确描述内容。一个描述性标题有助于考生明确任务。 如果出题人无法确定一个能明确内容的标题, 那就说明条目可能太异质了。

⑤ 答案选项应比匹配的条目多,除非答案选项能使用不止一次。答案选项数目多就能减少猜题对分数的影响, 也能防止学生通过排除法得出正确答案, 因为这并不需要学生总是能知道正确的联系。

⑥ 以逻辑顺序排列答案选项。知道答案的学生应该能很容易找到答案。以字母顺序排列姓名或以时间顺序排列日期能减少找答案的时间。

⑦ 题目说明中应具体阐述匹配的基础及是否答案选项能用不止一次。此举可减少歧义, 使任务对所有考生都更加统一。

匹配题的一种变形就是分类或分组匹配。这种变形可有效用来评估知识应用、 理解或阐释。这是检测概念掌握程度的有效方式。下面举例说明这种题型。

例:

分组匹配

说明: 保健及美容产品广告商在以下 4 个方面引起共鸣。

A. 内心恐惧或不安全感

B. 势利或与一小部分特殊人群或个人产生认同的思想

C. 对追随他人、加入 “时尚行列” 的渴望

D. 吸引想获得权威感的人

陈述 1 至 6 都是虚构产品的广告。仔细阅读每句话, 在前面标出上述吸引内容的对应字母, 每个选项可以使用不止一次。

(A) 1. 不要让缺铁的血液使你颓废。保持活力, 请服用“复合维生素”吧!

(D) 2. 研究表明 “露西的强效小药片” 比普通止痛药效果强 10 倍。

(B) 3. 世界美女普尔豪斯公爵夫人每天两次用沫特尔海龟油洗脸。

(B) 4. 男人, 你是否厌倦了女用除臭剂? 做个男人。用止汗剂。把软弱的东西留给软弱的女人。

(B) 5. 售价 3650 美元的 “Inside Jogger” 不是每个人都享用得起。只有一小部分精英才配拥有。你是其中之一吗?

(C) 6. 与众同乐。喝百事可乐, 提供百事可乐。

## 9.3 编制可用的客观测试

有效评估要求将无关的分数差异源头最小化。在商业出版的测试中, 我们希望产品质量高, 即试卷的组织和布局及印刷都应该是高质量的; 因为这些也是我们花钱购买的。若测试或其他评估工具由当地准备, 那么确保质量的责任就落在了使用者自己身上。下面几小段将讨论测试题目安排要考虑的几大重点。尽管这些特点与客观测试有关, 但许多原则同样适用于评分量表、态度调查及其他评估形式。

1. 准备多于需要的题目数量。你出的每道题不见得都是好题, 尽管这听起来不太可能。遵守前几节的指导原则会有帮助, 但即使是专业出题人出的好题也达不到320\( {30}\% \) 。因此,很有必要出比最终考试多一半的题以供试用,而最终考试是由最好的题日组成的。

2. 仔细校阅题目。出完题目后, 最好放在一边等一或两个星期, 然后再回去校阅一遍。你会惊奇地发现, 当时写得很清晰直接的题几天后看起来会变得很晦涩。 最好让同事再看一遍。如果对此精通的人在测试中也很难解答出题目, 那么考生也解答不出来。

选完题目后, 必须开始准备试卷了。下面几条建议将助你减少测试外部特征给分数造成的外来影响, 以取得可靠而有效的考查手段。

3. 题目的排列应该便于阅读。为考生利益着想, 题目不应杂乱无章地挤在试卷上, 因为将题目分好有助于学生阅读和理解。选择题若答案都分布在同一行会更容易阅读。另外, 题目不应跨不同页, 因为这样会使考生迷惑。若几道题都跟同一幅图表有关, 那就把图表和所有相关题目安排在同一页上或对页上, 这样考生就不需要翻页回答同一个材料的题目。若不这样, 还有一个方法, 就是把材料放在单独一页, 不和剩下的试卷题钉在一起。其缺点在于, 优化题目安排以促进考生阅读理解题目会增加试卷复印成本, 因为每份试卷都需要增加页数 (不用说, 印刷字体应大, 方便阅读。)

4. 合理安排试卷布局以便可以单独用一张答题卷来写答案。单独用一张答题卷可能会使考试过程更困难一点, 但评分过程会更简单准确。大多数标准测试要求单独用答题卷, 但对低年级不作此要求。到了三年级, 大多数学生很容易就会使用了。使用答题纸是应该教给学生的一种应试技巧, 也应该早点让他们练习。机器评分现在很受推荐, 因其不仅可以节省时间, 还能减少评分错误率。即使是最简单的机器也能评阅答题纸、捕捉数据并存储在硬盘上。这种设备能极大地推动题目分析程序及进一步分析数据。

5. 把同一类型的题目放在一起 (判断正误题、多项选择题或匹配题)。每种不同的客观题都要有不同的题目说明。把同类题型放在一起就可以写出简明清晰的说明。每种题型也需要考生作出不同形式的回答。同类型的题目放在一起, 考生更能作出适当的答案。

6. 同题型里材料内容相同的题放在一起。这使试卷更连贯, 且给考生提供了适当的语境。这也能帮助师生看到考生的强项和弱项。

7. 题目难度从易到难。这一点尤为重要, 因为考试时间有限, 有些题目并不是所有学生都会做。对于那些较难的题目, 能力较低的考生即使碰到了也不太可能答对。让大多数学生都能回答出所有问题, 这样才能给学生鼓励, 尤其是小孩和能力稍低的学生。这也能激励他们尝试做完所有的题而不是轻言放弃。但专业判断比经验证据更支持这种题型。

8. 每种题型写一套具体说明。一套好的说明应告诉考生如何记录答案, 依据什么基础选择答案以及拟采用的评分流程。对于一套由选择题组成、不倒扣猜错题目的分数且使用单独答题低作答的试卷, 可以采用以下一组说明。

例:

说明: 阅读如下所有题目, 决定哪一项是题目问题或陈述的最佳答案。将答案写在单独的答题纸上, 请勿写在试卷上。把答题纸上所选字母旁的空格涂满; 即若你认为选项 \( \mathrm{B} \) 是第一题的最佳答案,则把这题后面 \( \mathrm{B} \) 旁边的空格涂满。你的分数将依据正确答案的数量而定, 因此最好每题都作答, 即使不确定哪个是正确答案。确保在答题纸上署名。

下列说明可用于判断正误题试卷, 答案记在试卷上, 总分将扣除猜错题目的分数。

例:

说明: 仔细阅读下面的句子。

若句子全部或部分错误,在句子前圈 \( \mathrm{F} \) ; 若句子完全正确,在句子前圈 \( \mathrm{T} \) 。你的分数将为正确答案数量减去错误答案数量, 所以不要盲目猜答案。若不确定答案, 跳过不答。确保在试卷上署名。

若使用单独的答题纸, 则上述说明就得修改。商业生产的光电扫描答题纸通常第一个答案区域 (A) 等于正确, 第二个答案区域 (B) 代表错误。而且, 若试卷使用多种题型, 或多题使用同一个参考答案或使用同一段原文材料, 则应在试卷开头提醒考生, 后面将另行说明, 他们应仔细阅读说明。对于缺乏经验的考生 (如小孩子) 及新题型, 通常应在说明后面举一到两个例子教他们怎么答题会有帮助。

9. 确保一题不会给其他题目的答案提供线索。除非出题人特别小心地安排测试题, 否则一题的答案可能会由前一题泄露出来。所有最终选择的题目应该仔细检查, 因为很可能一道判断正误题或句子填空题会透露一道选择题的答案线索, 反之亦然。在下面的例子中,判断正误题就给客观题提供了答案线索。

例 :

1. \( {TF} \) 导致肉毒中毒的细菌孢子存在于土壤和空气中。

2. 下面哪一种细菌会产生孢子?

A. 导致食物中毒的葡萄球菌

B. 导致肉毒中毒的杆菌

C. 导致伤寒的杆菌

D. 导致肺炎的肺炎球菌

10. 确保正确答案随机排列。有些出题人想通过按照某种规律排列正确答案来简化评分工作。比如,在判断正误题中,他们用重复的 \( \mathrm{T}\text{、}\mathrm{\;T}\text{、}\mathrm{\;F}\text{、}\mathrm{\;F} \) 或在选择题中用 A、C、B、D 的模式。如果形成模式, 那么有些应试能力高的考生就会发现这个模式, 并利用其作为答题的方式, 尽管他们并不知道答案。在四个或五个选项的选择题里, 正确答案经常出现在中间而非开头结尾。选择题的正确答案应出现在任何可能的位置。比如, 在 50 道四项选择题里, 出题人应使每个选项位置的正确答案不少于 10 , 也不多于 15 题。用文字处理设备来做这个重新安排答案选项的任务就非常容易, 不难达到要求。若试卷用机器评分, 把正确答案按规律排列没什么好处。

11. 若答案选项有合理的模式, 则应该遵循。在答案为日期或数量的测试题里, 答案选项应按照大小升序排列。这样考生就很容易处理选项, 避免答案位置给考生提供线索的可能性。有时把答案选项以字母顺序排列也是可以的。

## 9.4 客观测试的评分

我们完成了测试的设计、复印及实施后, 评估程序仍未完成。试卷还必须评分并对分数进行解读说明。第三章已经讨论了常模参照和标准参照框架下的分数解析。 但分数也会被猜答案导致的错误影响。考试前必须决定好分数是否进行猜题校正。 考生应被告知是否会使用校正, 因为这可能影响其考试的策略。考试专家并不完全认同猜题校正的效度, 但它似乎能稍微提高一下考核的精确性。校正对于碰运气起很大作用的题目更为重要, 比如判断正误题。

## 1. 猜题校正

众所周知, 考生在客观题上碰到不确定题目时猜答案的倾向各有不同。这就导致了与个人真实成绩差异无关的分数变化。考生猜得越多, 分数就越不可靠, 因为靠猜测做对题目就意味着将机会性或随机性考查错误带入分数。考试时间紧导致的猜测倾向的差异尤为重要, 因为不是每个人都有足够时间完成题目。在这种情况下, 因没有时间仔细完成题目而猜答案的人就会比那些空着题目不答的人得分高。禁止考生猜答案, 且答案错误要受到扣分惩罚的一大原因在于, 应使所有考生猜答案的行为更加趋同。

(1)猜题校正公式

解决猜答案问题的一个方法是用一个猜题校正公式调整分数。最常用的公式是基于这样的假设, 即所有的错误答案都来自于猜测。预计考生要么回答正确要么略过不答。猜题校正通过考生分数减去预计猜对的分数进行调整。在四选项选择题测试中,一个人仅靠猜也能从四个答案里选出正确答案的概率为 \( 1/4 \) 。因此,每回答错误三道题, 则可能猜对一题。这种逻辑用数学语言表示如下:

校正分数 \( = R - W/n - 1 \)

其中, \( R \) 是答对的题目数量, \( W \) 是答错的题目数量, \( n \) 是一道题的答案选项数目。

考生跳过不答的题目未体现在这个公式里。在一份判断正误试卷中 (只有两个可能的答案),公式中的 \( n - 1 \) 就变成了 \( 2 - 1 \) 或 1,猜题校正变成正确答案数量减去错误答案数量所得的差。

下面两个例子, 第一个有关判断正误题, 第二个有关五选项选择题。它们说明了公式的用法。注意猜答案的影响假定在判断正误题里面更大, 因此校正导致分数变化更大。



<table><tr><td/><td>测试类型</td><td>选项数量</td><td>答对题 日数量</td><td>答错题 目数量</td><td>未作答 题目数量</td><td>校正后的分数</td></tr><tr><td>例 1</td><td>判断正误</td><td>20</td><td>48</td><td>20</td><td>7</td><td>\( = {48} - {20}/\left( {2 - 1}\right) \) \( = {48} - {20}/1 \) \( = {28} \)</td></tr><tr><td>例 2</td><td>多项选择</td><td>20</td><td>48</td><td>20</td><td>7</td><td>\( = {48} - {20}/\left( {5 - 1}\right) \) \( = {48} - {20}/4 \) \( = {43} \)</td></tr></table>



(2)对猜题校正公式的批评

猜题校正公式受到批评的原因是其假设条件很难满足, 而且一般来说不能达到校正猜测分数的目的。该公式基于以下两大假设: 第一, 所有猜测都是盲目的, 每个选项被选择的概率等同; 第二, 每个错误选项都是由猜测造成的; 即考生绝不会因为受信息误导或误填涂答案而答题。第一个假设排除了学生可能是基于部分信息或排除一些选项而猜的答案。若是这样, 公式里的概率就变了。在四选项选择题里, 学生答对的概率更大。只有在时间很紧的测试里, 不可能所有问题都得到合理的回答, 考生才会完全盲目猜答案。第二个假设排除了考生可能基于错误或未理解的知识而答错的可能性。但一个好的出题人会设计误导性答案来干扰那些知识片面或错误的324考生。

(3) 校正不足。针对四选项选择题, 该公式可能校正不足, 因为考生会排除一些选项后在剩下的较少选项里猜。在这种情况下考生会倾向于猜答案, 因为猜测被罚的分会比猜测增加的分数少。即使只排除了一个选项, 猜答案也能帮助提高考生分数. 另一方面, 应试能力不高的人可能因猜题校正公式的运用而害怕, 因此拒绝猜答案。

(4)技术因素。若没有省略任何问题, 学生的排名则不受影响, 这是校正公式的另一个特征。在此情况下, 原分数和校正分数之间的联系就很紧密。只有存在省略题目时, 相关系数才会小于 1.0 , 即使这样也仍然保持在 0.9 以上 (Ebel, 1979), 除非省略的题目数量有很大变化。

若省略的题目和原分数之间存在正相关关系, 那么只有通过猜题校正才能增加信度和效度。当然, 这种情况一般不会出现, 因为做得最快、答得最多的人通常都是知识最丰富的。此外, 应试能力强的考生可能在总体上回答的问题更多, 做得也更好。

(5)为什么要用猜题校正公式

说到这里你可能会问, 既然猜题校正公式有上述缺点, 那为什么还要用呢? 用这种公式的动机可能跟防止猜答案而非校正有关。由于猜答案直接导致错误偏差, 因此人们认为用该公式会增加信度。信度系数是评判测试质量最容易获取和最客观的依据, 因此人们对这些指数很重视, 即使是信度稍微提高也被视为试卷质量的提高。

猜答案给时间紧或两选项题目的试卷带来的问题最严重。这种测试的分数若校正一下会更可靠。在所有或大部分学生都有充足时间回答每道题的四选项或五选项选择题测试中, 只计算正确答案数量得出来的分数就比较令人满意, 猜题校正的做法几乎没什么好处。

## 9.5 利用试题分析改进客观测试

商业测试出版商不依靠出题人的判断力和技巧来决定出什么题。相反, 他们采取称为题目试做的试点研究来获得有关试题质量的经验证据。若一份试卷应包含 100 道题, 出版商就会试 150-200 道题, 以确定最终试卷具有其应具的特点。为使测试时间合理, 要准备几种有不同子题的试卷, 这样每道题与其他题交错出现。每种试卷都给几百名考生试做。尽管试验样本人群并不一定像一般样本一样代表目标测试人群, 但也应该包含跨度范围大的人群, 且与目标人群有同样的平均能力。最终题目的选择依据这里的分析。尽管本地编写的试卷很少如此大肆铺张地进行预测试, 但对试卷进行试题分析能改进题目, 以备下次使用 (这里描述的传统试题分析形式是项目反应理论或 IRT。这一过程需要大量样本, 且没有合适的计算机程序就没法实行, 很少用在当地测试应用中)。

实施试题分析有几种不同的方式。就复杂程度而言, 它们包括从基于复杂的试题反应理论的方式到相对简单的方式, 后者教师或研究员只需一点很少的训练就能容易使用。依靠合适的设备和软件可以设置程序, 使其能给出题人提供大量试题分析信息, 出题人无需多大工作。大多数大学和较大的学区都有可以实施试题分析的测试评分设备。

## 1. 简化的试题分析程序

实施试题分析的第一步是把每道题的回答列表显示——即每道题有多少人答对, 每个可能错误的答案有多少人选, 以及多少人没答。根据总分的情况, 你应获得高分组和低分组的上述信息。根据该表, 你就能回答出下面有关每道题的相关问题:

① 题目有多难?

② 该题有没有区分出最高分和最低分得主?

③ 每个选项都有人选吗? 还是有些选项没人选呢?

下面的讨论旨在描述试题分析所提供的信息类型, 列出了选自一份社会研究测试的四道题目, 还有对每道题的回答分析。该测试对象为一百名选修《当前美国问题》的高三学生。测试含 95 道四选项选择题。最高分 85 , 最低分只有 14 。试卷按总分顺序从高到低排列。前 25 份试卷选出来代表高分组 (分数在 59-85 之间), 最后 25 份试卷代表低分组 (分数在 14-34 之间)。这里描述的试题分析仅基于高分组和低分组的数据, 但对于班级大小的组来说, 最好从中分开高分组和低分组, 然后使用所有试卷。高分组和低分组每名学生对每道题的回答都进行了统计, 以获得每个选项被选的频率。频率显示在右栏。正确选项下面加了下划线。每道题后面都有简短的试题数据分析。

我们了解到的有关测试的第一点是总分的分布。该试卷很难。第三个四分位数 \( \left( {\mathrm{Q}}_{3}\right) \) 位于中位数分值点,正好是 \( {62}\% \left\lbrack  {\left( {{59}/{95}}\right)  = {0.62}}\right\rbrack \) 。该试卷太难的第二点表现在, 至少有 1 名学生的得分低于 24 分的巧合水平 10 分。当这种情况发生时, 必须检查分数分布以确定这是单独特例还是其他若干学生也是如此。这种低分可能是由于错误信息、有些题本身有严重问题、答案写错地方(若学生跳过试卷上某题未答但忘了在答题纸上空出时最容易发生这种情况) 或者就是故意考差。当碰到低于巧合水平的分数时, 考务官应找低分考生谈话, 看看考差的原因是什么。如果考生原本就想考差, 那么对这些答案进行试题分析的价值就很值得质疑了。该测试也显示了分数区间的广泛性。总分 95 的话, 分值跨度有 72 分, 四分位间范围为 25 分; 因此该测试成功地拉开了学生的层次。

一道题的难度取决于答对题目的考生比例。第一例中的题目比较简单, 因为高分组所有人及低分组 20 名同学都答对了。由于分析的 50 名学生中有 45 人答对, 因而该题难度值为 \( {0.90}\left( {{45}/{50}}\right) \) (注意难度指数其实是简单程度; 高数值意味着低难度)。

例 1 :

“每个人都开始改用春之息漱口水啦”体现的宣传技巧为:



<table><tr><td/><td>高分组</td><td>低分组</td></tr><tr><td>A. 粉饰法</td><td>0</td><td>2</td></tr><tr><td>B. 赶时髦</td><td>25</td><td>20</td></tr><tr><td>C. 推荐书</td><td>0</td><td>2</td></tr><tr><td>D. 亲民法</td><td>0</td><td>1</td></tr><tr><td>略过未答</td><td>0</td><td>0</td></tr></table>



尽管很简单, 但该题确实达到其区分目的, 因为错误答案出现在低分组。也就是说, 总分高的同学更可能答对该题。该题是好题的另一个原因是, 所有错误选项都有用; 即每个错误选项都有至少一名低分组学生选择。试卷以这样的两三道简单题开始是很好的。

第二个例子有点难但很有效; 难是因为 50 个学生里只有 13 人答对, 有效是因为所有 13 名答对的同学都在高分组。所有错误选项都吸引了低分组部分学生, 且吸引的低分组学生比高分组多。像这样的题目说明了盲目猜答案对分数的影响可能并没有想象中大。当错误选项非常吸引缺乏所测知识或技能的人时, 猜答案的影响就减少了。

例 2 :

1913 年之前没有联邦所得税法, 因为 1913 年前:



<table><tr><td/><td>离分组</td><td>低分组</td></tr><tr><td>A. 联邦预算平衡</td><td>3</td><td>5</td></tr><tr><td>B. 一般财产税提供的收入足以保证政府运转</td><td>9</td><td>15</td></tr><tr><td>C. 所得税不符合宪法</td><td>13</td><td>0</td></tr><tr><td>D. 美国普通工人收入太低, 没法征税</td><td>0</td><td>5</td></tr><tr><td>略过未答</td><td>0</td><td>0</td></tr></table>



下一个例子是个差题。首先,该题很难; 50 人中只有 8 个人答对,约占 \( {16}\% \) 。第二, 该题区分作用很差; 即低分组正确答案比高分组多。出现该结果的两大可能的原因是: 第一, 该题有歧义, 尤其是对于知识掌握多的学生来说; 第二, 学生并不了解《反腐败法》的条款。有两条证据证明第二种解释最有可能。高分组答案集中于选项 A 意味着信息错误, 且低分组答案统一分布, 显示随机猜测。为获得该题的正确答案, 学生得知道对某政党全国委员会的捐赠限制, 谁被禁止做出捐赠, 以及全国制造商联合会是个什么组织。人们可能会猜想是第一点和第三点造成了高分组的困难。

例 3 :

根据《反腐败法》, 一个政党的全国委员会可接受下面哪种捐赠:



<table><tr><td/><td>高分组</td><td>低分组</td></tr><tr><td>A. 琼斯先生的 1 万美元</td><td>15</td><td>6</td></tr><tr><td>B. ABC 帽子企业的 1000 美元</td><td>4</td><td>6</td></tr><tr><td>C. 全国制造商联合会的 5000 美元</td><td>2</td><td>6</td></tr><tr><td>D. 一家当地工会的 500 美元工会基金</td><td>4</td><td>7</td></tr><tr><td>略过未答</td><td>0</td><td>0</td></tr></table>



最后一题难度合理 \( \left( {{38}/{50} = {0.76}}\right) \) ,合理地作出了区分 \( \left( {{21}\text{比 17}}\right) \) ,但区分度不是很明显。答案的规律很统一。四个选项中只有两个有效。没人选 B 或 C。如果我们想改进这题,就得把选项 \( \mathrm{B} \) 换成“简单工作的工资”,选项 \( \mathrm{C} \) 换成 “付给接受福利救济人的钱”。选项 B 里的形容词 “容易” (也是题干) 以及选项 C 里的不劳而获思想可能使该题更难, 因此更有区分度 (注意谐音联想尽管不应出现在正确答案里, 但适合出现在干扰项里, 因为这会吸引缺乏本题所测知识或技能的考生的注意力, 从而使该题更有区分度)。

例 4 :

经济学中 “快钱”一词的意思是:



<table><tr><td/><td>高分组</td><td>低分组</td></tr><tr><td>A. 以低息借贷的能力</td><td>21</td><td>17</td></tr><tr><td>B. 普通股的股息</td><td>0</td><td>0</td></tr><tr><td>C. 竞赛中赢得的钱</td><td>0</td><td>0</td></tr><tr><td>D. 失业金</td><td>4</td><td>8</td></tr><tr><td>略过未答</td><td>0</td><td>0</td></tr></table>



## 2. 更多正式试题分析程序

前一部分提到的是非正式的、直接的试题分析方法, 其优点是概念很简洁。我们提到过题目的难度是以答对题目的受试者比例来表示, 在传统题目分析中, 这个定义完全足够了。如使用项目仅应理论法 (见第三章), 则要求一种更为抽象的定义。

在非正式程序中, 最大的限制是缺乏一个具体的区分度指数。对于一道题目, 如果得分高的人答对的比例比得分低的人高, 那么就认为该题目具有正区分度。但是在更为正式的情况下, 比如在商业测试开发中, 一道题目对于掌握信息与否的人进行区分的能力如何, 最好可以进行量化。有两种常用方法可以对题目的区分能力进行说明。

(1)区分度指数

一种常见的程序叫作区分度指数, 可以从研究干扰项功能的相同数据分布中计算出来。出于技术原因,这类分析通常用于前 \( {27}\% \) 和后 \( {27}\% \) 的受试者 (那就是极端的 \( {54}\% \) ,而不是 \( {50}\% \) ,这点前面已提到)。但是,不管具体离散区间是多少,原理是相同的。如果受试者数量少, 高分组和低分组通常分别高于和低于中位数。参加分析的人数越多, 越可能整体降低区分度指数数值, 因为如果分布的中间部分没有被排除, 不同组之间的差异会缩小。

区分度指数(D)可以这样计算,用高分组中答对人数 \( \left( {N}_{U}\right) \) 减去低分组中答对人数 \( \left( {N}_{L}\right) \) 之差除以小组人数(N)。区分度指数的计算公式如下:

\[D = \frac{{N}_{U} - {N}_{L}}{N}\]

用这个公式来计算我们所举例子中的数据, 可以得到以下数值:

例 \( {1D} = \left( {{25} - {20}}\right) /{25} = {0.20} \)

例 \( {2D} = \left( {{13} - 0}\right) /{25} = {0.52} \)

例 \( {3D} = \left( {2 - 6}\right) /{25} =  - {0.16} \)

例 \( {4D} = \left( {{21} - {17}}\right) /{25} = {0.16} \)

这些数值说明了试题区分度的一些重要方面。第一, 特别难的题目 (第三题) 或者特别简单的题目 (第一题和第四题) 区分度比较差。能答对的人和不能答对的人都很少,所以 \( D \) 值几乎等于零,几乎没有区分度。测试中包含一些区分度很小的简单题目也是可以接受的, 可以给学生很积极的鼓励, 但不应包括难度太大的题目, 除非测试的目的是为了发现特别出色的人。对大多数测试来说, 最好是大部分题目难度中等, 因为这些题目的区分度是最高的。比如, 如果高分组的所有人都答对了, 低分组的所有人都没有答对, 那么区分度即达到最高值 1.00 。从上述例子中还可以清楚看到第二点,即如果低分组答对的人数多于高分组, \( D \) 会是负值。这就是所谓的负区分度题目。这样的题目是不理想的情况, 因为说明这道题和测试中其他题目的测量对象有偏差, 或者根本不能测量任何东西, 或是表述不清楚误导了有水平的受试者。如果一道题是为了测量一项重要指标, 而且出现了负区分度的情况, 则测试制定者必须改正这道题目或者采取其他测试方法。

除了具有正区分度 (就是高分组答对的人更多), 测试题目中的干扰项设置得当也能发挥比较好的作用。如低分组中选择干扰项的人更多, 那么干扰项就发挥了恰当的功能 (有时候称作正区分度干扰项)。例 1 和例 2 就是如此。每个干扰项, 低分组选择的人都更多。干扰项对于测试质量并不是特别重要, 但是质量特别高的测试干扰项都能发挥很好的作用。

## (2)题目一测试总分相关系数

如果测试是通过电脑来评分的, 而且配有相关电脑设施, 就可以用另一种方法来计算题目的区分度指数, 即计算每道题目和测试总分之间的相关系数。这种方法有一个好处, 即题目的评分可以为错误或正确, 如果采用了一些复杂的题目形式或者答题快可以加分 (这两种评分方式在韦氏智力量表中都会用到, 虽然严格来说这不是客观测试), 可以根据正确程度来打分。题目一总分相关系数法用所有人的数据, 而不仅仅是极端值, 得出的相关系数和区分度指数有相似的特征。很多光学扫描设备的控制软件也有题目分析选项, 可以得出和我们非常相似的结果, 但其更可能采用题目- 总分相关系数,而不是区分度指数(D)。总分和单题得分之间的相关系数,记作正确或错误 (1 或 0),被称作点二列相关系数 \( \left( {r}_{pb}\right) \) (在项目反应理论中,也有一个计算区分度指数的相关系数叫作点二列相关系数)。

(3)使用区分度指数

在测试开发中使用区分度指数的最简单方法就是保留数值最高的题目 (比如超过 0.50 , 去掉数值最低的 (比如低于 0.20) 及修改这两点中间数值的题目。那些区分度指数为负的题目, 应该删掉或者进行修改, 达到合理的区分度。在判断为什么题目的区分度很低时, 首先应检查题目的难度。题目难度太大或者太小, 区分度就很差。有时候, 一道题虽然计算出来的难度适中, 但是区分度还是很低, 比如若四个选项中有两个选项完全不合理, 则只剩下一个正确答案和一个干扰项。即使这样的题目很难, 只有少数学生知道答案, 很多学生还是可以靠猜测来答对, 因为只需要从两个选项中猜就行。当然, 测试制定者还要检查题目在其他方面是否有问题, 测试的制定是否符合好的题目编写原则。同样, 干扰项是否发挥了应有功能也很重要。如果干扰项明显有问题, 题目难度会降低, 太接近正确答案则会增加难度。对于选择题来说, 调整干扰项来控制题日难度是它的一个优势。330

## 9.6 编写论述题

要求受试者进行作答的论述题的一大好处是其可以测量受试者组织、整合知识的能力, 应用信息解决新问题的能力, 并且可以让受试者展示自己的原创综合思维。 要完成这些测试目标, 需要仔细计划每道题, 要求学生展现这些能力。如果只是提出一个问题, 让学生写出答案, 并不一定能对这些能力进行检验。

看看下面这两道论述题:

例 1 :

美国采用了哪些方法来预防和控制传染病?

例 2 :

请查看下表中的数据。

请解释 20 世纪以来美国在知识、医学治疗、生活水平方面的提升是如何改变表中死亡率的?



美国 20 世纪初和 20 世纪末死亡原因和每种疾病的死亡率

<table><tr><td rowspan="2">死亡原因</td><td colspan="2">每 10 万人死亡率</td></tr><tr><td>1900 年</td><td>2000 年</td></tr><tr><td>1. 肺炎</td><td>175.4</td><td>21.8</td></tr><tr><td>2. 腹泻和肠炎</td><td>139.9</td><td>1.5</td></tr><tr><td>3. 心脏疾病</td><td>137.4</td><td>399.9</td></tr><tr><td>4. 癌症</td><td>64.0</td><td>185.6</td></tr><tr><td>5. 白喉</td><td>40.3</td><td>0.01</td></tr></table>



受试者要回答例 1 中的问题, 只需要回忆和写下课本和课堂上学到的内容, 不需要更高级的思维活动。相反, 例 2 中的问题则需要受试者回忆每种疾病的特征和传播方式。他们必须将这些知识点和免疫、化疗、卫生水平的提高和寿命的延长联系起来。

论述题测试有两个难点。第一, 事实性知识和组织整合答案的能力易被混淆。 那些懂得更多知识点的学生通常会写出看起来更高级的答案, 却没有原创性。第二, 与做选择题相比, 需要花费更多时间来思考和写答案。所以, 成绩上的差异有可能是因为知识能力差异, 也可能是作答速度和形式问题。而且, 因为这类题需要更长时间, 所有题量有限, 达到内容效度会更难。

有人提议通过测试环境来解决这些问题。虽然每种建议都有实现的难度, 但其可能在某些情况下是合适的。有如下这些替代方法:

① “开卷”考试。这种考试允许学生在答题的时候翻看课本和课堂笔记。这种方式可以减少知识差异的影响。其缺点是水平较低的学生可能会花很多时间翻看资料, 而水平高的学生则可以有更多时间答题。所有, 那些需要翻书和笔记的学生可能会觉得“开卷”考试的时间比闭卷考试的时间还紧。

② “回家”答卷。这种方式消除了学生的考试时间压力, 他们想花多长时间就花多长时间。但是这种测试没有可靠保证。没人知道受试者是否是独立完成测试的。 尤其在当今的互联网时代, 学生在无人监管的情况下进行测试可能会有作弊行为。 实际上, 手机和个人电脑的普及甚至可以让小学生和初中生找到题目答案, 不管在家还是在学校的测试, 都可以通过相互之间或者互联网找到答案 (Van Sack, 2004)。 所以, 为了防止学生使用禁用资料来源, 教师需要严格规定哪些资料可以参考, 哪些不可以。

③ 划定范围。有一种方法结合了开卷考试和回家答卷的优点, 那就是给学生一系列学习问题, 考试题目将从中选择。可以给学生布置八到十题, 然后告诉他们考试考三道题。这种方式的优点是学生在备考时想花多少时间花多少时间, 可以参考任意资料, 但是在答题的时候必须接受监督。当然, 除非进行明确的监督, 否则学生可能事先把答案粘贴在某网站上, 在考试现场将答案读取和复制下来。

④ 制作小抄。这种方式是开卷考试的一种变通形式, 可以减少学生对课本的依赖。它允许每个学生带一张纸, 写上所有知识点、步骤和其他信息。这可在客观测试和论文测试中使用, 对一些公式占比很大, 老师又并不要求学生背诵这些公式的科目来说会很有用。如果担心测试可靠性问题 (比如同一考试重复施考的情况), 可以在收试卷的时候把小抄纸也一起收走, 这样可以防止学生记下问题帮助其他学生。因为存在滥用网络和其他资料的可能性, 小抄纸应该是手写在纸上的, 而不能是电脑文件, 且学生在考试中不能使用电脑或手机。

## 1. 编写论述问题

下面是一些有关如何编写高质量论述题的通用指南。

① 在编写问题之前想清楚拟测量的思维过程是什么。在决定需要提供什么样的引导材料才能让学生进行应答之前, 编写论述题的人必须充分考虑各种答案所代表的思维能力。比如, 如果你想用一个问题来评估八年级学生思考健康问题的批判性思维能力, 则需要找出体现批判性思维能力的证据, 比如对权威的合理性进行评估, 找出偏见或情感因素, 区分有效和无效数据, 判断数据是否支持结论。在决定哪些是你想测试的能力之后, 可以对材料进行选择、修改或编写新材料和题目, 要求受试者应用这些能力。

② 在组织问题的时候采用新的材料和组织形式。大体来说, 我们希望论述题能够检验受试者使用信息的能力。为了判断他们能否做到, 必须将他们置于特定情境下, 要求不仅需要重现课堂和课本知识, 还得应用其他能力。有些论述题是这样的, “列出导致日本军队袭击珍珠港的原因”或者“艾滋病的传播方式有哪些?”这两个问题只要受试者列数知识点就行, 检测的教学目标采用选择题的方式会更加高效。好的论述题,比如例 2 , 编写起来会更难。

③ 论述题最好以 “比较”、“对比”、“给出自己的例子”、“解释如何”、“如果这样……预测会发生什么”、“批评”、“区分”等词开头。这些措辞, 再加上采用的新材料, 有助于向受试者表达信息进行筛选、组织和应用。论述题的题目不要以 “什么”、 “什么时候”、“谁”等词开头, 因为这样的问题只是要求复述信息。

④ 在编写论述问题时确保清晰明了地向考生提出了任务要求。我们希望测试分数可以准确反映受试者在完成特定任务时的能力, 而不是其能否理解问题是什么。 这样的问题 “试讨论对社区健康有贡献的组织” 就是太宽泛模糊的问题。 “讨论” 这个词是什么意思呢? 是指列出这些组织然后说明它们都做了什么? 对它们的活动进行评估和批评? 还是找出组织结构的漏洞? 受试者是要考虑政府机构还是对社区卫生有贡献的所有公立私立机构? “对社区健康有贡献”又是什么意思? 是指执行健康法规, 治疗和预防疾病, 还是资助了教育和研究? 下例给出了更合适的措辞方式, 它可以使所有受试者对题目得出一样的理解:

例:

以肺结核为例, 描述以下机构对于该疾病的预防, 以及对该病患者的治疗和照顾方面可能有的贡献。

a. 地方和州立健康部门

b. 美国公共卫生服务局

c. 美国农业部

d. 全美肺结核协会

e. 美国公共卫生协

这种命题形式可以让学生对题目有一样的理解, 而且不会牺牲掉学生答题时的自由度。

⑤ 要求学生对于争议性问题进行论述, 应该对提供的证据进行评估, 而不是学生的观点。对于个人和社会来说, 很多问题并没有一致的答案。然而这些问题在教育中常常很重要。对于这些有争议的问题, 要求学生接受某种观点或解决方案是不合理的。然而, 对于某种观点和结论, 可以检测他们收集和应用证据的能力。比如 “要确保美国所有人享受合适的医疗保险, 国会应该通过哪些法案?”这个问题就很模棱两可, 没有标准答案。但是受试者可以给出这样的回答: “有人建议让联邦政府出资承担所有医疗服务费用和医药费用。你赞成吗? 请列出事实, 给出有逻辑的论证来支持你的观点。”这样的问题难点在于阅卷。如果没有给出详细的标准, 要求对正反两方答案和论点进行评估, 老师很有可能会给自己认同的答案打高分。在评估的时候, 应该注重论点的质量, 而不是回答是否符合老师的立场和观点。

6 适当调整问题的长度和复杂度以符合受试者的成熟度和测试环境情况。年龄更大, 更为老到的学生可以理解和回答更为复杂的问题。另外, 如果测试对时间没有太高要求, 受试者则可以进行更为复杂深入的思考。

## 2. 设计论述题测试

在完成测试题目的编写后, 还有些事项需要注意, 这样才能确保测试按照预想的方向展开。遵循以下原则可以有效减少一些对分数产生的不必要影响。

① 确保在有效答题时间内题目不要过多过长。在论述题测试中应该有多少题, 取决于预期作答的长度和复杂度、学生的成熟度, 以及测试时间。论述测试不是为练习学生答题速度, 受试者应该有时间思考题目后组织答案。题目越复杂, 答题时间越长。受试者经验越丰富, 特定难度下答题速度越快。在一项一小时的测试中, 老师经常会期望学生可以回答 3-5 道中等难度的论述题或 20-30 道多项选择题。这种测试长度对于大学生来说比较合适, 但是对于初高中生来说也许就太长了, 这种测试测的就是答题速度而不是能力了。对于有些难度, 需要学生进行整合和组织的论述题, 应该让学生有 15 分钟的作答时间。对于多项选择题, 每题 45-60 秒是比较合理的时间。

② 如果有多道论述题, 问题应该有难度差异。大多数课堂测试的目标是对学生课堂材料掌握程度进行区分。如果所有问题都会难倒大多数学生, 那么成绩偏差的学生就一道题也不能答好了。相反, 如果所有问题都相对简单, 就不能对能力强的学生进行有效测量了。有难度区分的测试才适合所有受试者。

③ 在大多数情况下, 所有测试者应该回答同样的问题。在大多数班级, 同样的教学目标适用于所有学生。允许学生选择回答哪道题, 会在区分学生时减少对他们共同之处的关注。将学生甲对于问题 1 的回答与学生乙对于问题 2 的回答进行对比, 会增加测试中的主观性和测量误差。在大型全国性考试中, 学生接受的是不同的课程教育, 让学生选择问题作答也许是合适的, 但是对于班级测试, 这样做会降低测量的质量。要避免这个问题, 可以为每个问题制定严格合理的评分标准。

④ 为整个测试编写一套总说明。教学人员经常在论述测试中写上一句简单的指示一“请回答下列问题”。这个表述不足以告知受试者题目的性质。好的指示应该清楚说明学生在参加测试时采取的总计划; 答案的形式应该是什么, 是连贯的文章还是要点; 评估答案的大致标准; 完成测试的时间; 每个问题的分值或问题的比例。

## 3. 论述题的评分

论述题测试的一大缺点是在完成测试后还有很多工作要做。合理评估论述题测试不仅需要很好的题目还要合理有效地评判学生的作答。题目之间和受试者之间的得分差异会造成能力测量误差。参照接下来的原则可以让你更好地对学生的回答进行评估:

① 在评判每道题每个答案的合理度时, 提前决定需要考虑哪些特征。如果需要评估的特征不止一个, 应对它们分别进行评估。比如, 在为学生的回答打分时, 如果你想评估拼写和语法、知识和组织能力。这些是不同的能力特征, 应该分开进行评估。当然如果要将拼写和语法纳入评分, 应该提前告知学生。

② 在说明要达到什么样的标准才能得满分时, 准备好参考答案和标准答案。这个举措可以帮助你在为不同试卷评分时保持一致。如果评分要花几天时间, 这点很重要。

③ 再看下一个问题前读完前一个问题所有答案。这样做有两个目的: 第一, 评分人在给不同试卷评分的时候, 可以保持相同标准; 第二, 在为同一个学生评分的时候, 前一题的回答不会影响对后一题的打分。

④ 完成一道题的评分后, 将试卷打乱再对下一道题进行评分。对试卷进行评分的时候, 很有可能会将某个学生的答案和刚刚评完的学生答案进行对比。如果某个学生很不幸, 试卷接在一个成绩特别好的学生之后, 他的成绩很可能会受影响。打乱试卷顺序, 每道题和不同试卷的批阅顺序也会不同。

⑤ 批阅试卷时尽量不看考生姓名。你越是不了解不知道所评试卷属于谁, 给学生的作答判分时就能越客观。对所有受试者来说, 回答质量的评分标准是一样的。 有时候, 老师会不按这个标准来, 而是希望根据学生水平的差异调整标准。在评分时, 不应该对个体差异进行这样的调整, 而应该在之前进行, 按照测试目标、内容和学习经历进行区分。如果老师对某些学生有不同的教学目标和期待, 应该提供不同的测试。

⑥ 在论述题的回答中写上评论和纠错。如果学生得到反馈, 知道自己的长处和短处, 测试的激励效果会更好。这可以鼓励学生好好学习。这一直以来是个公认的真理。老师经常对常见评语和错误进行记录, 可以了解自己教学的效率。

## 9.7 总 结

编写高质量的测试题目是一项可以学习的技能。在本章中, 我们介绍了几条所有高质量试题应满足的原则, 包括: 保证阅读和词汇水平符合测试的目的; 确保每道单项选择题只有一个最佳答案; 保证考查重要内容; 保证题目的独立性; 避免太偏的题目; 确保题目提出了一个清楚的问题。

虽然正误判断题价值有限, 但是很受欢迎。在编写判断题的时候应注意以下几点: 保证每道题没有含糊, 对错分明; 避免特定限定词; 避免模糊数量词; 避免使用否定句; 每个题目只表达一个概念; 保证正确和错误的陈述长度接近; 正确和错误的数量接近。对常规的正误判断题可进行四种变形处理: 在重要概念下划着重线来减少模糊性; 要求受试者改正错误的地方; 围绕同一组材料来出题; 将几个简短陈述放在同一个标题下。

多项选择题在测量教学目标上更有灵活性。这类题通常要求受试者读一段题干, 然后从三到五个选项中选出最佳选项。在编写多项选择题时, 应遵循以下原则: 确保题干提出了一个清楚的问题; 尽量把题目内容放在题干, 减少阅读负担; 只在题目中包括必要材料; 避免否定词; 在检测理解和应用目标时, 使用新颖材料; 确保只有一个最佳答案; 确保错误答案也是合理的; 避免出现对正确答案无意识的提示; 间隔使用 “全都正确” 和 “全都不正确” 这样的选项。单项选择可以是复杂、有很多选项的形式, 也可以是成对陈述的形式。

配对题目是一种特殊的多项选择题型, 提供多个题干和多个选项。好的配对题应该包括同质的陈述和较短的选项。受试者从简短的选项中选择, 每一栏应该有一个清楚的标题。选项数量应该多于题干数量, 选项排序应该有逻辑顺序, 作答指示应说明配对的依据是什么。

在编写测试题时, 应该: 写下比实际要用的更多的题目; 仔细检查题目; 将题目排好, 方便阅读; 将题目进行排版, 可以使用分开的答题纸; 按照形式和内容进行分组; 按照难易程度进行题目安排; 为每类题目写好答题指南; 确保某道题不会泄露另一道题的答案; 确保正确答案没有某种有规律可循的模式。

选择题的一大特征是受试者可能靠猜答对题目。猜测会降低测量的信度, 因为分数会产生随机误差。要校正猜测带来的误差, 可以先计算靠纯猜测可以答对几题, 然后从总分减去这个数值。这样的校正办法也是有问题的。

商业出版商在向公众发布测试之前会对题目进行评估。这个过程就是题目分析, 涉及对题目难度进行检查, 确保难度范围合适, 对水平高低学生进行区分。大多数测试目的下, 好的题目应该是中等难度, 平均区分度指数为 0.50 左右或更高。进行题目分析还为了确保所有误导选项发挥了应有的作用。

通常来说, 论述题只有在测量组织能力和原创能力时才使用。在编写论述题的时候, 应该大致遵循以下原则: 在编写题目之前弄清楚打算测量什么样的思维能力; 使用新颖材料; 用 “比较”、“解释……原因”等词开头; 将问题说清楚, 不要有歧义; 如果是有争议的材料, 在提出问题时, 让学生论证自己的立场; 依据受试者的能力, 调整测试的长度和复杂度。在准备测试的时候, 应确保在考试时间内, 题量不要太大; 不同的问题难度不同; 要求所有受试者回答同样的问题; 为测试写好测试说明。在为论述题评分时, 应提前决定好的回答有哪些特点; 准备好参考答案; 在批卷时, 先批完一道题再批下一道题; 在批下一道题时, 打乱试卷顺序; 批卷时不要看考生名字; 在试卷上写评语和改正错误之处。

## 9.8 习 题

1. 为什么仅供当地使用的测试的编写人员通常遵循的试卷开发程序较差?

2. 要编写高质量的测试, 有哪些要求?

3. 在什么情况下, 效标参照测试比常模参照测试更合适?

4. 一位老师为生物课设定了十个目标, 每个目标安排了五个题目。如果学生五个问题答对了四个, 那么就算掌握了目标。这种测试方法最适当的叫法是什么?

5. 列出采用和不采用效标参照测试的正反论点。

6. 在一所初中, 一位老师完全负责为所有班级制定自然课的期末考试。在制定测试的时候, 他没有和其他老师商量。该出题过程有什么优缺点? 如何提高?

7. 在中学的社会课上, 一个常常提到的目标是提高学生对不同新闻媒体的新闻进行批判的能力。如何改进对这一目标的表述, 以便对其进步情况进行测量?

8. 请看本书第五章制定测试蓝图部分为卫生课某个单元制定的测试蓝图。蓝图中哪部分适合使用知识回忆性练习或选择题练习? 该决定受到了哪些因素影响?

9. 为某个熟悉科目设计四道选择题, 测量对该科目的理解和应用能力。

10. 编写一系列正误判断题来测量第九题中同样的测量结果。那种题目类型对评估学生的知识水平更有效?

11. 为你正在学或教的单元准备一套简短的客观测试。对每道题的测试目标进行说明。

12. 下列测试中哪些应当对分数中的猜测成分进行校正。请提供判断理由。

a. 有 100 道题的正误判断测试。所有学生都回答了所有题目。

b. 有关空间关系的 70 道选择题测试。每题 5 个选项, 每题正确答案至少有一个, 可能超过一个。所有学生答完所有题。

c. 50 道选择题,每题 4 个选项,只有一个正确答案。仅 \( {40}\% \) 的受试者完成了所有题目。

d. 60 道选择题,每题 4 个选项,只有一个正确选项。 \( {90}\% \) 的学生答完了所有题目。

13. 一位大学教授在一个大班中进行了客观测试, 试卷评分后将成绩记录在班级记录册中。在把试卷发给学生之前, 这位教授还应该做些什么? 为什么?

14. 收集五道你在测试中看到的差题。说明题目的问题出在哪里。

## 推 荐 阅 读

Albanese, M. A. (1988). The projected impact of the correction for guessing on individual scores. Journal of Educational Measurement, 25, 149-157.

Albanese, M. A., & Sabers, D. L. (1988). Multiple true-false items: A study of interitem correlations, scoring alternatives, and reliability estimation. Journal of Educational Measurement, 25, 111-123.

Bennett, R. E., & Ward, W. C. (1993). Construction versus choice in cognitive measurement: Issues in constructed response, performance testing, and portfolio assessment. Mahwah, NJ: Erlbaum.

Berk, R. A. (Ed.). (1984). A guide to criterion-referenced test construction. Baltimore: Johns Hopkins University Press.

Cohen, A. S., & Wollack, J. A. (2006). Test administration, security, scoring and reporting. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 355-386). Westport, CT: Praeger.

Drasgow, F., Luecht, R. M., & Bennett, R. E. (2006). Technology and testing. In R. L. Brennan(Ed.), Educational measurement (4th ed., pp. 471-516). Westport, CT: Praeger.

Gronlund, N. E. (1982), Constructing achievement tests. Upper Saddle River, NJ: Prentice Hall. Harper, A. E., Jr., & Harper, E. S. (1990). Preparing objective examinations. New Delhi: Prentice Hall of India.

Hopkins, K. D., Stanley, J. C., & Hopkins, B. R. (1990). Educational and psychological measurement and evaluation (7th ed.). Upper Saddle River, NJ: Prentice Hall.

Linn, R. L., & Gronlund, N. E. (2000). Measurement and evaluation in teaching (8th ed.). Upper Saddle River, NJ: Merrill/Prentice Hall.

Mager, R. F. (1975). Preparing instructional objectives (2nd ed.). Belmont, CA: Fearon.

Nitko, A. J. (2003). Educational assessment of students (4th ed.). Upper Saddle River, NJ: Merrill/Prentice Hall.

Osterlind, S. J. (1989). Constructing test items. Boston: Kluwer.

Schmeiser, C. B., & Welch, C. J. (2006). Test development. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 307-354). Westport, CT: Praeger.

Thissen, D., Steinberg, L., & Fitzpatrick, A. R. (1989). Multiple-choice models: The distractors are also part of the item. Journal of Educational Measurement, 26, 161-176.

Van Sack, J. (2004, June 14). Cheating keeps getting easier: Students using cell phones to cheat on exams. The Patriot Ledger. Retrieved July 20, 2007, from http://ledger.southboston.com.

Wainer, H. (1989). The future of item analysis. Journal of Educational Measurement, 26, 191-208.

## 第10章 表现评估和作品评估

## 10.1 引 言

对教育界内外的大多数人来说, 测试一词意味着通常用于评估认知目标的卷面测验手段。此类测试常常采用选择一作答题型, 考生可从一组选项中选出答案。经验表明, 熟练的教师和测试编写者能够通过认知测试来评估几乎所有学习效果, 因此卷面测试适用于很多教学目标, 但也会与其计划用来考查的某些教学目标大相径庭、无甚用处。学术界之外也有不少教学任务和学习表现可能不适合以传统测试来评估。

## 10.2 传统认知测试的人为因素

几乎所有测试在某种程度上都存在人为因素, 因为我们基本不会直接测评教学目标或工作表现, 而测试标准化则加剧了这一问题, 因标准化测试更加需要采用选择一作答式题目以便于机器阅卷和计算机分析。即便是阅读理解类型的认知题材, 我们也会觉得最适合以客观测试进行评估, 但问题在于如何将评估任务和教学目标相匹配。通常情况下, 阅读理解通过段落大意多项选择题来考查学生能力。这种评估方式与传统意义上的阅读理解有所不同, 传统的阅读理解基于学生理解所读内容, 将新知识与以前学过的知识相结合, 进行批判性评价的能力。人为因素同样存在于客观的拼写测试, 要求学生从三四个错误拼写中选出正确的一个; 这也存在于英语句法测试, 要求学生区分语法正确或错误的句子。但是正常拼写过程要求学生正确拼写出单词而非辨认出单词的正确拼写, 同理, 我们考察英语用法知识通常需要学生正确遣词造句。因此英语写作课程意在使学生达到掌握拼写及句法技能的水平, 创作出语法正确、拼写错误最少的文章。而考查学生拼写句法技能掌握程度的最直接方法就是检查他们写出的文章。但是单单判定语法或是拼写错误并不能完全等同于学生的认知能力。尽管客观卷面测试有间接性, 不少教育者还是愿意接受这些人为因素来换取客观性和方便性。然而, 教育界越来越倾向于采用 “真实性评估”, 即将知识技340能运用到解决实际问题的任务, 来衡量教学过程中以及类似于《有教无类法案》要求进行的大型标准化测试中的教学目标掌握程度。

不少重要的教学目标及认知能力并不适合通过卷面测试来评估, 最明显的就是需要某项技能的直接行为展示或是创造具体作品的题材, 例如音乐、体育、演讲、戏剧课上的表演, 视觉艺术、工艺美术或语言艺术项目。

这种情况下评估教学目标的掌握程度会很困难, 这类课程教师可能只会收集少量评估材料来考查学生表现, 因此教学评估呈弱化趋势, 而人们认为过程评估和作品评估过于主观, 比不上那些较明确的学科测评, 因其评分标准较为客观。这种看法更加剧了教学评估的弱化趋势, 同时也会成为某些情况中不重视期末成绩的理由。

教师不倾向于以衡量学术活动的评判方式统一评价不同类型的教育作品, 部分原因在于他们认为音乐、艺术、体育等学科方面的表现受既有能力影响较大。人们普遍认为, 在这些学科中, 学生作品及表现质量很大程度上取决于学生上课之前掌握的技能和能力, 因而不见得是教学成果。例如, 有些艺术类学生上课第一天就能画出极富创造力且相当不错的作品, 但也有学生不管接受多少指导都不可能画出一幅满意之作, 这种现象当然也存在于英语写作或是微积分问题求解方面。但是人们不愿把英语写作或微积分方面的成就归功于天赋, 反而归功于努力、潜力或前期受教等, 比如人们会认为, 歌喉不好可能是由于超出学生本人控制之外的因素, 但不会运算求解则非不可控因素。

## 10.3 作品评估

以前有必要区分具体作品评估和表现评估的不同情况, 例如艺术课上做的雕塑, 或是演讲、形意舞这类不会留下永久记录的表现。前者的评估较为从容, 而后者则必须在表演之时或是根据可能有错误的记忆进行评估。随着视频技术的广泛应用, 不再需要区分两者, 表演也可转化成具体作品。

多数情况下, 评估的核心往往是作品本身, 而非创作作品的过程。例如, 老师通常感兴趣的是学生创作的诗, 而不是作诗过程。此外, 评估作品比评估过程更简单易行。作品中会有单个对象 (或表现) 可以与掌握程度外在标准或者其他人的作品表现进行对比。而创作过程包含多个部分, 每部分即便有记录也很可能是暂时的, 必须权衡各部分表现得出总体性评价, 整个过程中每一步都要确定评价标准。但是有时创作过程和作品并不好区分, 比如一场演讲或是一次舞蹈表演。有些情况下, 创作过程与作品同等重要, 甚至更为重要: 首要问题是安全时; 学生作品本身可以视为暂时性的作品时; 作品评价尤其难以进行时。但是即便是以上情况, 现代记录程序可以为后续评价永久记录表演过程。

安全。如果创作过程较为危险, 则重点必须放在确保创作过程正确进行方面, 例如化学实验规程、体操表演, 或是木工和机械车间使用电动工具等。我们不仅要关注程序步骤及安全措施是否清楚准确, 还要看是否认真按照程序进行操作, 这些情况中我们对某个人的评价很大程度上受其是否遵守规程所影响。

暂时性作品。某些情况中, 具体作品或表现相对于创作过程来说是次要的, 因为该作品只是创作更好作品或取得更好表现过程中的一小步。举个网球发球的例子, 一个运动员可能发球比班上任何人都有效, 但发球方式不正确, 即使他的发球可以得分, 网球教练也不会给他高分。好的发球不能单以成功与否来评价, 因为不使用正确的发球方式就不会有提高。多数网球教练更乐于看到方式正确却撞网的发球, 也不愿看到方式不正确却得分的发球。计算机编程是另一个需要强调操作程序准确的领域, 一项计算机程序能够执行指定任务并不意味着该项程序合格, 适当的程序和编程效率也是重要的考虑因素。

难以评估的作品。如果作品评估具有主观性, 那么评估过程因素而非作品本身更为实际。例如, 评价教学过程比评价教学成果更加简单易行, 因为还未设计出令人满意的评价体系来评估教学效果。但有教学过程评价体系, 比如以过程一成果研究结果为基础的评价体系。咨询是另外一项过程比结果更易于评估的活动,管理风格亦是如此。

## 10.4 在认知任务中运用表现评估和作品评估

以前, 认知能力通常不会以表现评估和作品评估手段来评估, 但现在通过表现评估和作品评估方式来评价认知能力受到越来越多的关注。近来的教育改革呼吁以认知心理学在教育中所起作用的发展为基础, 这些发展使得评估认知能力成果及过程受到越来越多的关注。而关注认知心理学则源于对传统教育实践的批判, 传统的教育实践严重依赖客观卷面测试, 卷面测试成为评估教育效能的唯一标准 (Lane & Stone, 2006; Nickerson, 1989)。根据上面的讨论, 选择一作答式测试不能使学生直接展示其对教学目标的掌握程度, 因此需考虑其人为因素。加之课堂上越来越多地运用认知心理学原理, 从而要求加快培养学生的高层次加工技能及批判性思维技能。 人们普遍认为这些技能必须通过表现评估和作品评估手段来评估。尽管评估实现教学目标的过程技术上切实可行, 但目前认知目标大部分评价重点在于作品评估, 而表现评估一般与之相结合。

大多数情况下, 通过表现评估来考察认知目标主要涉及使用建构题型。建构题型要求学生根据问题或提示给出答案, 而非从一组选项中进行选择。根据所评估的教学目标, 可能会要求学生写一篇文章, 或者解决某个问题, 或是以其他方式展示某项技能。表现测试项目的基本特点是模拟实际情况, 考生有机会在示范任务中展示其技能熟练程度。第九章给出了设计建构题型的一般准则。

如果目的是衡量特定背景下的教育表现, 则要利用另一种不同的表现评估方式。 这种情况下, 最常用的方法是创立作品集并对之进行评估, 该作品集包括学生在某个领域中的作品, 可能包含进行中的作品、修订的作品、最终作品及学习过程反思等。 强调记录学习和进步过程的作品集经常用于形成性评价目的, 而 “最佳作品” 作品集则展示的是学生的最终成绩。

## 表现评估的评分

表现评估的评分一般有两种形式: 标准答案与参考答案。标准答案形式较为简单明了, 一组选项中有一个或多个正确答案, 学生的答案只要对应上一个标准答案即算正确, 这种评分广泛应用于考察认知能力的个体测试, 例如韦克斯勒量表和斯坦福- 比奈智力量表 (参见第十二章)。相较于标准答案评分形式, 参考答案评分则较为复杂。参考答案题目中没有一个或一组正确答案, 评分主要根据一套评分标准, 称之为评估细则。大多数情况下, 评估细则按照层次梯度描述可能的答案, 确定智力量表不同分数所对应的预期知识和技能水平。图 10-1 所示为八年级数学作业测验范例以及对照的评分准则。

在运用评估细则打分时, 必须有明确的标准说明教学目标规定的技能熟练程度, 同时评分者需在运用评分标准方面有足够训练。这两项至关重要。另外还需要为评分者提供评分标准中各个分数的考生参考答案范例。一旦评分者训练不足或是运用模糊不清的评分标准, 作业测验的分数会比与其相对的选择一作答式测试更加欠缺客观性及可靠性。相反, 弗雷德克里森和柯林斯 (Fredericksen & Collins, 1989) 在探讨全州写作测试评估的广泛使用时指出, 通过训练有素的评分者和仔细敲定的评分标准, 参考答案式评分利用评估细则能够得到精确可靠的结果。莱恩和斯通 (Lane & Stone, 2006) 针对评分细则进行了详细的阐释。采用计算机对作文进行评分方面的最新进展也使得建构题型更加可行, 此项技术快速发展, 相关信息可通过 http:// www.ets. org/ research/erater. html 网站获取。



习题 C

拉米雷斯先生请四名学生制作钥匙扣。他给朗达、山姆、托尼和尤塔四个人一块木板, 让他们平分使用。

朗达测量后切下木板的四分之一。

山姆测量后切下剩余木板的三分之一。

托尼测量后切下剩余木板的二分之一。

尤塔使用最后剩余的木板。

10. 四名学生均分木板了吗? 画图说明你的答案。使用下列检查表辅助作答, 以便你的思路易为别人所理解。 检查表此图和说明清楚描述了四名学生是如何分配木板的。 1 解答思路符合逻辑。 ] 解答拼写、大写、停顿正确, 书面整洁。

## 评分细则

注: 适当情况下接受同义词组, 评估重点应在于答题内容和理解的证据。 第 3 页第 4 题如果学生测量后继续切割剩余木板的四分之一, 结果会如何? 请充分解释你的答案。 (2 分) 说明如果学生测量后继续切割剩余木板的四分之一, 之后的木板总要比前一块木板短, 理论上学生不可能切割至本板尽头, 或者学生到最后可能在切割木屑, 得 2 分。 说明木板最终会被用完但没有说明如何会这样的, 得 1 分。 第 3 页第 5 题学生没有清楚理解拉米雷斯先生对切割木板的说明。拉米雷斯先生应怎样说才能使其说明更加清晰? (1 分) 他可以跟学生说每人测量并切下 16 英寸长的木板, 或者切下总长为 64 英寸的木板的四分之一。(见注) 第 5 页第 10 题四名学生均分木板了吗? 画图说明你的答案。(4 分) 根据以下列出的特征, 选择与其最接近一项学生答案进行打分。(见注) 4 分: 答案包括图示和解题说明, 表明学生清楚理解该题模式答案中图示应展示一个整体被均分成四部分答案中解题说明应增强图示效果, 用句子或计算或结合两者来比较每段木板的长短 3 分: 答案包括图示, 表明学生清楚理解该题模式, 但解题说明不充分答案包括解题说明, 表明学生清楚理解该题模式, 但图示不充分答案中图示和解题说明细节有限 2 分: 答案仅提供恰当图示答案仅提供恰当解题说明答案中解题说明不能增强图示效果答案由于语言语法错误难以理解 1 分: 答案图示或解题说明不充分答案不明确 0 分: 此题未作答字迹模糊、难以辨认的答案不得分。



图 10-1 数学表现评价练习示例及评分细则

资料来源: 改编自 F. L. 芬奇主编的《教育表现评价》(1991 年)。芝加哥: 里弗塞德出版公司。

## 10.5 过 程 评 估

过程总是包括若干部分或若干步骤, 因此过程评估强调评价该过程中的每一步, 而检查表和评定量表则是考察不同步骤的主要手段。

## 1. 使用检查表

评价学生是否采用了恰当的程序通常要用到检查表或定级量表。一般来说, 使用检查表应优先于定级量表。在使用检查表时, 观测者只需要观察学生表现, 在观察表上记录预期行为存在与否。相反, 使用定级量表时, 观测者必须判断该行为出现的频率或者该行为的质量。另外, 使用定级量表过程中的判断非常耗时, 因此可能严重限制所评定行为类别的数量。

设计检查表需遵循以下几步:

① 明确恰当的表现或作品。

② 列举重要的行为和特征。

③ 列举被评估人可能会犯的常见错误。

④ 以适当的格式整理列表。

明确恰当的表现或作品。设计检查表首先要明确指出最终作品应是什么样的。 大多数情况下, 当强调用检查表来考察某个过程时, 精确定义作品本身也许不太可能, 但必须概括地进行具体说明。这一步的目的在于为确定重要的行为和特征提供关注重点。

列举重要的行为和特征。设计检查表至关重要的一步在于详细列出一系列行为和特征来描述成功的表现或作品。一张合理的检查表要包括实现最终作品或表现所需的所有重要且相关的行为和特征。但检查表中应排除所有人都表现出的行为和特征 (如心脏继续跳动) 以及对学生无法评估的行为和特征 (如 “有积极的认知经验”), 这些行为特征不会产生有用信息, 而且会使检查表显得杂乱无章。描述行为的说明措辞应使观测者的阐释需要减少到最低限度。检查表需要包含尽可能多的内容, 但同时不能够过于冗长复杂而使得判断过程难以控制。下面的例子是一个网球高手应该具备的部分行为特征:

① 握拍方式正确。

② 击球时双脚站在正确的位置。

③ 保持手肘笔直。

④ 正手击球至对方场地。

⑤ 反手击球至对方场地。

⑥ 发球至对方场地指定区域。

⑦ 有效截球。

⑧ 顶球。

当然, 上述每一个动作都可以进一步细分, 例如, 正确发球或是头顶扣球都涉及很多步骤。检查表中行为与特征的详细程度取决于所观察行为的详细程度或概略程度。

与上述列表中相关的任何明确或不明确的表现与特征都可以作为标准。这些标准可以非常精确, 例如学生可以与理想的握拍方式偏差几分之一英寸或是旋转多少度, 也可以不是特别精确, 例如裁判一致认为怎样才算是正确的握拍方式。制定标准的初衷在于提高根据统一标准判断某个表现存在与否的概率。例如花样滑冰比赛的裁判会参考比较对先前评分较低的选手表现的评判, 以此调整自己的评判标准, 从而降低对有望夺冠的选手的评分变化情况。

列举被评估人可能会犯的常见错误。仅确定学生已完全执行操作过程中的必备步骤远远不够, 同时还需要注意是否存在不当行为, 这也很重要。例如, 观察某位老师时, 可能会发现该老师展现了与良好教学相关的大部分行为举止, 但他/她对学生的不良行为予以挖苦讽刺。关注这些负面表现与所有的积极表现一样都有重要意义。

以适当的格式整理列表。确定一系列合适或不合适的行为与特征后, 需要按照观察者最可能遇到的顺序进行排列。整个列表要形成观察表格式, 简单易读, 同时需要给观察者留出空白来作核对标记, 表示某项行为存在与否。对于重复出现的行为, 例如打岔中断, 回应表要按照时间段来安排, 如果某个指定时间内该行为出现, 观察者只需作核对标记即可。其他方式可以要求观察者指出某行为出现的次数, 或估计某个活动上花费的时间。要根据回应的种类留出适当的空白。

检查表做好后, 必须对结果进行解释。如果结果要用于给学生表现予以反馈或协助老师提高教学质量, 可以分别对各个部分 (各行为特点) 加以说明; 如果检查表结果要用于作总结性评价, 各个部分则必须概括为总得分, 整个总结可以通过合计各项目分数得出, 当然还需要考虑到必须避免的行为, 可能也会需要根据各项目的重要性对其加以侧重处理。

## 2. 使用定级量表

定级量表可以用于评估一系列行为和特点, 与检查表的用途大体相同, 不同之处在于前者要求观察者针对某个行为提供评分或者评定等级, 以此来说明该行为特质或发生频率。但若是为了评估正在进行的过程, 通常倾向于使用检查表, 因为过程评估省去了定级量表需要的评定时间。构建评定量表的更多信息详见第十一章。最简略的评定量表应包括一系列行为和特点及其说明, 观察者可根据说明在指定范围内针对某个行为选择一个评分, 以此评定该行为的某些特质。不过, 量表更常以图形形式出现, 两端有端点说明, 中间有数字或者词语说明量表上的分数。量表可能有许多形式, 包括如下的简单形式:

化学实验室安全规程的正确使用情况

化学实验室安全规程的正确使用情况







另一种方式是让观察者想象出一个某个行为或特点的最佳模范人选, 把他/她放在量表的一端, 然后想象量表另一端的一个最坏的范例。观察者之后的任务就是指出在整个连续序列中被观察者应该处于哪个位置。下列是这种方法的示例:

根据两个给定的例子评定学生演讲开场白的质量







10.6 评估作品及表现

在作品或表现评估中, 参照预定表现标准比较学生作品比参照其他学生的表现更可取。第三章中我们对两种评估方式进行了区别: 参照预定标准被称为标准参照评估, 以其他学生表现为标准的方式称为常模参照评估。按照尼特科 (Nitko, 1984) 的定义, 标准参照测试是 “经过仔细构建以产生可直接依据特定表现标准加以解释的测试” (第 12 页)。前文已经提到作品和表现评估的主要目标是获取学生掌握特定教学目标程度的说明, 而常模参照评估则说明某个学生相较于其他学生的表现水平, 说明不了教学目标的掌握程度。

除了与表现测试的基本原理不一致之外, 常模对比在评估作品和表现时还会造成某些问题。多数情况下, 学生作品在许多方面都存在差异, 因此给不同作品的合理对比造成很多麻烦。任何两件作品都有众多不同之处, 一件作品可能在某些方面较好, 但在其他方面较差。例如, 评估某个科学项目, 教师或裁判必须考虑到独创性、科学贡献、整齐度、坚固性、创造性、陈述说明的广度和质量、参考文献的使用等。那么进行常模对比时应如何权衡这些特点呢? 如何将一个大胆独特但是呈现方式不太合适的项目和一个较为传统、创新性较差但是结构清晰准确、记录细致详细的项目作比? 这种情况下, 很明显两者很难进行比较。要使评估此类作品更加简单直白, 则需要判断哪些方面对进行评估的教学目标较为重要, 明确界定教学目标掌握标准。汉布尔顿和皮东尼亚克 (Hambleton & Pitoniak, 2006) 对设定及评估表现标准提供了有用的建议。

## 1. 多位观测者的优点

设计表现测试或检查表的老师通常是唯一进行测试及检查表评估的人, 但在研究、临床试验及高风险教学背景下, 多位观察者进行观察会具有明显的优势。首先, 不同裁判之间可以进行对比, 从而获取评估可靠性信息, 如果所有裁判反应一致, 那么说明评价具有信度, 若两位观察者意见不同, 那么说明观察的说明、观察结果的评分或观察者自身能力可能出了问题。可以核查那些有争议的内容, 从而判断出是这些内容本身还是评分规则需要进一步清晰界定。另外, 观察者训练不足也常常造成评分一致性信度较低。

多位观测者还有其他优点。例如, 结合多位观测者的反馈得到的分数可能会比单个观测者得出的分数更精确, 原因在于每个观测者的误差可以彼此之间相互弥补。 事实上, 可以认为综合评定对评估信度所起的作用与延长测试完全一样。

## 2. 多位观测者的可靠性或一致性

评估不同行为观测者的可靠性或一致性程度可以用不同方法, 其中最广泛使用的方法建立在普适理论的应用基础之上 (第四章已简要提及相关内容)。该方法的统计方面超出本书讨论范围 (有关讨论和示例详见罗伯特 \( \cdot  \mathrm{L} \) . 桑代克和罗伯特 \( \cdot  \mathrm{M} \) . 桑代克,1994),但基本逻辑非常简单直接。若所有被观察者 (用 \( \mathrm{N} \) 来代表) 的所有行为 (用 \( \mathrm{B} \) 来代表) 由多位裁判或观测者 (用 \( \mathrm{J} \) 来代表) 进行观察,那么观测结果共有 \( \mathrm{N} \times  \mathrm{J} \times \) \( \mathrm{B} \) 种变化情况,均可以依据数据来源加以分类,其中一个来源在于被观测者 \( \mathrm{N} \) 之间的真正差异,一个来源在于观测者 \( \mathrm{J} \) 之间的特点差异,另一个来源在于行为 \( \mathrm{B} \) 之间的348特点差异。此外, 若裁判们对于某个被观测者的不同行为意见相悖 (称为裁判乘以行为或 \( \mathrm{J} \times  \mathrm{B} \) 互动关系),或者被观测者们在某个裁判面前行为表现不一致 (称为被观测者乘以行为或 \( \mathrm{N} \times  \mathrm{B} \) 互动关系),或者对不同被观测者的同一行为裁判们意见不一致 (称为被观测者乘以观测者或 \( \mathrm{N} \times  \mathrm{J} \) 互动关系),这三种数据来源也会增加观测结果的变化情况。裁判们对被观测者的意见不一致, 可以将之视为在某个存在异议的行为方面裁判对被观测者的评估有很大的不可靠性。换言之, 如果评估完全可靠的话, 那么所有裁判应该对 1 号被观测者的某项相关行为给出同样的评定, 裁判对 2 号被观测者的行为评定也应该完全一致, 以此类推, 对不同的被观测者给出的评定会有所不同, 但是裁判对单个被观测者的评定必须一致。因此, 当裁判乘以被观测者互动的变化系数大于零时, 就可以认为评估结果缺乏完全的可靠性。

若要考察两个裁判的两项不同评估的可靠性, 例如某项特定行为存在与否, 那么可以使用更加简单的数据统计来表示, 称之为卡帕统计 (Kappa)。卡帕统计可以理解为一致性比例, 并通过随机一致性的概率加以调整, 具体计算如下面四联表所示:



<table><tr><td colspan="2" rowspan="2"/><td colspan="2">第一个裁判</td></tr><tr><td>存在</td><td>不存在</td></tr><tr><td rowspan="2">第二个裁判</td><td>存在</td><td>a</td><td>b</td></tr><tr><td>不存在</td><td>c</td><td>d</td></tr></table>



表中每个字母的意义如下:

\( \mathrm{a} = \) 两个裁判均记录该行为存在 (意见一致)

\( \mathrm{b} = \) 第一个裁判认为该行为不存在,第二个裁判认为该行为存在 (意见不一致)

\( \mathrm{c} = \) 第一个裁判认为该行为存在,第二个裁判认为该行为不存在 (意见不一致)

\( \mathrm{d} = \) 两个裁判均记录该行为不存在 (意见一致)

字母 \( \mathrm{N} \) 表示观测次数 \( \left( {\mathrm{N} = \mathrm{a} + \mathrm{b} + \mathrm{c} + \mathrm{d}}\right) \) ,那么意见一致比例为:

\[A = \frac{a + d}{N}\]

可以证明随机一致性概率为:

\[C = \left\lbrack  {\left( \frac{a + b}{N}\right)  \times  \left( \frac{a + c}{N}\right) }\right\rbrack   + \left\lbrack  {\left( \frac{c + d}{N}\right)  \times  \left( \frac{b + d}{N}\right) }\right\rbrack  \]

那么卡帕统计值可以定义为:

\[\text{ 卡帕 } = \left( {A - C}\right) /\left( {1 - C}\right) \]

假设两个裁判在 100 个观测片段中评定存在攻击性行为的结果如下:



<table><tr><td colspan="2" rowspan="2"/><td colspan="2">第一个裁判</td></tr><tr><td>存在</td><td>不存在</td></tr><tr><td rowspan="2">第二个裁判</td><td>存在</td><td>50</td><td>13</td></tr><tr><td>不存在</td><td>16</td><td>21</td></tr></table>



那么随机一致性概率为:

\[C = \left\lbrack  {\left( {\left( {{50} + {13}}\right) /{100}}\right)  \times  \left( {\left( {{50} + {16}}\right) /{100}}\right) }\right\rbrack   + \left\lbrack  {\left( {\left( {{16} + {21}}\right) /{100}}\right)  \times  \left( {\left( {{13} + {21}}\right) /{100}}\right) }\right\rbrack  \]

\( = {0.4158} + {0.1258} = {0.5416} \)

意见一致的总比例为:

\[A = \left( {{50} + {21}}\right) /{100} = {0.71}\]

卡帕统计值为:

\[\text{ 卡帕 } = \left( {{0.71} - {0.5416}}\right) /\left( {1 - {0.5416}}\right)  = {0.17}/{0.46} = {0.37}\]

如果一致性比例没有大幅度超过随机一致性概率, 则说明观测者需要加强训练。

卡帕统计量也可以用于评估某项教学目标掌握程度测评结果的可信度。在这种情况下, 应该判断的是掌握/没掌握而非行为出现/未出现, 进行评估的两项测评结果要么来源于两个不同的测试, 要么来源于一分为二的一个测试。

## 10.7 系 统 观 测

有些教学目标和临床干预并不需要认知行为, 也不需要作品, 而是集中于个性特征和态度的变化。要获取个性特征和态度的相关信息, 有一种方法是在自然情境中进行系统观测, 其他方式将在第十四章中加以讨论。

尽管日常生活的自然情境因人而异, 但是在日常生活中观测行为表现有其重要优势。日常生活情境中进行观测可以避免专门为测试设计特殊事件的需要, 这一点使真实情景的观察非常有吸引力, 并且可能得到更确切的行为表现反馈。

当然, 观察与我们日常相关的人是我们正常生活的一部分, 我们会留心他人在做什么, 并对其行为表现做出回应。我们对他人的印象会通过观察而形成和变化, 但这些观察比较随意偶然, 不系统也无明确目的。若要求我们对自己的评判提供具体例子加以证明, 证明海伦是团队领导者或者亨利靠不住, 会发现大多数人都难以提供一两个以上具体的实际行为观测来证实自己的整体印象。事实上, 人们倾向于在少量外显的观察结果基础上彼此分门别类, 并以自己的整体印象来看待他人的所有特征, 这种现象被称为成见效应。如果观测数据要产生可靠的个体信息, 同时避免不当的350一概而论, 那么就必须进行有组织、有目的的系统观测。

这里有必要区分现在讨论的观测程序及第十一章中的评级程序。搜集系统观测数据时, 要求观测者的担当客观机械的记录工具, 但在评定观测数据时, 测评者需综合整理现有证据。在系统观测中, 观测者的功能仅限于提供被观测者社会交往、建议、攻击性行为或任何相关行为类别数目的精确记录, 相当于一台摄影机或录音设备, 只不过灵活性更大, 功能性更强。但在观测结果评定中, 这个人体 “仪器” 必须对信息进行判断、权衡及诠释。

系统观测程序在婴幼儿研究中充分发展, 该程序特别契合儿童研究设定。婴幼儿还没有学会像大人一样完全掩饰隐藏自己的情感, 因此观察婴幼儿能够获得更多信息。同时婴幼儿不那么会以语言来表达自己, 因为他们的自我认知有待发展, 语言能力也有待提高。基于以上原因, 系统观测程序在研究婴幼儿中得到充分发展。

## 1. 进行系统观测

根据某种行为表现, 针对某人个性的某个方面相对客观地提炼出有意义且真实可靠的评价远非易事。首先, 行为表现会不断发展变化, 没有明显的中断。例如一名学龄前儿童这一刻在沙盘上做“蛋糕”,下一刻就会转而听老师跟一组学生讲话, 接下来又会用大积木建造房子。在此过程中, 他坐下来休息了一会儿, 顽皮地戳了戳另一个孩子, 对着老师喊 (也可能是笼统地对着整个世界), “快看! 我制作了什么!” 但是这样的记录不完整。不存在任何言词描述能够捕捉到一个活泼孩子的全部生活细节, 甚至仅仅 5 分钟的生活细节都捕捉不到。那么, 到底应该观测什么? 究竟哪些行为表现能够代表一个人的个性特质? 整个观测什么时候进行? 持续多长时间? 观测者应怎样进行训练? 应该怎样组织观测过程? 现在把我们的注意力转到上述实际问题上。

应该观测什么? 若观测一连串复杂的行为要产生任何有意义的信息, 那么整个观测活动应该有中心, 我们必须着眼于某个关注点或者寻找某个关注点一如领导能力、缺乏安全感、社交能力、情绪紧张、精力水平、进取性、依赖性等特质的迹象或是诸如此类的多项个性特质标志——我们也可能同时关注所有上述标志。具体的研究或实际问题决定了应该观测哪些行为内容, 而整个观测计划应遵从于如何界定与实际问题紧密相关的行为表现内容。

哪些行为表现能够代表一个人的个性特质? 即使是选定了某个特质进行研究之后, 还必须确定哪些行为表现是该特质合适的标志。思考一下如下行为:

独坐

踢其他孩子

紧紧抓着老师的手或衣服

以地上的混乱吸引注意力

背后议论其他孩子

在讨论中主动提供信息

以上哪个行为能够作为幼儿依赖幼儿园老师的标志? 还需要增加哪些行为表现? 若要产生有实际意义的观测数据, 必须在儿童典型童年行为及其动态发展知识基础上做出如上判断。

进行观测的时间和时长。一旦开始系统观测, 就必须决定每个被观测者要在哪儿及什么时间进行多长时间的观测。这些判断体现了广泛观测的高成本与需要获得被观测者典型可靠的形象之间的一种折中。由于每天的情况因人而异, 因情境而异, 与其选择一两个较长时段进行观测, 还不如在不同日期选择几段较短时段进行观测。 这种情况下, 被观测者的行为表现更具代表性, 所得评分也更加可靠。但同时必须注意行为表现不能过于简短, 否则将会难以判断某个具体动作的象征意义。此外系统观测过程中相关的出行时间、管理任务等实际考虑也会限制我们针对某个孩子或团体进行的观测样本数量。

为了增强判断过程的可操作性, 可能把每天 5 分钟的观测分割成更短的时段更有用, 比如说 1 分钟以内或者 30 秒, 这样的观测数据就包含了某个行为表现存在与否的迹象。例如, 对每个儿童每天进行 10 次观测, 每次持续 5 分钟, 每次 5 分钟的观测又被进一步分割成 10 个时段, 每个时段持续 30 秒, 这样观测者就可以记录某个孩子是否出现了任何明确的攻击性行为。假设观测者决定只计算那些被观测儿童出现目标行为的观测时段数量, 每个孩子都会获得一个分数, 值域可能在 0 -100 之间, 表明他/她出现攻击性行为的时段数量。若所有观测时段中出现的攻击性行为数量均有记录, 那么可能会得出与上述情况有所不同的分数。但不论何种情况, 我们会发现, 这种基于短时段观察行为的精确数据记录而得出的分数具有较强的信度。

对行为观测数据信度的理解可能有误导性, 这些情况中的信度通常定义为两位不同观测者之间的一致性, 而信度系数的大小决定于用何种方法测算一致程度。意见一致的百分比反映了两位观测者达成一致的次数百分率, 当指定行为出现比例非常高或非常低时, 意见一致百分比往往会夸大实际情况。比如当某个行为经常出现, 很可能两位观测者都会有记录, 所以达成一致。同样地, 当某个行为几乎不会出现,352很可能两位观测者都没有记录下来, 所以也会达成一致。因此, 若某个行为出现比例极高或极低, 那么观测数据总会具有较高信度。之前讨论过的卡帕统计量则校正了这些机会变量。当然在目标行为表现可能出现的情境中进行观测最合适不过, 例如观测攻击性行为最好是在自由玩耍的那段时间, 而不是听故事或看电视时段。

观测者应怎样进行训练? 即使观测的行为表现经过仔细界定, 观测者之间仍可能产生分歧。举个较为极端的例子。一位研究员记录了在进行观测的教室中关于教师性别的观测者间一致性比例能够达到 \( {95}\% \) 。某种程度上差异不可避免,因为观测者注意力不断变化, 且针对某个行为出现与否, 观测者之间意见相左很正常。但是可以通过加强对观测者的训练来提高观测数据的可靠性, 训练课程上多位观测者基于同一个行为进行记录, 交换意见, 讨论并调和彼此之间的差异, 这样的课程是提高观测数据一致性的有效方法, 让之前经过训练的观测者旁听课程并提出建议也极为有用。这些程序有利于提高观测数据及数据解读的一致性, 有助于将行为示例归类到正确的观测类别中。

应该怎样组织观测? 观测活动一经开始就必须进行记录, 这一点至关重要。目击者事件重述的观测数据研究表明记忆误差和选择性记忆会使叙述者对某个事件的印象产生偏差, 即使是突出的不寻常事件也一样 (Hyman & Kleinknecht, 1998)。例如对于观察学龄前儿童过程中出现的较为普遍且高度反复的事件, 只有即时记录被观测儿童的行为表现, 才能够获得所发生事件的充分记述, 能够观察到的数据数不胜数, 几乎所有事件都如此, 靠记忆对儿童行为进行准确事后描述很可能导致严重遗漏或扭曲某些事实。

因此所有系统观测项目笔记提供即时有效的记录观测事件的方法, 有很多可能的方法有助于记录行为观测数据, 广泛使用的一种方法是相关行为类别系统编码。 比如, 可通过初步观测来界定三到四岁儿童可能出现的攻击性行为范围时, 可以设立如下代码:

字母 \( \mathrm{h} = \) 撞击

字母 \( p = \) 推挤

字母 \( \mathrm{g} = \) 跟别人抢东西

字母 \( \mathrm{c} = \) 骂人

诸如此类。可以准备一张空白观测表, 按照观测时间段加以划分, 不间断观察被观测儿童过程中可以迅速设计新代码。

记录谁对谁做了些什么对观测者来说具有重要意义, 那么两段式或三段式编码可以详细记录相关信息——第一个符号表示施动者, 第二个符号表示动作, 第三个符号代表受动者。很明显, 要使用如此复杂的记录体系, 对观测者进行充分训练至关重要, 能够熟练使用速记的观测者自然可以更充分地记录观测数据 (表格上应留空来做笔记)。这些记录之后会加以编码或进行评分。

另一种有效方式是将观测情景录成录像带或使用录音带记录观测者的观测数据, 通过这种方法能够获得被观测者行为表现的永久记录, 且形式较为完整。可以稍后分析录音带, 也可以重复观察模棱两可的行为, 获得精确的观测数据。

笔记本电脑也有助于更精确地记录行为表现, 可以进行计算机编程接收整套编码程序, 也可以实现输入信息模板化。这类程序不仅能够减轻观测者负担, 提高观测数据精确性, 而且随后的计算机数据分析也较为简单易行, 可以消除转录错误 (但记录错误不可消除)。决定信息组织形式和信息格式时最重要的问题在于将对记忆的依赖程度降到最低, 最大程度地记录保存行为表现原型的重要细节, 制定尽可能少的干预观测过程和观测行为的记录程序。

## 2. 系统观测的优缺点

系统行为观测的若干特点使其成为评估个性特征的极具吸引力的方法, 但是也存在一些明显的缺点。直接系统观测的优缺点总结如下:

系统观测的优点。系统观测最突出的优点在于: (1)系统观测数据提供实际行为记录; (2) 系统观测数据可用于现实生活情境; (3) 系统观测数据可用于观察儿童。

① 实际行为记录。我们观察一个人时, 得到的是这个人做了什么事的记录, 而不是理性分析或主张断言。若观测程序计划周详, 观测者得到充分训练, 那么得出的评分很大程度上能够避免观测者的个人偏见或喜好。被观测者个体行为记录反映的不是他们如何看待自己或别人怎么看待其自己, 被观测者的行为举止能直接说明问题。如果通常情况下的核心关注点是行为表现的变化, 那么观测则是获取信息最直接的方式, 大多数情况下也是最常用的一种方式。同时, 这也能发现个人态度, 也就是我们如何理解自身及自己的行为或信仰与现实生活情境中我们如何做没有太大关系。因此直接行为观测应避免这类无效信息。

② 常用于现实生活情境。观测技术不仅限于实验室环境, 还可以运用到自然发生的生活情境中, 可以在托儿所中、教室里、食堂里、操场上、野营地中、军队休息室里、生产流水线上或任何工作娱乐场所中进行观测。观测过程中会产生相关实际困难或局限性, 稍后会加以阐述, 但除了其若干缺陷, 直接观测仍然是研究自然环境中个体特征时广泛运用的一种方式。354

③ 常用于观察儿童。之前已经提到观察手段可以用于观测婴幼儿, 不管年龄有多小, 年龄越小越容易观测。婴幼儿缺乏自我意识, 因此观测者可以很轻易地坐下来观测他们的行为, 不需要任何特殊程序或预防措施。由于观测者的出现可能会改变年纪稍大的儿童或成年人的社会环境, 所以有些情况下有必要在被观测者面前把观测者隐藏起来, 有时会使用单向观察镜。当然使用此类实际安排很大程度上限制了进行观测的设定类型, 可能更简单有效的方法是让观测者悄悄地进行观察, 或者观测者的存在时间长到被观测者能够忽略其存在, 将其视为周身环境中很自然的一部分。

直接观测的最大价值在于观察儿童, 因为儿童是直接观测最可行的领域。儿童语言沟通能力有限, 情感及行为理由的分析表达经验不足也不够熟练, 在陌生人面前比较腼腆。因此在儿童群体中, 系统观测是了解个性特征的重要方式。

系统观测的缺点。直接观测作为信息搜集手段有其值得肯定的地方, 相比之下, 也存在若干缺点, 极大地限制了直接观测的效度。这些局限性或缺陷既包括我们首先考虑到的实际问题, 也包括理论问题。

① 观测过程成本过高。造成系统观测成本较高的首要因素在于系统观测要求观测者进行适当时间的训练。在运用系统观测过程中, 每个被观测者都必须在若干时段加以观测, 某些情况下可能会延长至若干小时。若针对大量个体或某个团体进行观测, 观测时间会迅速积少成多。因此系统观测及行为表现记录通常局限于能够投入必要时间的研究项目。在教学实践中, 教师或辅导员几乎不可能找到在大量学生中进行直接观测需要的人力物力。但对于某些特殊服务或特殊项目中的个别候选人, 直接观测能够提供候选人的有用信息。

直接观测过程的成本远不止记录信息所需的时间投入, 任何特殊设定或记录装置都需要额外资金。此外, 若原始记录是流水账式日记记录, 或是记录某个被观测者或被观测群体行为的录像带, 那么记录分析也很可能耗费大量时间, 因此成本较高。

② 难以把观测者安排进观测环境。必须考虑到观察记录实际情况的观测者的出现是否会真的改变实际情况。在不少需要观测的情景中, 把观测者隐藏起来不太实际, 因此我们希望有理由说明, 在观测初始阶段观测者的存在会明显造成干扰, 但过了这段时间后被观测者会逐渐开始忽略观测者的存在。让被观测者忽略观测者的存在可能在某些情景中比较容易, 但在其他情景中则比较困难, 例如当被观测群体人数较少, 或者观测者有必要近距离观测行为活动, 或者被观测群体见面时间过短, 还不习惯被观测。这些情况下被观测者可能不会把观测者视为正常环境的一部分。

③ 无法排除主观因素和个人偏见。在观测程序中要采取必要的预防措施来避免观测者对观测数据的个人理解和偏见。观测者不能过于熟悉所进行的研究, 被观测者接受的实验处理, 以及被观测者测试分数或其他信息, 以免这些信息会影响观测者的看法。观测者最好能够起到中立记录工具的作用, 能够灵敏感知某些类型的行为并加以记录。但是观察者是人, 我们只能通过加强训练及屏蔽观测目的信息来使观测主观性降到最低限度, 不可能完全排除主观性。因此必须认识到观测者在最终结果中所起的作用, 特别是当研究现象较为复杂或是研究现象涉及个人理解因素。

④ 难以界定一系列有实际意义且富有成效的行为类别。观测活动总是具有选择性, 只能观测并记录某些有限的个体行为内容。此外, 如果观测数据要进行量化处理, 就必须对数据分类、分组并计算。任何分类系统某种程度上都是强加于无限变化的生活事件之上的随机框架, 因此建立起能够完全服务于预期观测目的的分类结构并不容易, 对某个特定观测计划中的行为类别或者在某个给定标题下的活动类型不可能达成完全一致。为达到某个观测目的, 我们可能会决定根据外显行为来划分攻击性行为, 如撞击、推挤或抢夺等。但其他情况下可能更适合记录突发性事件 (如果我们能够观测得到): 如应对财产纠纷产生的攻击行为, 回应语言污蔑的攻击行为或是正在进行的某项活动受到阻挠时的攻击行为等。无论哪种情况, 设定进行记录分析的行为表现类别要比行为观测评分意义更为重大。

⑤ 难以判断个别行为的重要性。若要得出可靠客观的评估结果, 系统观测通常要侧重于非常细小且较为离散的动作, 或者要把观测及分析过程分成不同部分。这种情况下, 真正的危险在于可能会丢失行为表现的含义或动作的真正意义。我们观察到一个三岁小孩拥抱另一个三岁小孩, 那么这个动作表示的是攻击还是喜爱? 孤立地看, 根本没办法说明情况。或者假设一个小孩打了另一个小孩, 这明显是攻击性行为, 但此行为在孩子生活中又象征着什么呢? 是反对之前被另一个小孩控制的正当反应吗? 还是由于家里发生的某些事而产生的攻击性行为? 抑或此行为象征着其他事情? 或者没有任何象征? 这种情形下, 某个动作相关的含义很可能是推测性的, 必须是由其他信息来加以证实或反驳的。

⑥ 观测数据具有外部性。观测数据是外部的, 也就是说只关注能够看到的现象, 不能提供内部状态信息。当脱离情境分析一点点行为表现时, 观测数据的外部性将会被放大。但外部性是所有研究行为表现的观测方法的基本特点, 因此我们必须承认判断行为含义时存在的问题, 同时认识到, 我们观测到的只是被观测者做了些什么,而不是这些行为体现了什么。

## 10.8 总 结

在心理学和教育研究中, 尽管大部分教学目标及相关行为表现都能够通过传统认知测试进行评估, 但某些情况必须使用其他技巧。这些方法在评估学生表现、作品、态度或个性特征时显得尤为重要。如果能够选择的话, 评估作品一般要比评估过程容易得多, 但在某些情况下, 评估重点必须放在过程上, 过程评估通常要用到检查表或定级量表。

检查表要包括以下内容: (1) 指定恰当的表现或作品; (2) 列举重要的行为特征; (3) 列举常见错误; (4) 以适当的形式整理列表。定级量表在评估作品时要比评估过程更为有效, 因为使用定级量表需要更多时间, 若要用定级量表评估过程, 那么我们通常会面临需要评估的内容过多但进行评估的时间较少的两难境地。

自然发生的情景中, 行为表现最好通过系统观测进行评估。为使系统观测更加有效, 必须弄清以下问题: 应该观测什么? 哪些行为表现能够代表一个人的个性特质? 整个观测什么时候进行? 持续多长时间? 观测者应怎样进行训练? 应该怎样组织观测过程?

系统观测具有如下优点: (1) 代表实际行为; (2) 可用于现实生活情境; (3) 可用于观察儿童或其他难以语言沟通的被观测者。但系统观测也可能产生若干问题, 具有如下缺陷: (1) 观测过程成本过高; (2) 难以把观测者安排进观测环境; (3) 无法排除主观因素和个人偏见; (4) 难以界定一系列有实际意义且富有成效的行为类别; (5) 难以判断个别行为的重要性; (6) 观测数据具有外部性。

## 10.9 习 题

1. 思考下列某初中自然课的教学目标, 指出每项目标最恰当的评估类型: 卷面测试、过程评估及作品评估, 并说明选择理由。

a. 为科技展览设计科学项目。

b. 阐述脊椎动物分类法知识。

c. 成功进行滴定实验操作。

d. 以本地的生态挑战做课堂展示。

2. 设计一份适用于评估科技展览项目的检查表。

3. 设计一份适用于评估体育课上垒球队表现的定级量表。

4. 设计一次表现测试来测评音乐欣赏课所要求的学生个性特征。

5. 如何以课堂讨论为基础进行系统观察? 制定一份观测数据记录计划。

6. 在某项研究中, 你建议使用系统观测方法来研究小学生的社会适应情况。那么你可能遇到什么问题? 对观测结果进行说明时, 你可能需要注意哪些问题?

7. 日常生活的系统观察有哪些优点?

## 推 荐 阅 读

Barrios, B. A. (1988). On the changing nature of behavioral assessment. In A. S. Bellack & M. Hershon (Eds.), Behavioral assessment: A practical handbook (pp. 3-41). New York: Pergamon.

Berk, R. A. (Ed.). (1986). Performance assessment: Methods and applications. Baltimore: Johns Hopkins University Press.

Evertson, C. M. (1986). Observation as inquiry and method. In M. C. Witrock (Ed.), Handbook of research on teaching (pp. 162-213). New York: Macmillan.

Finch, F. L. (Ed.). (1991). Educational performance assessment. Chicago: Riverside.

Fitzpatrick, R., & Morrison E. J. (1971). Performance and product evaluation. In R. L. Thorndike (Ed.), Educational measurement (pp. 237-270). Washington, DC: American Council on Education.

Hambieton, R. K., & Pitoniak, M. J. (2006). Setting performance standards. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 387-431). Westport, CT: Praeger.

Hyman, I. E., Jr., 8. Kleinknecht, E. (1998). False childhood memories: Research, theory, and applications. In L. M. Williams & V. L. Banyard (Eds.), Trauma and memory (pp. 175- 188). Thousand Oaks, CA: Sage.

Kubiszyn, T., & Borich, G. (1987). Educational testing and measurement. Glenview, IL: Scott, Foresman.

Lane, S., & Stone, C. A. (2006). Performance assessment. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 387-431). Westport, CT: Praeger.

Nitko, A. J. (1984). Defining "criterion-referenced test." In R. Berk (Ed.), A guide to criterion-referenced test construction (pp. 8-28). Baltimore: Johns Hopkins University Press.

## 第11章 态度及定级量表

## 11.1 引 言

第十章已经提到, 对于某些重要的教育决策, 通过传统认知测试难以获取决策需要的相关信息资料。有些教育决策涉及教学过程及教学作品方面的教学目标, 而有些教育决策则需要个人特征及态度相关信息。例如, 音乐欣赏课老师可能会关注学生对音乐的体会和感觉, 以及学生对音乐的认知性知识。而社会学课程教学目标则强调良好公民品德的形成, 对文化背景不同的各个民族的积极态度及了解政府运作基本知识。了解某个人的个人特征和态度要比了解其认知特点困难得多, 在认知测试中我们只需衡量最佳能力或者测试者能做多少任务, 但在评估个性态度时, 我们需要衡量标准能力、个人偏好和个人性情, 因此通过测试来准确表示学生最佳能力要比表示标准能力容易得多。

可以通过以下三种主要方式来了解个人特征: 第一, 运用第十章讨论的方法直接观察个人行为; 第二, 通过推荐信或者定级量表等方式间接从其他人处获得相关信息; 第三, 通过某种形式的自述报告直接获取相关信息。评估最佳能力的自述报告 (即认知能力测试) 将在第十二章中加以论述, 白述报告评估性格特征及兴趣将在第十四章进行讨论。本章则介绍从他人陈述中搜集某人相关信息的方法, 同时会涉及如何引导启发自我陈述, 说明对某些人或某些对象的态度或看法。

## 11.2 从他人处了解某人性格

体现某人性格的一个重要方式在于他/她给其他人留下的印象, 因此可以将后者看作是前者性格相关信息的重要来源。例如可以咨询老师, 使其提供学生学习欣赏音乐的程度或者反对吸毒的程度等方面的信息, 也可以让学生在上述问题上进行相互评价。这两种情形中, 前者运用了上级或主管评级的方法, 而后者则说明的是同辈评价的情况。

不少情形都证明上述了解他人性格的技巧非常有用。可能下列问题我们都想寻求答案: A 喜欢 B 的程度如何? A 认为 B 在身边是个讨人喜欢的人吗? 是个高效率员工吗? 聘用他的风险大吗? A 认为 B 认真负责吗? 值得信任吗? 情绪稳定吗? 被评价者的老师、主管、前雇主、部长甚至是朋友都经常会遇到这类问题。

定级量表也可用于了解某个人的认知特点、能力水平及成就情况, 此类信息通常可以通过表现评估直接获取, 或通过应试者完成的卷面测试间接获取, 但定级量表能够提供有关他人对某个人认知功能的印象方面的有效补充信息。某些情况下, 特别是对于年龄较小的孩子或者不能独自做出应答的人来说, 他人填写的定级量表可用来代替应试者亲自完成的评估测试。当然, 做重要决策时若要用到定级量表, 则必须确定他人填写的评定量表能够对个人技能进行准确评估。

## 1. 推荐信

在教育及职业背景下, 第三方提供的推荐信是了解他人的最常用方式之一。推荐信所含信息可以用于不同目的, 最常见的目的是用来评定人选: 如申请入学、颁发奖助学金, 招聘、确定某团体会员资格、忠诚审查等。但是在没有结构的自由交谈中用到的这类描述个人的材料到底如何使用, 如何提供信息呢? 事实上, 尽管每年都会写大量的推荐信 (Knouse,1989 的调查显示, \( {90}\% \) 的公司及几乎所有研究生院校都使用推荐信), 但很少了解推荐信的充分性和效度。关于推荐信的价值, 存在不同看法, 对于推荐信中所含信息的可靠程度和可信程度, 以及这些信息对申请者行为动作的影响程度, 事实研究并没有得出任何定论。

近期进行的推荐信研究大部分特定于研究生院校录取。早期的一项推荐信研究通过分析 33 名心理学实习岗位求职者的 67 封推荐信 (Siskind, 1966) 发现 958 种陈述, 分布如下:



<table><tr><td>陈述类别</td><td>数量</td><td>比例</td></tr><tr><td>积极陈述</td><td>838</td><td>87</td></tr><tr><td>对于某种特征不清楚的陈述</td><td>17</td><td>87</td></tr><tr><td>提到某些客观缺点的陈述, 例如年轻、经验缺乏等</td><td>44</td><td>5</td></tr><tr><td>其他指出缺点的陈述</td><td>59</td><td>5</td></tr></table>



评审员确实会用到推荐信, 给某个人写的所有推荐信会存在中等程度的一致性 (信度为 0.40)。一项针对一系列推荐信中常用形容词的经典研究说明了这种关系是如何产生的 (Peres & Garcia, 1962)。该研究从工程师求职者的推荐信中选出 170 种不同形容词, 几乎所有形容词都是正面积极的语气, 然而一旦比较最佳员工及最差360员工, 所用的形容词就大有不同, 能够明显区分这两组求职者。可能称某个求职者 “适合的”、“乐于助人的”、“坦率的”; 也可能称他/她“机智灵活的”、“见多识广的”或 “富有成效的”。前三个形容词同等适用于最佳员工及最差员工, 但后面三个形容词则仅仅用于描述最佳员工。很明显, 从推荐信中进行推断的效度很大程度上取决于评审员读懂字里行间的言外之意的程度, 还取决于评审员如何权衡这些好听委婉的评语, 通过使用恰当的区别因素来鉴别推荐信中提及的优点到底是与工作契合的还是背离的。巴克斯特、布洛克、希尔和罗泽尔 (Baxter, Brock, Hill, and Rozelle, 1981) 在研究研究生院校申请者的推荐信时发现了类似结果。克努斯 (Knouse, 1989) 综述了如何使推荐信更加有效的方法。阿莫特、布莱恩和惠特科姆 (Aamodt Bryan, and Whitcomb, 1993) 发现, 若使用明确的评分标准, 推荐信可以算作研究生院校学生表现的有效预测指标。

另外, 推荐信作者可以自由选择自己所写的内容, 因此不存在统一的核心内容, 不管是描述某个人的推荐信还是针对同一个职位不同求职者的推荐信都是如此。一封推荐信可能涉及某个人的社交魅力, 另一封涉及其诚信正直, 还有一封可能会涉及其创造力。除此之外, 推荐信作者在夸赞方面个人习惯会相差甚大。例如, 应该怎样理解 “聘用此人为您工作, 您将会非常幸运”这样的陈述呢? 针对此, 有些雇主或者学校尝试通过建议推荐信作者应该涉及哪些具体特征来解决上述问题。

还需要考虑到申请者可以自由选择由谁来写推荐信。当然, 可以预想到除了天真幼稚的申请者之外,所有人都会选择自己认为能够给予自己支持的人来写推荐信。

尽管几乎完全不清楚推荐信到底能否提供对某人的有效评价, 能否准确评估其出彩的地方或者优缺点, 但没有理由对推荐信的效度过于乐观。推荐信相关信息缺乏统一的参照标准, 这使得理解说明推荐信尤其困难和充满风险。

2000 年 6 月 30 日一篇发表在《美国高等教育纪事周报》上的文章揭示了一些推荐信在美国高校录取工作中如何起作用的趣闻 (Schneider, 2000)。文章中也提到了我们在前面讨论过的语言意义不明确的问题, 但是更难以保证诚信的障碍在于缺乏保密性, 推荐信作者没办法确定究竟谁会阅读自己所写的内容。《纪事周报》上的这篇文章引用了几个案例, 其中推荐信的描述对象因为信中内容对推荐信作者进行报复。因此,需要推荐信的个人必须正式放弃其获取别人提供评价的权利越来越普遍。 但是, 施耐德 (Schneider) 指出, 这种权利放弃在法庭上遭到反对, 若未来雇主拒绝了求职者, 有关人员获得推荐信相关信息。尽管存在很多问题, 推荐信仍然可能是教育领域及商业领域中某个职位相关候选人的主要信息来源。

## 2. 定级量表

推荐信中的非结构化陈述具有极大的主观性, 对不同的人缺乏统一的核心内容或参考标准, 同时难以量化此类非结构化材料信息。这些问题推动了定级量表的发展。设计定级量表是为了获取评价者及被评价者对于一系列普遍特点的评估, 同时这些特点必须在统一的量化标准内进行描述。

我们都有过测评评估相关经历, 要么评价他人, 要么评价自己。在许多成绩单里经常出现定级量表, 尤其是描述非学术表现的部分。我们经常能够看到某个部分这样表述的:



<table><tr><td>特征</td><td>第一阶段</td><td>第二阶段</td><td>第三阶段</td><td>第四阶段</td></tr><tr><td>努力程度</td><td>_____</td><td>_____</td><td>_____</td><td>_____</td></tr><tr><td>行为表现</td><td>_____</td><td>_____</td><td>_____</td><td>_____</td></tr><tr><td>品德表现</td><td>_____</td><td>_____</td><td>-</td><td>_____</td></tr><tr><td>适应能力</td><td>_____</td><td>_____</td><td>STARATION</td><td>_____</li></td></tr><tr><td colspan="5">\( \mathrm{H} \) 表示优秀, \( \mathrm{S} \) 表示合格, \( \mathrm{U} \) 表示不合格</td></tr></table>



许多公共部门和企业都会给被求职者列为推荐人的那些人分发评价表, 要求评价个人 “主动性”、“创造力”、“工作热情”及“与人相处的能力”等。这些企业或机构通常要求主管对员工进行人事考核, 针对不同的特点或整体表现把员工分为 “非常优秀”、 “优秀”、“优良”、“良好”、“合格”或“不合格”等不同等级。高校、医学院、奖学金项目及政府部门等要求将定级量表作为其选拔程序的一部分。除了上述实际应用情况, 定级量表也可用于很多研究项目, 每天都有大量等级要评定, 且通常都是无奈之举。

定级量表最常用于回顾分析, 总结一段时间内评价者通过接触被评价者所形成的印象。有时候定级量表与访谈或一段时间的观察同时进行。一般情况下, 定级量表包括过去或当前经历的评价性总结, 在此总结过程中, 评价者的 “内置计算机” 对数据进行复杂的不定的加工处理, 从而得出最终评定结果。

最常用的评定程序在于给评价者列出一系列特征、一组数字、形容词或者描述来代表特征的不同水平或不同程度。评价者指定某个数字、字母、形容词或描述符合某个特征, 从而对一个或多个人的某个特征或某些特征进行评估。图 11-1 举例说明了两种定级量表, 类似于公司评价中层管理人员所用的定级量表。第一种定级量表评估领导力特征, 是原始定级量表八个方面中的一个, 通过不同层次的领导力定义来给出领导力特征的一般描述。第二种定级量表要求整体评价员工在多大程度上能够履行某个特定岗位的职责。这两种量表说明了各种不同的定级量表格式。在简要说明362定级量表模型的主要不同形式之前, 让我们首先考虑几个问题, 即在请一组评价者进行评价时可能产生的一系列问题。



以此人鼓舞信心的能力为例。除职位因素以外, 他/她得到多少尊重? 人们尊重他/她的决定吗? 他/ 她害怕为自己坚信的东西冒风险吗? 他/她鼓励团队协作吗?

---完全没有, 肯定是同事中随大流的一个人, 不会去说服他人认同自己的方法最为得当。

---在尝试领导他人中获得部分成功,但仍未达到强有力的境界。领导下属时较为被动。

一一良好的领导者, 其他人期待此人的话; 同事尊重他, 人们需要此人的意见。

---优秀的领导者, 能够接管任务并使一切步人正轨; 人们乐于同意此人的想法, 下属及同事尊重他。

请在如下标尺上标出此人在其目前岗位上的整体等级:



图 11-1 两种不同形式的定级量表



## 3. 得出合理定级时存在的问题

两类普遍存在的问题导致难以得到精准有效的评定结果。首先, 根据定级说明, 某些因素会限制评价者进行公正谨慎评价的意愿; 其次, 即使出于好意, 某些因素也会限制评价者进行一致恰当评价的能力。接下来我们一一讨论上述问题。

(1)影响评价者认真评价的因素

汇总评定结果时, 我们通常会假设所有评价者都会遵循评定说明来打分, 因此评估过程中的任何不足之处完全出于偶然或人类不可避免的失误, 但事实并非如此。 至少存在两种情形会降低评分的效度: 第一, 评价者不愿意费心费时去遵循评分程序的规定; 第二, 评价者可能对被评价者带着情绪, 某种程度上不愿意给出可能会伤害或者有益于别人的评价结果。

不愿意付出足够的精力。即使在最佳情况下, 评定等级也是令人头疼的事情。 对某个人细致周到的评价需要大量精力。若要提供统一的参考体系, 评分程序编写者必须列出大量的特征, 设计出详尽的行为描述来例证所有特征。这样的程序有助于得出优秀的量表评定结果, 但是若评定量表过于冗长, 被评价者数量众多, 整个评定工作任务量就会过重, 而且似乎并不值得如此付出。若以得过且过的方式进行评定工作, 那么整个评定过程就会效果欠佳。评估很可能是匆忙进行的表面分析, 更注重尽快完成任务而非做出精准的分析评估, 除非评价者打心底赞成量表评定的重要性。

对被评价者带着情绪。远程管理员和非个人机构通常需要评价来让人进行决策制定。公共委员会、军队司令部人事处、大型公司人事主管或是学校体系的行政人员远离一线主管、中队指挥官或授课教师, 后者才是实施量表评定的人。评价者通常会与被评价者有较大联系, 例如办公室员工、应征人伍的军人或全副武装的下级军官, 或课堂上的学生, 但与各组织中要求进行评定工作的人则并没有多少联系。管理或领导的首要原则之一在于“好领导要照顾下属”。某个组织的精神面貌取决于该组织领导照顾员工的决心。一旦面临测评, 那么 “照顾” 就意味着确保自己人和竞争对手一样好或甚至略好。

因此, 很多情况下, 评价者可能更侧重于保证与自己联系紧密的被评价者获得较高评分, 而非提供客观准确的信息。公开评定结果的公共政策及要求评价者与被评价者针对评定过程中任何不利因素进行讨论使得上述情况不断恶化。而行政裁定中有关晋升或加薪需要的必须达到的最低等级方面的规定则更是加剧了上述问题。毫无疑问, 量表评定会在某个标度绩点基础上攀升或累积。因此, 量表评定标准趋向于 “优秀”等级, 这样的结果在所有量表中占有较大比例。“优良”几乎成为不满意的代名词, 而 “合格” 等级则是为评价者最初就打算尽早摆脱掉的那些人准备的。

当然某些情况下也会产生相反的效果。若主管近期与下属发生了一些不愉快, 那么报复的方式之一就是给出低于实际等级的评定。若下属要评价主管, 就像学生评价教师表现一样, 报复几率可能会更大, 因为一般的评定多是匿名评价, 所以这可能为不满主管的下属提供了一次发泄情绪的机会。

因此, 我们必须意识到评价者不会自始至终都可靠可信, 也不会全心全意地为相关机构的利益做出有效评定。另外, 评定工作对评价者来说是件令人头疼的事情, 并且评价者可能会倾向于保证自己熟知之人的利益, 而非局外的组织机构。若要使评定项目有效进行, 必须持续游说监督。但是, 一些限制条件制约了积极宣传克服评价者自然习惯及其所认同的团体利益的程度。

(2)影响评价者精准评价能力的因素

即使评价者目的明确, 尽全力提供有效信息, 仍存在某些因素可能限制评价者所做评价的效度。这些因素主要集中在评价者没有机会去直接观察被评价者, 被评价特征有一定隐含性, 待评价层面意义含糊, 缺乏统一的参考标准及评价者的偏见和个人特点。

缺乏直接观察的机会。评价者通常没有机会去观察被评价者。例如, 一位高中老师教 5 个班级的学生, 每班 30 人, 要评价共 150 名学生的 “主动性” 和 “灵活性”。 一位大学教授教某门课, 课上有 100 名学生, 可能会收到某职业介绍所或大学行政部门的评价表, 要求提供类似的针对某些学生的评价。上述情况下, 与每名学生的接触程度通常不足以为所要求进行的评价提供充分基础。被评价者可能在评价者面前出现了好几个小时甚至是几百个小时, 但这些时间任务繁重, 评价者及被评价者关注的是其他更加急迫的事情, 而非量表评定要求的针对某些特征进行观察并形成评价。

在公共部门或企业背景中, 也会产生同样的问题。首要任务是完成工作。尽管理论上主管可能会有大量时间来观察每个员工, 但实际上他/她可能要忙于其他事务。我们能够说服主管, 投入更多精力来观察评估员工有益于其工作, 但大部分主管从其他任务中平衡出来并用于观测评估员工的精力及时间, 是有实际限制的。

问题可能不仅仅在于缺乏直接观察的机会, 还在于没有机会去观察被评价者的某个具体特征。任何人观察其他人都需要在有限情境中进行, 这些情境只能体现其行为的某些方面。教师主要在课堂上观察学生, 领班主要在生产线上观察员工, 等等。在传统的教室里, 不能确定老师能否观察该情形下的学生, 从而得出其 “主动性” 及 “创造力” 相关信息。主要通过讲座来授课的大学教授也不适合评价学生的 “独创性”和 “与他人合作的能力”。主管也不能够对进行日常工作的职员做出评价。因此建议进行等级评定时, 不管是出于研究目的为管理措施打下基础, 还是为指导其他决策制定, 我们都需要考虑到评价者是否有充足的机会在充分的情景中观测被评价者, 从而使得等级评定有实际意义。若答案为否, 那么就应该放弃评估有关的特征。

不同的评价者以不同的角色来观察个体, 所以关注的方面也可能有所差异。学生对老师进行观察的方面可能不同于校长, 后备军官学校的学生对其他有可能成为军官的同学的看法可能不同于军官。对于能够决定评价者的人来说, 应当考虑究竟谁能够拥有观察相关表现的最佳机会。正常情况下, 此人应该是我们要求进行评价工作的那个人。

被评价特征有一定隐含性。若是被评价者之外的人评价某个特征, 那么该特征就必须产生可观察的行为表现。这些行为特点本质上具有社会性, 例如在社交聚会上感觉很自在, 说话声音愉悦, 积极参与小组项目等是在与人交往中产生的, 可以直接进行观察。相反, 有些特征是个人内在品质, 例如 “缺乏安全感”、“自立”、“紧张不安”或 “孤独” 等。这些特征是个性品质中较为隐蔽的部分, 只能从个人行为中进行大致推断, 因此我们称之为内在特征。

因此, 外人很难评价某个极为隐蔽的特征。内心斗争或是紧张不安可能表面上看不出来, 即使能看得出来也是间接地出现。除此之外, 所有人不可能以同一种方式表现某个内含特征, 例如, 极度缺乏安全感在某个孩子身上可能表现出来的是攻击其他学生, 在另一个孩子身上可能就是逃避到自己的内心世界里去。不能简单地把缺乏安全感认为是外显行为的一个方面, 缺乏安全感其实是一种潜在特征, 不同的人表现形式可能不同, 即使是同一个人在不同的时间不同的情况下表现形式也会有所差异。只有全面了解这个人, 结合心理洞察力, 才可能从外显行为中推断出此人现在的内心动态。

鉴于上述原因, 评定隐含个性的程序通常会不尽如人意, 除非在特殊情况下让经验丰富的观察者评定自己熟知的人。一旦评定某些个性特征既需要全面了解此人, 又需要从所观测的行为中进行推断, 那么这种评定多具有较低的信度和效度。而评定那些能够通过行为表现显示出来的特征则较为精确, 即外显特征, 例如某个人怎么与他人交往。相较于内含特征, 外显特征评定起来更为可靠, 且效度也较高。评定具备社会属性的外显特征所表现出来的行为时, 评定效度一定程度上是因为这些外显特征的意义主要来自于某人对他人的影响作用。

被评价层面意义含糊。不少定级量表要求大范围地对抽象的特征做出评定, 例如之前提到的定级量表中包含的 “个人品德” 和 “适应能力”。这些特征或多或少要比量表中其他的内容更为笼统模糊, 因此不同评价者对于这些词语的含义也不太可能达成一致。对一个小学生来说“个人品德”是什么意思? “良好个人品德”是如何表现出来的? “良好个人品德”意思是不在墙上乱写乱画吗? 不随地吐痰? 不拉扯女生头发吗? 还是说每天给班级领取简报? 加人少年红十字会? 放学后留下来帮助老师打扫教室? “良好个人品德”究竟意味着什么呢? 两个不同的评价者在针对“个人品德” 评价某组学生时不可能脑子里想的是同一个意思。

同样地, 思考一下 “主动性”、“个人品格”、“监督能力”、“思维灵活性”、“执行影响力”或 “适应能力”等。这些特征都是定级量表在实际运用中意义较为含糊的例子。 尽管不同评价者对于不同特征的词语意思会有一定的一致性, 但也存在大量的不同理解。表示特征的词语越抽象, 不同的人对它的理解差异就会越大。上述列举的品质就非常抽象。某个孩子获得的个人品德等级取决于评价者对个人品德的理解, 若一位老师将个人品德界定为遵守学校规章制度, 那么他/她必定会给遵守校规的学生较高的评分。另一位老师可能认为积极参加学校活动是衡量个人品德的指标之一, 那么评分较高的学生就会大有不同。因此, 要获得一致的等级评定, 第一步就要在不同评价者之间针对被评价特征的意义达成最低要求的一致性。完成这一步任务的方法是在定级量表上给出合适定义。如果以“学生遵守学校规章制度”来界定品德良好的人, 那么对于个人品德这个词语就可以形成共识, 前提是定级量表说明中要明确给出定义。

缺乏统一的参考标准。许多定级量表要求把被评价者分门别类进行评价, 比如:

突出、中等偏上、中等、中等偏下、不合格

优秀、良好、一般、较差

卓越、优良、中等、一般、较差

突出、优秀、比较满意、满意、不满意

优秀、突出、相当不错、良好、合格、不合格

多好才算 “良好”? 评为 “良好” 的某人相较于整个被评价的小组排名在前 \( {10}\% \) 吗? 前 \( {25}\% \) ? 还是前 \( {50}\% \) ? 或者这个人排名不在较差的 \( {10}\% \) 之内? 将此人进行比较的整个组组成如何? 组员都是同龄人吗? 是同一个公司的员工吗? 是同一个工作岗位上的人吗? 工作岗位相同的员工工作年限相同吗? 如果答案是否的话, 评价者应如何了解在某个岗位上有一定工作经验的员工属于哪个水平呢?

这些问题的关键在于, 对被评价者进行评估时需要统一标准。对措辞和分类理解不同, 对参照人群定义不同, 以及参照群体中个人经验不同等因素都会造成评价者之间评价标准有所差异。这种现象在学术评分中的现象相似, 在类似的课程中老师给出的 \( \mathrm{A}\text{、}\mathrm{\;B}\text{、}\mathrm{C} \) 等级比重会有很大差别。量表评价时用到不同的分类,数字、字母或者形容词也是如此。这些标准是非常主观的说明, 因此不同评价者之间差别可能会很大 (你也可以很简单地解释这个问题, 例如, 用一组词语一频繁地、经常地、很少一一问几个朋友每个词语代表的百分比。在 160 名大学新生中, 我们发现频繁地这个词代表的百分比范围在 \( {50}\% \) 到 \( {95}\% \) 之间,有的认为经常地这个词至少代表 \( {50}\% \) 的频率,还有的认为很少这个词意味着 \( {65}\% \) 的频率),评价者之间的差异不仅在于他们评定的等级不同, 还在于他们评定等级的扩展范围不同。有些评价者比较保守, 很少会给出过高或过低的评分, 还有的评价者则倾向于给出较为极端的等级。评定等级的幅度差异会降低不同评价者之间的可比性, 这些幅度差异其实是每个评价者个人品性和价值观构成不同的表现, 而非偶然变化。

若要克服缺乏统一参照标准引起的问题, 就要给文字说明附加具体比例。例如, 许多高校和研究生院校推荐表会要求在某个比例范围内评定“整体学术能力”、“专业学科知识”等, 比如:

出色、优秀、中等偏上、中等、中等偏下

定义 “出色” 为 “在参照人群中排名前 5%”, 其他类别也分别给出具体定义, 如 “排名前 \( {10}\% \) ”、排名前 \( {25}\% \) ”、排名前 \( {50}\% \) ”、排名后 \( {50}\% \) ”。此量表比例通过要求评价者指定参照人群来给出附加定义, 如 “高年级大学生” 或 “研究生一年级”。但是,有时会发现 \( {25}\% \) 的高年级大学生被评定为在高年级大学生中排名前 \( 5\% \) 。

评价者的偏见和个人偏好。评价者不仅仅在一般的严格或宽容度上有所不同, 在其他个人偏好方面也各有特色。生活阅历让我们每个人都有各自的喜好及对他人特征的独特而又各式各样的理解。你可能不会信任跟你说话时不看着你的人, 你十几岁的儿子可能认为那些听古典音乐的人“落伍”了, 你的老板可能认为握手坚定有力是性格坚强的体现, 你的网球队友可能坚信眼睛小的人不值得信任。这些大家认为的品质说明上述特征是具体存在的, 而对这些品质的描述能够让作出评价的人很清楚地用语言表达出来, 不管这些成见正确与否。

我们每个人还有大量其他更含糊更抽象的偏见, 可能会影响我们进行量表评定。 这些偏见会逐渐形成我们对他人的印象, 从而影响自己对他人的反应, 同时也会成为我们评定的一部分。某些情况下, 它们还可能会影响我们对一两个特征的评价, 但通常情况下, 此类偏见形成对某个人整体的偏好或反感的一部分, 而这种整体的反应会影响我们评价的所有对象特征。因此, 量表评定反映的不仅仅是评价者的整体主观评价标准, 还是其对被评价者特征的偏见。

另一种可能会影响评价者对某个工作岗位 (或某个教育方案) 整体评价的效度的个人偏好, 即是对理想行为类型看法上的个人差异。我们发现, 对相似工作岗位上员工的不同主管在其认为重要的特性方面有很大差异, 例如, 有些评价者可能认为 “主动解决问题”是下属应该具备的最重要特征, 但其他主管可能认为这个特征并不重要。从这方面来说, 不同评价者对不同特征的重要性有不同的权衡, 因此针对被评价者中究竟谁最为有效这个问题, 不同评价者不可避免地会持不同看法。

(3)评价效果限制因素的结果

评价效果限制因素的影响表现为量表评定结果的系统性, 信度较低, 以及评定程序效度存在问题。我们用以下四个方面来总结这些问题: 宽容评价误差, 成见效应, 低信度, 可疑效度。

宽容评价误差。上文已经提到, 评价者通常更认同自己评价的人, 甚于要求进行量表评定工作的组织机构。除此之外, 普遍存在评价者不愿意非难人类而给出较低评分的情况, 至少在美国是如此。最终结果就是等级评定倾向于集中在高分端。这当中心照不宣的道理就是, 所有人就算不比其他人更好, 至少也是一样好, 所以中等这个词实际上并非一组等级中的中点, 而是整个组里排名较低的位置。有点类似于368橄榄的商业广告分类, 最小的称为 “中号”, 以此类推, 从 “大号” 到 “加大号”, 再到 “特大号”, 一直到 “巨大”。我们偶尔会跟学生开玩笑说, 一套合理的评价教师效果的锚点应保证等级评定中心与评定范围中心相吻合, 所以这些锚点就可能是 “较差”、“中等”、“中等偏上”、“优秀”和“完美”。

若所有评价者中普遍存在宽容评价误差, 也就不会特别成问题了。我们只需要记住, 等级评定不能从字面意思上理解, “中等”意味着 “较差” 而 “良好” 意味着 “中等”。评定量表编制者甚至试着消除这种仁慈倾向, 在量表中额外加了几步, 指出中等水平值得肯定的地方, 因此设计了区分差异的空间, 评价者不需要以将某个人或某个特征列为 “中等” 来表示否定。但是不同评价者的 “宽容评价误差” 程度不同, 这个问题比存在宽容评价误差更为棘手。对这些程度上的差异进行纠正十分困难。

成见效应。与被评价者接触有限, 缺乏直接观测评定量表规定的具体特征, 个人偏见影响对被评价者的整体偏好等问题会产生另外一种误差, 即评价者倾向于从整体印象出发进行评价, 不会对个性的具体方面加以区分, 任凭对被评价者的整体反应去影响对每个具体特征的评价。1920 年, E. L. 桑代克称这种类型的评价误差为成见效应。

当然, 理想特征之间应该存在正相关关系。我们发现, 当通过客观测试评估不同能力时, 不同能力之间存在正相关关系。当然我们说的并非成见效应, 成见效应能够在词汇能力和数学能力之间产生假相关关系。很难判断我们评定的不同特征之间的关系多大程度上是真实的, 多大程度上是成见效应产生的假象。但是, 当不同特征之间的相关性超过评定这些特征的评价者内部一致性, 那就需要仔细考虑了。兰迪、山科斯特和科勒 (Landy, Shankster, & Kohler, 1994) 发现, 人们逐渐形成一种共识, 认为尽管成见效应是真实现象, 但其明显存在的事实不一定是定级量表质量的良好指标。

低信度。我们发现, 应用传统的等级评定程序时, 不同评价者之间的一致性整体较低。当使用常规类型的数字或图表定级量表分别进行两组评定时, 两组评价结果之间的一致性非常低,一般在 \( {50}\% \) 左右。但是有证据表明,若涉及量表时仔细推敲, 详细说明量表区间终点或其他定点, 若评价者经过良好训练, 有充分机会去观察被评价者, 则可以提高量表评定结果的信度。(Landy et al., 1994)

若多位不同的评价者对所有被评价者熟悉程度相同, 如果能够合并不同评价者的量表评价, 那么评价结果的信度会大有提升。多位评价者共同评定的效果与延长测试时间相同, 合理运用斯皮尔曼一布朗预测公式 (详见第四章) 可以估测多位评价者共同评定的信度。因此, 若单个评价者的信度表示为 0.55 的相关性, 那么多位评价者共同评定的信度估测如下:

0.71 (两名评价者)

0.79 (三名评价者)

0.86 (五名评价者)

0.92 (十名评价者)

但是, 很多情况下, 增加同样资格的多位评价者可能并不现实, 甚至根本不可能。一名小学生只有一名日常课堂老师,一名员工也只有一位直接主管。因此若其他评价者与被评价者之间接触有限, 增加评价者人数可能反而会削弱评定结果, 而非增强效果。

可疑效度。我们讨论过的所有限制与干扰因素, 尤其是评价者自身偏见及低信度问题, 常常会降低量表评定的效度。但通过实验来确定评估效度几乎不可能实现。 我们使用量表的事实说明, 测评上述个性特征没有其他更好的方法。我们通常也没有办法来核实量表评定的准确性。

从某种意义上说, 量表评定的效度有时是不言自明的。若要评价其他人如何看待某人, 比如某个孩子是否受同学喜欢, 某个领班是否受员工爱戴等, 那么评价结果就是这些其他人的反应, 与上述特征或行为直接相关。

若将量表评定作为预测指标加以研究, 那么就有可能获得统计数据, 用来量化预测的准确性。此类有效证据必须在所有设定及所有预测标准方面建立起来。某些情况下, 评定量表可能是最有效最合适的预测指标, 美国西点陆军军官学校 (陆军副官长办公室, 人事研究部, 1953 年) 进行的军事服务才能评定量表研究为此提供了一个经典案例。此研究表明, 战术指挥官和学员们评定的量表结果与之后进行的量表评定在战斗力方面一致性最大, 关联性要高于西点军校学员档案中的任何其他特征。 这个评判指标同样是一种评级, 但这个研究结果可能是在该情形中我们能够得到的最好的 “回报”。而在其他情况中, 量表评定结果可能一点效度都没有。因此, 必须具体情况具体分析。

量表经常用于衡量评判标准, 在这种情况下, 要尽可能做好每一步, 确保量表的准确性和可靠性, 因为量表代表了评判其他程序的标准, 因此研究改善量表的方法对我们颇为有益。

## 4. 提高评分效率

目前为止, 我们揭示了量表评价方法作为一种测评手段存在的问题。评定程序中确实存在许多风险和缺陷, 但除了这些限制性因素, 评定量表仍然是在不同情境中进行评估的主要方式, 而在这些广泛多样的情境中我们必须基于人们的判断进行评估。比如, 人们如何评价某个有潜力的医学院学生的诚信, 如何评价某个想要成为销售员的人的社交能力, 如何评价六年级学生的成熟程度, 如何评价私人秘书的责任心等, 都能够给我们提供大量信息, 让我们获悉这些人的品质如何。评定量表值得肯定的地方在于, 兰迪等 (Landy et al., 1994) 发现, 如果把量表设计最佳方法与评价者经过充足的程序训练相结合, 量表评定能够准确并有效评价个人特征。那么应如何去解决上述量表评分程序使用过程中出现的一系列问题呢? 如何搜集兰迪等人说明的高质量数据呢? 首先, 我们应该思考量表设计, 其次讨论量表评定计划及实施过程中的程序。

(1) 改进量表设计

常见的量表设计主要由两部分组成: ① 一组刺激变量 (待评价的特质); ② 应答选项模式 (所给评分形式)。最简单最传统的量表形式中, 刺激变量即为特征名称, 应答选项包括数字类型及形容词类型。定级量表部分详细说明了这种形式。但这种形式可能体现上文中提到的大部分缺陷, 因此, 在此基础上进行了多次格式改编与改进, 从而克服或者至少降低上述缺陷。改进的版本中, 对刺激变量或者应答选项或者两者同时加以控制, 其中的一些改进说明如下。

改进描述刺激变量的方式。过于简单的特征名称意味着刺激变量不符合要求, 原因有两个。首先, 不同的人对词语的理解不同。同一个小孩, 对约翰逊女士表现出来可能是 “主动性”, 而在科尔德罗先生面前则表现为 “不服从”, 但是科尔德罗先生认为的 “品德良好” 对于约翰逊女士可能就是 “听话循规蹈矩”。其次, 特征名称通常尤为抽象, 且无法产生可观察的行为表现, 例如, “适应能力”。我们没办法直接观察某个孩子的适应能力, 相反只能观察到这个孩子对某些情景和某些人的反应, 某些反应可能是适应能力差的, 对这个孩子适应能力的评价则是要根据我们偶然的观察进行推测。

通过将评定特征稳固建立在可观察的行为表现基础上, 定级量表使用者会在特征理解上得到更高的一致性。这些尝试能够在三方面改进定级量表的刺激变量。

① 能够明确定义特征名称。“社会适应能力”其实是个较为模糊的标签, 如果能详细说明这个标签的意义, 那么就会有更多的实质性内容, 正如下文例子所示:

社会适应能力。工作及游戏情景中与孩子及成年人交流的兴趣与技巧; 与人交往时既愿意付出也愿意得到; 基本符合社交行为准则。

毫无疑问, 对被评价的每个特征进行详细定义是改进量表评定程序的第一步。 但是不能确定简单的文字定义能在多大程度上解决不同评价者在特征语义理解方面的个人差异问题, 因此也就不能确定能否解决不同评价者在理解评定任务方面的个人差异问题。

② 特征名称能够用更多重点突出且描述具体的短语来代替。例如, 我们可以将抽象且笼统的社会适应能力分成几个部分, 每个部分涉及某个较为具体的可观测行为。因此可将该词分成如下几个部分:

与其他孩子进行团队协作

与其他孩子一起玩

与老师及其他大人互动

遵守校规

这种情况下, 对此特征进行评价则需要对上述限制较大且较为具体的学生行为的各个方面加以评价。

③ 所有特征都能够用一些具体行为表现的描述替代。通过这种方式可以进一步加强量表的具体性和实质性。因此“与其他孩子进行团队协作”这个笼统描述可以通过以下行为进行详细说明:

与其他孩子进行团队协作:

积极参与小组活动。

提出并坚持建议。

接受少数服从多数的决定。

完成自己的分内任务。

帮助他人完成任务。

上一步列举的其余三个组成部分也可以进行类似的详细划分, 用于定义 “与其他孩子进行团队协作”这个行为的描述能够使此行为更加具体明确, 并且能够大大降低要观察及要记录的行为表现的含糊性, 但还是包含主观理解的成分在内。例如, 如何判断何种程度上的参与才算是 “积极参与” 等。

以大量具体行为来替代笼统的特征, 有望提高不同评价者对特征语义理解的一致性, 同时能够使评价者更加近距离地进行实际观察, 使评价者能够更好地了解被评价者的行为表现。若评价者不能观察到被评价的相关特征, 那么, 若要用具体的可观察到的行为来代替特征名称, 量表设计者就必须重新审视量表与评价者能够实际观测到的行为之间的关系。

通过一系列具体行为表现来提高特征语义理解的一致性及被评价行为的具体性也存在一定代价。上述变更大大延长了评定时限, 提高了定级量表设计的复杂性。 要求一位评价者给出不同量的评价是有数量限制的, 另外, 上述量表得出的冗长的行为分析报告可能会让使用这份报告的人比较迷惑。因此, 将抽象概念转化为一系列具体行为的做法可能在如下情况下最为实际有效: ① 当评价极为简单时, 例如 “出现” 或 “未出现”; ② 基本形成相关规定, 说明如何把某个具体行为的具体评价组织总结为一个或多个分数, 以分数来描述更广范围内的行为表现。

改进应答类别。通过选择数字、字母或形容词来表示对某人特征的评价仍然很常见, 尤其是在学校成绩单或者行政部门及企业人事考核系统中。但是, 这些程序除了简单易行之外没有什么可推荐的。正如之前讨论的, 所有类别通常会比较随意且不太明确, 没有哪两个评价者会以同样的方式去理解各个类别。一个主管可能只将 \( 5\% \) 的员工评定为“优秀”,而另一位主管可能会把 \( {25}\% \) 的员工评定为 “优秀”。某老师评价的 \( \mathrm{A} \) 类可能是另一位老师的 \( \mathrm{B} \) 类。因此,运用主观标准进行等级评定极为普遍。

为了使定级量表更有实际意义, 并且不同评价者之间达到更高的一致性, 可以尝试使用下列内容:

① 百分比;

② 图形量表;

③ 行为描述;

④ “有无”式量表;

⑤ 出现频率或评价相似程度。

① 百分比。若要提高不同评价者之间的一致性, 更好地区分某位评价者作出的评价, 通常会要求评价者以某个明确群体的百分比占比来进行评价。一位教授在评定某种奖学金申请者时, 可能根据如下量表评估奖学金候选人:

此培训水平中排名前 \( 2\% \)

排名前 \( {10}\% \) 但排名前 \( 2\% \) 除外

排名前 \( {25}\% \) 但排名前 \( {10}\% \) 除外

排名前 \( {50}\% \) 但排名前 \( {25}\% \) 除外

此培训水平中排名靠后的 \( {50}\% \)

从理论上说, 某个明确群体的具体百分比例可以为不同评价者提供了统一质量标准, 实现不均匀分布类别区分度的最大化, 尤其是在排名靠前的候选人当中。但是, 这种方法通常只能够部分可行, 因为宽容度的个体差异不容易控制, 结果我们仍会发现 \( {25}\% \) 的被评价者会被归入排名前 \( {10}\% \) 的范围内。

② 图形量表。第二种不同方法更侧重于改变具体量表格式, 而非进一步明确定义。通过此类定级量表, 评价人可在一条线的某些适当节点处做出标记, 从而记录评价结果, 无须选择某个数字、字母或者形容词来代表某个特征的等级。这种量表称为图形量表, 其基本格式如下:







使用图形量表能够得出美观的页面布局, 也较为紧凑简洁, 有效利用空间, 对量表使用者来说也不会像打印出来的表格那样令人生畏。尽管简单明了的图示能够帮助经验不太丰富的评价者, 因其将建构直观地呈现为连续体的形式。但对于经验丰富的评价者来说,图示在他们进行等级评定时似乎并没有多大作用。

③ 行为描述。我们已经了解到, 刺激变量能够以较为具体的行为描述来表示。 此类行为描述也可以与图示设计相结合, 作为另一种量表方案。对于某个特征, 我们可能会有如下描述类型:







上面列出了三种描述行为的表述, 用来界定量表中的三个点。量表能够使评定任务更加具体, 使量表步骤更加统一。但是, 使用行为描述并不能确保所有评价者都以同样的方式看待事物, 因为评价者必定会在理解行为描述时进行主观判断。

图 11-2 是一种较为奇特的量表格式, 给出了较为清晰的行为描述相关说明。



<table><tr><td rowspan="2">表现范围</td><td colspan="5">表现的好坏程度</td></tr><tr><td>远远超过工作要求</td><td>超过工作要求</td><td>符合工作要求</td><td>有待提高</td><td>米达工作最低要求</td></tr><tr><td>工作质量</td><td>一跳就能越过高楼</td><td>需要的跑才能越过 高楼</td><td>需助跑才能越 过矮楼</td><td>能够爬上楼梯</td><td>一进门就绊倒</td></tr><tr><td>速度</td><td>比出膛子弹还快</td><td>跟出膛子弹一 样快</td><td>存在缓慢的子 弹吗?</td><td>经常走火</td><td>持枪时自伤</td></tr><tr><td>适应能力</td><td>能在水上行走</td><td>游泳游得好</td><td>用水洗</td><td>喝水</td><td>长期浸满水的</td></tr><tr><td>沟通能力</td><td>能跟上帝对话</td><td>能跟天使对话</td><td>能与他对话</td><td>自言自语</td><td>与自己争辩</td></tr></table>



图 11-2 员工绩效考核

④ “有无”式量表。当大量具体行为描述作为题干时, 要求回答选项只对所有符合被评价者特征的陈述打勾。这种类型的定级量表称为行为检查表。图 11-3 即为这种量表形式的例子, 它是由适应生活技能检查表 (Morreau & Bruininks, 1991) 改编而得。

1.5 .23 自己脱掉有粘扣或没粘扣的靴子

_____1.5.24 自己给衬衫、女式衬衫或上衣扣扣子

_____1.5.25 穿衣服正反面正确

_____1.5.33 自己系鞋带

_____1.5.34 自己选穿干净、平整、没破的衣服

_____1.5.44 自己系好或解开衣服上的安全别针

_____1.5.50 根据天气变化和不同活动选择郊游穿的衣服

左侧数字对应生活能力课程设置中的行为目标

图 11-3 适应生活技能检查表内容

资料来源: 适应生活技能检查表 (CALS)。版权 (C) 1991, 河滨公司 (The Riverside Publishing Company) 出版。保留所有权利。

如果此类评估程序能够得出特征量表评分, 而不是一长列具体行为表现, 那么每种分值必须要有对应描述。最简单的方式就是按照 +1、-1 或 0 给每个描述打分, 分值取决于针对被评价的特征 (例如毅力、诚信或可靠性) 或者某个评价标准 (例如学术成就、工作绩效, 或者治疗响应能力等), 此描述是满足标准的、不满足标准的, 还是中性的。把所有核对的题目分数相加, 会得到量表分数, 在后文讨论适应性行为量表时会更加详细地说明检查表。

⑤ 出现频率或评价相似程度。与检查表中每一项的回答不是有就是无的形式不同, 给评价者的选项包括 “总是”、“通常”、“偶尔”、“很少” 或者 “从未” (以这些类别系统阐述需要回答的题目时, 必须注意各题目描述语中不能够出现表示频率的词语。 否则, 评价时将会犯句法错误, 比如, 约翰尼 “总是” “会通常接受大多数人的决定”)。 另一种方法是, 把被评价者分为与描述中陈述的行为 “极为相似”、“非常相似”、“有点相似”、“不太相似”、“根本不同”等类型。表示频率或者相似度的词语可能不同, 因为上述词语只是给出相关提示。另外, 某个人的评分可能会同时考虑上述行为重要性和出现频率, 也就是说, 某个较为重要的特征所获分值可能会比次要特征高, 某种 “总是”出现的行为获得的分值可能高于“通常”出现的行为。

之前已经提到, 不同评价者不会以同一种方式来理解上述未明确的频率或者程度, 所以评价者自身偏见及个人偏好的不同这个问题依然存在。当心理学概论班的学生被问及每个频度副词代表多大的时间百分比时, 得到的回答真是五花八门。

对某些学生来说,总是意味着时间频率高于 \( {80}\% \) ,但有些同学则认为是每次都出现。他们认为通常或者经常这些词意味着 \( {50}\% \) 到 \( {95}\% \) 的时间频率,其他频度副词也存在类似的差异。此外, 当被选中的具体行为数量较大, 只是打勾表示有或无所得出的结果与更详细的表格形式结果相关性很高。

## 5. 提高评分准确度

若在不符合等级评定要求的条件中使用定级量表, 就算是设计得最好的量表也不可能得出可靠且有效的结果。评价者没办法提供他们没有的信息, 也不可能强迫他们提供自己不愿意提供的信息。因此, 我们必须选择那些与被评价者关系紧密的评价者, 要求他们评价能够观察到的特征。同时, 应该给评价者以指导, 说明我们期望他们做出怎样的评价。如果可能的话, 评价者应该在经过量表使用培训之后开始观察被评价者。若几位评价者对被评价者个人的熟悉程度类似, 那么就可以收集每个人的量表后将其合并。应该尽最大努力去激励评价者诚实认真地进行评价工作。 接下来让我们更详细地说明这些问题。

(1)挑选评分者

大多数情况下, 理想的评价者应该是最有可能在某些情境中观察被评价者, 最有可能启发被评价特征的那个人 (有时, 适合简单接触交流之后开始评价某人, 例如求职者工作面试时的第一印象等, 但并非经常如此)。同时, 评价者最好能对被评价者持客观公正态度。在摘要中大致说明了上述两种要求全面了解及公正客观的有利条件。但是, 可能实际运用中只能部分实现上述目标, 因为熟悉某人与对其公正客观通常是相互矛盾的。

管理因素通常决定分配谁去执行等级评定及某组织机构需要的评估工作。例如, 学校里, 教师一般是学生特征及行为表现的指定评价者; 工作中, 通常由上司来评价下属。由于每种情况下都是直接监管关系, 那么大体上都会存在一种持续且较为密切的人际关系。但是此类关系通常是单向关系且缺乏公正客观性。教师或上司只能看到学生或员工的部分特征, 也就是与某种特定关系相关的特征, 当不同的人拥有不同的权力时会形成这些特定关系。教师或上司可能适合于评价自己能够直接观察的特征及行为表现, 主要关乎工作表现质量。正如我们所预计的, 在工作绩效评价或学科知识评价上, 上司之间或教师之间存在较高的一致性。但是, 还有很多其他特征会出现在其他类型的关系环境中, 例如与同龄人或者下属之间的关系。如果要求评估上述特征, 同龄人或者下属之间的评价可能会更加全面, 在这种情况下, 进行评价工作的应该是这些同龄人或者下属。

## (2)决定谁应该挑选评分者

挑选相关人员来评价某个工作岗位的申请者或大学入学申请者,需要考虑另一个问题。通常要求申请者提供一定数量的推荐信或者提交由限定数量的个人填写的评估表。由申请者决定评价者人选时, 我们能够预想得到, 他/她会选择的评价者通常会提供对自己有利的评估。申请者与某些人存在某些特定关系, 并能够获得相关信息, 如果要求申请者提供相关人员的姓名及地址, 那么就能获得申请者更全面的信息。例如, 可以要求某位求职者提供上一份工作的直接上司姓名, 要求某位奖学金申请者列举两名主要指导老师姓名或者自己上过的两门及两门以上课程的讲师姓名。 这个要求将决定由谁来提供等级评价的责任从申请者身上转移到使用量表的组织机构身上, 这种责任转移能够有效降低对申请者的故意偏向, 从而可能产生更为有效的评定结果。

(3)为评分者提供相关培训

即使评价者有积极性, 用来记录评价结果的量表也经过精心设计, 但合理有效的评定结果也不会想当然出现。必须给评价者进行讲解如何运用定级量表, 使其接受进行合理有效评价的重要性。但是, 说来容易做来难。之前提到过, 一方面评价者不愿意付出必要的精力, 另一方面评价者与被评价者关系较为紧密, 这两方面是造成问题的两个阻碍因素。这些问题只能通过训练指导评价者来解决, 必须让评价者明白其任务极为重要。同时, 如果希望评价者在评价工作期间始终保持认真公正, 则说服工作必须持续下去。

所有评价者都应该在使用具体评价量表方面进行充足的练习, 因此, 极其需要进行培训, 训练评价者在监督之下使用量表。训练使评价者能够讨论被评价特征的意义, 准备等级评定练习表, 同时核查评定结果。评价者也能够注意到偏见因素, 例如普遍存在的宽容评价误差等, 从而避免这些因素。评价者额外的练习能够得出分布更加均匀的评定结果。当然培训不可能消除评定过程中的所有缺陷, 但能够大大降低扭曲事实的影响, 因扭曲事实在评定过程中更为常见。 (4)挑选用于评分的品质

通过评价过程中应该得出哪些类型的信息是由两条原则决定的。首先, 若通过更加客观可靠的指标能够提供需要的信息, 可以避免使用量表评定程序, 相较于其他人对某个人智力进行评价, 设计优良的能力倾向测试更能表明一个人的认知能力。 若有精确的生产记录, 应优先考虑, 代替主管的生产等级评定。只有在没有更好的指标可用的情况下才会采用量表评定方式。

其次, 量表评定应限制在评定较为外显的品质特征 - 可以通过实际可观察到的行为来表示的特征。我们不能指望评价者窥探到被评价者内心, 然后告诉我们发生了什么。另外, 必须牢记评价者与被评价者之间接触联系的程度和本质, 例如简单面试之后的一组等级评价应该限制为面试中能够观察到的品质, 面试中能观察到的品质应该包括被面试者的干净整洁、沉着冷静、讲话方式、回答问题时的流利程度等。 勤奋、诚信、主动性和独创性等特征在上述有限的接触中是不能直接观察到的, 尽管说与被面试者共事一段时间的人可能会对这些特征有较为精确的评价。所有的量表评定应该针对可观察的行为表现, 且情景设置中评价者应对被评价者有较深的了解。

(5)合并多位评分者的独立评价结果

之前提到量表评定的众多局限性之一在于其信度较低。如果多位评价者具有相当好的机会去观察被评价者, 通过合并这些评价者的独立量表评价可以提高量表评价的可靠性。但是, 适合在某种特定情境中一一学校、工作、营地等观察某个人的评价者数量有限, 通常只会有一个人与被评价者之间存在紧密的特定关系。一名学生只会有一位班主任, 一名员工只有一位领班, 一名露营者只有一位露营指导老师。其他人可能与之也有某些接触, 但极为有限, 合并这些人的评价可能会为关系最为紧密的评价者的评价信息增加不了多少内容。

注意我们详细说明了独立量表评价的合并问题。如果量表评定是独立进行的, 那么误差因素就是独立存在的, 可忽略不计。但是, 若是通过某种会议协商程序将不同的评价结合起来, 我们就不清楚会发生什么了。误差可能会忽略不计, 智慧可能会胜出, 或者由于某位评价者过于教条主义且立场强硬, 其偏见可能会占据上风。因此合并不同的独立量表评价结果是抵消个人误差的唯一可靠方法。

(6) 基于评分者的参与来设计定级量表

设计用于评估表现的量表的普遍方法是使最终会使用量表进行评价的评价者参与设计量表。设计此类量表分三个阶段进行:

第一阶段。一组潜在评价者对被评价的特征方面达成一致, 这些方面包括某项特定任务表现中较为突出重要的方面。例如, 下列分类可能是某大型公司一线主管可能具备的重要特征:

专业知识与判断力

责任心

人际交往能力

组织能力

客观性

审时度势的能力

第二阶段。潜在使用者制得出一系列关键特征, 或者实际观察到的行为实例, 从而说明在每个方面, 怎样的表现算是优秀、一般及较差表现 (关键特征一词来源于这样一种想法, 即这些行为对某种情况下的成功或者失败起关键作用)。然后, 要求第二个独立组的评价者将每个特征分配到适当的特征方面。只有当第二个独立组的评价者在将关键特征对应到特征方面取得一致时, 这些关键特征才能够纳入最终版本的量表中。

第三阶段。第二个独立组的所有评价者说明每个描述对应哪部分的优秀等级, 所有评价的平均水平和一致性需要进一步核实, 保留评价者达成一致的一部分特征, 整个量表体现出不同的均衡分布的量表值。下列特征选自名为“与学生人际交往能力”的量表, 此量表用于评价大学老师 (Harari & Zedeck, 1973)。该量表分数范围是 1 分 (低) 到 7 分 (高)。



<table><tr><td>刻度值</td><td>描述</td></tr><tr><td>6.8</td><td>若理解不了某个概念或感觉茫然, 教授能够感觉到并采取措施改变局面。</td></tr><tr><td>3.9</td><td>讲课时, 教授经常让有问题的学生在办公时间去咨询他。</td></tr><tr><td>1.3</td><td>教授可能会使不同意自己观点的学生难堪或出丑。</td></tr></table>



在使用上述方法时, 评价者在知悉每个方面的相应描述后, 就可以确定哪种描述最接近被评价者的行为表现。量表使用者表示与传统评定程序相比, 这种评定程序的方法偏差、成见效应误差和宽容评价均较小 (Campbell, Dunnette, Arvey & Hellervik, 1973) 较小。

(7)使评价者在评定之前集中关注行为表现

反对等级评定的一种说法是, 等级评定通常是在事实发生之后, 根据对被评价者的笼统且未经分析的印象来进行评价。我们在评定过程中避免过度依赖记忆的方法在于, 在进行最终评定程序之前预先介绍整个评定程序, 然后设计一种记录表, 明确某种行为表现的关键特征——正如上一步所说明的一一同时留出空间来记录被评价者可取的行为与不可取的行为。

上述量表设计步骤较为费时, 且得出的量表可能有点烦琐。在使评价者参与评定量表设计时需要更多的经验, 然后我们才能判断先前使用量表所得优势在之后的使用过程中是否依然存在, 以及上述所得优势是否足以证明设计量表所需要的额外投入是合理的。但是以上述方式设计的量表有一个优点, 即量表能够产生具体的行为描述, 与其他方法 (Landy et al., 1994) 相比, 能够更加可靠有效地进行评估。

## 6. 用于特殊情况的评分程序

针对特殊情况设计了几类评分程序, 此处我们讨论其中的三种: (1) 适应行为量表, (2) 排名程序, (3) 强制一选择模式。

(1)适应行为量表

针对幼儿或者某些能力极度有限的人的评价工作, 需要设计新的评分程序, 结合等级评定程序与能力测试的某些特点。提供信息的人 (父母、老师、看护等) 完成适应行为量表, 提供被评价者的相关信息。此类例子包括美国智能障碍协会家庭和社区环境适应行为量表, 是美国智力障碍协会 (AAMR) 即现在的美国智力和发育障碍协会 (AAIDD; Nihira, Leland 8. Lambert, 1993) 设计的第二版 (ABS-RC: 2)。此外还有美国智力障碍协会学校环境适应行为量表 (ABS-S: 2; Lambert, Leland, & Nihira, 1993), 适应生活技能检查表 (Morreau & Bruininks, 1991) 及瓦恩兰适应行为量表 (Sparrow, Balla, & Cicchetti, 2005) 等。

上述量表有类似的格式, 都会有一组特征, 基于儿童不同年龄段典型的发展阶段任务, 或者独立生活所需技能。然后要求提供信息的人说明被评价者能否完成该项任务, 上述特征可以用 “是/否” 打分, 或者在某个范围内评价, 说明该表现的典型程度。然后将这些回答累加, 将总分与规范标准相比较, 说明某个儿童的发展水平或者某个人的障碍程度。下列特征可能会出现在上述量表中:

使用卫生间

使用刀叉

投球

堆叠三块积木

使用不规则动词

交友

显然, 可能用到的题目数量庞大, 这些题目也可以再划分成不同的类别, 例如, 原动力、自我打理、社交能力、语言表达能力及学校相关技能等, 每个部分的官给出不同的分数。

适应行为量表最适合于需要获取某个人官能水平信息的情况, 从而补充说明认知能力测试所得信息或者代替认知能力测试来获取相关信息。适应行为量表最常用于评估有学习障碍的儿童, 经常用来判断它们是否适合某些类型的特殊教育服务 (参见第八章)。

380

特殊教育学校录取的少数族裔儿童比例过高, 这方面的担忧增加了对适应能力量表使用的兴趣。有人担心标准化智力测验可能会有失公正地将某些特殊发展的少数族裔儿童定性为智力和发育障碍。其实许多少数族裔学生在非学校环境中能够正常表现, 也就是说他们不符合标准化智力测验得出的诊断标准。使用适应行为量表能够在不同的环境中更好地了解这类学生的表现, 有助于诊断团队对该类学生的安排做出更好的决策。

尽管上述量表的使用有助于整体评判某个有学习困难或发育问题的儿童, 适应行为量表也存在重要缺陷。主要其中一个缺陷在于, 适应行为量表过于依赖知情者提供准确信息的意愿或能力, 例如父母尤其会倾向于从最好的一面看待自己的孩子, 不愿意承认自己孩子的缺陷。

另外一个问题与上述缺陷相关, 涉及某些特征的干扰性及要求知情者提供信息的对象在很多情况下是陌生人的问题。事实证明, 适应行为量表不能完全替代认知能力标准化测试, 因为适应行为量表分数与学校表现相关性不是很强。但是适应行为量表可以有效地补充说明非学术环境中的能力表现信息。

(2)排名程序

如果所有评价者均比较了解被评价者中的绝大多数, 则可以要求评价者针对每个被评价特征对被评价者进行排名。所以, 老师可能应说明在对班级项目及“职责范围之外”的活动贡献方面, 哪个学生最为突出, 哪个学生次之, 以此类推。通常会让评价者从极端案例开始, 朝着中间案例进行评价, 因为相较于大量的中间普通案例, 极端案例通常会比较容易区分。上述特征有时会转化为形式化的交替排序, 也就是首先挑选出最高的, 然后是最低的, 之后是下一个最高的和下一个最低的, 以此类推。允许平分 (即被评价者分数相等) 的情况存在, 这样可相对减轻评价者的工作量。若不允许出现平分情况, 排名的人可能会认为整个排名任务不合理, 尤其是排名对象较大的时候。

排名是一项费时费力的工作, 但确实能实现以下两个目标。首先, 排名会督促评价者对被评价者加以区分, 不允许评价者将所有被评价者或者大多数被评价者当作同一个类别对待, 但其他等级评定做法可能会发生这种状况。其次, 排名能够消除评价者之间的宽容程度或宽容评价差异, 不管评价者对被评价者多么宽容, 总要有人成为最后一名; 不管评价者如何苛刻, 总要有人成为第一名。因此能够在最终评分中消除评价者的评价标准个人差异。

原始排名并不能提供有用评分, 因为排名前后的意义取决于群体规模大小, 3 个人中排名第 3 与 30 中排名第 3 意义大不相同。此外, 排名等级代表不了某个特征相对应的等级。参照之前讨论的百分位数常模 (第三章), 在正态分布中, 某个群体的排名两端的一个或两个案例代表的差异性要远大于排名靠中间的案例。正因为如此, 惯例上需要把排名转化为规范化标准分数, 不管群体规模大小, 从而能够获得某种具备统一意义的分值, 且整个分数范围内有统一单位。

## (3)强制一选择模式

目前考虑的所有不同量表形式有同一个基本模型。评价者一次只能观察一种特征, 然后把被评价者对应到一组类别中的某个等级, 或者根据某个具体特征将其置于某个相对位置。现在, 我们考察上述模型的一种变形。这类格式的特点是, 评价者必须从一组特征中做出选择, 判断哪个特征 (或哪些特征) 最准确地描述了被评价者的行为表现。例如, 评价讲师的量表可能包括如下特征描述:

a. 对学习迟缓者有耐心。

b. 讲课时充满信心。

c. 保持学生的听课兴趣及注意力。

d. 使学生熟悉每节课的课程目标。

评分者的任务就是从上述一组描述中选出最能描述被评价者的一或两个项目。 注意这组描述均为正面描述, 是评价讲师好的方面。选定的这些项目应该是对讲师程度相同的正面描述。但是, 这些项目确实存在不同, 不同之处在于认定好讲师和差讲师的区分程度。在上述情况中,最有区分度的是 \( \mathrm{a} \) 描述,区分度最小的是 \( \mathrm{b} \) 描述, 也就是说, 好讲师可以界定为对学习迟缓者有耐心, 但差讲师则不会如此, 但好讲师与差讲师同样可能在讲课时充满信心。好讲师某种程度上更可能被评价为能够保持学生听课兴趣和注意力, 且使学生熟悉课程目标。因此 a 描述应该对应 2 分, c 描述和 \( \mathrm{d} \) 描述对应 1 分,而 \( \mathrm{b} \) 描述对应 0 分。这组描述中某位讲师的评分即为选出的最能够描述这位讲师的两项分数之和。整个量表的评分则是 25 组或者 30 组上述包含四项描述的模块的分数之和。上述类型的评分有很好的半分信度 (通常在 0.85 和 0.90 之间), 因此这种量表能够提供较为可靠的分数, 至少在评价者眼中是这样的。 当然, 这样的分数表明不了不同评价者之间是否存在较高一致性或者缺乏一致性。

通过将评价量表转化为强制一选择模式, 量表编制者希望达成以下三种目标:

① 消除评价者慷慨或宽容评价标准上的不同。由于一组描述中包含对某人同等有利的题目, 倾向于积极评价他人的评价者将不会在所有题目中有意选择某一项。 因此能够得到对被评价者更为准确的评价, 原因在于被评价者真正的本质决定了应该选哪些描述。

② 将评价者有意抬高或降低分数的可能性最小化。大多数的评定量表都是由评价者来控制评价过程, 评价者可以按照自身意愿给某个人高分或低分。但在强制- 选择量表中, 评价者不能轻易确定积极评价或者消极评价, 因此不能够随意提高或降低某个人的分数。这种方式的成功取决于量表编制者均衡分组项目吸引力的技能。 尽管有迹象表明强制-选择量表相较于其他量表, 不太容易受有意偏见的影响, 但在坚持己见评价者面前还是避免不了受到评价者自身偏见的影响。

③ 产生较好的分数分布情况及更加接近正态分布的等级评定分布。所有选项具有相同吸引力能够最小化宽容评价误差, 从而得出较好的分数分布情况。

强制一选择量表的一种变化形式是 \( \mathbf{Q} \) 分类。这种量表形式给评价者提供了大量描述被评价者的陈述, 评价者将每种陈述对应到几种类别 (通常是七种) 之一, 按照能高度描述被评价者到完全描述不了被评价者的顺序排列。这种方法的独特之处在于其要求评价者进行某种特殊的对应分配。思考一下这个简单的例子: 若有 50 种陈述, 共分为 5 类, 那么分配任务即是分别将 5 种陈述对应到两个最为极端的类别中, 接着分别将 10 种陈述对应到紧接着的两种类别中, 剩下的 20 种则默认分配到中间的类别。正如大多数强制一选择量表形式, \( \mathrm{Q} \) 分类常用于个性描述,而非表现等级评价。

强制一选择模式的缺陷。强制一选择量表最为突出的缺陷在于, 评价者不喜欢使用这种形式。其主要原因是, 这种量表剥夺了评价者的控制力, 使评价者不能轻易凭借自身整体感觉来给出或高或低的评分, 从而使其灰心, 主要表现在评价者不愿意勤恳地进行评价工作。

强制 选择量表也需要量表编制者在设计陈述题目时运用大量技能, 从而使得各个选项同等可取, 但同时又能区别描述更为成功的个人。这种设计方法要求所有选项必须在实际使用之前经过大量测试, 从而确定哪些选项能够区分成功者和失败者。

强制一选择量表在 1945 年至 1965 年间引起了大量关注、研究以及一些实际运用, 但是设计量表的任务量较重, 且评价者对其反响较为消极, 所以近年来对强制一选择量表的关注逐渐减少。但此类量表仍然用于评估某些个性及态度, 也用于评估职业兴趣和职业倾向。

## 11.3 态度测量

前几节中, 我们讨论了通过其他人给出的信息来了解某些人的方法, 包括其能力、个性特征及其他特点, 这些其他人在需要的信息类别方面较为了解被评价者。当然, 也可以直接从被评价者身上获得上述信息。

第十二章至十四章将讨论如何评估个人能力及个性特征。在态度测量中, 我们侧重于获取可靠的分数来代表某个人对某件事的情绪强度。类似于其他自我陈述方法, 态度评估仅限于被评价者所了解的事物且自身愿意进行交流的事物。

大多数人对评估个人特征的项目有着类似的社会期望认知, 所以每个人倾向于以类似的方式回应上述量表选项, 通常以一种保持自己良好形象的方式, 而这种倾向是上述量表内在的缺陷。但是由于每个人对不同特征的社会期望都会不同 (也就是说, 关于 “正确” 答案是什么的一致性较低), 所以上述评估方法受回应偏差的影响较小。当我们要探索某个群体的整体态度水平, 不需要了解个人态度时, 最好是进行匿名回答, 这样的做法能够提高该群体的回答更真实地反映该群体态度的可能性。

态度评估工具的主要问题在于其编制过程中存在明显的简易性。只是因为能较快地收集选项, 简单地形成工具表并不代表这样的量表就能够可靠有效地评估其拟评估的特征。除非以系统方式设计态度量表, 否则就算使用已知的设计良好的量表, 得到的结果可能也是无意义的。

态度评价量表的构建通常始于一系列陈述, 能够反映出对目标概念的所有可能观点。这些观点主要来自于阅读材料、朋友同伴以及作者的意识深处。这一过程的目标是选取大量能够代表所有可能选项的陈述, 用于评估所要研究的态度。这些选项应该涵盖最为积极最为有利的陈述,一直到最为消极最为不利的陈述,包括某项态度的所有方面。每项陈述应该简单明了, 描述一个简单的概念, 侧重于感觉而非事实, 即侧重于态度本身而非某项信息。下列如何选取态度评估量表中的各项陈述的建议是由爱德华兹 (Edwards,1957) 的经典设计发展而来, 它们能够有效改进态度量表设计:

① 不能使用描述过去情况的陈述, 要使用描述现在情况的陈述。

② 避免事实性陈述及可能将其理解为事实的陈述。

③ 确保所有陈述只能有一种解释说明。

④ 不能使用与所要考察的个人心理构建无关的空洞陈述。

⑤ 避免使用大多数人或几乎无人赞同的陈述。

⑥ 确保陈述能涵盖所有有关的心理构建全部范围。

⑦ 陈述措辞简洁、直接、明了。

⑧ 陈述要简短 (很少会超过 20 词)。

⑨ 确保每项陈述只表达一个完整想法。

⑩ 避免使用绝对程度的词语, 如 “所有”、“一直”、“没有”或者 “从未” 等, 因为这些词通常会招致歧义 (这些词表达的是绝对意义吗?)。

⑪ 谨慎适度使用具有评价性质的词语, 例如 “只有”、“仅仅”、“只不过” 等类似词语。

⑫ 陈述应当是简单句, 而非复合句或复杂句, 无可避免地必须使用复合句或复杂句的情况除外。

⑬ 避免使用已完成量表的使用人理解不了的词语。应符合目标读者的阅读水平。

⑭ 不能使用双重否定句 (详见第 14 页)。

## 1. 累加态度评估量表

态度评估量表通常需要评定对象使用数字来表示其对该项陈述中所描述的事物或者立场的感觉强度, 以这种方式对陈述作出回答, 然后统计所有回答来估测某项态度的强度。获取上述数字指标的一种最常用的方法是让调查对象指出自己对若干陈述的感觉水平, 通常指调查对象同意或不同意该陈述的程度。这种方法被称为累加评分, 因为某个人的态度是由每项陈述所得回答的总和来反映的, 也称之为李克特量表, 以 20 世纪 30 年代首次引入此量表的伦西斯。李克特的姓命名。下例为调查对象针对量表选项做出回答的评分说明。

5- 非常同意

4- 基本同意

3 中立

2——基本反对

1 非常反对

若要评估某学校老师对按照能力水平进行学生分组的态度, 你可能会提出下列陈述:

① 按照能力水平给学生分组会阻碍学生的社交能力发展。

② 当学生跟与其能力水平相当的同学一起上课时, 学生能够取得更大进步。

③ 天才学生应该进天才学生班。

④ 接受特殊教育服务的学生应该分到普通班级。

上述陈述①和④表示反对按能力分组的态度, 而陈述②和③则支持按能力分组。 所以教师们可以针对每项陈述给出评分数字, 表明自己对此项陈述的同意程度。上述量表中包括的陈述必须被占据态度序列两端的持肯定态度的人及持否定态度的人同时赞成, 从而纠正受访者同意大多数陈述的倾向, 这种倾向被称为默从倾向。非常同意陈述 1 和 4 的人会反对陈述 2 和 3 , 若非如此, 我们必须质疑这些人是否认真对待此任务。如果意思不发生实质变化, 通常情况下很难逆转陈述说明, 但同时描述情绪范围的两端是必不可少的。

在综合所有选项得出每个人的态度分值过程中, 应该颠倒转换否定陈述的选项得分, 那么以否定陈述表示反对的人就可以得到正分值。以否定陈述表示强烈反对应该与以肯定陈述表示强烈同意处理方式类似。先在该选项能够打的最高分值基础上加一分, 然后减去受访者实际打的分值, 并以上述方式转换分值。例如, 在上述五分制量表中, 若量表各选项经过打分, 分值高代表对按能力分组的积极态度, 那么非常同意陈述 4 的对应数字是 5,但实际分值应该是 \( 6 - 5 = 1 \) 。因此,若某人非常同意陈述 2 和 3 , 非常反对陈述 1 和 4 , 那么就得到了最高分 20 分, 但反过来, 若某人非常同意陈述 1 和 4 , 非常反对陈述 2 和 3 , 则会得到最低分 4 分。

## 梯度数

量表中的梯度数极为重要, 梯度数量越多, 量表的信度就越大, 其原因在于用于表达某人立场的范围会随之增大 (我们已经在第四章讨论过范围限制对信度的影响)。量表梯度增加至七级时, 信度提高最为明显, 而且基本不会使用超过七级的选项, 因为超过七级的那些额外级数所带来的可靠性增量很小, 同时也很难再增加有意义的锚点。通过增加陈述题目数量来提高可靠性更加容易。

## 分数锚点类型

上述五分制量表显然是进行态度评价时最常用的形式。尽管同意至反对分数锚点非常灵活, 当某些锚点类型适合陈述题目的意义时, 也会使用其他分数锚点。例如, 态度序列中的 “有效至无效”、“重要至不重要” “喜欢我至不喜欢我” 等锚点在某些合适的情景中已得到成功运用。

## 梯度数应为奇数还是偶数

在编制量表时, 必须决定是使用奇数梯度还是偶数梯度。多数受访者更倾向于奇数, 因为他们对某项陈述持中立态度时能够选择恰当的选项。若梯度数为偶数, 受访者可能会感觉当自己对某个问题真的持中立态度时, 会被强制选择立场。另一方面, 对不愿意投入足够的时间来回答所有选项的人来说, 重复选择中立是最简单的解决力法。

使用偶数梯度, 不给个人回答时有做出中立选择机会的一个缺陷在于可能会增加未回答陈述的数量, 因为某些受访者在不能选择中点的情况下可能会拒绝回答。 一般来说, 包含中立点所获得的受访者支持会大于强迫其选择立场所导致的损失。 若以图表形式来展现回答选项, 并且受访者能够通过打勾或者圈出线段上的某个数字的形式进行回答, 不愿意选择立场的那些受访者可能会强加一个中立点, 在量表两种类型中间做记号表示立场。

## 2. 单项目量表

若侧重于群体态度而非个人态度, 一般做法是通过一份调查问卷评估对若干事物或若干观点的态度。通常情况下, 一项简单陈述代表一个所研究的问题。尽管单个人的回答缺乏足够的信度, 提供不了此人态度的有用评价, 但是群体倾向能够以这种方式进行准确判断, 因为整个群体中的回答误差常常会得到平衡, 从而得出该群体情绪的可靠指示。这即是民意调查的基础。

尽管单项目量表很常见, 它们也有其内在问题。第一, 单项目量表不利于评估群体内部一致性, 因此评估可靠性需要通过误差幅度比例来表示。民意调查报告中会出现一些常见的表述,支持率为 “ \( \mathrm{X} \pm  3\% \) ” 或者 “民意调查误差幅度为 \( \mathrm{X}\% \) ”。第二个问题在于, 如果受访者对该项选择理解错误, 那么此人的评估结果将无效。第三, 也可能存在如下风险, 即此单项的文字表述方式可能会有系统地使评价结果带有倾向性。请思考如下两种陈述:

① 为了在学校达到废除种族隔离的目的, 应该强制父母使用校车接送孩子。

② 法庭应该采取任何合理措施来在学校废除种族隔离。

可能在作者看来, 上述两种陈述均反映出对使用校车作为达到废除校园种族隔离的手段之一的肯定态度。但当以单项使用时, 上述两项陈述可能会产生截然不同的结果。即使是那些积极支持废除种族隔离的人也可能会对第一条陈述做出消极反应。 单项目量表措辞上的微小差异造成的语意不定是民意调查中很常见的问题, 这也是为什么两个相反立场的支持者都能说自己得到了大部分公众的支持。从某种程度上来说, 这种偏见可能会出现在任何态度评价量表中, 但当使用大量陈述题目时, 正面选项与负面选项同时存在偏见的可能性会相互抵消。

## 3. 态度评估量表示例

在设计职场男女平等主题的态度评估量表时, 第一个任务是搜集大量题目来描述该主题范围内的所有话题及对该主题的观点。对于女性职场机遇, 话题可能涵盖平等就业机会、儿童保育、性自由、个人独立, 以及性别角色分化程度等。每项陈述应该简洁明了, 描述一个简单的概念, 侧重于感觉而非事实, 也就是说, 侧重于态度本身而非信息。

(1)题目筛选

最初产生的题目总数通常会过大, 不能用于评价量表。同时, 理想的情况是, 仅使用我们确定能够评价某项特征的题目, 所以有必要筛选出最佳题目。筛选最佳题目主要是通过不同评价者审核评估所有题目, 评价者的作用不是说明针对某道题目是否达成一致, 而是评估在目标观念的 “支持至反对” 量表中, 某项陈述题目对应于哪一部分。另外应该要求评价者指出与态度方面不相关的陈述题目, 针对某个特征的某些方面没有提供相应陈述说明的地方提出建议。量表分数锚点的范围可能从 9 分 (说明一项非常赞成的陈述) 到 5 分 (表示中立) 再到 1 分 (说明非常反对或敌对的陈述)。

评价者评估的目的在于发现: ①每道陈述题目对应于 “支持至反对” 量表的哪一部分; ② 一组评价者对于每道陈述题目的意义达成一致的程度。最终目标是筛选出一组陈述题目来代表从支持到反对的所有不同程度, 且所有陈述题目对每个人传达的意思几近相同。

每道题对应“支持至反对”量表的位置是由评价者评定的量表中值来表示, 其模糊性则由以四份位距所表示的评分差异来体现。思考一下下列两种陈述, 其中评价者使用了九分制量表:



<table><tr><td/><td>中值</td><td>四分位距</td></tr><tr><td>妻子的工作和事业与丈夫的工作和事业同样重要。</td><td>8. 1</td><td>1.5</td></tr><tr><td>女性时尚是使女性处于次要地位的手段。</td><td>7.0</td><td>5.1</td></tr></table>



上述第一项陈述极有可能被纳入最终态度量表题, 是非常 “赞成” 的一条陈述, 评价者们对这条陈述应该对应量表的哪一部分具有高度一致。而第二项陈述则是较差的选择, 尽管平均而言, 对这条陈述的评价暗示了对职场男女平等的较为赞成的立场, 但评价者之间对该项陈述所含深意存在较大分歧。不同评价者将该项陈述对应到量表上的 1 到 9 分不等。此外, 有 10 % 的评价者将此项陈述标记为与所研究方面无关, 因此上述程度分歧的陈述应从量表中删除。

根据评价者的评估结果, 我们能够筛选出一组合理简要的陈述题目, 其语意清晰, 能够代表所有程度的观点强度, 能够涵盖所要研究领域的主要方面。陈述题目通常情况下最好以图 11-4 所示的形式展现给调查对象, 使调查对象能够指出每项陈述的可接受程度。调查对象可以打 4 分、 3 分、 2 分、 1 分、 0 分,其中 SA(非常同意) 得分为 4 分, SD(非常反对) 得分为 0 分。所有回答将以上述方式录入计算机, 9 项否定陈述 (陈述 \( 3\text{、}5\text{、}8\text{、}9\text{、}{14}\text{、}{16}\text{、}{17}\text{、}{18}\text{、}{19} \) ) 将通过计算机进行分值转化,从而得出量表总388分, 20 项的分数范围可能是在 80 分 (非常同意女性社会平等) 到 0 分 (非常反对) 之间, 40 分则被视为中立。



<table><tr><td>对女性平等待遇的态度</td></tr><tr><td>阅读每项陈述, 根据如下标准圈出最能代表你对该项陈述感受的代号。</td></tr><tr><td>SA……非常同意。</td></tr><tr><td>A - - 基本同意。</td></tr><tr><td>？一无意见,既不同意也不反对。</td></tr><tr><td>D - 基本反对。</td></tr><tr><td>SD——非常反对。</td></tr><tr><td>SAA?DSD</td></tr><tr><td>SAA?DSD2. 女性有权选择是否生育。</td></tr><tr><td>SAA?DSD3. 大多数女性天生不适合主管或管理工作。</td></tr><tr><td>SAA?DSD4. 俱乐部或公众场所不能有性别限制。</td></tr><tr><td>SAA?DSD5. 女性的位置应在家里。</td></tr><tr><td>SAA?DSD6. 男女应该有同样的晋升标准。</td></tr><tr><td>SAA?DSD7. 妻子的工作事业与丈夫的工作事业同样重要。</td></tr><tr><td>SAA?DSD8. 从根本上说, 男女身体构造不同, 适合担任不同角色。</td></tr><tr><td>SAA?DSD9. 追求事业的女性很少会有满意的家庭生活。</td></tr><tr><td>SAA?DSD10. 男女没有先天心理差异。</td></tr><tr><td>SAA?DSD11. 男性应该共同承担家务——做饭、打扫卫生等。</td></tr><tr><td>SAA?DSD12. 所有女性都应有权选择独立自主的事业。</td></tr><tr><td>SAA?DSD13. 男女应该有统一的性别标准。</td></tr><tr><td>SAA?DSD14. 推动女性解放的人员是失意失败的女性。</td></tr><tr><td>SAA?DSD15. 除体力外, 男性能做的事, 女性可以做得一样好。</td></tr><tr><td>SAA?DSD16. 女性解放只关乎少数极端女性。</td></tr><tr><td>SAA?DSD17. 大量投资女性教育没有意义, 因为她很可能会结婚, 用不着高级训练。</td></tr><tr><td>SAA?DSD18. 本质上, 女性处于顺从地位, 而男性则占支配地位</td></tr><tr><td>SAA?DSD19. 女性天生就该退居次席和辅助地位。</td></tr><tr><td>SAA?DSD20. 男女应该在各个方面得到同等对待。</td></tr></table>

图 11-4 态度量表范例



## (2)题目分析

搜集一组陈述后, 按照上述建议汇总成一份量表, 接下来应该在试验群组中予以试行。从理想化的角度来说, 应在机读答题纸上作答所有题目, 便于将回答录入计算机进行数据分析。各项回答的分数相加, 确保转化否定陈述的分值 (在 SPSS 统计分析软件中, 最简单的转化方式是使用转换菜单中的计算代码命令, 在选项数加 1 的基础上将记录回答分值减去。在 EXCEL 表格中, 必须新设一个新变量, 在适当单元格中设置相应公式。例如要转换 \( \mathrm{Q} \) 列的五分制变量评分,使转换后的结果显示在 \( \mathrm{P} \) 列中,则应在 \( \mathrm{P} \) 列的每一行中输入以下命令 “ \( = 6 - \mathrm{Q} \) ?”。这种情况下,“?”代表该行数)。因此, 每项回答都与总分相对应, 得到的相关性系数表示每一项如何影响整个测试的可靠性。相关系数越高, 该题目越适合。一道适合的题所需的相关性大小取决于研究问题和测试长度, 负相关可能说明打分出现错误或者应该修改该道题。通过删除、替换或者修改不适合的题, 能够大大提高测试信度。

(3)信度

运用阿尔法系数判断态度评估量表的内在一致性信度非常重要。正如其他测量可靠性的方法一样, 阿尔法系数大小受样本数量对所评估方面的内部变量影响, 因此在样本中试行量表尤其重要, 因其能够表明某项特征总的合理变量。例如, 若要在一群受过高等教育的人群中评估其对高等教育价值的态度, 很可能会发现变量很小, 结果导致较低的内部一致性信度。内部一致性是我们能够对样本群体加以区分的指标, 也是我们在评估一项单方面特征的凭证。如果在一份量表中评价若干特征, 却只记录了一个分数, 那么这若干项特征会相互抵消, 量表的变化量和信度也会很低。所有题目之间的相关性要素分析能够说明问卷中是否存在多个方面特征。

## 4. 其他格式

态度评估有时会运用我们目前为止讨论的累加格式以外的格式。一种替代格式给出的是如图 11-4 所示的一组陈述, 注意涵盖某些中立性陈述 (累加评价量表中通常不会包括, 也不是必须包括中立性陈述), 同时指导答题对象标记出: (1) 自己同意的所有陈述; (2) 最能代表自己观点的陈述一 可能是个具体数目。这种格式中, 最好每项陈述都对应一个准确定义的分值, 因为某个人的分值将会是此人赞成的所有陈述题目的分值平均分。这种态度评估方式最初是由 L. L. 瑟斯通 ( L. L. Thurstone) 在 20 世纪 20 年代提出的, 称为瑟斯通量表。

另外一种略有不同的方法是筛选少量陈述 (通常五到六个), 且各个陈述内容属于相同性质, 仅在某种具体态度上程度不同。下列例子关于堕胎的可接受程度, 形式可能如下:

① 任何女性想有选择是否堕胎的权利。

② 如果医生建议堕胎, 堕胎就应该是合法的。

③ 若因强奸或乱伦导致怀孕, 堕胎应是合法的。

④ 若威胁到母亲的健康或幸福, 堕胎应是合法的。

⑤ 若威胁到母亲生命, 堕胎应是合法的。

上述五项陈述描述了一种许可梯度, 同意陈述 1 的人大体上会同意陈述 2 到 5 (如果陈述 1 到 5 顺序正确), 同意陈述 2 但反对陈述 1 的人可能赞同陈述 3 到 5 , 以此类推。态度序列中, 某个人的立场是由其接受的最高标准来界定的, 这种量表 (称为格特曼量表, 以最初提出此量表的心理学家姓名来命名) 有若干逻辑上的优点, 但事实证明难以设计这种量表。

## (1)语义差异法

另外一种态度评估的替代形式运用较为广泛, 也就是所谓的语义差异法, 由奥斯古德 (Osgood) 等对形容词代表的语义域结构的分析发展而来 (Osgood, Suci, & Tannenbaum, 1957)。通过因子分析研究, 奥斯古德等研究者发现, 不同形容词所表达的语义变化大部分可以用三个主要方面来表示, 称为评价、能量及活动。表示每个方面极端相反情况的成对形容词如下:



<table><tr><td colspan="2">评价</td><td colspan="2">能量</td><td colspan="2">活动</td></tr><tr><td>好</td><td>坏</td><td>强</td><td>弱</td><td>积极</td><td>懒散</td></tr><tr><td>美好</td><td>航脏</td><td>能干</td><td>无助</td><td>繁忙</td><td>虚度</td></tr><tr><td>公正</td><td>不公</td><td>支配</td><td>服从</td><td>主动</td><td>被动</td></tr></table>



类似的上述形容词组可用于了解某个人对任何目标对象的看法, 包括一般概念, 例如堕胎, 也可以是某个具体的人, 比如某人的老师或者自己。通常形容词组的顺序是打乱的, 在答题纸上, 一组形容词中肯定和否定的两端也会颠倒过来, 从而减少不假思索的定式思维回答。在一张五级到九级的量表上, 要求调查对象通过在一对形容词中间的某个点上做出标记, 说明自己如何看待目标概念或目标人物。例如, 如果某个调查对象认为堕胎的想法非常好, 他/她就可能会在接近 “好” 的地方做出标记; 认为堕胎不好也不坏的调查对象则可能会在两个相反形容词的中间做出标记, 以此类推。

语义差异法为搜集对一个或若干目标事物或目标观念的印象提供了一个简单快捷的方法。但是形容词词组通常会不适合于描述目标, 因此可能需要调查对象展开想象才能作答。有人怀疑, 上述情况中的回答可能会流于表面, 且只是纯粹的字面意思表达而已。

(2)内隐态度

我们目前讨论的所有态度评估程序都存在一个缺陷, 即仅仅涉及语言回答。这些回答能够传达出人们感受到的或者相信的事物, 但是调查对象可能不会完全坦诚直率地说出自己的所想。更重要的是, 人们的行为可能与其口头上赞同的信念或感觉不相符。一个孩子可能口头上赞成善意对待其他民族, 但在挑选邀请玩伴或者朋友来参加自己生日宴会时, 还是会避免选择其他民族, 或者也许不会。必须承认表示某种态度的口头陈述存在上述情况。尽管说, 在上完某门大学课程或看过电视节目之后, 学生可能会改变自己赞成的态度语言陈述, 这本身就有很大关系, 但是不能够自动假设, 针对目标事物或目标群体, 学生行为的其他方面也发生了改变。

最近, 对通过反应时间来测量智力 (详见第十二章) 的关注重新兴起, 引起某些研究者运用相似的方法来评估潜意识的信念和态度, 包括刻板印象, 即对某些阶级的人的看法是建立在先入为主的概念之上, 而非实际证据之上。这其中的基本理念是, 不管某人口头上表达出来的对某些观念的态度如何, 此人若是认为若干组观念不可比较, 会反应较慢。若干方法已开发出来评估内隐态度和信念 (参见 Banaji, 2001)。一个常用的方法称之为内隐联想测试或 IAT (Greenwald, McGhee, & Nosek, 1998), 通过男性、女性、数学和艺术这四个概念进行了阐释 (参见 Greenwald & Nosek, 2001)。若 IAT 背后的假设正确, 某个人如果持有性别偏见, 认为男性擅长数学而女性擅长文科, 那么此人就会对男性一艺术和女性一数学这两组刺激因素搭配的反应较慢, 而对男性一数学和女性一文科这两组刺激因素搭配的反应较快, 原因在于前两对概念在其定式思维中是不存在的。

IAT 测试有五个阶段。每一阶段, 如果屏幕上闪现的词语是某个概念或者成对概念的例子, 应试者须按下右键, 如果屏幕上闪现的词语是其他概念或其他成对概念的例子, 就按下左键。第一阶段中, 该应试者应对男性词汇如男孩、他的或先生选择左键, 而对女性词汇如女性、她的或女士选择右键。测试第二阶段中, 与艺术相关的词语, 例如诗歌、音乐或小说替代了表示男性的词汇, 而与数学相关的词语如公式、代数或乘法代替了表示女性的词汇。

第三阶段开始首次测试态度。这一阶段中, 应试者应按要求在屏幕上出现男性词汇或者艺术词汇时 (若应试者持有性别偏见, 这一对词汇即是互相矛盾) 按左键, 屏幕上出现女性词汇或数学词汇时 (同样互相矛盾) 按右键。第四阶段交换艺术词汇和数学词汇的回答按键, 即艺术词汇选右键, 数学词汇选左键。之后的第五阶段中, 应试者在屏幕上出现男性词汇或数学词汇时按左键 (与定式思维相匹配), 在屏幕上出现女性词汇或艺术词汇时按右键 (同样与定式思维相匹配)。IAT 测试的理论背景及测试程序预测, 对不矛盾的词语组合做出反应的时间要短于那些互相矛盾的词语组合。也就是说, 第五阶段的反应时间会较短, 而第三阶段测试应试者是否持有所调查的性别偏见时的反应时间会较长。每阶段的平均反应时间之间的差异大小被视为衡量偏见强度的一种方法。

在上述方法基础上, 人们又提出了许多不同方法来评估不同态度。这方面的研究工作大部分都集中在对不同种族人群的态度上。例如一个人若持有反对黑人的态度, 当要求对黑人面容的图片及 “贬低” 内涵的词汇做出相同反应时, 或者要求对白人而容的图片与 “积极” 内涵的词汇做出另一个相同反应时, 此人会反应较快, 而当要求对黑人面容的图片及 “积极” 词汇做出相同反应时, 或者要求对白人面容的图片与 “贬低”词汇做出另一个相同反应时, 此人反应会较慢。上述方法被广泛用于不同种族之间的对比 (例如, 日本人和韩国人), 但这种方法的使用不仅限于上述例子中的成见或者种族偏见。

内隐态度的评估在态度评估研究领域越来越受关注。内隐态度评估的支持者认为, 内隐态度可以用来揭示潜意识态度, 而这种潜意识态度难以通过常规方法来评估。但批评者则认为这种方法的信度和效度较低。坎宁安、普里彻及巴纳吉 (Cunningham, Preacher, & Banaji, 2001) 的一项在实施方法和统计过程方面都十分复杂的研究为上述方法的信度和效度提供了有力支撑, 但是若要大规模运用, 这种方法也很烦琐费时。这个方法要求使用计算机精确计量反应时间, 所以只有会使用计算机的人才能使用上述方法。

## 11.4 总 结

为了深刻理解其他人的个性和态度, 你可以直接从其他人身上获取信息, 观察其行为表现, 或者从知情人获取信息。个性评估和态度评估通常通过非正式的推荐信或者正式地系统地使用评定量表来完成。两种方法都存在类似的局限性, 主要集中在评价者进行准确评价的意愿及能力。除上述局限性之外, 这两种方法毫无疑问会继续广泛使用在学校、行政部门、企业的绩效评价中, 以及教育研究和心理研究中。 我们应当尽最大努力减少这种评估方法的局限性。

评估程序的局限性来源于如下特点:

1. 评价者不愿意对其他人做出不利评价 (宽容评价误差), 当评价者认同被评价者时这种现象尤为明显。

2. 评价者之间存在的 “人道” 个人差异 (评价者标准差异) 或宽容评价及苛刻评价的个人差异较大。

3. 评价者倾向于根据自身整体喜恶对被评价者做出反应, 难以区别个人品质的各个具体方面 (成见效应)。

4. 评价者与被评价者之间接触有限---时间有限, 观察被评价者的情境类型有限。

5. 被评价特征意义含糊。

6. 个性变化中许多内在方面的内隐性和不可观察性。

7. 人类评价的不稳定性和不可靠性。

考虑到上述局限性, 当达到如下标准时, 量表即能够较为准确地体现被评价者的情况:

1. 仅限于评估人际关系中的外显特质。

2. 把被评价特质分解为实在具体的行为方面, 针对这些行为方面进行评价。

3. 量表形式强迫评价者加以区分, 或者能够控制评价者的评价标准差异。

4. 选定的评价者通常是在被评价特征出现的情境中有最大可能观察被评价者的人。

5. 说服评价者认同等级评定的价值, 并且评价者在使用评定量表方面得到充分训练。

6. 当若干评价者适合进行评价工作时, 合并若干评价者的独立评定结果。

在某种程度上, 评价者认识不到等级评定的重要性的评价程序, 也可能为政府部门及企业所运用, 特别是在通过强制一选择方法控制评价者自身偏见的影响时。

态度评估量表主要用于为赞成或者不赞成某个群体、制度或者某个问题的强度评分。尽管上述反应只能说明言语表达上的态度, 也可能与实际行为不一致, 但上述表达也可能预示着行为上的变化。内隐联想测试及相关评估方式为克服上述问题提供了希望。

## 11.5 习 题

1. 如果你在给申请贵公司工作岗位或者向你的学校提出入学申请的某个人的推荐人写信, 你的信中会包含哪些内容来获取对该申请者最有用的评价呢?

2. 为你就读的学校或者你任教的学校使用的不同量表制作一份完整的清单。 各种情况中会分别使用哪种评定量表或评估表格?

3. 你在上题中列出的评定量表有多有效? 所得到的评分结果分布情况如何? 不同使用者使用该量表的一致性如何? 你对定级量表的信度有什么印象? 你觉得这些量表避免成见效应及其他误差的情况如何?

4. 哪些因素会影响评价者认真进行评价的意愿? 这个问题到底有多严重? 针对此问题怎么办?

5. 相较于由三位评价者组成评价委员会共同进行评定, 为什么三位单独评价者独立进行评定更为可取?

6. 在某大型公司的人事办公室, 要求招聘面试官在面试结束后对求职者打分。 下列特征中你认为哪个的评分最为可靠? 为什么?

a. 主动性 b. 外貌 c. 工作背景 d. 可靠性 e. 情绪平衡

7. 在关于若干社区使用的报告单的小型调查中, 最常提到的是下列四种特征: a. 有礼貌; b. 有合作精神; c. 良好的卫生习惯; d. 与人共事。如何将这些特征细分或者修改一下, 从而使得课堂教师能更好地用它们来评价学生?

8. 同辈评估与上级评估相比, 有何优点? 有何缺点?

9. 相比于评定量表, 排名有何优点? 有何缺点?

10. 假设要设计一份强制一选择量表, 用于评估某城市学校系统中的教师效能。 与其他类型量表相比, 强制一选择量表有何优点? 使用过程中会产生哪些问题?

11. 假设你正在负责自己公司引进的人事考核计划。为了取得最好的评定结果, 你会采取哪些步骤?

12. 哪些因素会限制书面态度量表的有用性? 除书面态度量表外, 老师可使用哪些其他方法来评估学生态度?

13. 准备一份简短的态度评估量表的初稿, 用于评估教师对客观测试的态度。

## 推荐阅读

Aamodt, M. G., Bryan, D. A., & Whitcomb, A. J. (1993). Predicting performance with letters of recommendation. Public Personnel Management, 22, 81-90.

Banaji, M. R. (2001). Implicit attitudes can be measured. In H. L. Roediger II & J. S. Nairne (Eds.), The nature of remembering: Essays in honor of Robert G. Crowder (pp. 117-150). Washington, DC: American Psychological Association.

Cunningham, W. A., Preacher, K. J., & Banaji, M. R. (2001). Implicit attitude measures: Consistency, stability, and convergent validity. Psychological Science, 12, 163-170.

Edwards, A. L. (1957). Techniques of attitudes scale construction. New York: Appleton-Century-Crofts.

Egan, O., & Archer, P. (1985). The accuracy of teachers' ratings of ability: A regression model. American Educational Research Journal, 22, 25-34.

Greenwald, A. G., McGhee, D. E., & Schwartz, J. L. K. (1998). Measuring individual differences in cognition: The Implicit Association Test. Journal of Personality and Social Psychology, 74, 1464-1480.

Greenwald, A. G., & Nosek, B. A. (2001). Health of the Implicit Association Test at age 3. Zeitschrift fur Experimentelle Psychologie, 48, 85-93.

Knouse, S. B. (1989). Impression management and the letter of recommendation. In R. C. Giacalone 8.P. Rosenfeld (Eds.), Impression management in the organization. Hillsdale, NJ: Erlbaum.

Lambert, N., Leland, H., & Nihira, K. (1993). AAMR Adaptive Behavior Scale-School Edition (2nd ed.). Austin, TX: PRO-ED.

Landy, F. J., Shankster, L. J., & Kohler, S. S. (1994). Personnel selection and placement. In L. W. Porter and M. R. Rosenzweig (Eds.), Annual Review of Psychology, 45, 261-296.

Morreau, L. E., & Bruininks, R. H. (1991). Checklist of adaptive living skills. Chicago: Riverside.

Morrison, R. L. (1988). Structured interviews and rating scales. In A. S. Bellack & M. Hershon (Eds.), Behavioral assessment: A practical handbook (pp. 252-278). New York: Pergamon. Nihira, K., Leland, H., & Lambert, N. (1993). AAMR adaptive behavior scales-Residential and community (2nd ed.). Austin, TX: PRO-ED.

Saal,F. E., Downey, R. G., & Lahey, M. A. (1980). Rating the ratings: Assessing the psychometric quality of rating data. Psychological Bulletin, 88, 413-428.

Sparrow, S. S., Balla, D. A., & Cicchetti, D. V. (1984). Vineland adaptive behavior scales. Circle Pines, MN: American Guidance Service.

## 第12章 能力倾向测试

## 12.1 引 言

能力倾向测试通过选定任务中测量一个人的当前表现, 以此获取相关信息, 进而用于预测其在未来或在不同情形中的表现将会如何。我们能够预测的情况可能包括在校表现、工作业绩, 或应对人生挑战的情况。能力倾向测试和学业考试在测试任务方面有所不同, 但差异通常很小, 且属于技术差异。例如, 阅读理解或算术题都可能通过能力倾向测试和学业考试进行测量。一般来说, 能力倾向测试更侧重于一般生活经历, 学业考试更侧重于具体教学, 但是测试内容和过程方面的不同通常只是程度上的不同, 而非性质上的不同。这两种测试差异明显的一个方面在于其设计目的。 学业考试通常用于了解学生在过去的教学中有哪些收获或知识与技能水平的高低, 而能力倾向测试则用于预测被测试者在未来的表现如何。二者的关键区别更多在于测试目的和功能,而不是测试内容。

最早设计的能力倾向测试是用来评价一般认知能力的。能力倾向测试目前仍主要用于评价进行认知任务时的一般认知能力, 估计今后的情况还是这样。后来, 测试的重点有所转移, 人们开发出了许多针对某些专门能力的测试来确定被测试者更具体的优势 (及弱点)。

在本章中, 我们首先探讨几种有关认知能力本质的主要理论, 然后关注那些侧重于一般认知能力的测试, 即通常称之为 “智商测试” 的测试。在一般能力测试领域, 我们首先讨论那些由经过培训的考官进行的一对一测试, 接下来探讨为群体设计的测试。在下一章中, 我们将侧重探讨专业能力测试, 尤其是教学侧重的能力。

## 12.2 认知能力理论

早在许多世纪以前, 人们就已经认识到人类在认知能力方面存在个体差异。在 《理想国》中, 柏拉图认为人们的认知能力及其他特质是其社会地位的基础。到了 19 世纪后期, 英国哲学家赫伯特 - 斯宾塞认为一般认知能力 (他称之为智力) 是人类最重要的特征和自然选择的基础。20 世纪, 人们呼吁心理学研究者将他们的方法运用到与学校或心理缺陷有关的具有社会意义的问题上。正如我们在第一章中所见, 阿尔弗雷德・比奈 (Alfred Binet) 是最早提供实用测量设备的人之一 (详细说明参见 R. M. Thorndike, 1990a, 或 Rogers, 1995)。

## 1. 比奈理论

国际义务教育普及运动使许多教育工作者意识到儿童应分为两类: 一类是因为能力差而无法学习, 另一类是因为积极性差或其他原因而不愿学习。第一个被人们广泛认可的区分这两类儿童的测试是 1905 年在法国由阿尔弗雷德。比奈 (Alfred Binet) 和西奥多・西蒙 (Theodore Simon) 设计的。

比奈的理论其实算不上是心智能力理论, 但他认为随着年龄的增长认知能力也会提升, 就像体能一样。此外, 他认为, 智力是通过复杂的心理活动来表现的。因此, 他和西蒙设计的量表是由一系列智力 “谜题” 组成, 按照学生答题由易到难的顺序排列。在他们 1908 年的第二版设计中, 根据不同年龄段孩子的平均水平, 测试题目按不同年龄层次进行分组。每个年龄层次的谜题或任务有几类, 包括两词或三词的短时记忆游戏 (重复三个数字), 一些信息题目 (说出熟悉物体的名称), 以及一些需要推理的题目 (把打乱的词组成有意义的句子)。不同的年龄段可以使用不同难度的题目。

比奈一西蒙量表的目的是确定孩子的 “智力水平”, 或者现代术语所谓的年龄当量。然而比奈感兴趣的并不是按照标准来比较, 而是每个孩子到底能做什么。因此, 他坚持自己的智力水平理念, 反对将其改为 “心理年龄”。

虽然比奈被认为是现代智力测量的创始人, 但他并没有提出关于认知能力的任何理论。他的成果完全是靠实证经验得出的, 并没有任何理论作为。他认为, 智力是人类普遍具有的一个功能, 但他没有考虑它是如何组织或运行的。

1911, 比奈英年早逝。这一年, 他的第三版测试出版。同年, 德国心理学家威廉・斯特恩引入术语智力商数来表示一个孩子的智力与同龄人相比的等级。比奈显然不会同意这一做法, 但木已成舟。从此, “智商” IQ) 逐渐成为 20 世纪美国行话的一部分。正如我们第三章中有关规范的讨论, 智商这一词在指数描述方面不再有任何意义, 而且近些年来智商一词又获得了许多新的意义, 所以应该停止使用 “智商” 评定。然而, 智力一词仍然有实用意义, 所以我们将讨论智力测试, 而不是智商测试。 后者不存在。

## 2. 斯皮尔曼的 \( g \) 理论

最早的智力理论之一是由英国心理学家和统计学家查尔斯。斯皮尔曼 (Charles Spearman) 在 1904 年提出的。斯皮尔曼指出, 认知能力和学业成就之间存在正相关性, 于是他得出一个结论: 一种普遍的心智能力是存在的。他称这种能力为一般智力, 并认为一般智力在不同测试中的出现是认知能力和学业成就之间的正相关性的主要原因。1927 年斯皮尔曼公布了其发展成熟的双因素理论。斯皮尔曼认为心智能力包括两个因素:一般智力,他称作 \( g \) 因素,以及某个具体测试中的某种因素或能力,他称之为 \( s \) 因素。因此,根据这一理论,在一组测试分数中存在的个体差异可以用 \( g \) 因素和 \( s \) 因素中存在的个体差异来解释。其余的是测量误差。斯皮尔曼把 \( g \) 因素比作一个心理引擎, 它为心智力行为提供动力。我们也即将看到, 这个理论仍有很多追随者, 其中最出名的是阿瑟·延森 (Arthur Jensen, 1998)。 3. 瑟斯通的基本心理能力理论

在美国,斯皮尔曼的理论被认为是过于简单化。由 E. L. 桑代克及后来的 L. L. 瑟斯通 (L. L. Thurstone) 带头的一些心理学家认为人类智力有许多不同的维度, 这些维度在很大程度上相互独立。到了 20 世纪 30 年代, 瑟斯通用他开发的一种名叫共同因素分析的统计方法来确定这些维度。这方面的研究在 1938 年达到顶峰, 体现在他发表的描述基本心理能力的专著中。瑟斯通认为至少存在 11 种基本心理能力 (Thurstone, 1938 年)。

因素分析是找出哪些类型的测试互相相关, 从而属于同一个维度。例如, 要求语文能力的测试之间相关性较高, 而语文能力测试与数学能力测试之间的相关性则较低。同样, 数学能力测试之间的相关性要高于数学能力测试与语文或空间技能测试的相关性。如果我们把若干语文测试, 若干数学测试和若干空间测试放在一起用因素分析考察它们的相关性, 我们会发现一正如我们所期望的一一每一类测试都有一个对应的维度。因素分析能精确定量地描述出这些不同的维度。

瑟斯通认为, 这些常见的维度或因素是造成不同行为的原因, 类似于斯皮尔曼认为 \( g \) 因素是为行为提供动力的一个心理引擎。因此,虽然瑟斯通讨论了智力,但他认为智力是多面的。一个人可能在某一方面能力较强, 而在其他方面能力平常或较弱。然而, 瑟斯通指出, 这些因素似乎是呈正相关的。晚年时他开始接受智力分级的观点:一种类似于 \( g \) 因素一样的因子使基本因素互相关联,而基本因素使不同测试之间具有相关性。

斯皮尔曼和瑟斯通将智力理论分成两大类: 智力本质上是一种东西还是有许多方面? 他们的理论和许多后来的理论都是从不同测试关联度和测试内容的研究中发展而来的, 被称为心理测量理论或结构理论。如果一组测试都呈正相关关系, 则这些测试之间一定存在一个共同的深层原因。这个原因是通过考察这一组测试内容的相似点或者完成测试所要求的认知过程的相似点来确定的。例如, 如果我们在一组测试中发现其正相关联系, 而这些测试都要求快速执行相对简单的任务, 那么我们可以得出结论——有一种能力 (智力的某方面) 是通过执行的速度来体现的。

用这种方式定义智力的问题之一就是测试的选择决定了研究的领域。1920 年以前, 在最初的斯皮尔曼与桑代克的争论中就明确提出了这一点。若所研究的测试组合中的测试均来自大量不同领域 (斯皮尔曼的方法), 那么通常能够发现某种能力的一般因素。另一方面, 如果每个领域都包括若干测试 (桑代克的方法), 那么每个域都会出现一个代表因素。因此, 早期那些主要基于测试内容分析的理论并没有取得明显或令人满意的成效。

## 4. 延森理论和韦氏理论

当代两大智力理论或多或少是直接沿袭斯皮尔曼和桑代克/瑟斯通传统发展而来。其中的一个理论集中体现在亚瑟。延森的著作中, 它基于对执行复杂程度不同的动作所需反应时间进行研究, 并研究这些测试方法与不同测试组合中发现的第一个一般因素的关系。这项研究主要以实验室研究和智力测试的预测效度为研究中心。另外一个理论源于大卫。韦克斯勒 (David Wechsler) 的研究, 基于临床研究, 侧重于通过使用测试分数的类型来诊断认知问题。

(1)延森的理论

19 世纪 80 年代, 弗朗西斯 - 高尔顿爵士 (Sir Francis Galton) 认为完成简单的动作所需的反应时间可以用来衡量一个人智力高低。由于上述测试方法与学校成绩或其他智力行为没有多大联系, 所以人们将注意力转移到比奈当时正在开发的各种测试任务上。然而在 20 世纪 70 年代初由延森 (Jensen, 1982)、亨特 (Hunt, 1987), 以及其他人进行的一系列研究表明, 反应时间长短和完成复杂认知任务得分之间存在稳定的负相关关系。

电脑定时装置使研究人员能够记录实验对象对所受刺激所需反应时间的不同方面。一个典型的研究是让实验对象坐在控制台前, 台上有一系列反应按键, 呈弧状排列在主键周围。实验对象把一根手指放在主键上, 当按键灯亮时, 实验对象应尽快把手指放到亮灯的按键上。这是一个最简单的任务, 仅仅涉及反应而不包含任何决定, 除了灯亮时实验对象将手指从 \( \mathrm{A} \) 键移到 \( \mathrm{B} \) 键。更复杂的任务会要求实验对象根据灯的颜色去按不同按键。在这种情况下, 实验对象不仅需要做出反应, 还需要决定选择自己应做出哪种反应动作。第一类反应和第二类反应的时间差便是决策型任务所要求的认知处理时间。这类研究的结果通常是那些处理信息更快的人 (即反应时间短) 在标准智力测试中也可能取得更高分数。

延森的发现使得这些关于智力本质的理论结论非常有趣。他发现反应时间与他理解的斯皮尔曼的 \( g \) 因素在智力测试中是有联系的。延森在研究中发现,正是一系列智力测试的共同部分,也就是他认为近似于 \( g \) 因素的因子,导致了测试和反应时间之间存在的相关性。这使延森得出如下结论: 个体智力的不同存在生物学基础, 它在自然中非常普遍, 可以理解为大脑在处理信息效率上的个体差别 (Jensen, 1991, 1993)。延森 (Jense,1998) 最近出版了一本名为 \( \langle g \) 因素 \( \rangle \) 的著作,书中深入讨论了 \( g \) 因素的历史, 以及证明其重要性的研究。

能力测试的预测效度的研究进一步证明,一般认知能力的存在影响着人们在各种领域的表现。一些作者称, 大多数为就业或人才培养设计的认知能力测试的预测能力都包括在第一个或是最普遍的因素组合中 (Gottfredson, 1997; Herrnstein & Murray, 1994; Ree & Earles, 1992; Schmidt and Hunter, 1992)。

这个理论还处于基础研究阶段, 并没有得出任何新的实用智力测量方法。但是这个理论及其受到的回应引发了公开讨论, 主要涉及智力的本质是什么? 应该怎么合理应用智力测试? 我们将在本章末尾关于《钟形曲线》一书的讨论中提到上述争论的影响。

(2)韦氏理论

1939 年, 时任纽约贝尔维医院临床心理医生的大卫・韦克斯勒 (David Wechsler)。发表了一项名为韦氏一贝尔维的测试来测评成人患者的智力。该测试实际上是一系列的小测试, 其中大部分是一战期间军事测试题目中作为群体测试的阿尔法测试组合和贝塔测试组合。韦克斯勒将上述测试改成了针对个人的测试, 将其分为两种量表, 一种是由阿尔法测试改编的需要使用语言的测试, 另一种是由贝塔测试改编的不需要语言的测试。阿尔法测试有一个语言分数, 用来反映语言智商 (VIQ)。贝塔测试能得到一个操作智力 (PIQ), 最后由两个分量的总和得到全面的智力情况 (FSIQ)。韦氏认为这种全面的智力情况可以大致相当于 \( g \) 因素。波克 (Boake, 2002) 考察了韦氏一贝尔维测试从其一战前测试前身的演变历史, 他的研究表明韦克斯勒的贡献只是将已经存在的测试结合成一个测试组合, 而不是开发新的方法来评估认知能力。

斯皮尔曼会争辩说, 韦氏一贝尔维测试得到的全量智商 (FSIQ) 并没有衡量一般智力,而是衡量了他所谓的总智力。他把 \( g \) 因素定义为不同认知测试的共同点,但是这个共同点不同于在一系列不同的测试中得到的总分。后者只是将 \( g \) 因素与所有的具体因素及测量误差结合, 不具有任何明确意义。斯皮尔曼认为只有从所有测试中提取出一个共同因素, 并抛开所有的具体因素和误差才能衡量一般智力。出于同样的原因, 他反对比奈衡量一般智力的方法。

韦克斯勒 (Wechsler, 1944 年) 把智力定义为 “有目的地采取行动, 理性地思考, 并有效应对其周边环境的总能力” (第 3 页)。但是, 他的理论是由临床实践推动的。 因此, 分数中的规律具有临床意义, 可以用于诊断病症。经过多年的发展, 随着对测试成绩和分数规律的理解逐渐深入, 测试所蕴含的实际理论也变得复杂。韦氏理论可能是在这一学科内最具影响力的, 启发了成百上千的调查研究。他的理论主要体现在三种以他的名字命名的个人智力测试中。然而, 这只是临床理论, 只是如何最有效地使用测试成绩的相关指导, 而不是关于智力本质的科学性理论。考夫曼 (Kaufman,1990)用将近 700 页包含大量信息的篇幅讨论了韦氏成人版测试的应用, 他对韦氏儿童版测试也进行了类似的探讨 (Kaufman, 1994)。萨特勒 (Sattler, 2001) 全书九章中的六章都在探讨韦氏的智力测试。

## 5. 卡特尔一霍恩的流动一固定智力理论

1943 年, 雷蒙德・卡特尔 (Raymond Cattell) 首次提出将认知过程根据处理经验分为两大类。该理论沉睡了 20 年, 因为卡特尔随后专注于人格研究。1966 年, 约翰・霍恩 (John Horn) 联手卡特尔恢复了卡特尔对智力的研究。1966 年, 霍恩/卡特尔宣布发现流动智力是解决问题和处理信息的能力, 且在很大程度上不依赖于经验。 这种能力可以用于不同的认知活动并提升知识, 发展技能。将流动智力应用于生活而产生的这些能力, 卡特尔和霍恩将其称为固定智力。由于这两种能力都是广泛而全面的,它们所用的符号 \( {G}_{f} \) (一般流动智力) 和 \( {G}_{c} \) (一般固定智力)。使用大写字母将它们与斯皮尔曼的 \( g \) 因素区分开来。

多年来, 霍恩和他的同事们已经将与上述理论相关的能力扩大到 9 种。大多数能力仍是经过对测试组合的因子分析而确定的, 但能够覆盖的任务种类更多, 并且与以前的理论相比, 它们似乎更紧密地联系于生物过程。这 9 个因素如下:

\( {G}_{f} \) - 流动智力一在新的情况下进行推理的能力

\( {G}_{c} \) 一固定智力一一一般知识的广度和深度

\( {G}_{q} \) - 定量能力 - 理解和运用数字符号与概念的能力

\( {G}_{v} \) - 形象化处理 - 理解空间关系和图案的能力

\( {G}_{a} \) 一听觉处理一一辨别声音及识别声音的规律和联系的能力

\( {G}_{s} \) - 处理速度 - 快速作出决定 (反应时间) 并保持注意力

\( {G}_{sn} \) - 短时记忆一 在短时间内掌握并使用信息的能力

\( {G}_{lr} \) 一长期检索一将信息永久储存并回忆的能力

\( {CDS} \) - 快速正确决定一一迅速做出正确判断的能力

卡特尔-霍恩理论为两种最流行的认知能力测试提供了理论基础, 即斯坦福-比奈智力量表第五版和伍德科克-约翰逊认知能力测试。本章后文会进一步讨论这两种测试。这一理论逐渐影响了韦氏量表的发展。

## 6. 卡罗尔的三阶层理论

通过漫长的统计分析, 约翰・卡罗尔 (John Carroll, 1993) 对具有超过 400 个因子的能力研究进行了重新分析, 想找到其共同的主题。根据不同研究者的研究得出结论很困难, 其中一个难题就是研究者并没有就研究因素分析的合理方法达成共识。 此外, 研究通常无法进行合理比较, 因为缺少足够的共同变量。卡罗尔尝试过克服这些困难, 回到了最初的数据, 将同一种方法应用到所有的研究, 并尽可能地寻找对应的变量。其结果是类似于瑟斯通理论的一个层次模型, 在顶部 (阶层 III) 的是广泛的认知能力,一般智力或 \( g \) 因素; 第二层 (阶层 II) 是少量的与卡特尔一霍恩模式类似的一般能力因素; 最底层 (阶层 I ) 是大量相对具体的因素, 用于描述分类更细的测试表现的能力。最近, 卡罗尔和霍恩强调流动智力一固定智力理论和三阶层理论的相似性,并呼吁将其合并成卡特尔一霍恩一卡罗尔(CHC)理论。该理论是目前很多学校心理实践的基础。

## 7. 斯滕伯格的智力三元理论

从 20 世纪 70 年代开始, 罗伯特・斯滕伯格 (Robert Sternberg) 进行了一系列研究。他由此提出一个理论, 尝试将智力放在统一的社会、生理和心理测量的情境中考量。他称这个理论为智力三元理论, 因为它是由三个亚理论组成的 (Sternberg, 1985)。

第一个亚理论是情境亚理论。该理论认为不同情境下的行为都被认为是明智的。斯滕伯格认为智力的传统观点都是在学术环境中形成的, 重视信息的大量储备与抽象的推理能力。然而, 在非学术环境和其他文化中重视的行为和能力可能会大有不同。斯滕伯格已经进行了所谓的 “街头智慧”或 “实践智慧”等非学术适应性行为研究,并发现这些研究很大程度上独立于智力的传统测量分数。E. L. 桑代克于 1919 年就预料到了这一争论 (斯滕伯格的几个研究中存在的问题在于, 用大学生进行测试, 而大学生在智力水平上是比较相似的一个群体。这个问题将弱化斯滕伯格的实践智力测试和传统智力测试之间的明显关系)。

斯滕伯格体系中的第二个亚理论是经验亚理论。斯滕伯格认为, 智力的一个重要方面是行为自动化或常规化的能力。当人遇到新的情况时, 会应用认知资源解决由新情境所造成的问题。越聪明的人就能越迅速地解决这些问题, 把陌生转换成熟悉, 从而使用智力资源来处理其他问题。例如, 当一个人到达一座新的城市时, 他/她一开始要投入相当多的精力了解周围的地形和路况。斯滕伯格认为,一个人越聪明, 他/她就越能够迅速地得到周围区域的一张认知地图。与智力水平较低的人相比, 他/她也能更快地像本地人一样确定目的地的位置与方向。这样他/她就能将注意力和解决问题的能力用于其他新的经历。

第三个亚理论是组分亚理论。这个理论与延森和亨特考虑的问题类似, 因为其试图解释问题是如何解决与信息是如何处理的。

组分理论本身由三部分组成。其中第一项是表现组分, 涉及处理刺激因素, 在工作记忆中存放信息, 从长期记忆中检索信息及处理信息。获取知识组分的功能是通过有选择性地将表现要素应用于刺激因素来获得并储存新信息。元组分具有管理功能, 控制表现成分和获取知识成分来处理问题, 并确定何时问题已得到了圆满解决。

智力三元理论在作为模型来解释人类大脑的运作方面具有前景。但是, 那时理论没有发展出实际的智力评估程序。为了检验这个理论的元素, 人们设计了各种测试。然而, 除非这套程序有了可用的商业形式, 这个模型只能具有极弱的临床或诊断应用性。布罗迪 (Brody, 2003) 重新核查了斯滕伯格测试目前为止所产生的有用证据, 却发现极度缺乏此类证据。斯滕伯格 (Sternberg, 2003) 做出了相关回应。在同一期杂志上, 戈特弗雷德松 (Gottfredson, 2003) 对关于智力三元理论实际意义的许多声明提出了质疑。

## 8. 戴斯一那列里的 PASS 模型

另一种试图结合生理学和信息处理的理论是 J. P. 戴斯和杰克・那列里 (J. P. Das & Jack Naglier, 1994) 提出的 PASS 理论。该理论由 A. R. 卢里亚 (A. R. Luria) 提出的脑神经生理学模型发展而来, 这些作者把智力表现分为四个基本过程: 计划、 注意、同时性处理和继时性处理。该模型试图把这四个过程与具体的神经结构或区域——也就是卢里亚所称的功能系统——联系起来 (Das & Naglieri,2001)。

最基本的功能是注意。一个人必须注意到刺激因素才能处理它所包含的信息或解决它提出的问题。无法集中注意力被看作是智力表现差的原因之一。

一旦注意力集中到刺激因素上, 其包含的信息可能要求同时性处理或继时性处理。经过同时性处理的信息 “据说是可观测的, 因为元素是相互关联的, 并能接受检验”, 要么是直接检验, 要么是根据记忆的间接检验 (Das et al., 1994, 第 15 页)。同时性处理涉及语言理解及其他需要一次性理解整个问题的任务。每当任务的各要素必须以特定的顺序来执行时, 继时性处理便可发挥作用。完成技术性动作和刺激因素的序列回忆是继时性处理的具体实例。

模型的计划部分与斯滕伯格的元组分相似, 它参与决定何处集中注意力及任务需要何种处理类型。计划过程还包括监测问题是否成功解决, 以及根据需要修改解决方法, 直到问题得到解决。这四个过程在现有知识基础范围内运作。“知识积累可以看成是一个人储存在记忆中的经验累积的结果。因为所有流程都在知识背景下进行,而这种信息基础会影响所有的认知过程和运动程序” (Das et al., 1994, 第 19 页)。

## 9. 加德纳的提议

1983 年, 霍华德。加德纳 (Howard Gardner) 出版了一套关于人类组织能力的理论, 并称之为多元智力理论。加德纳 (Gardner, 1983) 确定了人类成就的七大领域, 人们可以在这些领域中观察到个体差异, 并把它们称为不同形式的 “智力”:

1. 语言一一文字才能

2. 逻辑一数学——根据视觉或数量材料进行抽象推理的能力

3. 音乐——熟悉音调和听觉材料

4. 空间一一观察和控制空间关系的能力

5. 身体一动觉一一协调大动作和精细动作的能力

6. 人际——处理与他人的关系和在社会环境中有效工作的能力

7. 内心一一自知之明。

我们之所以在这里讨论加德纳的理论, 是因为该理论广受欢迎并具有较大影响力, 特别是在教育圈, 但它至少存在两个问题。首先, 显然这些都是我们可以观察到人类行为个体差异的各个领域, 这些能力都或多或少具有一定重要性和价值。E. L. 桑代克在 1920 年就提出了抽象、机械、社会智力, 但人们的关注点一直在那些抽象的能力上, 因为它们具有社会价值。像加德纳这样, 广义地使用智力来指社会价值中不同的能力, 会使这个词失去意义。加德纳所说的智力和我们所用的不是一个意义, 就像我们指的认知能力一样。另一方面, 谁会对有关多能力的理论感兴趣呢?

加德纳理论存在的第二个问题是, 它不能产生有关这些能力的组织或这些能力相对重要性的经得起检验的假设。加德纳的确指出在不同的职业或活动中, 某种或某几种能力或许会具有特殊价值, 但这是再明显不过的事实。迄今为止, 很少有实质性的研究表明除循环论证之外, 这些能力还存在较多实际意义 (也就是说, 运动员运动能力强, 音乐家音乐能力强, 律师语言能力强, 等等)。

从实际操作来看, 加德纳的理论和智力三元理论一样, 缺乏可以用来评估个人的测试方法。与三元理论已经有大量调查研究作为其基础不同, 多元智力理论仍是一个抽象的模型。除非这个理论具备了研究基础和评价工具, 并证明其社会价值, 否则很大程度上它仍将缺乏科学性和实用性。

## 12.3 个人一般能力测试

正如我们前面提到的, 目前流行的智力测试很少是从某一个理论发展而来, 但大多数测试都受到了某种理论的影响。在本节中, 我们将介绍四种广泛使用的衡量认知能力的方法, 并简单地讨论几种其他方法。所有这些方法都是由受过训练的测试员设计来对个人进行测试的, 且多数情况下, 施试者测试期间的临床观察结果是评估报告的重要组成部分。我们在此章节中的讨论远远不够全面。萨特勒 (Sattler, 2001) 对大多数这些方法提供了更多细节, 同时还有更多其他方法。

## 1. 斯坦福-比奈智力量表第四版

## (1)早期的比奈智力量表

在比奈和西蒙所处的时期, 查尔斯。斯皮尔曼提出了一个对所有能力测试的发展都有指导作用的智力理论。斯皮尔曼提出, 存在一个普遍的智力功能, 他称之为一般智力或 \( g \) 因素,它影响着个人在认知能力测试中的表现。许多早期的测试,不是把这个想法作为其理论基础就是企图反驳这个有关一般智力的理论。比奈创立的智力量表, 以及按照其思想脉络开发的量表, 总体上与一般智力理论是一致的, 但正如前面提到的, 斯皮尔曼可能会称这些方法为总体智力测量法。

比奈一西蒙智力量表的若干改编版 1920 年前就已经在美国发表, 但流传下来的版本是由刘易斯・特曼 (Lewis Terman) 设计的。它出版于 1916 年, 被称为比奈一西蒙智力量表斯坦福修订版, 从那时开始它就被称为斯坦福一比奈智力量表、斯坦福一比奈量表, 或比奈量表。20 世纪 30 年代, 1916 年版的斯坦福一比奈量表进行了大量修订,并由此产生了两种形式的测试,即 \( \mathrm{L} \) 表和 \( \mathrm{M} \) 表。 1960 年,第三版 LM 表公布,包括 1937 年版中最好的测试题目。 1972 年, 新的标准规范得以制定, 但测试本身没有406改变。近 50 年里, 该测试第一个真正的修订版于 1986 年出版, 即斯坦福-比奈智力量表第四版 (R. L. Thorndike, Hagen, & Sattler, 1986a, 1986b)。稍后将讨论的第五版是在 2003 年发布的。

斯坦福一比奈智力量表的前三个版本最初是由特曼开发, 并由特曼和莫德·美林 (Maud Merrill) 修订。它们按照年龄层次划分, 每个年龄段包括六种不同的测试, 每个层次的测试内容也不同, 但所有的测试都包括图片任务、口语词汇任务、物体记忆任务、句子任务、数字任务、珠串视觉顺序任务、理解实际情况中应如何做的任务、类比任务、发现图片和文字的谬误、识别异同、解算数题、完成句子等任务。在斯坦福- 比奈智力量表第四版测试中, 测试题目按类型分组, 针对被测试者的词汇题目分为一组任务, 理解题目分为第二类独立任务, 不同类别的任务以此类推。该版测试保留了大部分原始题目类型, 也增加了一些新的题目类型。

在使用斯坦福一比奈量表前三个版本时, 考官通常从比考生目前年龄低一年左右的层次开始测试。如果考生通过了这一级的所有测试, 考官会继续下一个年龄段的测试, 依此类推, 直到达到 “顶层” - 所有任务都失败的年龄层次。如果一个或多个测试在初始层次就失败了, 那么考官会返回到 “基础” 年龄段, 也就是所有测试都能通过的最高年龄层次。然后考官继续测试以确定孩子的“顶层”。测试的结果只有一个分数, 用来表现受试者的一般能力。

心理年龄 (MA) 的计算方法是基础年龄加上通过的所有超过基础年龄测试所代表的心理年龄月数。在五岁或更低的年龄段测试中, 每一个测试代表一个月, 因为测试层次间的差量为半年。从 6 级到 14 级, 每通过一个测试代表 2 个月。高于 14 级时, 每通过一个测试所赋予的权重更大, “以便将高等级的智商与低年龄段相匹配” (Terman & Merrill, 1960, 第 62 页)。比如, 假设一个孩子通过了六岁阶段的所有测试, 七岁阶段的三个测试和八岁阶段的一个测试, 而超过八岁阶段的测试都失败了, 那么他的心理年龄计算方法如下:



<table><tr><td>测试表 我</td><td>心理年龄积分</td></tr><tr><td>基础年龄</td><td>6 岁零个月</td></tr><tr><td>6 个 7 岁测试中通过 3 个</td><td>6 个月</td></tr><tr><td>6 个 8 岁测试中通过 1 个</td><td>2 个月</td></tr><tr><td>6 个 9 岁测试中通过 0 个</td><td>零个月</td></tr><tr><td>心理年龄 \( = \)</td><td>6 岁 8 个月</td></tr></table>



认知能力的规范指数由心理年龄(MA)与生理年龄(CA)的关系得出,进而得到智商水平, 也就是 IQ。最初, 获得智商指数的方法是除法, 用心理年龄除以心理年龄。公式是:

\[\mathrm{{IQ}} = \left( {\mathrm{{MA}}/\mathrm{{CA}}}\right)  \times  {100}\]

测试的安排原则是每个年龄段平均心理年龄等于生理年龄, 该比率得到的平均值为 100 (因此产生了智商 100 只是普通智商的理念, 且标准差约为 16 (实际标准差约为 12-20 , 这取决于年龄)。智商比率是前两版测试使用的。然而从 1960 年修订版开始, 斯坦福一比奈智力量表得到的结果是标准分数, 调整之后得到相同的平均值 (100) 和标准差 (16), 也就是之前的智商比率。标准分数的使用使不同年龄获得的指数含义相同 (选定 100 和 16 是为了保持与之前做法的连续性)。标准分数所得到的数字量表和最初的智商比率是几乎相同的, 且优势是不同年龄之间具有一致性。这同时也避免了我们在第三章中指出的问题, 即当发展比率发生显著改变时, 年龄当量便毫无意义。

1986 年版斯坦福一比奈智力量表 (SB-IV) 在很大程度上避免使用智力商数或 IQ 这两个词, 而是用标准年龄分数 (SAS) 替换。这个词能更贴切地揭示该指数的实质, 而此术语用法的变化可能最终将消除一些多年来由智商一词衍生出来的外延意义。 然而, 标准年龄分数和智商数值度量基本上相同 (平均值为 100 , 标准差为 16)。斯坦福-比奈智力量表第五版 (SB5) 于 2003 年 (Roid, 2003) 出版后, 作者重新使用智商这一术语, 并稍微改变度量标准以符合韦氏量表。它的平均值为 100 , 标准差为 15 。在某个人所在年龄组中, 斯坦福-比奈智力量表和百分位等级之间的关系大概为:



<table><tr><td>斯坦福一比奈智商总量表</td><td>百分位等级</td></tr><tr><td>130</td><td>98</td></tr><tr><td>120</td><td>91</td></tr><tr><td>110</td><td>75</td></tr><tr><td>120</td><td>50</td></tr><tr><td>90</td><td>25</td></tr><tr><td>80</td><td>9</td></tr><tr><td>70</td><td>2</td></tr></table>



(2)斯坦福一比奈智力量表的组织

斯坦福一比奈智力量表第四版表明其已明显转离比奈和特曼的理论立场。 1986 年之前, 斯坦福一比奈智力量表只能得出一个一般智力的总得分。第四版建立在卡特尔和霍恩的流动智力一固定智力理论上, 共组织了十五个子测试来评估并得出四个领域或能力维度的分数。将测试词汇、理解、纠错和语言关系的测试相结合, 得到语言408推理分数。规律分析、抄写、矩阵、折纸和剪纸测试所得分数相加, 得到一个抽象/视觉推理分数。定量推理分数由数量、数字系列和建立方程组合而得。最后, 四个记忆测试得出短时记忆分数。口头推理和定量推理量表用来表示卡特尔一霍恩理论中的固定能力, 并可以结合起来给这种能力打分; 而抽象/视觉推理是一种流动能力。短时记忆得分是短时记忆 \( {G}_{sn} \) 的一个指标。把四个领域的分数相加得到的组合分数基本上等于早期斯坦福一比奈量表测定的一般智力维度。

在斯坦福-比奈智力量表第四版中, 为了使测试与被测试者的能力水平相匹配, 对测试做出了调整, 使其任务水平更符合他/她的能力水平。此次调整主要在于把词汇测试作为引导测试, 并结合生理年龄来判断受试者最有可能成功的难度水平。这样做是为了尽可能有效覆盖该考生的能力水平, 尽量减少在太简单或太复杂的题目上浪费的时间。

斯坦福一比奈智力量表第四版的实施在某种程度上比它前几版更加复杂。测试以词汇测试开始, 考官从略低于考生实际年龄的题目开始测试 (每个层次有两个题目, 儿童连续两个层次都完成了两个题目的层次点即为达到了基础层次)。考官会不断给出更难的题, 直到受试者在连续两个年龄层次的四道题目中失败三道或四道, 也就是达到了上限。在基础层次之上, 每完成一个题目加一分, 再加上基础层次以下所有题目分数, 就得到了词汇测试原始分数。词汇测试分数和该儿童年龄用来判断其余测试的起点。其他测试中, 找出基础层次和上限的方法与词汇测试相同 (关于如何实施之后测试的详细描述见 Sattler, 2001)。

每进行一项子测试都会有一个原始分数, 以证明被测试者通过了基础层次以下的较为简单的题目。每项子测试的原始分数会根据考官手册中的表格转换为该年龄层次的规范标准。个人子测试标准分的平均值为 50 , 标准差为 8 。结合上述因素, 得出四个领域的分数和所有子测试的复合分数。四个领域分数和总分数通常以标准年龄分数来表示一该年龄层次的正态标准分数, 其平均值是 100 , 标准差是 16 。

复合标准年龄分数与心理年龄及早期版本中斯坦福-比奈智力量表中的智商有许多相同的属性。但它也可以利用四个领域的分数: 文字推理、抽象/视觉推理、定量推理和短时记忆。上述领域的分数都彼此相关, 并有助于整体测量, 但彼此之间又有不同, 使得每个分数都能用于描述一个人的认知功能的不同方面。

虽然斯坦福一比奈量表的个人测试都很短, 但却相当可靠。某年龄组中个人测试的 KR-20 信度中位数为 \( {0.73} - {0.94} \) 。除物体记忆测试外 (它的层次比其他子测试少), 所有子测试的信度都超过 0.83 。若年龄组内各领域分数的信度越高, 基于四个领域分数得到的复合得分, 其 KR-20 信度通常就会超过 0.95 。

个人测试之间表现出中度至高度相关性。用标准化数据表示年龄组内相关性, 折纸、剪纸和物体记忆的相关性是 0.29 ; 词汇、理解的相关性是 0.73 , 而大部分的相关性处于 \( {0.3} - {0.5} \) 之间。一般情况下,同一个领域内的测试之间的相关性更高。同一个领域的分数关联度都在 0.6 和 0.7 之间, 这表明它们衡量的是有共同核心的离散概念。这些相关性与指导方法发展的理论是一致的。对斯坦福一比奈智力量表第四版中的标准化数据的独立分析 (Boyle,1989; R. M. Thorndike, 1990b) 证实, 单独测试之间通常彼此关联, 而这些联系与开发测试所用的理论所预测的是一致的。

## 2. 斯坦福-比奈智力量表第五版

2003 年 2 月, 斯坦福-比奈智力量表第五版 (SB5; Roid,2003) 公布。第五版和第四版之间有明显的继承关系, 但也有显著变化。该方法由五个因素得出总分, 而不是四个, 每个因素包括一个语言测试和一个非语言测试。还能得到四个额外的分数: 语言智商、非语言智商、全量智商以及一个简化智商量表。测试的安排和它们产生分数如表 12-1。

和斯坦福一比奈智力量表第四版一样, 斯坦福-比奈智力量表第五版使用一项引导测试过程来调节测试起点。引导测试由非语言流动推理测试和词汇测试组合成, 它们同时也构成该测试方法的简短形式。其它测试分为五个或六个级别, 考生测试起点由他们在常规测试中的分数决定。

(1)斯坦福一比奈智力量表第五版的子测试

如表 12-1 所示, 斯坦福-比奈智力量表第五版的子测试可分为两种: 语言类和非语言类, 或分别测试卡特尔一霍恩一卡罗尔理论中的五个因素。虽然大部分非语言测试不需要使用语言做出回应 (除了知识测试外, 所有回应可以用手指或其他动作来表示), 但考官口头给出指示, 所以测试实施过程需要语言理解能力。这和在本章后面介绍的真正的非语言测试一一例如通用非语言智力测试 (UNIT) 和非语言智力测试 (TONI) - 不同。



表 12-1 全量智商量表

<table><tr><td>非语言智商</td><td>因素指数 \( {}^{c} \)</td><td>语言智商。</td></tr><tr><td>流动性推理 (36 个题目) \( {}^{\mathrm{d}} \) 物体序列/矩阵</td><td>流动性推理</td><td>流动性推理 (5 个级别) 早期推理(2 - 3) 语言谬误 (4) 语言类比(5 - 6)</td></tr></table>

续表

<table><tr><td>非语言智商</td><td>因素指数</td><td>语言智商</td></tr><tr><td>知识 (5 个级别) 程序性知识 \( \left( {2 - 3\text{级}}\right) \) 图片找错 \( \left( {4 - 6\text{级}}\right) \)</td><td>知识</td><td>词汇(44 道题目) \( {}^{\mathrm{d}} \) 题目 15-44, 根据答案质量得 1-2 分</td></tr><tr><td>数量推理 (5 个级别) 每个级别有不同题目</td><td>定量推理</td><td>定量推理 (5 个级别) 每个级别有不同题目</td></tr><tr><td>视觉一空间处理 (6 个级别) 组合拼板 \( \left( {1 - 2\text{级}}\right) \) 规律分析 (3-6 级)</td><td>视觉一空间处理</td><td>视觉一空间处理 (5 个级别) 相对位置 \( \left( {2 - 3\text{级}}\right) \) 方向 \( \left( {4 - 6\text{级}}\right) \)</td></tr><tr><td>工作记忆 空间和数字顺序 (2---6 级)</td><td>工作记忆</td><td>工作记忆 词句记忆 \( \left( {2 - 3\text{级}}\right) \) 上一词记忆 \( \left( {4 - 6\text{级}}\right) \)</td></tr></table>



\( {}^{a} \) 全量智商是将语言智商和非语言智商的分级分数相加得到的结果。

\( {}^{b} \) 非语言和语言智商是将其所在列的子测试的分级分数相加得到的结果。

\( {}^{c} \) 五个因素指数由其所在行的两个分级分数相加而得。

两项引导测试没有划分层次。

(2) 语言子测试

词汇 (知识) - 两个引导测试之一。子测试包含 14 道看图词汇题目 (出示给考生某物体的照片, 要求考生说出所示图片中物体的名称), 到 10 岁层次每答对一个得 1 分。然后是 30 个定义题目, 一个确切的定义得两分, 说出使用方法或同义词得 1 分, 错误答案得 0 分。连续四次错误后测试停止。

早期推理/语言类比 (流动性推理, 五级) - 在第二级, 考生描述图片的内容 (根据答案的质量最多给 2 分)。第三级要求把三张图片上的物体分类 (根据类别数最多给 6 分)。第四级涉及语言找错 (“这个句子有什么错误或荒谬的地方” [根据答案的质量最多给 2 分])。第五、六级是双重类比,题目形式一般是 (? 对 \( \mathrm{X} \) 来说就像是 \( \mathrm{Y} \) 对? [最高每题 2 分])。在该测试及后续的语言测试中, 若考生在某一级的分数低于或等于两分, 则测试停止。

计数/算术/词语问题 (数量推理, 五级) - 测试题目包括计算图片中物体数量 (二级) 和解决字词问题, 如字词变换或说出某种物品的重量。

空间关系/几何形状 (视觉空间处理) - 一根据指示把方块放在图片上, 并表示第一个、最后一个、上方、下方和其他空间关系 (2-4 级); 用指向关系解决语言问题 (“往东走一千米, 然后左转, 步行一千米, 左转, 继续步行一千米, 此时的位置在起点的什么方向?)。答对一个得 1 分。

句子记忆/上一词记忆 (工作记忆, 5 级) - 重复有 2-11 个单词的句子 (2 和 3 级)。每个完整复述得 2 分, 出现一个错误得 1 分, 否则零分。对于 4-6 级, 考官问两个或多个难度递增的问题, 考生应回忆每个问题的最后一个词。以正确的顺序确切说出词语得 2 分, 说出一个词或顺序错误得 1 分, 否则为 0 分。

(3)非语言子测试

物体系列/矩阵 (流动性推理) - 这是一项引导测试。前 4 个题目 (年龄 2-4 岁) 包含形状匹配。考官会把一个物体 (如正方形) 展示给小孩子, 要求后者从 3 或 4 个选项中找出相同的一个来匹配。接下来考生必须从 5 个选项中找出一个符合逻辑序列的物体。紧接着就是像这样的 3 个简单矩阵题:







在 6 个物体系列题目之后, 题目 18-36 (13 岁及以上) 是难度递增的矩阵题目。 每一个正确的回答得 1 分, 四次连续失败后测试停止。

拼板/拼图案 (视觉/空间处理, 六级) - 在第一级的四个题目中需要把如图的几何图形组成一定形状。







第二级的 6 个题目包括把形状组合起来 (例如, 两个矩形拼成一个正方形) 来形成一定形状。二级以上的所有题目要求考生用几何图形匹配一张图片。一个简单的题目可能是这样的:







当考生在某一级别的非语言测试中得分为 2 分或更少时, 语言测试和后面的非语言测试都中止。两级以上的题目, 得到完全正确的图像得 2 分, 如果有一个小错误得 1 分, 否则为 0 分。

延时反应/方块跨度 (工作记忆, 六级) - 在这个子测试的第一级, 考官会把一个物体藏在杯子下面, 考生须找到物体在哪。在第二级及更高级别中, 越来越多的绿色木块 (最多 2 行 8 个) 被置于一张卡片上。考官以特定顺序敲木块, 而考生必须以相同的顺序敲击相同的木块。每一个正确的顺序得 1 分。

知识 / 图片找错 (程序性知识, 五级) 一一在前两个层次, 考生需要根据指示行事或者指出图片上物体的用途 (例如, 铅笔是用来画图或写字的)。在 4-6 级, 考生需要找出图片中的错误 (例如, 一辆有方向盘的自行车)。每一个正确的回答得 1 分。 称这种测试为非语言测试似乎有点怪异, 因为回答是口头形式的。

数量关系/计数/数列 (数量推理, 五级) - 2-4 级考生必须找出联系、计数, 并识别数字。5、6 级要求考生从 4 或 5 个选项中选择正确答案, 使其符合数列的数量规律。一个简单的非图片类题目就如 \( 4\text{、}9\text{、}{16}\text{、}{25}\text{、}\underline{?} \) (正确答案: 36)。每一个正确的回答得一分。

第五版和第四版的主要区别在于, 在引导测试后进行所有测试组合时, 先进行非语言测试再进行语言测试。一个更大的差异是回到早期比奈的风格, 也就是要完成一个级别的四种非语言题目后考生才能继续到下一级别。例如, 如果测试从第三级开始, 考生要在完成非语言知识、数量推理、视觉空间处理和工作记忆题目后才能进行第四级的非语言测试。非语言测试一直进行到考生达到非语言测试的上限。考生完成所有的非语言测试后, 再完成语言测试, 方法与之前相同。在我们的例子中, 考生要完成第三级的口头流动性推理、数量推理、视觉空间处理和工作记忆题目后再进行第 4 级的语言测试。在第四版中, 考生要完成子测试后才能进入下一个类型的题目。

传统比奈量表的另一个变化在于对一些题目的评分。最后 30 个词汇项和其他子测试中的一些题目得分为 0 分 (错误), 1 分 (符合但不完美) 和 2 分 (完全正确或显示更高的抽象水平)。韦氏量表 (见下文) 使用不同的计分方法, 但它和比奈量表不同。出版商的信度估算 (因素分数和智商测算信度约为 0.90 , 子测试信度约为 0.80 ) 表明, 让考官评判考生回答的质量不会影响测试的精确度, 部分原因可能是对考官高水平标准化的培训。实际使用的信度可能会更低。

新的比奈量表比以前适用于更广泛的年龄范围。测试标准适用于从年仅 24 个月的幼儿一直到 90 岁的老人的年龄范围。全国规范代表样本有 4800 人。 5 岁以前的标准量表年龄间隔为 2 个月, 5-16 岁标准量表时间间隔为 4 个月, 16 岁之后有较大的间隔, 但不会超过 5 年。这是对过去做法的一个相当大的改进, 因为过去针对孩子的标准间隔可能是半年或更长。在发育迅速的年龄段, 生日前后几天所得的标准年龄分数可能有好几分的差别。随着年龄范围的界定更为具体, 测试所得智商水平应该更精确。

出版商的研究表明, 第五版测量的认知能力构建类似于比奈早期版本和韦氏量表测量的认知能力。全量智商的相关性约为 0.80 , 比第四版子量表大于等于 0.64 的相关性更高, 它与同源韦氏智商的相关性大于或等于 0.66 。

新比奈量表中的一个较大变化是可以运用 “变化敏感分数”。在 1997 年的会议上, 一位作者呼吁测试出版商摒弃智商量表, 支持根据题目反应理论方法建立的量表 (参见 R. M. Thorndike, 1999)。E. L. 桑代克 1926 年做出了类似测试的原型, 但这个想法由于计算困难和根深蒂固的利益限制没有广泛使用。通过把基于题目反应理论的得分度量法引入九种测试分数的计算中, 比奈量表的出版商好像已经实现了一半的目标。然而, 他们也放弃了斯坦福一比奈智力量表的 “标准年龄得分” 并重新用智商来表示。这是令人遗憾之处, 因为正如我们在第三章了解到的, 智商要么没有意义, 要么意义被过度放大。

我们还要提到对第五版中的另一个保留意见。测试手册 (Roid,2003) 确定了 10 种量表的 “确认” 因素分析, 它们符合该测试宣称可以测量的 5 个要素指标的模型。 出版商引用这些发现来证明因素指数计分设计的效度。当我们完全复制出版商的分析方法, 就能够发现同样的结果。然而当我们使用限制较少的因素方法, 如卡罗尔 (Carroll,1993) 使用的方法, 试图重现五个同样的表现维度时, 我们只能够找到与语言维度和非语言维度对应的因素 (Thorndike,2003)。由于假设的五维结构只能用非常具体 (和重要的) 步骤复制, 使得我们开始怀疑五因素指标分数的效度。迪斯坦法诺和多明布鲁夫斯基 (Distafano & Dombrowski, 2006 年) 的标准化数据独立研究发现, 比奈-5 量表的子测试之间的相关性可以由一个总因素进行解释。我们不建议将该因素指数得分应用到实际工作上, 除非作者宣称的结构和解读得到独立确认。

## 3. 韦氏量表

另一个地位较高的个人一般能力测试就是韦氏系列, 其中第一版韦氏-贝尔维量表出版于 1939 年。该测试会定期进行扩展和修订。该系列目前有三个测试级别: 韦氏学前及幼儿智力量表第三版 (WPPSI-II ; Wechsler \( {}^{ \oplus  },{2002} \) 年)、韦氏儿童智力量表第四版 (WISC-IV; Wechsler, 2003 年) 和韦氏成人智力量表第三版 (WAIS-III; Wechsler, 1997) (在写这篇文章的同时, 韦氏成人智力量表 WAIS 第四版标准化测试已经完成。修改后的测试可能会在 2009 年夏季出版, 并与韦氏儿童智力量表 WISC 第四版具有相同的基本结构)。这些测试分别适用于 \( 2 - 6\left( {2\text{ 岁 }6\text{ 个月 }}\right) \) 到 \( 7 - 3 \) (7 岁三个月), 6-0 (6 岁) 到 16-11 (16 岁 11 个月), 16-0 (16 岁) 及以上年龄。量表最初由一系列子测试发展而来, 每个都有不同难度的题目。它们最初的设计是要得到两个子分数 (语言智商和操作智商) 及一个整体能力评分 (总量智商)。从 1991 年的韦氏儿童智力量表第三版开始, 测试已经经过修改, 使计算与卡特尔一霍恩一卡罗尔理论中的一些维度对应的所谓的 “指数分数” 成为可能。在韦氏儿童智力量表第四版中, 传统语言和操作智商已被废除。韦氏儿童智力量表第四版 (Wechsler, 2003) 测试中子测试的标题, 及其子量表的安排和图示题目 (类似实际测试中的题目) 显示如下。在实际测试情况下, 考官会提供更详细的说明。标有星号的子测试是补充测试, 用于更彻底考查的某特定领域或在一个测试操作实施错误时进行补充。韦氏儿童智力量表第四版和韦氏成人智力量表第三版的四个指标得分 (韦氏学前及幼儿智力量表第三版除外, 因其保留了语言和操作量表, 还有普通语言组合) 是由子测试的因素分析推导出的。这四个指标的分值在专业领域中引起了广泛讨论。所有韦氏测试的量表中常模组的平均值均设为 100 , 标准差设为 15 。 语言理解指数(VCI)

---

<!-- Footnote -->

① 所有韦氏测试都是由心理公司的工作人员编制。大卫・韦克斯勒 1981 年去世。一些以他的名字命名的测试甚至是他死后多年才开发的。

<!-- Footnote -->

---

① 相同点。羊毛和棉花哪些方面是相似的?

② 词汇。腐败是什么意思?

③ 理解。人们为什么买火灾保险?

④ * 信息。独立日是哪一天?

⑤ * 文字推理。孩子需要根据语言提示找出一个内在概念。

## 感知推理指数 (PRI)

⑥ 方块设计。使用我给你的四个方块, 做一个如图所示的一样的设计。







⑦ 图片概念。孩子识别有共同属性的物体 (例如, 哪些是花?)

⑧ 矩阵推理。类似斯坦福一比奈的矩阵题目

⑨ * 补充图片。我会给你看一些照片。每张照片都缺了一个重要部分, 告诉我缺少的部分是什么。







## 工作记忆指数 (WMI)

⑩ 数字跨度。我会说一些数字。仔细听, 当我说完后, 请按照我的顺序说出这些数字。

\( \begin{array}{llllll} 7 & 3 & 4 & 1 & 8 & 6 \end{array} \)

然后, 我会再说一些数字, 但这次我停下来时, 请反序说出数字。

\( \begin{array}{lllll} 3 & 8 & 4 & 1 & 6 \end{array} \)

⑪ 字母一数字排序。要求孩子识别字母和数字, 并对考官重复它们。

⑫ * 算术。如果 1 打鸡蛋卖 60 美分, 那么一个鸡蛋是多少钱?

## 处理速度指数 (PSI)

⑬代码。最上面一行中的每幅图对应着一个数字。在第二行中填写与各图对应的数字。



<table><tr><td>入</td><td>C</td><td>L</td><td>义</td><td>8</td></tr><tr><td>3 1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr></table>

<table><tr><td>试</td><td>▲</td><td>8</td><td>X</td><td>C</td><td>△</td><td>▱</td><td>  </td><td rowspan="2">等</td></tr><tr><td/><td/><td/><td/><td/><td/><td/><td/></tr></table>



⑭ 寻找形状。看 (左侧的) 这个形状, 再看 (右侧的) 这些形状。如果右侧的形状中有和左侧相同的, 请选择是, 如果没有, 请选择不是。

⑮ * 排除。儿童必须标出有相同属性的动物 (如标记所有的鸟)。

量表的每个子测试分别得出一个单独的分数, 然后根据一组与考生年龄相同的样本, 将分数被转换成正态标准分数, 其平均值为 10 , 标准差为 3 。子测试的标准分以四个不同的分组结合得出, 从而得到语言理解指数、知觉推理指数、工作记忆指数和处理速度指数的总成绩。指数得分被调整为平均值 100 和标准差 15 的分数。 个指标得分相加, 得到认知能力的总测量值, 其本质就是传统的全量智商。

韦氏量表个人子测试的折半信度一般是 0.80 左右。指数得分和全量智商 (FSIQ) 的信度都超过 0.90 。测试一重试信度略低, 但一般在 0.80 左右。大量证据表416明, 指数得分效度主要来自于标准化数据的因素分析。全量智商与其他认知能力的测量措施有实质联系。

## 4. 伍德科克-约翰逊心理-教育测试组合第三版

伍德科克-约翰逊心理教育测试组合第三版旨在同时衡量智商和学业成绩 (WJ-III; Woodcock, McGrew & Mather, 2001)。这个方法是直接从卡特尔一霍恩-卡罗尔模型发展而来并声称要测量该理论 9 个因素中的 8 个 (正确选择速度被省略)。和斯坦福一比奈量表一样, 伍德科克-约翰逊心理一教育测试组合第三版是所有年龄段都能使用的一个方法。该测试组合 (WJ-Ⅲ COG) 的认知部分包含 20 个子测试, 测试 7 个卡特尔一霍恩一卡罗尔理论 (CHC) 中各因素的影响, 而不同的年龄有数量不同的测试。数量能力是通过该测试组合的学业成绩部分 (WJ-III ACH) 完成的。一共有 22 个成绩测试来测试口语、阅读、数学、写作和一般知识。子测试及其测量的能力因素见表 12-2 。请注意测量固定智力 \( {G}_{c} \) 的测试包含在两部分中。



表 12-2 伍德科克一约翰逊能力和成绩子测试的因素分配

<table><tr><td colspan="4">认知测试组合</td><td colspan="3">成绩测试组合</td></tr><tr><td>一般功能</td><td>广泛因素</td><td>标准测 试组合</td><td>扩展测 试组合</td><td>广泛因素</td><td>标准测 试组合</td><td>扩展测 试组合</td></tr><tr><td>语言能力</td><td>语言理解/ 知识 \( \left( {G}_{c}\right) \)</td><td>语言理解</td><td>一般性知识</td><td>口语 \( \left( {G}_{c}\right) \)</td><td>故事回忆 (R)</td><td>看图识字</td></tr><tr><td/><td/><td/><td/><td/><td>理解指示 (R)</td><td>\( \square \) 语理解 (R)</td></tr><tr><td/><td/><td/><td/><td>知识 \( \left( {G}_{\mathrm{c}}\right) \)</td><td/><td>学术知识</td></tr><tr><td>思考能力</td><td>长期记忆 \( \left( {G}_{1r}\right) \)</td><td>视觉一听觉 学习</td><td>检索流利度 (T)</td><td/><td/><td/></tr><tr><td/><td/><td>视觉一听觉 学习 延 迟 (S)</td><td/><td/><td>故事回忆一 延迟 (S)</td><td/></tr><tr><td/><td>视觉一空间 思维 \( \left( {G}_{v}\right) \)</td><td>空间关系</td><td>图片识别</td><td/><td/><td/></tr><tr><td/><td>听觉处理 \( \left( {G}_{a}\right) \)</td><td>声音混合 (R)</td><td>听觉注意力 (R)</td><td/><td/><td>声音拼写(R) (S)</td></tr><tr><td/><td/><td>完成词语 (R) (S)</td><td/><td/><td/><td>声音意识(R) (S)</td></tr><tr><td/><td>流动性推理 \( \left( {G}_{f}\right) \)</td><td>概念形成</td><td>分析一合成 计划 (S)</td><td/><td/><td/></tr></table>

续表

<table><tr><td colspan="4">认知测试组合</td><td colspan="3">成绩测试组合</td></tr><tr><td>一般功能</td><td>广泛因素</td><td>标准测 试组合</td><td>扩展测 试组合</td><td>广泛因素</td><td>标准测 试组合</td><td>扩展测 试组合</td></tr><tr><td>认知效率</td><td>处理速度 \( \left( {G}_{s}\right) \)</td><td>视觉 匹 配 (T)</td><td>决策速度 (T)</td><td/><td/><td/></tr><tr><td/><td/><td/><td>快速图片命 名 (T) (S)</td><td/><td/><td/></tr><tr><td/><td/><td/><td>成 对 排 除 (T) (S)</td><td/><td/><td/></tr><tr><td/><td>短时记忆 \( \left( {G}_{sm}\right) \)</td><td>数 字 逆 序 (R)</td><td>词语记忆 (R)</td><td/><td/><td/></tr><tr><td/><td/><td>听觉工作记 忆 (R) (S)</td><td/><td/><td/><td/></tr><tr><td>阅读 \( \left( {G}_{rw}\right) \)</td><td/><td/><td/><td>基本阅读 能力</td><td>字 母 单 词 识别</td><td>词汇挑战</td></tr><tr><td/><td/><td/><td/><td>阅读流畅度</td><td>阅读流畅度 (T)</td><td/></tr><tr><td/><td/><td/><td/><td>阅读理解</td><td>段落理解</td><td>阅读词汇</td></tr><tr><td>写作 \( \left( {G}_{rv}\right) \)</td><td/><td/><td/><td>基本写作 技能</td><td>拼写</td><td>编辑</td></tr><tr><td/><td/><td/><td/><td>写作流畅度</td><td>写作流畅度 (T)</td><td>标点和大小 写的使用(S)</td></tr><tr><td/><td/><td/><td/><td>书面表达</td><td>写作样篇</td><td/></tr><tr><td>数学 \( \left( {G}_{q}\right) \)</td><td/><td/><td/><td>数学计算 能力</td><td>计算</td><td/></tr><tr><td/><td/><td/><td/><td>数学流畅度</td><td>数学流畅度 (T)</td><td/></tr><tr><td/><td/><td/><td/><td>数学推理</td><td>应用题</td><td>数量概念</td></tr></table>

注: \( \left( \mathrm{R}\right)  = \) 已记录, \( \left( \mathrm{s}\right)  = \) 补充测试, \( \left( \mathrm{T}\right)  = \) 已计时。



伍德科克-约翰逊心理一教育测试组合第三版的基本目标之一是根据单一样本提供一套综合能力倾向测试和成绩测试的测试方法, 这样能力倾向测试和成绩测试之间的差异可用于教育问题的诊断。测试都是根据大量的样本建立的, 年龄范围是 2-90 岁 (共 8800 多例)。这显然是在个人测试方面范围最广的尝试之一。

伍德科克-约翰逊心理一教育测试组合第三版的信度估计是相当令人满意的。个人子测试内部一致信度范围为 \( {0.76} - {0.97} \) ,中位数是 0.87 。卡特尔一霍恩一卡罗尔模型七个量表的信度是 0.81 -0.95 , 一般智力能力 (GIA) 标准测试组合的信度是 0.97 (拓展测试组合为 0.98), 一般智力能力与其他一般智力测试的相关性为 0.60 -0.70 。

## 5. 戴斯-纳列里认知评估系统

个人智力测试家族不断壮大, 最新的一个是戴斯-纳列里认知评估系统 (CAS), 旨在赋予认知功能的 PASS 模型以实际操作性。该方法包括测量模型中 4 大要素各要素的 3 项子测试 (共 12 项测试)。每个功能的两个子测试包括在基本测试组合中, 而标准测试组合中还增加了一项。测试及其安排情况如下 (每个功能的前两项测试包含在基本测试组合中)。

## 计划

匹配数字——考生在每行相同的两个数字下划线。

有规律的代码——类似于韦氏儿童智力量表第四版的代码子测试。

有规律的连线——考生根据一定顺序将数字和字母或数字和数字连线。

## 专注力

表达性专注力——考生在有干扰的情况下识别文字或图片 (例如, “红色”一词打印为蓝色)。

数字检测——考生必须在有某项特点的数字上画圈 (例如, 加粗的数字), 而不能在没有该特点的数字上画圈。

接受性专注力——考生必须将有共同特征的成对字母圈出来 (要么外形特点一致 \( \left\lbrack  \mathrm{{KK}}\right\rbrack \) 而不是 \( \mathrm{{KP}}\rbrack \) ,要么词汇特点一致 \( \left\lbrack  \mathrm{{Aa}}\right\rbrack \) 向不是 \( \mathrm{{Ab}}\rbrack \) )。

## 同时性处理

非语言矩阵一一类似瑞文 (Raven) 的渐进矩阵 (见下文)。

语言一空间关系一考生将图片和它的文字描述匹配。

图形记忆一看到一个几何图形后, 考生必须在一个更复杂的几何图案中找出它。

## 继时性处理

词语序列——类似于韦氏儿童智力量表第四版的数字跨度子测试, 但此处使用单音节词而不是数字。

句子复述一考官读出一些句子, 句子的某些词类用颜色代替 (例如, “黑色正在将绿色涂成蓝色”)。考生必须精确重复这句话。

句子问题——考生必须回答根据“句子复述”部分类似句子提出的问题 (例如, “谁被涂成了蓝色?”答: 绿色)。八岁以下的考生还有一项语速测试。考生必须重复十遍一句有三个词的句子。

有六个子测试需要精确计时, 原因要么是为了给出题干, 要么是为了计算反应速度。有好几个测试的分数是按秒计的。

对于个人子测试, 量表分数的基础是 1100 个男孩和 1100 个女孩的标准样本, 其年龄都在 5-17 岁之间, 平均年龄为 10 岁, 标准差为 3 。全量智商量表分数的平均值是 100 , 标准差是 15 。测试作者指出这 12 项子测试的内部一致性信度为 0.75 到 0.89 之间, 中位数为 0.82 。四个量表的信度介于 0.88 和 0.93 之间, 全量智商量表的信度大概是 0.96 。子测试 21 天左右后再测试, 其信度平均值为 0.73 , 而全量智商量表的信度平均值为 0.82 。戴斯和纳列里 (Das & Naglieri,2001) 给出了一个例子, 说明了戴斯-纳列里认知评估系统如何用于诊断学习障碍。

查阅《心理测量年鉴》会发现还有其他设计优良的个人认知能力测试。考夫曼儿童评估测试组合第一版得到了广泛使用, 其第二版 (KABC-Ⅱ) 可能会更受欢迎。正如戴斯和纳列里的戴斯一纳列里认知评估系统一样, 该测试的最初目的是评估同时性和继时性处理情况。该测试设计优良, 在某些应用情况中可作为比奈量表或韦氏量表的合理替代测试。

## 6. 认知能力的非语言性测量

从最早的测试方式的发展开始, 语言在智力测试中的重要性就已经得到关注。 第一次世界大战前, 波狄厄斯 (Porteus) 就设计了一系列的视觉迷宫测试题来测试认知能力, 不涉及使用语言。一战期间, 美军的心理学家设计了一系列非语言测试, 用于不能阅读或英语水平不高的新兵。韦氏在其测试量表中包括了源于这些军队测试的子测试。在本节中, 我们会描述三种无须使用语言的测试: 其中两个的使用已久经证实, 另一个是近期发明的。我们在《在印测试》中还可找到其他几种非语言智力测试。

(1)瑞文的推理矩阵

此测试的最初版本是 J. C. 瑞文 (J. C. Raven) 在 1938 年发表的。它用于衡量斯皮尔曼智力理论所暗指的更高水平的能力。也就是说该试验的目的在于 \( g \) 因素的测量。延森 (Jensen,1998) 认为瑞文的测试几乎纯粹是在测量 \( g \) 因素,以致在许多测试组合的因素分析中,此测试被用来标记 \( g \) 因素。因为它是不计时考试 (考生想花多少时间都可以), 所以它实际上是一个能力测试, 用来评估个人可达到的最高级别, 而不是看一个人解决问题的速度快慢。所有题目都以矩阵格式呈现, 并且测试是渐进的, 即题目越来越难, 考试进行到后面考生要从多达八个选项中选出正确答案。

在最简单的一级, 测试题目主要考查发现规律的能力。考题会展示一张图, 图中缺一部分, 而考生的任务就是找到符合项。这类题目可能是这样的:420







矩阵题型的基本格式就是题干呈二维安排, 题干特征存在两个或多个变化规律。 斯坦福-比奈第 388 页展示了一个简单的矩阵子测试题, 其题干要素的两个特征一个按行改变, 另一个按列改变。在更复杂的题目中, 题干要素可能有三到五个特点沿着行、列、对角线或圆周改变。这类题目可能是这样的:







瑞文的渐进矩阵常模还没有根据美国代表性样本进行系统的样本测试, 且由于测试只能得到一个总认知能力分数, 它在一般的筛选和研究应用中更实用, 而非在临床诊断中。信度估计值一般介于 0.80 和 0.90 , 但结果会随着测试群组的不同而发生改变。

(2)非语言智力测试 (TONI)

非语言智力测试 (TONI) 现已是第三版 (TONI-3 [Brown, sherbenou, & Johnson, 1997])。它首次出版于 1982 年, 目的是提供一个不需要使用语言的规范测试。该测试日前有两种形式, 每种形式里有 45 道题目。所有题目都类似于瑞文的渐进矩阵。指令通过手势给出, 测试能够为 6 岁 0 个月至 89 岁 11 个月的人提供标准的总体能力得分。题目根据难度排序, 若五个连续题目中错了三个, 则测试停止。常模根据地域、性别、社会类型、种族、残障状况和社会经济地位分层。在不同年龄组中 \( \alpha \) 系数信度为 \( {0.89} - {0.97} \) 。同组的类似形式信度为 \( {0.74} - {0.95} \) 。正如我们预期的, 非语言智力测试 (TONI) 与语言智商 (VIQ) 的相关性较低 (约为 0.55 ), 而与韦氏操作智力 (PIQ) 相关性较高 (约为 0.75 )。作者认为, 该测试适用于有阅读障碍、注意力缺乏症/注意力缺陷多动障碍 (ADD /ADHD)、听力丧失、学习障碍和情绪障碍及不会英语的考生。想了解更多信息, 请访问该测试出版商的网站 http://www.proedinc.com。 (3)通用非语言智力测试

1998 年, 布鲁斯・布拉肯 (Bruce Bracken) 和史蒂夫 - 麦卡勒姆 (Steve McCallum) 推出通用非语言智力测试 (UNIT) 来 “公平测试 5-17 岁儿童和青少年的一般智力和认知能力, 因为传统的依赖语言进行测试的方法可能会对其结果有不利影响 "(第 1 页)。该测试包括六个子测试, 其中的三个要利用记忆过程, 另外三个需要运用推理过程。子测试根据内容进一步划分为符号性或非符号性测试。六个测试分类如下:



<table><tr><td/><td>推理子测试</td><td>记忆子测试</td></tr><tr><td>符号子测试</td><td>类比推理</td><td>符号记忆 物体记忆</td></tr><tr><td>非符号子测试</td><td>方块设计 迷宫</td><td>空间记忆</td></tr></table>



该测试的双重分类得到五个可能的分数。但遗憾的是, 作者称之为商数; 即记忆商数 (本质上是卡特尔一霍恩一卡罗尔模型中的短时记忆因素)、推理商数、符号商数、 非符号商数和全量智商商数。作者认为, 此类测试有多种多样的临床应用, 包括有听力障碍的人, 来自于非主流文化的人, 以及英语能力有限的人。测试所有指令都通过手势给出, 考生通过手指或操作物体来做出回应。由于测试的题干和过程对考生来说是陌生的, 所以每个题目都提供了例练习题。各种子测试的一般题目形式如下:

① 符号记忆。每个考生有 10 张小卡片。每张小卡片上都有用国际符号表示的男人、女人、男孩、女孩或婴儿,颜色为黑色或绿色。然后考生会拿到一张卡片,上面有一个或多个 (最多 6 个) 以特定顺序排列的图案, 考生有 5 秒时间看卡片。题卡被拿掉后, 考生应根据手势按照原顺序对卡片进行排序。

② 立方体设计。考生最多会拿到 9 个立方体, 每个立方体有两个白色的面, 两个绿色的面, 以及两个在对角线方向上的白色和绿色的面。考生应在看到题卡后按照批示重现题卡上展示的设计。这个测试和韦氏儿童智力量表第三版的方块设计之间的差别在于, 这个测试中的设计可能是三维的。

③ 空间记忆。考生会拿到 16 个薄片,8 个黑 8 个绿,还有一个,要么是 \( 3 \times  3 \) (题目 1-11) 或 \( 4 \times  4 \) (题目 12-27) 规格的答题方格卡。题卡展示 5 秒后被撤回。片卡撤走后, 考生应立即把正确颜色的薄片放在网格的正确位置上, 重现卡片上的图案。

④ 类比推理。这个测试包括矩阵题目, 类似于瑞文的渐进矩阵测试。共有 31 题。

⑤ 物体记忆。考官把有包含 1-7 个物体的图片展示给考生看 5 秒。图片被撤走后, 考官拿出另一张图片, 其上的物体和第一张相同, 但是会增加一些物体。考生应把薄片摆在第一次出现过的物体图片。

⑥ 迷宫。这和报纸或杂志上常见的益智题很相似。考生拿到一张迷宫的图片, 图片中有一只老鼠在迷宫中央, 迷宫外有一块或多块奶酪。考生的任务就是找到一条路线, 使老鼠可以吃到奶酪, 且设计的路线不能够跨越迷宫的分隔线。

通用非语言智力测试 (UNIT) 是根据全美国 2100 名年龄在 5 岁 0 个月和 17 岁 11 个月之间的样本设定的常模。此常模组适合于简易组合测试, 包括适用于筛选的符号记忆和立方体设计子测试 (仅产生全量智商结界); 标准测试组合在简易测试组合基础上增加了空间记忆和类比推理, 并能为五种测试提供分数; 拓展测试组合包括所有六种测试。根据测试手册, 各子测试中各年龄段内部的平均信度为 0.64 (迷宫) 至 0.91 (立方体设计), 简易测试组合的全量智商信度为 0.91 , 标准测试组合的信度为 0.87 (符号智商) 至 0.94 (全量智商), 拓展测试组合的信度为 0.88 (推理智商) 至 0.93 (全量智商)。临床样本的信度更高。一般来说, 通用非语言智力测试 (UNIT) 量表与由韦氏儿童智力量表第三版所得不同成绩有相关性, 比如两种方式的全量表智商的相关性为 0.88 。

## 7. 简易个人测试

使用个人能力倾向测试的一大问题在于其成本非常高。对于每一个考生, 一个训练有素的考官至少要花一个小时。对昂贵的成本存在三种回应: 第一种是在下一节会提到的逐渐开始开发的群组测试; 第二种是仅使用标准测试中的一部分测试 (请注意斯坦福一比奈智力量表第五版、戴斯一纳列里认知评估系统、通用非语言智力测试和伍德科克一约翰逊心理教育测试组合第三版中有基本测试和扩展的测试选项); 第三种就是编制一些简易个人测试。

不少人提出了韦氏量表的各种简易形式。萨特勒 (Sattler, 2001) 提供一系列图表, 列出了已被用于特殊情况的子测试, 并讨论了合理的测试方式和解读程序。对于较简易的测试组合, 分数只应解释为说明全量智商量表。

语言测试与广泛的智力能力测量都有高度相关性的事实, 引起有关专家开始研发完全以语言材料为基础的各种简短测试。一种特别受欢迎的类型是看图识字测试, 因为孩子们对这种形式非常感兴趣。皮博迪 (Peabody) 看图识字测试第三版 (PPVT-III; Dunn & Dunn, 1997 年) 可能是看图识字测试中最有名的。这两种形式的测试中每个形式的测试都有 204 张图板 (17 个层次, 每个有 12 项)。每块板包含四张图片。考官给出一个词, 考生指出与这个词有关的图片。该测试大约需要 10--- 15 分钟, 可表明考生的一般语言能力。要了解对其他测试的讨论, 请参见萨特勒 (Sattler, 2001)。

考夫曼和考夫曼 (Kaufman & Kaufman, 2001) 强烈反对使用完整测试的简易版本, 而支持最近公布的三种简易测试: 考夫曼简易智力测试 (K-BIT), 韦氏简易智力量表 (WASI), 以及广域智力测试 (WRIT)。考夫曼和考夫曼认为, 现有测试简易版的问题在于其不恰当或不充分的标准规范。在大多数情况下, 简易版测试是从完整版测试中选取的一些子测试, 但是评价标准却是使用完整版标准。当单独考察子测试, 而不是把子测试放在整个测试组合中看待时, 材料难度降低了, 导致认知能力的较高假性估测。考夫曼和考夫曼综述的简易测试是根据完整的简易测试制定标准规范的, 因此测试标准不会被曲解。这三种简易测试的合理使用范围是从童年 (约 5 岁) 到老年期 (约 85 岁)。

考夫曼和考夫曼 (Kaufman & Kaufman, 2001) 对于缩略版测试的批评可能并不适用于斯坦福一比奈智力量表第五版的缩略版本, 因为这两个测试都是在测试开始时作为引导测试进行的。因此, 考生总会完成简易测试, 而其他的测试则依附于它, 这样便反驳了上述认为简易测试形式脱离了大环境的批评。简易测试的规范制定和整个测试规范制定的过程是一样的。

考夫曼简易智力测试 (Kaufman & Kaufman, 1990) 使用了两个子测试: 测试语言能力的词汇测试和测试非语言能力的矩阵测试。该考试的实施时间为 15---30 分钟。韦氏简易智力量表 (The Psychological Corporation, 1999) 有两个版本, 简易版本包括词汇和矩阵推理来衡量语言和非语言能力, 完成大约需要 15 分钟, 较长的版本增加了相似性 (语言) 和方块设计 (非语言) 子测试, 耗时约 30 分钟。四个子测试与完整韦氏测试组合类似。广域智力测试 (Glutting, Adams, & Sheslow, 2000) 耗时 30 分钟左右, 包括四个子测试: 两个非语言类 (矩阵和方块设计) 测试和两个语言类 (词汇和类比) 测试。所有三个测试得出一般认知能力分数, 其信度超过 0.90 。这三个测试都适用于快速筛查和研究应用, 但不适合全面的认知诊断。

## 12.4 群组一般能力测试

在考官经过充足培训后, 进行一对一测试有一定的好处。考生不需要阅读, 所以年龄小的孩子和文盲都可以进行测试。同时, 一个有洞察力的考官可以使考生保持对测试的热情与动力。此外, 考官可以观察考生在测试过程中的表现, 从而做出诊断, 这一点在分数中反映不出来。但是, 不同的考官介绍任务的方式和对考生回答的评价可能不同, 从而会导致一些误差。与考官面对面可能会使某些考生无法说出他们原本知道的答案, 而最关键的一点是个人测试非常昂贵。若学校要了解每个孩子, 或者教育机构或培训项目要了解它们所有的申请者, 它们是不愿选择这种测试方式的。出于成本的考虑, 大部分能力测试已经成为团体测试, 使用铅笔填涂或计算机手段实施测试且可对测试进行客观判分 (即使测试并不属于计算机适应性测试, 它也可通过计算机实施)。

一系列测试已经运用于教育环境中。三个使用比较广泛的系列是由麦格劳一希尔和加州考试局 (CTB) 编写的认知能力测试, 由美国心理公司发布的奥的斯一列侬学习能力测试, 以及由教育测试服务局和加州考试局/麦格劳-希尔编制的大中小学能力测试。但是,我们将把这一类测试与我们熟悉的认知能力测试 (CogAT) 结合起来说明。和许多群组一般能力测试一样, 这些测试都能得到多个分数, 包括一个口语表达能力分、一个数量能力分及非语言能力分。此外, 测试还将得到一个整体能力分, 称为标准年龄得分 (SAS)。这些测试的最新版本 (Lohman & Hagen, 2003) 包括九个子测试。每个子测试中的示例题目请见图 12-1、12-2 和 12-3。



词汇

表示不礼貌的词语:

A. 不高兴的 B. 生气的 C. 不诚实的 D. 粗鲁的 E. 健谈的

句子填空

马克非常喜欢他的科学课老师, 但他不_____他的数学老师。

A. 遵从 B. 讨论 C. 在乎 D. 渴望 E. 喜欢

词语分类

鸽子、老鹰、鹪莺、麻雀

A. 飞蛾 B. 蝙蝠 C. 海鸥 D. 蜜蜂 E. 松鼠

语言类比

豌豆对豆子来说就像桃子对_____

A. 坑 B. 树 C. 吃 D. 皮肤 E. 苹果



图 12-1 与认知能力测试类似的语言类测试题目样题



<table><tr><td>数量比较 1. 4 个 10 美分 II. 5 个 5 类分</td><td>如果 \( \mathrm{I} \) 比 \( \mathrm{{II}} \) 的钱多,选 \( \mathrm{A} \) 如果 I 比 II 的钱少, 选 B 如果两项钱数一样多, 选 C</td></tr><tr><td>数列 \( \begin{array}{lllll} {18} & {16} & {14} & {12} & {10} \end{array} \) A. 7 B. 8 C. 9 D. 10 E. 12</td><td/></tr><tr><td>完成等式 \( {189} +  - \) A. 0 B. 3 C. 8 D. 9 E. 18</td><td/></tr></table>



图 12-2 类似于认知能力测试中的数量题样题





图 12-3 与认知能力测试中的题目类似的非语言类试题样题



上述测试有多层次的组织形式, 印在一本小册子上, 涵盖从 3-12 年级不同的年龄段 (也有初级水平测试, 适合幼儿园到三年级。出版商会根据用户的要求, 提供仅含有某一级别考试的小册子)。这本小册子的设计使考生可以任意选择八个难度之一进行测试, 这取决于考生从哪一级开始做及在哪一级停止。此处说明的模式是语言类比子测试的, 其他的子测试也有类似的模式。注意这个子测试两个相邻级别有 20 个共同项。所有测试都遵循这个重叠模式, 但重复题目的数量取决于子测试的长度 (36、48 或 60 道题)。



<table><tr><td colspan="4">认知能力测试语言类比子测试中的题目范围模式</td></tr><tr><td>级别</td><td>起项</td><td>止项</td><td>一般年级</td></tr><tr><td>A</td><td>1</td><td>25</td><td>3</td></tr><tr><td>B</td><td>6</td><td>30</td><td>4</td></tr><tr><td>C</td><td>11</td><td>35</td><td>5</td></tr><tr><td>D</td><td>16</td><td>40</td><td>6</td></tr><tr><td>E</td><td>21</td><td>45</td><td>7</td></tr><tr><td>F</td><td>26</td><td>50</td><td>\( 8 - 9 \)</td></tr><tr><td>G</td><td>31</td><td>55</td><td>10 — 11</td></tr><tr><td>\( \mathrm{H} \)</td><td>36</td><td>60</td><td>12 +</td></tr></table>



所有答案写在一张单独的答卷上, 此外每个级别另有一张答卷, 答卷上只留这一级别要答问题的空间。测试的内容会越来越难, 所以测试的班级或个人可以灵活地选择一个难度水平。因此, 对于位于贫困社区的学校来说, 使用简单级别的测试所得到的结果可能会更准确,比如六年级学生可能会做 \( \mathrm{C} \) 级测试,而不是 \( \mathrm{D} \) 级测试。测试的难度跟考生的水平越接近, 测试结果就越准确。

如图 8-3 所示的任务类型, 非阅读性的群组测试也可以编制。对于非常年幼的儿童, 有必要避免要求他们进行阅读。同时, 我们需要密切注意孩子的进度, 以确保他们尝试解决问题, 并且解决的是正确的任务。对幼儿进行群组测试仍是值得质疑的, 但他们在学校学习了一段时间并已经习惯下面提到的一些指示后可以参加此考试。

认知能力初级测试有两个级别, 借此向下拓展多级别的范围。这些级别适用于幼儿园后期到三年级范围。在大多数情况下, 考官会大声读出每个题目说明, 朗读的速度会让每个孩子都有时间在测试册上做出回答。在上述水平层次, 测试不适用于独立答卷, 并且测试只包括两个语言类、两个数量类和两个非语言类测试。图 12-4 中有一些题目类型的说明。







图 12-4 与认知能力测试 (初级) 类似的题目



认知能力测试能得到三个独立的分数: 语言、数量和非语言。如同所有的个人测试, 虽然这些分数代表不同维度的个体差异, 但它们是相关的。事实上, 三个分数之间的相关性相当高, 平均约为 0.70。因此, 虽然每个测试衡量的因素不同, 但三个分数都有相当多的共同点; 这种共性可以被认为是一般认知能力因素。

在这一点上, 我们可以查看认知能力测试的九个子测试因素分析结果, 从而得到更清楚的说明。结果如表 12-3 中所示。一个因素可以理解为一个测试与一个潜在维度的联系。在表 12-3 中, 为了简化图像, 小于 0.10 的值被省略, 因为这样的值可以忽略不计。



表 12-3 认知能力测试多级别测试组合各因素的中值

<table><tr><td>子测试</td><td>总体</td><td>语言</td><td>数量</td><td>非语言</td></tr><tr><td>语言分类</td><td>0.71</td><td>0.48</td><td/><td/></tr><tr><td>句子填空</td><td>0.72</td><td>0.48</td><td/><td/></tr><tr><td>语言类比</td><td>0.72</td><td>0.42</td><td/><td/></tr><tr><td>数量关系</td><td>0.82</td><td/><td>0.14</td><td/></tr><tr><td>数列</td><td>0.81</td><td/><td>0.16</td><td/></tr><tr><td>建立等式</td><td>0.71</td><td/><td>0.18</td><td/></tr><tr><td>图形分类</td><td>0.72</td><td/><td/><td>0.30</td></tr><tr><td>图形类比</td><td>0.77</td><td/><td colspan="2">0.34</td></tr><tr><td>图形分析</td><td>0.62</td><td/><td colspan="2">0.36</td></tr></table>



在这个因素分析中出现的规律是相当清楚的。对于每一项子测试来说, 主要的负荷量在所有测试共有的一般因素上。此外, 中等大小的语言因素出现在所有的语言类测试中, 而一个较小的图形形象化因素出现在非语言类的子测试中。数量测试并没能找到一个数量因素; 它们的负荷量往往在一般能力因素上。而且, 九项子测试中, 每项都涉及该测试独有的能力 (特定因子) 元素, 它们的性质不能通过因子分析来了解。

接下来你可能会提出一个问题, “认知能力测试的效度在多大程度上归因于一般能力的因素, 又在多大程度上归因于不那么广泛的因素 (比如语言和空间因素) 呢?” 通过分析一个大型郊区学校的数据可以得到部分答案。针对此学校的五、七、九年级进行了认知能力测试, 可以将九年级某特定科目老师给出的成绩与该年级此次测试平均分数相比较。基于 4300 个案例的部分结果如表 12-4 所示。在此表中, 通常语言分数和数量分数这两类有较高的相关性, 非语言分数相关性较差, 三者中排名第三。这样的结果是在预料之中的, 因为教育在很大程度上依赖于文字和数字的符号系统。但应该注意的是, 相关性最高的几乎普遍是三个分数之和。这样简单相加能够有效衡量三个测试中共同具备的一般因素, 但正如我们前面所指出的, 它混淆了斯皮尔曼理论中的一般、具体和误差成分。



表 12-4 五、七、九年级认知能力测试分数与九年级课程分数的相关度

<table><tr><td colspan="7">九年级课程</td></tr><tr><td colspan="2">认知能力测试分数</td><td>英语</td><td>社会研究</td><td>数学</td><td>科学</td><td>总成绩</td></tr><tr><td rowspan="4">五年级</td><td>V</td><td>0.46</td><td>0.49</td><td>0.34</td><td>0.46</td><td>0.51</td></tr><tr><td>Q</td><td>0.45</td><td>0.49</td><td>0.39</td><td>0.50</td><td>0.54</td></tr><tr><td>NV</td><td>0.38</td><td>0.39</td><td>0.34</td><td>0.42</td><td>0.45</td></tr><tr><td>总分</td><td>0.48</td><td>0.52</td><td>0.40</td><td>0.52</td><td>0.56</td></tr><tr><td rowspan="4">七年级</td><td>V</td><td>0.49</td><td>0.53</td><td>0.36</td><td>0.42</td><td>0.55</td></tr><tr><td>Q</td><td>0.51</td><td>0.54</td><td>0.45</td><td>0.56</td><td>0.61</td></tr><tr><td>NV</td><td>0.41</td><td>0.43</td><td>0.38</td><td>0.46</td><td>0.49</td></tr><tr><td>总分</td><td>0.53</td><td>0.56</td><td>0.45</td><td>0.57</td><td>0.62</td></tr><tr><td rowspan="4">九年级</td><td>V</td><td>0.52</td><td>0.56</td><td>0.39</td><td>0.52</td><td>0.58</td></tr><tr><td>Q</td><td>0.52</td><td>0.57</td><td>0.48</td><td>0.59</td><td>0.63</td></tr><tr><td>NV</td><td>0.42</td><td>0.45</td><td>0.41</td><td>0.48</td><td>0.52</td></tr><tr><td>总分</td><td>0.55</td><td>0.59</td><td>0.48</td><td>0.60</td><td>0.65</td></tr></table>

注: \( \mathrm{V} = \) 语言类; \( \mathrm{Q} = \) 数量类; \( \mathrm{{NV}} = \) 非语言类。



你可能还会问, 能够在上述三种分数中加以区分的分数差异效度有多高。这些数据的答案是: 对于整个群组, 几乎没有; 预测某学科的学业表现的分数差异效度从未达到 0.05 。所以在学习表现的预测方面, 几乎完全是靠一般能力因素进行预测。

三种独立分数的意义主要在于, 它们能够使人们关注这三个测试分数不太一致的部分儿童。对于大部分儿童来说, 三个测试的标准年龄分数是相似的, 分数之间的相当高的关联性表明差别不会超过 10 分。若分差过大, 则其预测性或描述性价值会很低。一些人可能会有 20 分甚至 30 分的差异, 例如一个孩子的语言标准年龄分数可能是 80 而非语言标准年龄分数为 105 。人们可能会禁不住疑惑: 是什么导致了这种显著的差异? 是因为英语不是其母语吗? 一些西班牙裔学生表现出这种模式。相比之下, 亚洲儿童在数量量表方面展示出更好的表现, 而语言或非语言类的表现相对数量较差。是因为孩子有阅读障碍吗? 还是早期阅读技能教学的失败? 怎么帮助孩子在学校里取得进步? 治疗语言能力不足或开发非语言能力能达到预期目标吗? 利用分数差异的关键在于把它当作一个警示来提醒自己, 可能有一个非标准情况或为孩子制订最好的教育计划可能需要进一步的探索, 特别是个人测试的制定 (欲了解更多对非标准能力分布的孩子的测试, 请参见第八章。该出版商的《教师和辅导员解读指南》也给出了解释不同分数分布的建议)。

判断两个分数之间的差异是否足以引起注意的一种方式是考虑两个量表的测试标准误差。测试标准误差在第四章提到过, 即一个人反复做了几遍相同的测试之后, 得分的变化指数。除非两个分数之间的差异显著大于测试标准误差, 否则差异应该忽略不计, 因为这是由测试表现的随机波动引起的。一个合理的标准是差值应至少是两个较大的标准误差的三倍。因此, 语言和非语言分数的标准误差分别是 4.3 和 5.7 , 我们无须重视小于 18 分的分数差异。20-30 分的差异超过了这一标准, 它很可能表明存在重大不一致性。但是, 我们不应该机械化处理比分的差异, 要把两个分数之间存在非常大的差异看成一种迹象, 说明某些部分出现了问题, 需要通过个人测试、补充评价方法或仔细观察来进行更细致的考察。

## 12.5 多能力测试

在过去的 60 年中, 人们开发了大量的测试组合用于对特定的工作或培训项目的成功做出不同预测。用于工作分析的测试表明不同工作需要不同的能力。因此, 每个军队都开发了一个分类测试组合来帮助分配新兵,使其能有效地利用自己的能力。 因为在军事训练中积累了大量样本, 和以前的测试相比, 建立在这些样本基础上开发的测试组合能够提供大量的数据信息, 能够作为培训成功的指标, 或者较低程度上作为工作成功的指标。在下面的章节中我们会提到其中的一些数据。然而, 适合于民用的测试组合能引起更多人的兴趣。我们会说明其中两个: 差异化能力倾向测试, 主要用于高中辅导项目; 美国就业一般能力倾向测试组合, 专为职业咨询服务和就业安排设计。

## 1. 差别能力倾向测试组合

差别能力倾向测试组合 (DAT) 最初是由心理学研究公司于 1947 年发表的。作为指导测试组合, 它适用于中学水平, 其修订和精简版于 1963 年、1972 年、1982 年和 1990 分别设计。在测试组合设计中, 设计者比较注重不同测试间的低关联性, 但最主要的关注点是找到对高中辅导员有意义的测试数据。其结果是, 除了抄写速度和准确度的测试外, 其相互相关性约为 0.50 。然而, 部分能力的信度约为 0.90 , 很显然是因为同时测试了多种能力。在这里对八个子测试做出简要说明。第九项分数, 即学术能力倾向分, 是语言推理和数字推理 \( {}^{\left( l\right) } \) 分数之和。

① 语言推理 (25 分钟)。测试题目属于双类比类型, 例如: _____对 A 来说就像 B 对 _____一样。考生从五对词语中选择一对完成类比。_____对夜晚来说就像早餐对_____一样。

A. 晚餐一一角落

B. 温和一早晨

C. 大门一 角落

D. 流动一 享受

E. 晚餐一一早晨

② 数字推理 (30 分钟)。该测试包含强调理解而不仅仅是计算能力的数字问题。

\( 3 = {15} \) 的_____ \( \% \)

A. 5

B. 10

C. 20

D. 30

E. 以上都不是

③ 抽象推理 (20 分钟)。一系列的图案之间有一定联系和顺序, 考生应找出合适的选项以符合这个序列的规律。

---

<!-- Footnote -->

① 资料来源:与差别能力倾向测试类似的样题。版权 (C) 1990,1982,1972 培生教育公司。经允许转载。 保留所有权利。

<!-- Footnote -->

---







④ 空间关系 (25 分钟)。考生会看到一张平面图。考生应根据平面图找出其折叠后对应的立体图形。例子如下:







⑤ 力学推理 (25 分钟)。考生将看到一个机械设备或力学情境的图, 考生应选择符合该情境的选项。







⑥ 认知速度与精确度 (6 分钟)。每道题目由一些符号组合构成, 其中一个符号组合有下划线。考生应在答卷上选出相同的符号组合。





测试题目 示例答卷



⑦ 拼写 (10 分钟)。考生将看到一张单词表, 其中有些词有拼写错误。考生应判断每个词是否拼写正确。



<table><tr><td/><td>正确</td><td>错误</td></tr><tr><td>gurl</td><td>II</td><td>II</td></tr></table>



⑧ 语言使用 (15 分钟)。一个句子被分成了四个部分。考生应判断哪个部分有错,即 \( \mathrm{A}\text{、}\mathrm{\;B}\text{、}\mathrm{C} \) 还是 \( \mathrm{D} \) 有错误,如果没有错误,选 \( \mathrm{E} \) 。



<table><tr><td>A</td><td>B</td><td>C</td><td>D</td><td>A</td><td>B</td><td>C</td><td>D</td></tr><tr><td colspan="4">Ain't we / going to / the office / next week?</td><td>II</td><td>II</td><td>II</td><td>II</td></tr></table>



差异化能力倾向测试组合测试除了认知速度和精确度测试外, 基本上是能力测试, 时间限制一般是 20-30 分钟。测试组合总测试时间约为 3 小时 (2.5 小时的答题时间加上 30 分钟的考试说明时间)。 7-12 年级都能得到百分位排名、九分评分制相应值和分段分数。每项子测试都有规范, 语言推理和数字能力之和作为学术能力倾向的一般评价也有常模可参照。

## 2. 一般能力倾向测试组合

一般能力倾向测试组合 (GATB) 是由美国劳工部的就业保障局在 20 世纪 40 年代初研发的。前期的研究给许多不同的职位都设置了对应的试验性测试组合, 在此基础上得到了这一测试组合。针对特定工作的 50 种不同测试的分析结果表明, 许多测试中都有大量重复的部分, 但一项测试只衡量 10 个能力因素。开发一般能力倾向测试组合的目的是衡量这些不同的因素。一般能力倾向测试组合的最新形式包括 12 项测试, 并给 9 个不同的因素打分。其中一个是一般心理能力因素, 它通过三个测试 (词汇、算术推理和三维空间) 得到, 这些测试也是给更具体的因素打分的。每个因素按比例得到分数,平均值为 100 , 标准差为 20 。

① 语言能力倾向。分数由第 4 号测试也就是词汇测试得到。该测试要求考生在四组词语中找出一对近义词或反义词。比如:

a. 谨慎的 b. 友好的 c. 敌对的 d. 遥远的

a. 加速 b. 剥夺 c. 加快 d. 反对

② 数字能力。对于此能力倾向的评估基于两项测试。第一项是 2 号计算测试, 它要求对整数进行快速准确的运算。例如: 减法 \( \left( -\right) {256} \) 乘法 \( \left( \times \right) {37} \) 答案 173







296



第二项测试是 6 号算术推理测试, 由它得出数字能力分数, 它涉及口头提出的数量问题, 比如:

约翰每小时赚 8.20 美元, 那么他一周工作 35 小时能赚多少钱?

③ 空间能力倾向。该能力的评分由 1 号三维空间测试进行。考生必须在 4 个三维立体图中选出一个正确的,使它能由图示的平面图形得到, 虚线代表折叠部分。







④ 形状观察。该能力测试包括快速和精准地认知图形和图案。评分是通过两项测试得到的: (1) 5 号工具匹配测试; (2) 7 号形式匹配, 但两者提供的视觉刺激不同。测试要求考生从一系列选项中选出与题示形式类似的一项。 工具匹配



\[\left( {-1}\right) \left( {1 - \frac{1}{2}}\right) \left( {1 - \frac{1}{2}}\right) \left( {1 - \frac{1}{2}}\right) \left( {1 - \frac{1}{2}}\right)  =  - \frac{1}{2}\]





图形匹配

⑤ 文书认知。这一能力也涉及快速和准确的洞察力, 但它的刺激材料是文字的而不是纯图形的。 1 号测试为名称比较, 会提供几对名称, 考生应判断一对里的两个名字是相同的还是有细微的差别。如:

John Goldstein & Co. - John Goldston & Co.

Pewee Mfg. Co. - Pewee Mfg. Co.

⑥ 运动协调。这个因素同样与简单而精确的运动神经反应速度有关。该能力是通过测试 8 - 做标记测试评估的。如图所示, 考生应使用铅笔在答卷的每个方块中做三个标记, 速度越快越好。该测试的得分是 60 秒内正确标记的方块的数量。







⑦ 手部灵巧度。这个因素包含手部较大动作的速度和精确度。它通过两个小钉板测试进行评估: (1) 9 号放置测试 (2) 10 号翻转测试。在第一项测试中, 考生用两只手把一系列钉子从钉板的一个部位转移到另一部位。在第二项测试中, 考生选择用其中一只手从钉板中拿出一个钉子,将它旋转 \( {180}^{ \circ  } \) 后再把它放入钉板中。每个测试都有一个较短的时间限制, 所以只有一小部分考生能够移动或翻转所有的钉子。 每个测试都有三次尝试机会, 得分就是移动或翻转的钉子的总数。

⑧ 手指灵巧度。这个因素涉及比上一题更为精准的灵活度, 需要考生对手指有更精确的控制。一共有两项测试 - 11 号组装和 12 号拆卸测试, 它们都使用同一套设备——一块分成了两个部分的木板, 每个部分有 50 个小洞。每部分的小洞中均放置了铆钉。一叠垫圈堆放在一根轴上。在组装过程中, 考生用一只手拿起一颗铆钉, 另一只手拿起垫圈, 并把垫圈拧到铆钉上, 最后把组装好的铆钉放到木板另一侧相应的小孔中。考生的任务是在 90 秒内尽量多地组装铆钉和垫圈。在拆卸过程中, 考生把垫圈从铆钉上移开, 将铆钉和垫圈分别放回原来的位置。考生的得分就是组装和拆卸物件的数量。

这些装置测试 (无须纸笔) - 运动神经协调、手部灵活度和手指灵活度测试的装置在使用完后, 都会恢复到它们的初始状态, 方便下一个考生使用。

一般能力倾向测试组合 (GATB) 和差别能力倾向测试组合的比较表明, 差别能力倾向测试组合包括一般能力倾向测试组合所缺乏的机械理解和语言测试, 而一般能力倾向测试组合包括差异化能力倾向测试组合所没有的形状观察和几种动作协调测试。因此, 就它的覆盖面来说, 一般能力倾向测试组合更适用于职业领域而不是学校领域。一般能力倾向测试组合包括了运动协调测试后, 平均相关性偏低, 但其他的 “智力”测试的相关度和差别能力倾向测试组合差不多。100 个高三学生的一般能力倾向测试组合中不同能力分数的相关性见表 12-5 , 其中不包括语言、数字、空间的分数与一般智力分数 (就是由文字、数字和空间分数组成的一般智力) 的相关性, 相关性范围是 -0.06 到 0.66 。三个动作测试表现出相当显著的相关性, 但它们与洞察力测试的相关度一般且基本上和一般能力测试中的那些测试没有关联。观察力和智力分数之间也有密切联系, 同时, 这两种观察能力之间也具有重要的联系。



表 12-5 100 个高三学生能力倾向测试分数的相关系数 (来自 GATB)

<table><tr><td/><td>G</td><td>V</td><td>N</td><td>S</td><td>P</td><td>Q</td><td>K</td><td>F</td><td>M</td></tr><tr><td>G一智力</td><td>-</td><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>V一语言</td><td>0.73</td><td>\( - \infty \)</td><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>N---数字</td><td>0.74</td><td>0.42</td><td>-</td><td/><td/><td/><td/><td/><td/></tr><tr><td>S--- 空间</td><td>0.70</td><td>0.40</td><td>0.34</td><td>-</td><td/><td/><td/><td/><td/></tr><tr><td>P—形状观察</td><td>0.43</td><td>0.34</td><td>0.42</td><td>0.48</td><td>-</td><td/><td/><td/><td/></tr><tr><td>Q一文字观察</td><td>0.35</td><td>0.29</td><td>0.42</td><td>0.26</td><td>0.66</td><td>_____</td><td/><td/><td/></tr><tr><td>K一动作协调</td><td>-0.04</td><td>0.13</td><td>0.06</td><td>-0.03</td><td>0.29</td><td>0.29</td><td>-</td><td/><td/></tr><tr><td>F-手指灵活度</td><td>-0.05</td><td>-0.03</td><td>-0.03</td><td>0.01</td><td>0.27</td><td>0.20</td><td>0.37</td><td>-</td><td/></tr><tr><td>M一手部灵活度</td><td>-0.06</td><td>0.06</td><td>0.01</td><td>-0.03</td><td>0.23</td><td>0.17</td><td>0.49</td><td>0.46</td><td>Service</td></tr></table>



在差别能力倾向测试组合与一般能力倾向测试组合相应因素之间存在着相当大的相关性。一项研究中 (美国就业服务局, 1967) 的代表值如下:



<table><tr><td>量表</td><td>相关系数</td></tr><tr><td>语言</td><td>0.74</td></tr><tr><td>数字</td><td>0.61</td></tr><tr><td>空间</td><td>0.65</td></tr><tr><td>文字</td><td>0.57</td></tr></table>



但是, 这些较低的相关性足以说明这两种测试是不同的。二者的一大不同点就是差别能力倾向测试组合大多数情况下是纯粹的能力测试, 而一般能力倾向测试组合测试比较关注速度。

## 12.6 一般认知能力的作用: 《钟形曲线》

每隔几年就会有书或专著出版, 将公众的广泛关注吸引到关于人类心智能力数据的各个方面上来。《钟形曲线》就是这样的一本书, 它出版于 1994 年 (Herrnstein & Murray, 1994)。该书作者所倡导的基本想法是, 人的认知能力在复杂的社会生活的各个方面都是非常重要的, 而且这种能力的差异与各种各样的认知和社会生产有密切联系。作者指出, 严格筛选的教育机构对认知能力测试的使用, 如学业能力倾向测试和研究生入学考试, 建立了一个知识精英团队, 而这个团队的成员在社会中占据了大部分政治、社会、经济权力的位置。父母有高学历, 孩子往往也会受到高等教育, 而如果父母属于经济与社会的弱势群体, 孩子往往也要受到父母命运的影响。由此作者们认为, 基于这种阶级导致的认知能力的差别, 一般的多元化社会尤其是美国社会可能会形成一种极端的社会分层。虽然作者的看法没有参照种族或民族群体的情况 (他们的数据表明, 其结论是与种族无关的, 并且作者坚定不移地认为种族因素是 “不可知”的), 但在不同的社会阶层的种族比例不同。从这一点来看, 他们的论点似乎有些种族主义, 因为它意味着种族间存在能力差异。

《钟形曲线》几乎受到了来自所有可能方向的攻击, 有时针对正当理由, 有时针对无根据的论证。有些学者认为, 该书涉及种族和智力, 这种问题不应被提起, 而另一些人质疑其统计方法。许多早期回应被雅各比和格拉布尔曼 (Jacoby & Glauberman, 1995) 收录在 “关于《钟形曲线》的辩论” 中。有一个网站包含许多关于智力及其用途的内容,网址是: http://www.indiana.edu/ 10 intell。虽然赫恩斯坦和436默里提出的对社会政策的暗示和建议可能是非常值得怀疑的 (批评家会说是完全不合理的), 但我们可以试问数据是如何揭示一般认知能力和具体能力在预测学术或职业表现中的价值的。测试组合, 如差别能力倾向测试组合和一般能力倾向测试组合有用程度到底如何? 它们到底能在多大程度上帮助我们改善对教育或职业成就的预测? 由于涉及的样本大小, 各种各样的职业特色和成果质量的措施, 关于这些关系的最佳研究是由军事心理学家进行的, 因为他们使用了来自各种各样不同职业的大量样本, 得出了高质量的评估结果。

数以千计的研究表明, 能力测试成绩与工作成功的衡量标准有联系。多年来, 研究不同, 工作不同, 发现的结果也有所不同。因此, 人事心理学家倾向于强调特定作业对能力的要求, 并认为开展工作分析和具体的效度研究是非常有必要的。这不仅仅是为了研究每种类型的工作, 更是为了研究当地的职位情况。这就要求具体的效度研究。在法律的要求下, 美国联邦平等就业机会委员会对在职业选测、安排和咨询方面应用测试感到很为难。因为很少有就业情境能够提供足够多的新员工来帮助他们得到稳定的效度数据。但最近, 这种独特效度学说已受到严重质疑。

施密特和亨特 (Schmidt & Hunter, 1981) 指出, 每个研究的结果不同的原因有: ① 样本太小; ② 所研究的组别限制或筛选的程度不同; ③ 衡量标准的性质和信度的差异。施密特、亨特及其同事 (Schmidt & Hunter, 1992; Schmidt et al., 1985) 都进行了一些对现有数据的综合分析。综合分析是汇集大量现有的研究数据来校正刚才提到的不足之处, 并提取超越个体研究的研究结果的进行再分析的过程。延森 (Jensen, 1998, 第九章) 已审查许多最新的证据, 并且戈特弗雷德松 (Gottfredson, 1997) 也提供了一个很好的总结。下面的一般性结论由其著作产生:

① 一般认知能力对几乎所有的工作都有显著效度。效度的水平与工作的复杂程度相关, 复杂的工作相关性更高, 而简单是用于更简单的作业进行更复杂的作业更高和更低。

② 考虑过这些研究的预选的令人失望的结果和不可靠的测量标准后, 人们发现对于工作绩效,一般认知能力效度是相当高的。

③ 一般精神运动能力也有一定的效度, 对于更简单的工作 (比如管理仪器或包装), 它的效度更高, 这些工作对认知能力的要求是最低的。

④ 机械或技术理解测评给一系列职业增加了效度, 这些职业通常要和仪器或修理机械或电子设备有关。

⑤ 除了上述结论, 很难证明其他更具体的能力也具有效度。

这些基本的研究结果已在其他研究者的研究中得到证实。尼堡和延森 (Nyborg &Jensen,2001) 的研究发现,在黑人和白人两组样本中, \( g \) 因素和收入、工作威望都有巨大联系。最好的证据应该是由李和厄尔斯 (Ree & Earles, 1992) 总结的, 因为他们有大量的样本和相对高质量的衡量标准。他们利用武装部队职业能力倾向测试组合(ASVAB) 与培训和就业情况下的成千上万的样本, 发现了一个单一的一般认知能力复合指标。它可能是最有效的表现预测因子。事实上, 对于这些研究调查的许多军事职位来说,一般认知能力的因素是唯一有用的预测因子。

施密特和亨特 (Schmidt & Hunter, 1981) 运用到他们的综合分析法中的术语是效度泛化。虽然他们因为过度夸大不同工作的效度规律的一致性和真实测试效度而被批评,但他们的成果为工作具体化学说的修改带来了好的影响, 这个学说从 1950 年到 1980 年非常盛行。并且他们的成果及李和厄尔斯 (Ree & Earles, 1992) 的成果清楚表明, 如果要自信地展示特定教育项目或工作的不同效度规律, 那么效度研究的样本一定要被过去效度研究的样本大很多。

施密特和亨特 (Schmidt & Hunter, 1981) 审查了能力测试是教育和职业成功的预测因子的相关证据。这是看待考试成绩和职业之间关系的另一种方式。我们可以提问: 不同职业的人得到的测试分数如何以及在何种程度上不同? 我们可以把这个标为测试效度的分类性看法, 正好与预测性看法相反。也就是说, 如果我们让不同的人进行测试, 他们的能力模式会不会不同呢? 让我们先来看看一般认知能力的高低。 尽管许多数据集提供了这样的信息, 美国就业服务局提供的一般能力倾向测试的数据在数量和职业种类涵盖量方面都有一定的优势, 因此我们将重点放在这些数据上。 在一般能力倾向测试研究的四百多个不同职业中, \( G \) 量表的平均分数有明显的巨大差异。分数最高是数学家的 143 分到西红柿削皮员的 55 分。但是, 在我们了解它们的不同之前, 让我们先了解一个样品和另一个同样工作的样品间的一致性如何。在美国就业服务局研究的工作中, 48 个职位有 50 个或更多的情况下两个或更多的独立样本。而在这些工作中,样品 \( \mathrm{A} \) 和样品 \( \mathrm{B} \) 之间的相关系数为 0.93。显然,平均 \( g \) 值在特定的职业中是一个非常可靠、稳定的特点。

在我们发现职业之间这些比较稳定的差异的同时, 我们也发现在一个职业里的分数范围相当大。图 12-5 所示为一系列职业的平均 \( g \) 值和 \( \pm  1 \) 的标准差范围,该范围包括该职业的大约三分之二的人。虽然平均分的差异是相当可靠的, 但除了极端样本外, 重叠部分也是相当可观的。美国就业服务局研究的职业中, 大多数职业的平均 \( g \) 值落入一个相当狭窄的范围。这一点见表 12-6,442 个工作中有 246 个的平均438\( g \) 值位于 90 到 109 之间,或在相对于值为 100 的平均值半个标准差范围内。只有小部分职业对 \( g \) 值的要求非常严格。因此,只有 30 个职业的平均 \( g \) 值为 120 或以上。 一个能力在平均能力附近的人能适应广泛的职业岗位。





图 12-5 针对某些职业的一般能力倾向测试的一般智力平均分数 ( \( G \) 分数)。平均值周围的方块表示 \( \pm  1 \) 的标准差

表 12-6 不同职业一般智力平均(G)分数频率分配

<table><tr><td>分数水平</td><td>频率</td></tr><tr><td>\( {140} + \)</td><td>1</td></tr><tr><td>130—139</td><td>6</td></tr><tr><td>120—129</td><td>23</td></tr><tr><td>110—119</td><td>57</td></tr><tr><td>100—109</td><td>107</td></tr><tr><td>90—99</td><td>139</td></tr><tr><td>80—89</td><td>139</td></tr><tr><td>70—79</td><td>18</td></tr><tr><td>60 - 69</td><td>1</td></tr><tr><td>低于 60</td><td>1</td></tr></table>



我们可能会问这些职业在多大程度上能表现能力规律。我们会发现在何种程度上某些职业从业者的语言能力特别高 (或低)? 数量能力又如何? 运动协调或手指灵活性如何? 一般能力倾向测试数据也有助于回答这些问题。我们选择了 48 个职业, 每个职业至少有两个一样的样本,并根据一般能力倾向测试 (不含 \( \mathrm{G} \) ) 的八个主要分数计算的配对样本之间的相关性。 48 个相关性的范围是 -0.02 到 +0.97 ; 相关性情况显示于表 12-7 , 其中值是 0.72 。图 12-6 展示了三个工作中两个相同样本的分数模式: 一个高度一致, 一个具有平均一致性, 而另一个完全缺乏一致性。可得出的结论是, 模式的一致性问题只能针对特定的工作而言。有些工作确实显示一致性, 但有的不会。



表 12-7 成对工作的相关系数

<table><tr><td>相关系数</td><td>频率</td></tr><tr><td>0.90-0.99</td><td>11</td></tr><tr><td>0.80-0.89</td><td>9</td></tr><tr><td>0.70 -0.79</td><td>7</td></tr><tr><td>0.60-0.69</td><td>6</td></tr><tr><td>0.50-0.59</td><td>6</td></tr><tr><td>0.40-0.49</td><td>1</td></tr><tr><td>0.30-0.39</td><td>3</td></tr><tr><td>0.20-0.29</td><td>1</td></tr><tr><td>0.10-0.19</td><td>1</td></tr><tr><td>0.00-0.09</td><td>2</td></tr><tr><td>负值</td><td>1</td></tr></table>



图 12-6 一般能力倾向测试组合的工作组样本的平均分数记录, 虚线代表样本 1 , 实线代表样本 2



## 12.7 总 结

能力倾向个体测试最早是在 20 世纪之交针对教育问题而开发。斯坦福-比奈很快成为美国的主要测试。一战的需要促进了群组能力测试的发展。韦氏系列试验最早是针对成人能力评估设计的, 后来推广到各年龄段。近几年, 韦氏学前及初小儿童智力量表第三版, 韦氏儿童智力量表第四版和韦氏成人智力量表第三版是使用最广泛的个体能力测试。许多群组测试或多或少从第一次世界大战期间的那些测试发展而来, 认知能力测试就是一个很好的例子。

20 世纪 40 年代初引入了测试组合来给职业培训的潜力提供更好的预测。两个主要的测试组合是差别能力倾向测试组合和一般能力倾向测试组合, 前者用于学校辅导, 后者主要用于就业。这两个测试组合很相似, 但一般能力倾向测试组合更为重视速度和感知、文字能力。最近的证据表明, 对学术和职业的成功做出预测的其实主要是这些测试组合评估的一般能力。

## 12.8 习 题

1. 有人认为所有智力测试都应被称作学术能力倾向测试。这一观点有何可取之处和局限性?

2. 为什么说通过能力测试来评估一个学生的智力比老师的打分更好? 在什么情况下老师的打分会更适合?

3. 在以下所有情境中, 你会选择个人智力测试还是群组智力测试? 为什么?

a. 你在研究一个有严重语言障碍的男孩。

b. 你要选拔一些学生就读护理专业。

c. 你要准备给一个高三学生提出一些关于学习和职业计划的建议。

d. 你在研究得州学校系统的西班牙裔孩子的学习进步情况。

e. 你在一个政府机构中帮助一群被判犯罪的男孩。

f. 你想找到一个无法阅读的小孩的问题根源。

4. 一般的群组测试对希望进入专业领域的学生还是希望未来职业是贸易的学生更有用? 为什么?

5. 一则新闻报道说一个年轻的女子在心理医院住了三年后智商值由 62 提升到了 118 。这一说法有什么误导性? 哪些因素可能造成这两个分数的不同?

6. 预测大学的成功, 智力测试在哪些方面优于高中分数? 哪些方面不如后者?

7. 为什么智力测试与标准成就测试关联度比与学业成绩的关联度高?

8. 假如你是一名四年级老师, 并且刚刚得到了你班学生在全市四年级认知能力测试中的结果。你会怎么使用这个结果? 你还需要哪些信息?

9. 一个八年级学生在认知能力测试中得到了如下的标准年龄分数: 语言, 4 级——98;6 级——116; 8 ——104 级。哪一个分数最能代表孩子的真实学业能力水平?

10. 在开学前两周,一个优秀社区里的学校让所有刚进入幼儿园和在幼儿园没有做过测试的一年级学生进行了斯坦福-比奈第四版测试。这个做法有多值得和有用? 为什么?

11. 学校想到建立一些措施来找出需要接受阅读指导的学生。那些阅读能力落后于其潜力的学生是目标群体。达到这个目标的合理方式是什么?

12. 一系列的测试组合都是针对中学生和成人开发的, 为什么? 这种现状合理吗?

13. 与使用不同来源的测试相比, 使用差别能力测试组合等测试有何优点和局限性?

14. 一所职业高中开展了会计、美容师、牙科助手和经理培训项目。通过一般能力倾向测试得到了各种数据,包括平均值(M)、标准差(SD)和相关系数(r),四个职业的指导评分显示如下。作为学校辅导员, 你会怎么利用这些信息帮助同学选择合适的培训项目?



<table><tr><td/><td colspan="3">语言</td><td colspan="3">数字</td><td colspan="3">空间</td><td colspan="3">手部灵巧程度</td></tr><tr><td>职业</td><td>\( M \)</td><td>SD</td><td>\( r \)</td><td>\( M \)</td><td>SD</td><td>\( r \)</td><td>M</td><td>SD</td><td>\( r \)</td><td>\( M \)</td><td>SD</td><td>\( r \)</td></tr><tr><td>会计</td><td>106</td><td>16</td><td>0.51</td><td>112</td><td>15</td><td>0.37</td><td>103</td><td>20</td><td>0.38</td><td>105</td><td>21</td><td>0.36</td></tr><tr><td>美容师</td><td>96</td><td>15</td><td>0.24</td><td>92</td><td>13</td><td>0.31</td><td>100</td><td>16</td><td>0.25</td><td>98</td><td>17</td><td>0.07</td></tr><tr><td>牙医助理</td><td>106</td><td>13</td><td>0.26</td><td>102</td><td>14</td><td>0.34</td><td>107</td><td>16</td><td>0.30</td><td>115</td><td>19</td><td>0.36</td></tr><tr><td>办公室经理</td><td>105</td><td>12</td><td>0.21</td><td>105</td><td>14</td><td>0.24</td><td>106</td><td>16</td><td>0.06</td><td>103</td><td>21</td><td>0.09</td></tr></table>



15. “任何领域最好的能力倾向评估方法就是对该领域最新成绩的评估”。这一说法合理吗? 它的局限性是什么?

16. 阅读预备测试和智力测试的区别是什么? 对于一年级学生来说, 阅读预备测试与智力测试相比有哪些优势?

17. 对于高中毕业生的跟踪研究可以如何帮助改善学校的指导项目?

## 推 荐 阅 读

Belk, M. S., LoBello, S. G., Ray, G. E., 和 Zachar, P. (2002). WISC-III administration, clerical, and scoring errors made by student examiners. Journal of Psychoeducational Assessment, 20, 290-300.

Boake, C. (2002). From the Binet-Simon to the Wechsler-Bellevue: Tracing the history of intelligence testing. Journal of Clinical and Experimental Neuropsychology, 24, 383-405.

Bond, L. (1989). The effects of special preparation on measures of scholastic ability. In R. L. Linn (Ed.), Educational measurement (3rd ed., pp. 429-444). New York: Macmillan.

Bracken, B. A., &-McCallum, R. S. (1998). The Universal Nonverbal Intelligence Test. Itasca, IL: Riverside.

Brody, N. (2003). Construct validation of the Sternberg Triarchic Abilities Test: Comment and reanalysis. Intelligence, 31, 319-329.

Brown, L., Sherbenou, R. J., &Johnson, S. K. (1997). Test of non-verbal intelligence (3rd Ed.). Austin, TX: PRO-ED.

Carroll, J. B. (1993). Human cognitive abilities: A survey of factor-analytic studies. Cambridge, MA: Cambridge University Press.

Das, J. P., & Naglieri, J. A. (2001). The Das-Naglieri Cognitive Assessment System in theory and practice. In J. J. C. Andrews, D. H. Saklofske, & H. L. Janzen (Eds.), Handbook of psychoeducational assessment (pp. 33-63). San Diego, CA: Academic Press.

Das, J. P., Naglieri, J. A., & Kirby, J. R. (1994). Assessment of cognitive processes: The PASS theory of intelligence. Boston: Allyn & Bacon.

DiStafano, C., & Dombrowski, S. C. (2006). Investigating the theoretical structure of the Stanford-Binet-Fifth Edition. Journal of Psychoeducational Assessment, 24, 123-136.

Eysenck, H. J. (1986). Inspection time and intelligence; A historical perspective. Personality and Individual Differences, 7, 603-607.

Eysenck, H. J. (1988). The concept of "intelligence": Useful or useless? Intelligence, 12, 1-16. Garber, H. L. (1988). The Milwaukee Project : Preventing mental retardation in children at risk. Washington, DC: American Association on Mental Retardation.

Glutting, J., Adams, W, & Sheslow, D. (2000). WRIT : Wide Range Intelligence Test manual. Wilmington, DE: Wide Range.

Gottfredson, L. S. (1997). Whyg matters: The complexity of everyday life. Intelligence, 24, 79- 132.

Gottfredson, L. S. (2003). Dissecting practical intelligence theory: Its claims and evidence. Intelligence, 31, 343-397.

Gregory, R. J. (1987), Adult intellectual assessment. Boston: Allyn & Bacon.

Guilford, J. P. (1985). The structure-of-intellect model. In B. B. Wolman (Ed.), Handbook of intelligence (pp. 225-266). New York: Wiley.

Herrnstein, R. J., & Murray, C. (1994). The bell curve: Intelligence and class structure in American life. New York: The Free Press.

Hildebrand, D. K., 8-Ledbetter, M. F. (2001). Assessing children's intelligence and memory: The Wechsler Intelligence Scale for Children-Third Edition and the Children's Memory Scale,

In J. J. C. Andrews, D. H. Saklofske, & H. L. Janzen (Eds.), Handbook of psychoeducational assessment (pp. 13-32). San Diego, CA: Academic Press.

Horn, J. L. (1985). Remodeling old models of intelligence. In B. B. Wolman (Ed.), Handbook of intelligence(pp. 267-300). New York: Wiley.

Jacoby, R., & Glauberman, N. (Eds.). (1995). The bell curve debate. New York: Times Books.

Jensen, A. R. (1991). General mental ability: From psychometrics to biology. Diagnostique, 16, 134-144.

Jensen, A. R. (1993). Spearman's hypothesis tested with chronometric information-processing tasks. Intelligence, 17, 47-77.

Jensen, A. R. (1998). The g factor. Westport, CT: Praeger.

Kaufman, A. S., & Kaufman, N. L. (1990). Kaufman brief intelligence test. Circle Pines, MN: American Guidance Service.

Kaufman, J. C., & Kaufman, A. S. (2001). Time for the changing of the guard: A farewell to short forms of intelligence tests. Journal of Psychoeducational Assessment, 19, 245-267.

Mather, N., & Gregg, N. (2001). Assessment with the Woodcock-Johnson-III. In J. J. C. Andrews, D. H. Saklofske, & H. L. Janzen (Eds.), Handbook of psychoeducational assessment (pp. 133-165). San Diego, CA: Academic Press.

McGrew, K. S., & Flanagan, D. P. (1998). The intelligence test desk reference. Boston: Allyn & Bacon.

Newmark, C. S. (Ed.). (1996). Major psychological assessment instruments (2nd ed.). Boston: Allyn & Bacon.

Nyborg, H., & Jensen, A. R. (2001). Occupation and income related to psychometric g. Intelligence, 29, 45-56.

The Psychological Corporation. (1999). Wechsler Abbreviated Scale of Intelligence (WASI). San Antonio, TX: Author.

Ree, M. J., & Earles, J. A. (1992). Intelligence is the best predictor of job performance. Current Directions in Psychological Science, 1, 86-89.

Roid, G. H. (2003). Stanford-Binet Intelligence Scales, Fifth edition. Itasca, IL: Riverside Publishing.

Sattler, J. M. (2001). Assessment of children: Cognitive applications (4th ed.). San Diego, CA: Author.

Schmidt,F. L., & Hunter, J. E. (1992). Development of a causal model of processes determining job performance. Current Directions in Psychological Science, 1, 89-92.

Snow, R. E., & Lohman, D. F. (1989). Implications of cognitive psychology for educational measurement. In R. L. Linn (Ed.), Educational measurement (3rd ed., pp. 263-331). New York: Macmillan.

Sternberg, R. J. (1985). Beyond IQ: A triarchic theory of intelligence. Cambridge, MA: Cambridge University Press.

Sternberg, R. J. (2003). Issues in the theory and measurement of successful intelligence: A reply to Brody. Intelligence, 31, 331-337.

Thorndike, R. L., Hagen, E. P., & Sattler, J. M. (1986). The Stanford-Binet Intelligence Scale: Fourth edition. Technical manual. Chicago: Riverside.

Thurstone, L. L. (1938). Primary mental abilities. Psychometric Monographs, No. 1.

Woodcock, R. W., McGrew, K. S., & Mather, N. (2001). Woodcock-Johnson III. Itasca, IL: Riverside.

## 第13章 标准化成绩测试

## 13.1 引言

在第十二章中, 基于从成绩中获取的推断以及内容效度在测试设计中是否为中心因素, 我们对能力倾向测试和成绩测试进行了区分。我们描述了一些能力倾向测试或一般认知能力测试, 在这些测试及能力中, 被评估的认知过程是最主要的考虑因素。本章详述了“硬币”的另一面: 设计来衡量人们学到了多少知识或者储存了多少知识的测试。这里我们主要研究集中设计的测试, 也就是标准化成绩测试。这些测试由各个州或者全国的测试机构通过商业化的渠道发布, 许多学校和学区都会使用这些测试。这些测试的编制过程与老师准备一次课堂成绩测试的过程相似。但是, 地区性成绩测试和那些为更广泛的区域设计的成绩测试之间却存在着重要的差异。

## 13.2 标准化成绩测试的特点

商业化测试发布者往往期待着自己的测试能被广泛接受并且在接下去几年内都被使用, 因此他们十分愿意投入大量的时间与金钱来研发能吸引大批量用户的成绩测试及测试组合。国家测试机构也需要开发出一些评估方式来包含所有使用这些测试的学区的学习资料。研发适用范围如此之广的测试需要进行一系列的步骤。这些步骤包括熟知使用该测试的区域实施的课程、准备测试内容和技术的详细框架、编写试题、检查试题并去掉模糊或可能有偏见的题目、完成试题分析及为试题质量提供客观的评价, 然后重新将剩下的试题合并成最后的测试。在第五章的内容相关效度证据部分, 我们讨论了与测试框架和测试偏见相关的问题和过程。试题编写、分析和筛选的一般流程包含在第九章中。本章我们将关注被广泛使用的成绩测试的特点以及一些典型测试的特性。

目标范围。由于集中设计的测试在设计出来之后, 是要被各地区、各州甚至全国使用的, 因此标准化成绩测试只能涉及那些同一阶段的学生都有机会学过的知识。446测试设计者必须考察所有可能采用测试的学区的学习目标, 并且只挑选大多数学校共有的那些目标。因此, 标准化成绩测试并不像通常以为的那样十分注重死记硬背的知识, 因为各个课程体系之间几乎不可能在这类内容上有相似点。事实上, 测试设计者倾向于选择那些需要用到阅读理解、图表解读等获取知识的技能的测试。

包含常模资料。集中设计的测试与地区设计的测试相比, 最突出的特点就是它包含常模资料。标准化测试这一词就暗示了这些测试中含有常模资料 (尽管这个词汇事实上是指使用统一的施测程序), 测试的公布者会提供一系列常模信息来帮助解释测试成绩。第三章详细地描述了这类与测试共同给出的常模信息。

常模资料通过与其他同一年级的学生进行比较, 为学生的成绩提供解释和意义。 它们能得出阿曼达与其他同龄的或者同年级的或者来自于同类学校体系的学生相比, 她在数学方面的表现如何。因为测试组合中的所有题目都是以同类学生为标准设计的。这些常模资料也能得出阿曼达在数学上的表现相对于其在阅读中的表现如何, 抑或是詹森的阅读成绩与他的学术能力倾向相比又如何。这些常模资料也能被用来比较某一学校与全国的其他学校的表现, 这些学校可以是同一类的学校, 也可以是某一类社区中的学校。但是正如我们在第三章中指出的, 在进行这类比较时必须谨慎。

常模样本的质量绝大程度上由测试发布者的投入决定。因为常模样本可能包括成千上万的学生, 这要花费很多的财力。在阅读标准化成绩测试指南时, 审阅人很容易就会被为确保涉及大量有代表性的样本所做出的努力和投入打动。当然, 事实上测试发布者很难获取真正意义上的随机样本, 因为他们只能在获取许可的学区进行初步的标准化测试。而这些先行进行测试的学区往往都已经在使用发布者设计的一些测试了。尽管如此, 所有主要的测试发布者都会尽力保证标准化成绩测试的常模样本在重要的人口统计变量上能够代表可能的测试用户, 这些变量包括性别、种族、 社区类型和地理区域。如果不这么做的话, 就相当于在扼杀自己的生意。

## 13.3 标准化成绩测试的用途

在考虑了刚刚提到的标准化成绩测试的特点以及第七章中有关成绩测试结果对做哪些决策最有效的信息, 我们得出了以下这些结论。它们都关于标准化成绩测试能对于提供最有用信息的决策类型:

1. 日常的教学决策应主要根据地方性的测试来决定, 而不是根据标准化测试来确定。

2. 评分决策应该主要以地方性测试为依据, 以及包括有关单元或课程所教知识的学期论文或学期项目的其他评价类型。但是, 这也要根据该州或该校区在多大程度上对当地学校实施了该课程。

3. 诊断和弥补措施可以同时依据通过商业设计的诊断性测试及地方性测试得出的信息。

4. 分级决策需要进行大范围的学业成绩评估, 分数有统一标准的标准化成绩测试在判别学生的入学表现时会十分有用。

5. 指导和咨询决策通常是在标准化测试得出的常模比较的基础上做出的。

6. 选拔决策通常都意味着要与其他人进行比较, 对于这些比较而言, 充足的常模信息就变得十分重要, 要得到这些常模信息就意味着需要进行标准化测试。

7. 课程决策意味着要对不同项目进行广泛的比较, 这其中标准化测试可发挥其作用, 并且那些为特殊目标设置的地区性测试通常也能起到补充的作用。

8. 和课程决策一样, 公共政策决策也需要全面地了解学校的表现。因此标准化测试所具有的广泛性和比较性特点就有很大的价值了。

## 13.4 标准化成绩测试的类别

早期的客观成绩测试通常都是衡量考生单个学科的表现。如果学区想要评估学生在多个学科的表现, 比如阅读、数学和社会科学等, 那么它们就需要设计不同的测试以达到目的。使用那么多不同的测试非常昂贵并且很耗时, 这也需要教师们熟悉很多不同测试的规范化流程和施试流程。在过去几十年内, 这些单独的、不协调的测试都被测试组合所代替。这些测试组合可通过测试试卷册来实施。

这些整理好的测试组合有很多重要的优势。它们都经过全面的规划, 测试的组成部分都包含主要的学术技能和课程领域。每一部分都是在考虑其他部分之后设计的, 因此重复性可以降到最低, 并且重要的内容也能同时包含在测试组合内。

更重要的优势是这些测试组合的子测试已经在同类学生样本中进行过常模比较。在基于同一组学生使用组合测试的常模参照时, 个体内部以及个体之间的比较、 团体内部以及团体之间的比较会更加直接。如果参照组随着测试变化而变化, 那么测试组合就会出现更多问题。当然, 使用成绩测试组合也可能会有一些弊端。在比较不同的测试组合之后, 我们可能会根据自己的地方课程以及课程目标从一个测试组合中选择数学测试, 从另一个测试组合中选择语言测试, 再从其他测试组合中选择阅读测试。但是, 考虑到标准化测试最常使用的比较类型, 使用统一的常模参照 (和测试设计) 所得的好处要远远超过采用包含有一两个不太理想的测试的组合产生的损失。

## 13.5 群组标准化成绩测试

目前主要有五类规模较大的成绩测试组合, 它们是: 由麦格劳-希尔 (McGraw-Hill)发布的加利福尼亚成绩测试 (CAT) (也称为特拉诺瓦测试, 有英文和西班牙语两个版本); 同样是由麦格劳一希尔发布的基本技能综合测试 (CTBS); 由河滨出版公司(Riverside Publishing Company)发布的爱荷华州基础技能测试 (ITBS); 由美国心理公司 (The Psychological Corporation) 发布的都会成绩测试 (MAT); 以及由美国心理公司发布的斯坦福成绩测试 (SAT)。所有这些测试都包含差不多的技能, 但是每组测试组合都把这块 “技能派” 分割成了不同的数量, 然后重新进行组合。所以有些测试组合会比其他一些更早地涉及某些指定的话题。通常测试内容的领域包括阅读、语言技能、数学、科学、社会学、学习或研究技能及一个综合的学业成绩。每种测试适合的年级请见表 13-1 。



表 13-1 主要标准化成绩测试覆盖的年级范围

<table><tr><td>\( x \) 平</td><td>CAT</td><td>CTBS</td><td>ITBS</td><td>MAT</td><td>SAT</td></tr><tr><td>1</td><td>K. \( 0 - \mathrm{K}{.9} \)</td><td>K. \( 0 - \) K. 9</td><td>K. \( 1 - {1.5} \)</td><td>K. \( 0 - \mathrm{K}{.5} \)</td><td>1. \( 5 - {2.5} \)</td></tr><tr><td>2</td><td>K. \( 6 - {2.2} \)</td><td>K. 6 - 1. 6</td><td>K. \( 8 - {1.9} \)</td><td>K. \( 5 - {1.5} \)</td><td>2. \( 5 - {3.5} \)</td></tr><tr><td>3</td><td>1. 6-3.2</td><td>1. 0---2. 2</td><td>1.7-2.6</td><td>1.5-2.5</td><td>3. \( 5 - {4.5} \)</td></tr><tr><td>1</td><td>2. \( 6 - {4.2} \)</td><td>1. 6-3. 2</td><td>2. \( 5 - {3.5} \)</td><td>2. \( 5 - {3.5} \)</td><td>4. 5 . 5</td></tr><tr><td>5</td><td>3. \( 6 - {5.2} \)</td><td>2. 6-4.2</td><td>3</td><td>3. \( 5 - {4.5} \)</td><td>5. 5-6.5</td></tr><tr><td>3</td><td>4. 6-6.2</td><td>3. 6 - 5.2</td><td>4</td><td>4. \( 5 - {5.5} \)</td><td>7. \( 5 - {8.5} \)</td></tr><tr><td>7</td><td>5. 6-7.2</td><td>4. \( 6 - {6.2} \)</td><td>5</td><td>5. 5 . 5</td><td>8. \( 5 - {9.9} \)</td></tr><tr><td>8</td><td>6. 6-8.2</td><td>5. 6 7.2</td><td>6</td><td>6. \( 5 - {7.5} \)</td><td>9.0 -9.9</td></tr><tr><td>8</td><td>7. 6-9.2</td><td>6. 6---9. 2</td><td>5</td><td>7. \( 5 - {8.5} \)</td><td>10.0-10.9</td></tr><tr><td>10</td><td>8. 6---11.2</td><td>8. 6-11.2</td><td>\( {8}^{\mathrm{b}} \)</td><td>8. 5 - 9.5</td><td>11. 0---13. 0</td></tr><tr><td>11</td><td>10. 6-12.9</td><td>10.6-12.9</td><td>\( {\mathbf{8}}^{\mathrm{b}} \)</td><td>9</td><td/></tr><tr><td>12</td><td/><td/><td>\( {10}^{\mathrm{b}} \)</td><td>10</td><td/></tr><tr><td>13</td><td/><td/><td>\( {11} - {12}^{\mathrm{b}} \)</td><td>11—12</td><td/></tr></table>

\( {}^{a} \) 不同的发布者对其测试的不同等级使用不同的标示。表中给出的数值不与任何发布者公布的数值相对应。

\( {}^{b} \) 该范围是爱荷华州教育发展测试和学术能力测试覆盖的范围。



所有这些测试组合都已经存在很多年了, 并且已经经历过多次修改。大多数情况下, 任何时候都能找到至少两个版本的测试。这些测试在开发时, 都投入了相似的时间和精力, 并且也花了大量的时间来实施这些测试。它们总体的质量都很高, 并且它们涵盖了相似范围的学生以及相似的内容领域。但是从不同的测试中得出的单独分数的数量会有所不同, 少至 5 个, 多至 20 个。测试的开发过程以及规范化程序大体来说都是具有典范性的。这些测试在具体的题目、分试题规模、测试开发技巧、重要因素以及每种测试的特定目标都有所不同。每个决定使用哪种测试的人都需要认真比较各种测试, 来决定哪些测试目标和成绩报告是最符合当地情况的。

为了说明初级和高级测试在形式和内容上的变化情况, 图 13-1 包含与爱荷华州基础技能测试和爱荷华州教育发展测试 (ITED) 中阅读子测试相似的样题。随着考生年龄增大, 也变得越来越具有独立能力, 测试形式由教师主导的口语形式转变为学生主导的、完全的书写形式。图片在低等级的测试中经常出现, 因为在这个阶段学生还在建立基本的解码技能。同时, 低等级的测试也会更加注重词语分析及解码技能。 但是, 较高等级的测试则更加注重词语的含义及连续文本的阅读, 然后回答一些测试阅读能力的问题。

爱荷华州基础技能测试六级 (K.8-1.9) 初级早期测试组合

阅读: 词汇 (13 题), 10 分钟

教师说: “涂黑单词‘告诉’下面的圆圈。”

带走 告诉 谈话 喊叫

阅读: 图片 (13 题), 8 分钟

教师说: “将最能描述图片内容的单词下的圆圈涂黑。”







男孩 外套 船 蝙蝠

阅读: 句子 (13 题), 10 分钟

学生应选择最恰当的单词填入如下横线所示空格中。

比利遛了他的_____

狗 猫 母亲 鸭子

阅读: 猜词 (7 题), 5 分钟

学生应将最符合句中最后一个单词的图片下的圆圈涂黑。

猫坐在窗户上 (The cat sits in the window)。







阅读: 图片故事 (3 幅图, 13 题), 12 分钟

一幅图画显示两个人正在以某种方式进行交流。学生回答 4-5 道关于图片中正在发生什么的 “是非题”。

图 13-1 与爱荷华州基础技能测试和爱荷华州教育发展测试中评估阅读能力类似的测试题

爱荷华州基础技能测试七级(1.7 - 2.6)初级测试组合

阅读: 图片 (6 幅图, 23 题), 12 分钟

七级与六级差不多, 其中有三幅图包含 “是非题” (14 题), 其他三幅图包含选择题。

阅读: 句子 (14 道是非题), 7 分钟

如果你父亲总是做晚饭, 那你妈妈做过晚饭吗?

阅读: 故事 (5 个故事, 19 题), 15 分钟

学生阅读由四五句话组成的一个故事, 然后回答三四道有关这个故事的选择题。最后一个故事要比前四个长得多。

爱荷华州基础技能测试八级(2.5 - 3.5)初级测试组合

阅读: 图片 (6 幅图, 23 题), 12 分钟

与七级一样。所有题目都是选择题。

阅读: 句子 (14 道是非题), 7 分钟

与七级一样。

阅读: 故事 (3 个故事, 24 题), 15 分钟

与七级一样, 但是故事更加复杂。

爱荷华州基础技能测试多级测试组合 \( \left( {3 - 9\text{年级}}\right) \)

测试题本包含 24 篇难度和长度递增的阅读文章, 其中包括部分诗歌。问题也越来越难, 要求更多的抽象思维和理解能力。测试按照一定的顺序进行排列, 这样的话不同水平的学生从测试题本的不同位置开始测试。比如, 达到九级的学生做第 1-44 题, 但是十级学生做 19-68 题。九级和十级共同做的题目是 19-44 题。交叉的部分使得测试能够将不同等级的学生作为一个组来进行测试。



<table><tr><td>等级</td><td>第一题</td><td>最后一题</td></tr><tr><td>9</td><td>1</td><td>44</td></tr><tr><td>10</td><td>19</td><td>68</td></tr><tr><td>11</td><td>30</td><td>83</td></tr><tr><td>1.2</td><td>45</td><td>100</td></tr><tr><td>13</td><td>68</td><td>124</td></tr><tr><td>14</td><td>84</td><td>141</td></tr></table>



爱荷华州教育发展测试阅读理解部分 (9-12 年级)

阅读成绩根据测试组合中社会研究、自然科学及文学解读部分的 118 道阅读理解题得出。

图 13-1 (续)

在这些随着年龄范围变化而产生的测试侧重点变化中, 有两个方面尤其值得注意。第一, 为了符合不断成长的学生的能力水平, 测试的性质有一个渐进的变化; 第二, 在较高等级的测试中, 这些测试都会涉及广泛的复杂技能, 而不是只解析某些明确界定的能力。你可以访问 http://www.riverpub.com/products/itbs/index.html 及相关的链接获到更多关于测试组合的内容。其他发布商的测试组合的相关细节也可从其各自的官网获得。

## 13.6 个人成绩测试

在过去的几年中, 越来越多的人开始使用针对个人单独实施的成绩测试作为衡量认知能力的一种补充或者来代替其他测试。对单独实施的成绩测试的兴趣主要来源于诊断各种学习障碍的需要。学习障碍的一个主要指标是认知能力测试成绩与成绩测试之间存在比预期大的差异。这种差异一般最早在检查小组测试的成绩时就会被注意到。

当某种学习障碍在基于小组测试成绩被发现后,一般程序会包括获取关于这个孩子的认知能力和成绩测试的更精确的预估。这就意味着要进行单独的认知能力测试, 比如第十二章中提到的那些测试。然后再进行个人成绩测试。最近一些类似的测试已经开发出来, 并且更多的测试正在开发中。

皮博迪个人成绩测试 (PIAT) 是最早的个人成绩测试之一, 最初由美国辅导服务公司发布, 现由培生评估公司设计 (见 http://ags.pearsonassessments.com/group.asp)。这项测试最早在 1970 年发布, 并且在 1989 年修订。现在的版本 PIAT-R/ \( \mathrm{{NU}} \) (NU代表新常模) 能被幼儿园及 11-22 岁的学生所使用,并且只需要一小时就能完成。成绩能通过基本资料、阅读认知、阅读理解、总体阅读、数学、拼写、总体测试、书面表达以及书面语言而得。但是并不是所有年级的学生都有以上这些成绩。

1985 年, 美国辅导服务公司再次发布了考夫曼教育成绩测试 (K-TEA)。2004 年, 考夫曼教育成绩测试修订版 (K-TEA II) 发布, 参照常模是 4.6 岁到 25 岁的学生。该测试有两种平行的形式, 每种测试形式都有两个版本。简略版大约需要半小时来完成, 能提供阅读、数学、拼写和测试组合的成绩。完整版大约需要 60 -75 分钟才能完成, 它将阅读成绩测试细分为阅读解码、阅读理解和综合阅读。相似地, 数学测试也分为数学应用、数学计算和综合数学。拼写和综合测试组合的成绩也能从中得出。总的来说, 考夫曼教育成绩测试包含 23 项成绩。每一种形式都能被 1-12 年级的学生所使用。更详细的信息见皮博迪个人成绩测试 II 所给的链接。

皮博迪个人成绩测试修订版现存的版本比通常的标准化测试要长一些。但是, 一个新的常模群体在 1998 年时使用了该项测试。这 3000 个样本的地区、性别、年龄、年级、民族和家庭教育都进行过分层挑选。这些考生不仅参加了皮博迪个人成绩测试修订版和考夫曼教育成绩测试修订版, 并且还参加了两个单独实施的诊断性成绩测试——重要数学测试及伍德科克阅读掌握测试。所有样本都做了这四项测试, 因而教育顾问能够获取大量的有关个人成绩测试的选择。考夫曼教育成绩测试修订版与考夫曼儿童能力测试组合第二版一起实施, 使考官能够直接比较能力测试和成绩测试的成绩, 以达到进行诊断的目的。

第三种单独实施的成绩测试是由河滨出版公司发布的伍德科克-约翰逊成绩测试第三版 (WJ-Ⅲ)。这项测试与考夫曼教育成绩测试修订版相类似, 因为它们是由452同一作者 (见第十二章) 发布的作为单独实施的认知能力测试的补充测试, 并且在同样的样本中进行过测试。一样的常模样本使得学业成绩与能力的对比比其他测试得出的结果更加直接。另外, 常模样本包括 2-90 岁的人, 使得测试能被学龄前和学龄后的人使用。这项标准测试组合需要大约 50-60 分钟来完成,下含 11 项子测试。 这些子测试通过不同的方式组合, 以得出 6 项总体的学业成绩: 泛读 : 泛读 : 污辨识、阅读流畅度及篇章理解子测试)、口语 (复述故事及理解方向子测试)、数学 (计算、 数学熟练度及应用问题子测试)、书面语言 (拼写、书写流畅度及写作), 以及书面表达 (书写流畅度及写作)。四种专门成绩能从这些子测试中被计算出来: 学术技能 (字母一单词辨识、计算和拼写)、学术熟练度 (阅读流畅度、数学熟练度和书写流畅度)、学术应用 (篇章理解、应用问题和写作), 以及学业总成绩 (除了口语测试之外的所有子测试)。拓展的测试组合增加了 8 项子测试和 9 项测试集合。正如我们在第十二章中所说的, 这项测试组合中数量的子测试为伍德科克-约翰逊成绩测试第三版的认知测试组合提供了数量能力的成绩。伍德科克-约翰逊成绩测试第三版是最为综合全面的单独实施的成绩测试组合, 并且与伍德科克-约翰逊成绩测试第三版的认知测试组合一起实施时能作为非常灵活的评估体系。

## 13.7 中学及大学水平成绩测试

在小学阶段, 标准化测试倾向于关注处理单词和数字的基本能力。在中学及大学阶段, 重点逐渐转移至某一专门的课程, 甚至是某些专门的科目。因为课程变得越来越分化, 也就是说课程越适合所有学生就越代表这群学生只是总数中的一小部分, 因此, 统一的综合性评估就不是那么需要了。但是, 在一些情况下, 标准化评估也可能适用。

二战结束后, 出于对军队中获得的教育经历进行评估和肯定的需要, 爱荷华州教育发展测试应运而生。跟所有的一般能力测试一样, 爱荷华州教育发展测试组合目前提供由河滨出版公司设计的团队实施的成绩测试系列爱荷华基本能力测试。该测试是为不同背景的考生而准备的。因此, 该项测试侧重一般知识及阅读和理解不同领域材料的能力。目前的第九版爱荷华基本能力测试 (Forsyth, Ainsley, Feldt, & Alnot, 2001), 有一些基于 2000 年和 2005 年收集的常模资料而设计的平行测试形式 \( \left( {\mathrm{A},{2001};\mathrm{B},{2003};\mathrm{C},{2007}}\right) \) ,并且该测试包含三个等级 (适合 9 年级的 15 级、适合 10 年级的 16 级及适合 11 和 12 年级的 17 和 18 级)。A 卷包含的子测试和试题已在表 13-2 中列出。除此之外, 该测试会提供一个综合的阅读测试成绩。试题的题目明确告诉我们测试的重点在于获取、使用及解释不同类型和从不同渠道获得的资料。几乎所有的子测试都强调阅读技能的重要性, 并且大多数子测试之间都高度相关。因此, 尽管整套测试能为之后的学业表现提供一个较好的预测, 但是这些子测试并不是有效的诊断工具。它们也并不与任何课程中所教的知识密切相关, 因此也不能预示整个学校课程的有效性。有关爱荷华州教育发展测试和爱荷华基本能力测试的详细信息请登录 http://www.education.uiowa.edu/ITP/index.htm。



表 13-2 爱荷华州教育发展测试 A 卷中的子测试时间限制和试题数量

<table><tr><td colspan="2" rowspan="3">测 试</td><td rowspan="3">测试 时间</td><td/><td colspan="3">题目数量</td></tr><tr><td>测试等级</td><td>15</td><td>16</td><td>\( {17}/{18} \)</td></tr><tr><td>年级</td><td>9</td><td>10</td><td>\( {11} - {12} \)</td></tr><tr><td rowspan="6">核心测试组合</td><td>词汇</td><td>15</td><td/><td>40</td><td>40</td><td>40</td></tr><tr><td>阅读理解</td><td>40</td><td/><td>44</td><td>44</td><td>44</td></tr><tr><td>语言: 修改书面材料</td><td>40</td><td/><td>56</td><td>56</td><td>56</td></tr><tr><td>拼写</td><td>10</td><td/><td>30</td><td>30</td><td>30</td></tr><tr><td>数学:概念和解题</td><td>40</td><td/><td>40</td><td>40</td><td>40</td></tr><tr><td>计算</td><td>15</td><td/><td>30</td><td>30</td><td>30</td></tr><tr><td colspan="2">核心测试小计</td><td>160</td><td/><td>240</td><td>240</td><td>240</td></tr><tr><td rowspan="3">补充测试</td><td>社会学科资料分析</td><td>40</td><td/><td>50</td><td>30</td><td>50</td></tr><tr><td>科学材料分析</td><td>40</td><td/><td>48</td><td>48</td><td>48</td></tr><tr><td>信息来源</td><td>20</td><td/><td>40</td><td>40</td><td>40</td></tr><tr><td colspan="2">合计</td><td>260</td><td/><td>378</td><td>378</td><td>378</td></tr></table>



其他高中测试组合中更为常规的、更有代表性的是成绩与能力测试 (TAP) K、L 和 \( \mathrm{M} \) 卷 (Scannell,Haugh,Loyd,&Risinger,1993,1996)。基本测试组合中有八项子测试, 包括:

1. 阅读理解

2. 词汇

3. 书面表达

4. 信息处理

5. 数学概念和解题

6. 社会学科

7. 科学

8. 数学计算 (选做)

完整的测试组合提供一个阅读总成绩, 该成绩综合词汇和阅读理解; 一个核心总分, 综合书面表达、数学概念和总体阅读; 一个综合所有子测试成绩的完整组合成绩。 正如你所看到的, 组合测试综合了基本技能 (阅读、书写和数学) 及各领域的内容 (社会学科、科学和文学)。但是, 即使是在内容领域, 大多数重点也是放在功能性知识上, 如解释数据及解释科学实验的设计等。这样的改变使得测试与初等教学的核心更为接近, 也使它们在比较不同的学校和课程时更为有用, 另外就是在制定与某个学生相关的指导决策时也更为有效。但是, 强调功能性知识也使这类测试在衡量特定的课程内容时没有那么有效。不管是爱荷华州教育发展测试和学业成绩及能力测试都可以增加书面评估。爱荷华州教育发展测试和学业成绩及能力测试都与爱荷华基本能力测试及认知能力测试 (第十二章) 一起实施,为整个 \( \mathrm{K} - {12} \) 年级提供一套完整的评估工具。

除了上面提到的这些组合测试之外, 还有另外一些名字与特定的课程密切相关的系列测试。其中一个系列就是由美国教育考试服务局合作测试部研发的。测试的性质能从数学测试的类型中得知: 数字系统的结构; 算术; 代数 I、II、III; 几何; 三角; 微积分。通常而言, 这系列的测试是为某些上过特定课程的学生设计的, 这些课程包括初等代数、生物或是世界史。常模资料就是基于这些学习过这类课程的学生样本得出的。因此, 影响学生选课与否的个体因素也可能会影响常模程序的整体性。目前很少有人付出过努力来维持不同领域分数之间的可比性。因此, 跨领域的比较还存在问题。一些案例中的测试内容可能很好地涵盖了整个课程的内容, 因此也可以在学期末用来测评每个学生的表现, 但是这一步必须小心实施, 以此来保证课程目标与测试内容相对应。或者, 标准化测试可以用来评估其目标中所涵盖的学业成绩, 然后地方性测试可以用来评估剩下的部分。在这种方法中, 测试目标也属于课程目标。

为某个特定课程设计的测试应该扮演的一个角色是使一些学生能免上一些课程。一部分原因是因为很多年轻人在军队中都已经接受过各种各样的培训, 一部分也是因为意识到某些学生已经通过媒体或者其他非正式的教学接受过一些教育—— 比如, 通过阅读、广播和电视, 或者工作经验等一 因此教育工作者需要一个渠道来通过考试鉴定这些经历。美国教育考试服务局的大学水平考试项目 (CLEP) 就是这样一个渠道。

大学水平考试项目为评估具有大学课程同等效力的经历提供了一个统一的全国程序。考试包含 35 个不同的内容领域, 包括会计、非洲裔美洲史、三角函数和西方文明等。常模资料来自那些已完成指定课程的大学生及那些参加过同等效力测试的学生。最后呈现的标准成绩从 200 到 800 不等, 500 是基本参考人群的平均分 (美国教育考试服务局在学术能力评估测试中也采取相同的衡量标准)。如何使用这种测试得出的成绩由该学生想要申请的大学或者想要得到同等学分的大学所决定。就认定考试和执业考试来说, 合格等级如何制定还相当随意。尽管一般的常模资料可能对于那些已经参加过课程考试的人而言也是有效的, 但是却没有资料专门适用于个人申请的大学。成绩平衡的转移节约了时间, 但是却没有避免根据成绩错误归类已经掌握了课程的学生。能力考试和资格证书考试在当今社会相当流行。各州似乎将考试运用到了每件事情中, 从授予驾驶权到决定谁能提供心理咨询服务, 都用到了考试。但是设立获取证书最低分数线的体系还十分不合理。关于大学水平考试项目的详细信息请登录 http://www.college-board.com/student/testing/clep/about.html。

## 13.8 全国范围内实施成绩测试组合的问题——“乌比冈湖效应”

二十年前, 在西弗吉尼亚州实施基本技能综合测试的成绩公布后, 该州的医生约翰・康奈尔 (John Cannell,1988) 开始担忧了。从成绩来看, 他所在的州每个接受测评的年级的成绩都高于全国平均水平。但是, 在这些成绩公布之前, 有明确的证据显示西弗吉尼亚有严重的教育问题。该州没有接受过大学教育的成人比重为全美最高, 人均收入全国倒数第二, 美国大学人学考试 (ACT) 成绩全国倒数第三。当康奈尔开始研究全国的标准化成绩测试结果时, 他发现的东西更令人感到不安。他发现 50 个州中没有一个州基础阶段的成绩低于平均水平。这种现象很快就得名为“乌比冈湖效应”。这个概念是由加里森·凯勒 (Garrison Keillor) 在他的小说《牧场之家好作伴》中描述虚构的故乡并在联合公众广播节目中播出时提出来的。在他的小说中, 这个故乡 “所有的女人都很强壮, 所有的男人都很帅, 所有的孩子都高于平均水平。”

所有州都高于平均水平这个发现应该像敲 13 下的钟声一样, 应该引起人们警觉。这其中肯定有什么错误。统计学的基本概念告诉我们, 不可能每一个孩子或者每一个州都在平均水平以上。测试发布者和使用测试的学区很快就出来为自己辩护。

其中最常听到的解释是在使用标准化测试之后学业成绩有了提升。在修订期间七八年的转变, 使得标准化和实际使用之间有了很大的差距。但是, 现存的证据并不支持该解释。大学入学考试和学业能力倾向测试成绩总体而言都在下滑 (虽然近几本稍有回升); 每隔几年在一些美国学生中举行一次的美国国家教育进展评估成绩也不怎么上升了, 军事服役职业倾向测试组合的成绩也是相似的情况。如果测试成绩在测试实施的第一年要低很多的话, 那么总体学业成绩在测试实施之后有所提高这个假设是可以成立的。城市成绩测试六卷、加利福尼亚成绩测试 \( \mathrm{E} \) 卷以及爱荷华州基础技能测试 \( \mathrm{G} \) 卷和 \( \mathrm{H} \) 卷都是在 1985 年和 1986 年之间开始实施的,但是一些刚刚实施这些测试州的报告成绩也相当高。那么高的成绩并不是因为教师根据测试进行教学, 因为教师在考试日期之前也都没有看到过测试题。这么高的成绩也并不是因为自从上次常模测试后有所提高, 因为上次常模测试还没过去足够长的时间。

如此多学生标准化成绩测试的成绩高于平均水平的第二个解释是这些参加考试的学生与常模样本不同。尽管测试发布者花巨资来规范其测试 (基本上样本数量都会超过 20 万), 但是他们仍然没办法保证这些样本真正具有代表性, 因为正如之前提到的, 这些以规范为目的的测试只能在得到允许的地方实施。因此, 这些样本和 “真正”评估时使用测试的学生是不一样的。很多学区倾向于把那些得分可能较低的学生排除在测试之外, 比如像接受特殊教育或其他专门教育项目的学生, 这种情况就进一步加深了上述问题。常模规范研究中通常都要求包含这些学生, 使得到的常模资料能代表真实的学生群体, 而不是经过选择的一部分。一些学区或者地区的某些教师会将得分可能较低的学生排除在外, 或者至少不鼓励他们参加测试。当把这些表现较差的学生排除在外, 参与考试学生的教师或者学区就有把握使他们的表现高于常模学生群体。《有教无类法案》的要求可能会最终杜绝这种行为。

那么多学生的成绩高于平均水平的第三个解释是测试过程直接导致的课程变化。由于测试结果受到越来越多的重视, 改变课程以适应测试的可能性越来越大。 这其中的一些转变是合法的——只要他们不涉及应试教育。但是, 即使是最合法的形式, 改变课程来迎合测试目标也会破坏测试的抽样假设。因此抽样得出的标准成绩也会失去它们的意义。测试发布者也在一定程度上会加重问题, 因为他们会编制有关学生的信息以及基于每道题目学生课堂表现的详细报告, 如第三章所描述的一样。教师和学生能发现最常出现的错误是什么是具有教育价值的。但是如果这些知识使教学的关注范围变窄, 那么在逐渐地使常模数据无效之后, 这些测试也可能起到反作用。

如果一位教师意识到他的学生在做测试的时候总是忘了大写亚利桑那州州名一词, 那么这位教师告诉其学生总是要大写亚利桑那州 (Arizona) 这个词显然是不合适的。换个角度来说, 如果教师更改课程计划, 告诉学生所有州州名的单词都要大写的话, 就显得合理多了。但是, 这样的行为会改变抽样测试得出的成绩的意义, 因为标准化成绩测试是用来考察学生的行为, 然后从中得出一些普遍的情况。如果教师不知道测试包含了什么内容的话, 他们就必须确保其教学的内容包含了所有可能被测试的问题。另一方面, 如果教师知道测试大纲并且只教授大纲上的知识, 测试的内容抽样就会受到影响。参加这些测试的学生就只能学到测试所涵盖的一小部分内容。 比如, 当教师知道试题强调州名的大写, 但是却没有教会学生国家名称也要大写, 因为这类题目通常不会考到。在这种情况下, 课程的重点就会变窄。

那么多学生的成绩高于平均水平的另一个解释是教师可能在教授与测试相关的内容或者实施测试的时候没有按照标准的方式, 导致成绩升高。比如教师在考试过程中给予了学生不恰当的帮助, 或者给那些没办法在指定时间内做完测试的同学延时以使其完成测试。在初级阶段, 测试一般是在教室内没人监考的情况下实施。当过度重视学生的表现或者测试时没有人监考, 作弊的可能性就会上升。

两种公共政策因素会导致上述问题。第一, 教师一般都有压力要使他们的学生考好, 因为测试成绩可能会成为评估教师的基础。如果教师班里的学生在全州的考试或者学区考试中的表现低于平均水平, 那么他或者她的教学能力就会受到质疑。第二, 在教育行政管理层级上, 那些有责任使测试按标准实施的人可能更希望测试成绩上升, 因为测试成绩通常也是他们的评估基础。在很多州, 标准化测试结果通常都会作为教育系统的成绩单而被公众、媒体和立法机关所关注。结果, 测试项目各个层级的负责人都面临着利益与忽略可能导致成绩升高的不恰当的测试实施过程两者之间的问题。《有教无类法案》中的有些条款也可能会导致这些现象出现。

显然, 教师无论是给学生过多的时间来完成测试或者是帮助学生答题都是在作弊。相似地, 如果教师教学生测试中的问题也是不恰当的。但是, 如果教师因为担心学生在成绩测试中的表现而十分努力地让其学生掌握更多的知识, 或者鼓励学生更加刻苦地学习, 那么就不能算是作弊。事实上, 这样的行为可能会被看作榜样。但是像下列这些灰色区域可能就会引起问题: 教师使用与实际测试差不多的试题, 或者只关注测试中会出现的主题。这些行为都是不道德的, 但遗憾的是, 它们都很普遍。

一些学区甚至实施过一些系统的学习项目, 这些项目的课程都侧重于成绩测试的特定内容。测试发布者也编制了相应的指导测试的材料, 这也会影响学生的表现。 当然, 课程指南和测试内容之间的关系就像是一条双行道。如果测试发布者从普及的教学指南中选取测试的内容, 那么测试也很有可能被课程设计者所影响。

## 13.9 解析标准化成绩测试

标准化成绩测试的目的是为每个技能领域产生一个可靠的得分 (信度系数在 85 分以上或者 95 分以下之间的相当具有典型性)。测试兴趣往往集中在子测试成绩以及学生、班级、学校、学区的优势和弱势上。我们不仅想知道彼得的数学成绩和全国标准水平之间存在的差距, 我们也想知道数学成绩和测试组合中其他科目的成绩的差异。我们想知道艾伯森老师班上的学生在数学概念的掌握方面, 相比于计算能力的情况如何。我们也想知道, 在哪些方面彼得伯勒学区学校的表现优于平均水平, 在哪些方面则表现不足。另外, 我们可能会进一步想知道这些差异是否反映了所需的课程重点; 学校管理者、教师、家长及公众是否应该关注这些方面; 是否应该采取一些补救措施?

当涉及课堂教学决策, 调查成绩测试组合的子测试成绩并没有太大的价值。如果彼得在大写字母技能方面取得的成绩低于他现在所在年级的表现, 应该采取什么措施? 比起数学计算, 艾伯森老师所教班级在数学概念上取得的成绩低于年级平均水平, 艾伯森老师该采取什么样的措施? 她应该再教一些什么或者应该重新教一些什么内容? 回答这个问题的一个方法是看大写字母测试中彼得答错了哪些问题, 以及去了解艾伯森老师所教班级的学生不清楚哪些具体的数学概念。测试发布者提供的评分服务可以提供个人或者是部分学生的成绩。

因为大规模的测试项目是由计算机来评分和解析的, 只有评分项目的简单修改需要更多关于个人和班级成绩的详细信息。成绩报告单可以反映彼得在大写字母子测试中回答错误的题目。报告的项目也可以按照错误题目中包含的大写拼写规则来对这些错题进行分组。整个班级存在的数学问题也可以在报告中得到反映。通过这些信息, 艾伯森老师可以判定彼得的大写拼写错误是出现在句子的开头, 引证的开头, 人名、地名或者是其他地方。她也可以得知整个班级在各种概念和数学计算能力中的犯错频率。这个分析可以识别不同的学习困难并且提供相应的指导。通过这些报告, 测试出题者可以帮助老师们知道哪些内容需要一直重视一直去做, 也就是说, 深入探究规范测试的成绩来识别个人或者整个班级在具体测试中遇到了哪些困难。 第三章列举了这些能产生这类有效信息的报告。

详细分析特定试题对错的原因对教师来说有非常大的帮助。然而, 使用这个方法有一些需要特别注意的点。第一, 这些测试不包含足够的试题来充分评估每个特定的技能, 因为测试中涉及每个技能的题目可能只有一两个, 学生可以通过猜题来答对题目, 也可能因为分心或者其他与基本技能无关的原因答错题目。用一两个题目来判断一个学生是否掌握基本技能是十分不可靠的, 尽管未能正确回答问题可以提醒老师要全面测试这方面的知识技能, 也许在短期内由老师出的那些试题可以主要集中在那些同学做错的领域上。同样地, 如果大部分学生做错了某道题目, 这就可能需要实施更全面的测试来确定是不是整个班级在该类学习技能的掌握方面存在欠缺。

用一两道试题来评估教学目标是否实现存在更多的不足。如果教师对学生失分的题目很熟悉, 并且有压力要提高学生的成绩, 他们会倾向于教这些特定的题目或者至少会教这些题目的某些类型。这种方法会使成绩升高,但也可能导致“乌比冈湖效应”。

如果测试结果的分析对老师有帮助, 那它应该在测试结束后尽快到老师手上。 因为现代的、基于计算机的测试一般都是集中批改出分, 这不可避免地会在测试和教师得到测试成绩报告之间存在延迟。延迟都会使得该报告对学生或者整个班级的决策指导缺乏时效性。学习新的内容后, 以前学过的知识可能会被遗忘, 报告的准确性可能会降低。基于这些原因, 加快完成测试程序非常重要, 将参与学校的答卷集中起来, 加速将材料送至批改部门。从那一刻起, 教师可能就在美国邮政服务和写评分报告的部门的摆布之下了。

大多数测试评分服务非常重视测试和结果之间的时滞问题, 所以它们提供一个 24 小时的周转时间。在很多测试中, 测试结果还可以电子化传输, 所以测试试卷从来不会离开学校或者学区。这个过程需要扫描和电脑设备, 除了一些小地区, 大部分地方都具备这些实施条件。周转时间问题在整个州实施的测试中比较严重, 因为测试分析和成绩出来之前, 所有学校都要上交测试反馈。在一些情况下, 即使在当年拿到了测试结果, 也可能由于技术原因或者政治原因造成的程序处理问题, 使当年的测试报告无法顺利得到。当老师拿到这些测试结果时, 使用它们对相关学生制订教学计划为时已晚。

## 13.10 诊断型成绩测试

诊断主要涉及单个个人。为什么莎拉在阅读能力的考查测试中只得了低分? 为什么彼得在成绩测试组合的数学子测试中只取得了低分? 为什么他们会觉得难? 大多数情况下,诊断测试是在学生已经进行过测试或者说老师已经发现该学生在阅读、460数学或者其他科目中没有取得进步后实施的。虽然大多数诊断测试是针对个人的, 使用之前描述过的针对个人实施的成绩测试, 但是一些标准测试也可以起到诊断的作用并且可以适用于团体。下面我们举一个例子, 来阐明诊断型成绩测试的目的以及它是如何实施的, 还有其在使用和解释过程中存在的问题。

斯坦福诊断数学能力测试第四版出版于 2003 年, 是为 1.5-13 年级的学生设计的。该测试用颜色来区分不同的水平: 红色表示初级中段到二级中段以及三级水平中表现较差的学生; 橘色表示二级中段到三级中段的学生; 绿色表示三到四级以及在五级中表现较差的学生; 紫色表示四到六级中段以及在七级中表现较差的学生; 蓝色表示八到十三级。所有的六个层级从概念应用及计算能力两个方面来评价学生的数学能力。测试既有传统的笔试也有在线测试, 这样使得测试结果马上可以知晓。更多信息详见 http://harcourtassessment.com/haiweb/cultures/en-us/productdetail.htm? pid \( = {015} - {8893} - {45}\mathrm{\;X} \) 。

常模参照分数包括比例分数、年级当量、百分位数、正态曲线当量, 每一项子测试都是九分评分制。学生的每一项技能子测试都会得到一个原始分数, 该分数可以用来判断该学生成绩是高于还是低于录取分数线。

该测试已经针对秋天及春天进行过常模处理。但出于最大价值的考虑, 建议在秋季实施该测试, 这样可以立即进行诊断和弥补。在选定测试实施的年级时, 年级和学生的实际水平都应该考虑进去。太难或者太简单的测试都不能达到诊断目标。测试是结构化的, 这样可以在同一天内实施一项或者两项测试。如果一天内需要进行两项测试, 两项测试之间最好有十分钟的休息间隔。

在诊断中, 子测试成绩分析仅仅是第一步。包含在子测试中的特定技能的表现也必须被考查。但即使有这些分析, 可能还是不够的。如果比较彼得和他所在年级的常模成绩, 并且发现他的最低分数是整数乘法, 我们仍然不知道他在乘法的什么方面有问题。我们有进一步的指导来指示我们对于哪些方面应该进一步探究, 但我们仍然需要分析彼得乘法错误的问题来确定他是在概念上还是在计算过程上存在问题, 或者是否是因为没有掌握好算术。在初步确定弱势领域后, 我们需要观察彼得在这一领域的运算过程从而确定他做错了什么并且对错误原因进行假设。全面的诊断研究通常需要观察学生表现的整个过程和结果。

如果班里的单个学生在子测试中显示出了某方面的弱项, 我们首先应该寻找学生学习知识上的缺陷。如果一个班级的学生在子测试上都表现较差, 我们应该质问教学质量是否过关, 或者观察在地方课程中某些科目的引入是否有所延迟。地方测试结果和全国常模成绩之间的差异只证明了地方课程应该在何时引进科目这一问题上同意试题发布者的假设。如果在进行测试的时候, 某个主题 (如分数) 还没有教到, 显然没有必要去测试这个主题是否被掌握。在诊断测试中, 测试组过去的教学历史和教学重点必然会影响班级在诊断型测试组合中成绩的解析。

因为只有当子测试的材料涉及的内容是被教过的内容时, 子测试才能够提供有意义的诊断线索。我们可能会质疑分数和小数的材料是否为四、五年级组提供了有用的诊断信息。如果子测试的平均测试结果非常接近于机会得分, 我们将无法识别有缺陷的表现, 这就是测量学生没有学过的那些技能时会出现的情况。通常来说, 一项测试如果能更好地暴露学生的学习问题时, 那它用来判定学业成绩的能力会差一些。缺陷诊断功能和学业能力评价两者不相容, 一项测试能够满足其中一个目的却往往不能满足另一个。通常,诊断测试应更多按照标准参照或者掌握能力测试来设计, 这样平均水平考生的期望分数将会接近于理想分数, 对解释学习能力的缺陷和程度也可能更有价值。

斯坦福阅读诊断测试这个平行的测试组合, 可用来评估学生的阅读能力。测试也同样具有六级 (使用相同的颜色代码) 和相同类型的常模参照分数量表。所有六个层级都要评估词汇和阅读能力。前三个层级也有一个语音分析子测试, 另外三个更高层级有扫读子测试。这两项诊断成绩测试与斯坦福成绩测试的第九版具有同样的常模。

## 13.11 标准参照的标准化成绩测试

对引进课程测试的标准参照方法的热情使研究者产生了兴趣, 他们欲将该方法应用到标准化成绩测试中去。标准参照的标准化成绩测试有以下两种构建方法:(1)可以将目前常模参照中的试题纳入标准参照测试中; (2) 成绩测试可以被当作标准参照测试重新进行构建。第一种方法使用比较广泛, 然而并没有很多学校实施第二种标准参照考试。

## 1. 标准参照的标准化成绩测试案例

培生教育集团的分部哈考特测评集团的心理公司有两种阅读能力测试, 而这两种测试是城市成绩测试的组成部分: (1) 阅读调查测试; (2) 阅读诊断测试。第一个测试组合和标准参照的调查成绩测试相似, 第二个测试则是包含基本阅读技能的标准参照测试。关于城市学业成绩测试的详细资料可以通过以下网址获取: http:// harcourtassessment. com/haiweb/cultures/en-us/productdetail. htm? pid = E164C。 霍顿・米夫林公司 (Houghton Mifflin) 提供了 5000 道测试题, 可以在学校课程目标参照评估中根据老师和课程设置的需要来选择相应的试题组成标准参照测试。

密苏里大学的史蒂文・奥斯特林德 (Steven Osterlind) 尝试设计一个测试来衡量大学基本学科知识和技能的掌握情况。他使用的大学基础学科考试 (大学 BASE) 可用来评估个人及团体的表现。这个测试测量学生在英语、数学、科学和社会研究科目取得的成绩。成绩报告包括 4 个主要科目的成绩、总成绩、 9 个成绩组和 23 项具体技能的成绩。另外 3 项推理能力也有成绩来衡量, 其中包括解释能力、策略能力和适应能力。个人评估需要 3 个小时; 但是在评估团体表现时, 最后是算所有学生的平均成绩, 测试可以在 45 分钟内完成, 因为每个学生只需要完成测试的四分之一。在测试中可以加入写作题来评估学生的写作能力。这个测试可以在密苏里大学的网站中看到,具体网址如下: http://arc.missouri.edu/index.php? \( p = /\mathrm{{CB}}/ \) CBhome. htm。

## 2. 标准参照的标准化成绩测试存在的问题

通常来说,要用一个测试来同时满足常模参照和标准参照评估的要求是不可能的, 因为标准参照测试需要与班级或者学区的具体教学目标紧密相连。全国性成绩测试的发布者必须避免任何在大多数学区的课程中没有出现的目标。关注共同的目标在低年级及阅读和数学中效果较好, 因为在这些领域, 校区对于应该强调哪些目标都达成了一致。标准参考标准化成绩测试的需求使得一些试题出版商将教学目标与现有的试题结合起来, 并且声称这些新的测试可以用作标准参照测试。这些测试更加适合被称为目标参照测试, 而且被认为是一种效果不理想的评估形式。标准参照评估具有吸引力, 因为它避免了一些由测试带来的负面情况, 它不把没有考好的学生当作失败者。它也更为有用, 因为它提供了学生表现的具体信息。

虽然标准参照标准化成绩测试具有重要的优势, 就像刚刚列举的那些, 但要在标准化成绩测试中运用标准参照方法还存在很多逻辑问题, 需要实施大量的试题来可靠地评估大量的教学目标。比如, 在城市阅读诊断测试中, 大多数年级的测试都包含 200 多道题目, 但在评估某些目标时只包含 3 道题目。在城市成绩测试中, 只用 60 道题目来评估整体的阅读成绩。为了衡量一些东西, 不管是阅读理解能力等技能, 还是能否进行两位数加法运算这样的教学目标, 都需要适当数量的试题来衡量; 也就是说, 一项测评大量教学目标的测试报告肯定应比一个只汇报 7 个子测试分数的报告要长。

## 13.12 总 结

大多数标准化测试包括从一小部分相似的测试中选取的调查测试组合。测试通常会使用诊断测试和标准参照测试。调查测试通常在与选拔、分班、指导、课程和公共政策有关的决策中非常有用。诊断测试通常用来确定学生的优势和劣势。诊断测试实施起来很困难并且很耗时间。

在中学和大学阶段, 统一设计的学业成绩测试主要为能力的高低提供证据, 测试成绩好就证明能力出众, 能为优先分级提供依据。全州实施的成绩测试的一个重要争议点就在于“乌比冈湖效应”, 因为它使分数上升, 这样一来测试结果就很难正确解读。另一个问题是教育者总是在两种选项之间犹豫不定, 即他们是用目标参照来解释当地学校的学业成绩表现, 还是在全州用统一的评价标准来评价不同学校及学校系统的教学效果。

## 13.13 习 题

1. 标准化测试对于以下哪种目的较为有用? 对于哪些目标, 老师会希望自己出测试题? 为什么?

a. 确定哪些学生已经掌握了分数的加法和减法

b. 确定哪些学生的数学计算能力低于预期水平

c. 确定每个学生最擅长和最弱的科目

d. 确定需要在哪些班级进一步教授标点符号和大写技能

e. 在阅读教学课上成立阅读小组

2. 获取一份课程指南, 指南中要涵盖你正在教的, 或者打算教的, 抑或是将来可能教的科目的内容以及教学目标。仔细研究这个科目的一份标准成绩测试题。课程指南中的哪些目标在该测试中得到恰当测量? 哪些没有? 这个测试涵盖了多少课程内容?

3. 理性比较同一年级的两项不同的成绩测试组合。它们的区别在哪里? 你认为各自的优势在哪里?

4. 一项测试的指南声称它具备诊断的作用。你可以用什么标准去判定它是否真的具有诊断价值。

5. 为什么我们需要关心一组诊断测试的分数的信度? 信度对使用和解释这些测试有什么影响?

6. 一个从三所初中获得生源的高中有一个专门的数学提高班。如果按照九年级末标准成绩测试的分数来挑选学生参加该班, 它有什么优点和缺点?

7. 10 月, 你在四年级学生中进行了一次标准学业成绩组合测试。作为教师, 你将怎样使用这个测试结果?

8. 使用集中评分服务的一所学校购买了试题分析资料, 包括学校中每个年级和每个班的学生答题的正确率。学校该如何使用这些结果? 教师个人又该如何使用它们?

9. 六年级的卡森老师说: “比起学生的表现, 她更关心学生在课堂中的进步”。 从测量的角度看, 她的观点涉及哪些问题?

10. 从试验角度出发在某些小学中, 森特维尔的学校体系打算引入一个经修订的数学课程。这个计划旨在全面推行该课程之前, 先评估这个课程的效果。在小学数学科目中, 标准化成绩测试对这样的评估有多大的意义? 在这个过程中, 可能会出现什么问题? 如何解决这些问题?

11. 某州立法机关通过了一部法律, 要求所有学生必须掌握必备的生活技能才能获得高中文凭。实施这部法律首先要解决的问题是什么? 使用以下测试方法来判定能力高低的优缺点是什么?

a. 由各州教育部门统一设计的测试

b. 各地每个学校自行设计的测试

c. 全国统一发布的学业成绩测试

## 推 荐 阅 读

Cannell, J. J. (1988). Nationally normed elementary achievement testing in America's public schools: How all 50 states are above the national average. Educational Measurement: Issues and Practice, 7(2), 5-9.

Ferrara, S., & DeMauro, G. E. (2006). Standardized assessment of individual achievement. In R. L. Brennan (Ed.), Educational measurement (4th ed.). Westport, CT: Praeger.

Hall, B. W. (1985). Survey of the technical characteristics of published educational achievement tests. Educational Measurement : Issues and Practice, 4(1), 6-14.

Mehrens, W. A. (1987). Using standardized tests in education. New York: Longman.

Shepard, L. A. (2006). Classroom assessment. In R. L. Brennan (Ed.), Educational measurement (4th ed.). Westport, CT: Praeger.

## 第14章 兴趣、性格和调整能力

## 14.1 引 言

我们现在来探讨已出版的兴趣、性格和适应能力测评方法和程序, 关注点从一个人尽最大努力能做到什么转变为在日常生活环境中可能会做什么。大多数人都对性格及兴趣测试很好奇, 想要更好地了解自己或做出更好的决策, 并相信性格及兴趣测试在这方面可能会有所帮助。兴趣测试提供的信息对面临职业选择的人尤为重要, 了解个人兴趣模式有助于确定最适合自身生活方式及生活目标的职业选择和机遇。

自我认知对大多数人来说至关重要, 但我们往往会不加鉴别地对待自我认知测试, 有些人即便对那些以测试开发最高标准编制出来的测试方法进行认知能力测试持怀疑态度, 通常也会认可性格测试结果, 甚至性格测试开发过程中完全没有考虑测试编制标准。这里我们需要强调的是, 兴趣及性格测试对预期目的非常有用, 但前提条件是测试必须经过高标准的精心编制, 且只应在测试开发人员规定的范围内进行。

兴趣测试能够提供被测试者个人好恶一般模式的相关信息。不同个人的好恶情况往往相差很大。例如两个人在选择如何度过空闲时间时, 一人可能选择坐下来静静读书, 而另一个则会进行某项户外体育活动。你会选择哪个? 你倾向于作为团队的一分子来开展项目, 还是独自开展工作? 你愿意逛花店还是游乐园? 你想去欣赏歌剧还是去听摇滚音乐会? 我们很容易理解此类偏好可能会影响人的职业生涯满意度, 因为工作中如果能够越来越多地开展自己喜欢的任务, 那么我们对工作环境的总体满意度就会越高。

性格测试用于评估个人特质的类型, 每个人都有自己独特的性格特征类型。某些情况下, 性格测试评估较为普遍, 能够大概描述出某个人是什么样子的。但有些性格测试则用于测量更具体的特征, 如多大程度上可以认为被测试者性格内向或性格外向。而适应能力测试则用于评估多大程度上可以认为被测试者的个人特征能够适应日常生活情况。某些性格特征与心理健康和良好适应能力有很大关系, 例如有效应对愤怒情绪的能力。而有些性格特征则与心理障碍有关, 比如内心深藏的怀疑或猜忌。本章我们将主要讨论三种兴趣测试, 也涉及几种性格测试和适应能力测试, 之后会考察性格及兴趣评估中的一些特殊问题, 最后会通过考察兴趣和性格测试计算机评分和分析的使用情况来作结。

不同的性格和兴趣测试具有不同的测试日的, 使用方式也有所区别。性格和兴趣测试的一般用途有三种: 调查研究、自我探索和临床决策。通常情况下, 以研究为主要目的的性格测试旨在提供某特定性格特征的相关信息, 这些信息要么用于测量某些实验操作或处理过程中产生的变化,要么成为比较不同群体中个人特征的基础。 此外, 在研究背景下, 性格和兴趣测试经常独立进行, 不会与其他测试方法或采访结合使用。而以自我探索为目的的性格测试通常能够提供普遍特征或兴趣模式的相关信息。尽管许多自我探索性格测试的设计模式决定了只能由被测者来评分和分析, 但是此类测试最有效的方式则是与采访及教师反馈相结合, 且该教师最好经过相关培训, 在分析相关测试方法方面经验丰富。最后, 性格测试在临床决策中发挥重要作用, 包括诊断决策和治疗决策。若以临床决策为目的, 结合全面的临床访谈和详细的病人病历来进行测试尤为重要。那么, 性格和兴趣测试就变成了临床评估过程的一部分, 以数据采集为开端, 并贯穿于整个治疗计划的设计。

## 14.2 兴趣测量

## 1. 斯特朗兴趣量表

斯特朗兴趣量表 (SII) 是由斯朗特 (E. K. Strong) 最初设计、1927 年首次出版, 称为斯特朗职业兴趣量表 (SVIB) 的测试方法逐渐发展而来的。1974 年出版了斯特朗职业兴趣量表的重要修订版, 称为斯特朗一坎贝尔兴趣量表 (SCII)。1985 年再次修订, 又更名为斯特朗兴趣量表。1994 年的最新修订版沿用了此名称。多年来该测试的重要修订反映了, 出版商坚信心理测评方法必须经过不断更新来保证其质量和效度。在所有有效的兴趣量表中, 斯特朗兴趣量表依然是最受关注的量表之一, 这显然印证了上述观点。

指导斯朗特方法发展的最基本原理在于, 满足于某种特定职业的人具有相同的兴趣模式, 并区别于从事其他职业的人。因此判断某个人的个人兴趣与某种特定职业从业人员的特殊模式匹配程度, 是判断他对该职业的满意度, 或者某种程度上判断他是否会进入该职业并长期留任的预测指标。

斯朗特兴趣量表沿袭了起初的斯特朗职业兴趣量表设计模式。它由 377 项组成,以三种不同形式呈现出来。大部分测试采取的形式要求应试者选择 \( L \) (喜欢)、 \( I \) (中立) 或 \( D \) (不喜欢) 来答题。题目包括职业 (花店店主、外科医生、编辑等)、学习科日 (化学、体育等)、活动 (修理钟表, 与人会面及引导他人等)、娱乐休闲 (拳击、滑雪、 娱乐他人等), 以及不同类型的人 (芭蕾舞者、婴儿、杰出商业领袖等)。还有一种形式, 即应试者在两项一般活动 (例如冒险一试与谨慎行事) 和工作中的活动 (例如理念与物品) 之中按照自身偏好做出选择。在最后一种形式中, 应试者须指出某些个人特征在自己身上是否为典型 (例如激发同事的抱负, 喜欢摆弄小型工具等)。

尽管斯特朗兴趣量表仅需 40-50 分钟即可完成, 但它能够为应试者提供大量信息。量表分数有五种主要形式, 包括职业量表、一般职业类型、基本兴趣量表、个人风格量表和管理指数。量表结果有助于鼓励应试者遵循个人兴趣总体趋势, 并关注个人兴趣总体趋势如何与工作相关联。

(1)职业量表

斯特朗最初设计的量表就是职业量表 (OS)。斯特朗量表的所有版本中都包含职业量表, 并随着每一次修订进行了更新。这种职业量表能够反映出应试者反应模式与某个特定岗位从业人员的特殊模式匹配程度方面的相关信息。设计某种职业的评分标准, 例如化学家, 主要是通过处理分析数百名符合某种标准的化学家的工作量表, 包括工作年限、职业满意度和工作成就等指标。在每个指标中, 针对某项主题或活动, 选择喜欢 (或不喜欢) 的化学家比例将与一般群体中做出同样选择的人数比例进行比较, 作为参照的一般群体通常来自于除化学家之外的其他职业。若这两个比例相差悬殊, 那么这个指标按照化学家的评分标准进行评分。在化学家职业量表中, 某个人的原始分数即为此人按照生物学家典型模式做出反应的指标数量, 然后这个原始分数应转换为标准分数, 即该职业群体 (例如化学家) 的平均值设定为 50 分, 标准差设为 10 。为了进一步解释说明, 成绩单上不仅会给出标准分数, 还会给出其对应的相似程度。 40 分及以上说明此人的喜好与此岗位从业人员相同, 30 到 39 分说明此人的喜好与此岗位从业人员部分相同, 29 分及以下说明此人的喜好与此岗位从业人员大不相同。因此能够推断, 40 分及以上的人会喜欢上述职业的日常活动, 而 29 分以下的人可能不会喜欢上述职业相关工作。

1994 年的斯特朗量表中有 211 种职业量表, 包括 102 组男女不同的职业量表 (共 204 种量表)。必须针对不同性别设计不同的量表, 因为男性和女性在同一个工作岗位上表现出来的兴趣模式不一定完全相同。其余的 7 种量表仅根据某类性别的人员进行评分, 这 7 种量表描述的职业要么以女性为主, 要么以男性为主, 比如保育员 (女性) 和水管工 (男性), 很难在这些职业中针对不同性别得到足够的样本数。斯特朗兴趣量表 (Harmon, Hansen, Borgen, & Hammer, 1994) 中的《应用程序和技术指导》详细说明了每种职业样本性质的相关信息。

斯特朗量表职业评分标准为通过严格实证的非理论研究方法进行兴趣评估提供了范例。最初的指标分组并没有清晰的理念, 只是涵盖了各种刺激因素, 这些刺激因素能够使得一部分人选择“喜欢”而另一部分人选择“不喜欢”。因此评分标准的制定仅依据不同群体之间的差异, 没有考虑到某种特定职业所代表的心理建构。这种评分标准的开发方法称为实证量表构建。每种职业中选取的样本数量都非常大,一般会超过 200 个, 因此评分标准不太可能涵盖能够碰巧区分样本不同案例的所有指标。 每一个分数都说明了个人兴趣模式与特定职业从业人员的特殊兴趣模式相似程度有多大, 当然仅得知某人的化学家职业量表 (女性) 得了 45 分, 是没办法说明她究竟喜欢什么的。某个人的哪些兴趣与女化学家兴趣模式相似呢? 女化学家究竟喜欢的是什么呢? 当然, 斯特朗量表也会提供除化学家之外的大量其他职业评分, 在早期的斯特朗职业兴趣量表中, 作者提供了不同职业量表之间的相关系数, 发现有些系数明显很高。一组与科学相关的职业量表之间的相关系数如下:



<table><tr><td>职业名称</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td></tr><tr><td>心理学家</td><td/><td>0.77</td><td>0.72</td><td>0.40</td><td>0.71</td><td>0.74</td></tr><tr><td>数学家</td><td>0.77</td><td/><td>0.91</td><td>0.66</td><td>0.80</td><td>0.72</td></tr><tr><td>物理学家</td><td>0.72</td><td>0.91</td><td/><td>0.85</td><td>0.93</td><td>0.78</td></tr><tr><td>工程师</td><td>0.40</td><td>0.66</td><td>0.85</td><td/><td>0.88</td><td>0.52</td></tr><tr><td>化学家</td><td>0.71</td><td>0.80</td><td>0.93</td><td>0.88</td><td/><td>0.73</td></tr><tr><td>内科医生</td><td>0.74</td><td>0.72</td><td>0.78</td><td>0.52</td><td>0.73</td><td/></tr></table>



因此, 某些职业与其他职业存在一定联系, 这种研究结果促使测试开发人员将不同职业量表组合成不同集群, 重视某个集群中所有职业量表的个人评分, 而不仅局限于某些单独的职业岗位。“自然科学家”集群要比单独的“化学家”意义更为广泛, 特别是“自然科学家”集群所有职业量表与“销售”集群职业量表存在负相关关系。

在相关职业集群中, 某人的某项职业量表分值高低模式会逐渐形成此人的心理及职业情况描述。但是不同斯特朗量表之间的相关系数很难加以说明, 其原因有两个。首先, 同一个职业集群中的不同职业量表可能包含相同的指标, 以同样的方式评分。同理, 不同职业集群的职业量表也可能包含某些相同的指标, 但是以不同的方式评分。这种情况完全不同于我们之前遇到的案例, 之前的两项能力测试虽然包含的指标不同, 但存在较高相关系数。化学家职业量表和物理学家职业量表与上述情况469相似。出于某种原因, 化学家职业参照群体与物理学家职业参照群体以相似的方式对组成斯特朗量表的一组陈述做出类似选择。其他职业集群的职业量表与化学家、 物理学家职业量表存在负相关系数, 这是因为虽然不同的量表包含部分相同的指标, 但针对这些指标, 有的职业参照群体选择了 “喜欢”, 而有的则选择了 “不喜欢”, 所以这些指标的评分标准不同。

其次, 对于斯特朗量表之间相关性, 第二个容易混淆的特点在于, 很多人倾向于在大致相同数量的指标中选择 “喜欢”, 这一点虽然得不出什么深意, 但在纯统计层面, 上述特点能够使许多量表相关系数变为负相关。因此若要从不同岗位的职业量表呈负相关关系这个事实出发, 在兴趣模式构建本质方面得出实质性结论是不明智之举。

职业量表对即将或正在进行职业选择的人来说颇为有用, 而对于仍处于职业探索阶段的人, 下文即将提到的两种斯特朗量表评分能够提供更多信息, 即一般职业主题和基本兴趣量表。

一般职业主题。斯特朗量表中的第二种信息类型可以通过一般职业主题 (GOT) 获取。一般职业主题侧重于从心理学角度解释职业喜恶, 主要由约翰・霍兰德 (John Holland, 1985) 的设计发展而来。霍兰德基于自身使用斯特朗职业兴趣量表的经验以及相关的兴趣因素分析研究综述, 得出结论认为, 职业兴趣中存在六个焦点或六种主题, 代表了 6 种不同类型的个人和 6 种不同的工作环境, 分别称为现实型 (R)、探究型(I)、艺术型(A)、进取型(S)和传统型(E)和传统型(C)主题。他认为某个人在某个或多个主题方面较为突出与其所表现出的职业喜恶是一致的。从先验理性分析开始, 霍兰德针对每个主题列举了不同职业集群, 接着通过分析每一种职业与其所在职业集群的相关性, 该职业与其他职业集群的相关性改善了职业集群理论, 最终产生的职业集群分值较为合理, 信度较高, 内部一致性较高且时间方面稳定性较高, 不同职业集群的分数之间相关性较低。六种主题的直观效果如图 14-1 的六边形各顶点所示, 六边形中的数字代表 1994 年斯特朗兴趣量表中不同职业主题之间的相关性。相关系数证明, 六角形结构中相邻顶点之间常常存在较大的相关系数。 然而, 图中大部分相关系数相当低, 表明六种分值中每个都提供了应试者不同方面的信息。

霍兰德认为这六种主题不仅仅代表职业群组, 也代表人格模式。对这六种主题用来描述个人特征的词语分析为上述观点提供了证据支撑。经常用到的描述语如下:470





图 14-1 霍兰德职业主题及其与 1994 年斯特朗量表主题之间的相关性资料来源: 经出版社许可后修改转载。美国心理学家出版社, 加利福尼亚帕洛阿尔托, 94303, 选自斯特朗量表。1994 年及 2004 年版权归小利兰斯坦福大学董事会所有。保留所有权利。未经出版商书面同意禁止再次出版。斯特朗兴趣量表是斯坦福大学出版社的一个注册商标。

<table><tr><td>现实型</td><td>探究型</td><td>艺术型</td></tr><tr><td>强健的</td><td>任务导向的</td><td>有表现力的</td></tr><tr><td>粗犷的</td><td>内省的</td><td>独创的</td></tr><tr><td>实际的</td><td>善于分析的</td><td>直觉的</td></tr><tr><td>强壮的</td><td>好奇的</td><td>有创造力的</td></tr><tr><td>运动的</td><td>独立的</td><td>离经叛道的</td></tr><tr><td>机械的</td><td>内敛的</td><td>内省的</td></tr><tr><td>直接的</td><td>非常规的</td><td>独立的</td></tr><tr><td>坚持的</td><td>理智的</td><td>好胜的</td></tr><tr><td>社会型</td><td>进取型</td><td>传统型</td></tr><tr><td>善社交的</td><td>好胜的</td><td>认真的</td></tr><tr><td>负责任的</td><td>受欢迎的</td><td>有效率的</td></tr><tr><td>人性化的</td><td>自信的</td><td>遵从的</td></tr><tr><td>群体学向</td><td>愉快的</td><td>冷静的</td></tr><tr><td>理解的</td><td>善社交的</td><td>有秩序的</td></tr><tr><td>理想化的</td><td>精力充沛的</td><td>实践的</td></tr><tr><td>乐于助人的</td><td>能言善辩的</td><td>有物和地位导向的</td></tr><tr><td/><td>权力和地位导向的</td><td/></tr></table>



由于不同主题代表不同类型的人, 因此可以从总体来描述个人。现实型人偏好户外工作和建造和/或修理东西。现实型职业样本包括汽车修理工、园丁、水管工、警察和牧场主等。在探究型职业方面得分较高的人则喜欢各种形式的探询, 分析问题以及做研究。此类职业样本包括大学教授、医生和心理学家。艺术型的人喜欢创造性活动, 包括戏剧、音乐、写作等。相关职业包括艺术家、律师、图书管理员和记者。 社会型主题得分较高的人偏爱有关看护和指导的活动。该职业类型包括: 儿童保育员和护士等。进取型主题与销售活动、管理和说服相关, 进取型的职业包括房地产经纪人和旅游推销员。传统型主题包含数据处理, 会计及组织类活动, 传统型的人特别喜欢准确性要求较高及关注细节的活动, 相关职业包括会计和文职工作者。尽管说这六种主题主要是为了代表不同类型的人, 但必须强调的是很少有人会单纯只代表一种类型。也就是说, 大多数人的兴趣会反映出两个或两个以上的一般主题, 分数概况分析时会有所反映。例如,一个人可能会在社会型和进取型主题上获得相对较高的分数, 而这种兴趣模式的相关职业包括高中辅导员、公园管理员及娱乐项目协调人员等。

由于先前的斯特朗职业兴趣量表及其更新量表之间存在重叠的项目内容, 因此结合霍兰德的六边形结构来对斯特朗一坎贝尔兴趣量表 (SCII) 进行评分和说明较为容易。六种一般职业主题的分数 1974 年首次应用到斯特朗量表上, 用以补充具体职业的得分。此外, 给顾问和客户提供的报告表格, 根据某职业的一个或多个显著主题, 对不同的职业进行分组。因此, 给量表使用者提供的是以经验为基础, 根据一般职业主题整理的职业分数以及职业主题分数。

基本兴趣量表。第三种类型的得分主要来自基本兴趣量表 (BIS), 它主要是一般职业主题的分支。该量表于 20 世纪 60 年代首次引进, 之后进行了大幅修订, 逐渐更新成 1994 年斯特朗量表的修订版。共有 25 个基本兴趣量表, 每个基本兴趣量表都由一组同类项目构成。由于每个特定量表中的项目与量表中其他项目均存在较大相关性, 因此所有项目在量表内容和统计意义上属于同种类型。基本兴趣量表直接来源于斯特朗量表, 只使用统计标准, 没有引用任何理论。基本兴趣量表处理的职业主题比霍兰德模型主题更为具体, 但在内容上比职业量表更为广泛, 且反映出与其他量表之间较高的相关性。表 14-1 所示为基本兴趣量表, 体现了每个基本兴趣量表与一般职业主题的关系。



表 14-1 基本兴趣量表和一般职业主题

<table><tr><td>现实型</td><td>探究型</td><td>艺术型</td><td>社会型</td><td>进取型</td><td>传统型</td></tr><tr><td>农业</td><td>科学</td><td>音乐/戏剧</td><td>教学</td><td>公众演讲</td><td>数据管理</td></tr><tr><td>自然</td><td>数学</td><td>艺术</td><td>社会科学</td><td>法律/政治</td><td>电脑活动</td></tr><tr><td>军事活动</td><td>医学</td><td>应用艺术</td><td>医疗服务</td><td>贸易</td><td>办公服务</td></tr><tr><td>体育活动</td><td/><td>写作</td><td>宗教活动</td><td>销售</td><td/></tr><tr><td>机械活动</td><td/><td>烹饪艺术</td><td/><td>组织管理</td><td/></tr></table>



个人风格量表。斯特朗量表资料中包含的第四种信息类型是个人风格量表。共有四个量表, 每个都反映了广泛的生活及工作风格偏好。与 1994 年斯特朗量表不同的是, 量表包括工作风格、学习环境、领导风格和承担风险/冒险精神。分数以档案表格的形式呈现, 类似于职业主题和兴趣量表。但个人风格量表是按照双极量表设计的, 并且呈现出来的分数偏向于量表的左右两极, 即左极和右极。表 14-2 列举了量表左右极的概要定义。



表 14-2 个人风格量表左右极简要定义

<table><tr><td>个人风格量表</td><td>左 极</td><td>右 极</td></tr><tr><td>工作类型</td><td>处理概念/数据/物</td><td>与他人一起工作</td></tr><tr><td>学习环境</td><td>务实的</td><td>学术的</td></tr><tr><td>领导风格</td><td>以身作则</td><td>指导他人</td></tr><tr><td>承担风险/冒险精神</td><td>谨慎行事</td><td>冒险行事</td></tr></table>



管理指数。斯特朗量表资料中的第五种信息类型就是管理指数。辅导员多使用管理指数来辅助说明个人情况, 管理指数能够提供应试者答题的数据信息, 包括答题总数、“喜欢”“中立”和“不喜欢”的答案比例, 以及罕见答案的总数等。管理指数最大的用途在于初步检查单个测试实施及评分的效度, 同时在应试者整体的分数档案框架中也具有一定的说明意义。

解释斯特朗兴趣量表时, 鼓励顾问和咨询者从范围广泛且基于理论基础的职业主题出发, 通过内容基础相同的基本兴趣量表分数, 分析根据经验确定的具体职业量表。这种测试方法目前兼容了评分系统的基础及其提供的全面信息。

斯特朗兴趣量表日前仅由 CPP 公司 (前身是美国咨询心理学家出版社) 独家印发及评分。图 14-2 展示了目前斯特朗量表档案表的第 2-3 页样本, 基本报告共 9 页, 包含若干部分, 开头是简述, 提供了一般职业主题和基本兴趣量表的概述定义 (第 2 页), 列举了应试者得分最高的 5 种兴趣领域 (第 3 页), 表格其余页数提供了较多细节信息, 包括一般职业主题和基本兴趣量表的更详细信息。整个档案表同时提供了所有职业量表 (按职业主题分类) 和个人风格量表的评分结果, 报告结尾是管理指数及某些参考原则来帮助应试者理解测试结果。

根据应试者的年龄和职业经历, 美国心理学家出版社以传统格式出版了斯特朗量表其他六种报告。解读报告是长达 15 页的个人斯特朗量表档案的书面说明。此外, 2004 年采用了一种新的报告形式, 包含内容基本相同, 但有更多细节和色彩优化处理。此修订版报告有 9 页, 仍按照从一般主题到特定职业的顺序进行组织。上述

教育评价——教育和心理学中的测量与评估 (第八版)

斯特朗兴趣量表档案 简的样例/第 2 页

一般职业主题 第 1 部分

一般职业主题 (GOTs) 主要衡量 6 种范围广泛的兴趣模式, 可用于描述你的工作特质。大多数人的兴趣反映在两种或三种职业主题中, 它们结合形成一种兴趣集群。工作活动、潜在技能以及价值观等也可以分成六种主题。因此, 此量表能够说明你的兴趣和职业方向及教育方向的关系, 这可能对你来说是最有意义的。

你的标准分数基于在职人员组合群体的平均分, 但由于研究表明男性和女性倾向于在下列各方面做出不同回答, 你的兴趣水平 (极低、低、中等、高、极高) 取决于你所在性别组平均分与你的分数的比较。

主题描述



<table><tr><td>职业主题</td><td>代码</td><td>兴趣</td><td>工作活动</td><td>潜在技能</td><td>价值观</td></tr><tr><td>艺术型</td><td>A</td><td>自我表现、艺术 鉴赏、交流、文化</td><td>音乐作曲、表演、写 作、视觉艺术创作</td><td>创造性、音乐技 能、艺术表现</td><td>审美、原创性、独立性、 想象力</td></tr><tr><td>探究型</td><td>I</td><td>自然科学、医学、 数学、研究</td><td>进行实验室工作、解 决抽象问题、进行 研究</td><td>数学能力、研究、 写作、分析</td><td>独立性、好奇心、学习 能力</td></tr><tr><td>社会型</td><td>S</td><td>交际、团队合作、 相互帮助、社区 服务</td><td>教学、关心他人、咨 询、员工培训</td><td>与人交往能力、 语言能力、倾听、 表达理解</td><td>合作、慷慨、服务他人</td></tr><tr><td>进取型</td><td>E</td><td>商业、政治、领导 力、创业</td><td>销售、管理、说服、市 场营销</td><td>语言能力、激发 与领导他人的 能力</td><td>敢冒风险、威望地位、 竞争、影响力</td></tr><tr><td>传统型</td><td>S</td><td>组织、数据管理、 会计、投资、信息 系统</td><td>建立程序和体系、组 织、做记录、开发计算 机应用</td><td>处理数据能力、 数据分析、金融、 注意细节</td><td>精确性、稳定性、效率</td></tr><tr><td>现实型</td><td>R</td><td>机械、计算机网 络、体育活动、户 外工作</td><td>操作器械、实用工具、 建筑、修理、提供安全 保障</td><td>机械方面的才智 及灵活度, 身体 协调力</td><td>传统、实用性、常识</td></tr></table>

得分最高的主题 主题代码

艺术型、探究型、社会型 AIS

<table><tr><td>职业主题</td><td>代码</td><td/><td>标准分数和兴趣水平 50</td><td>6070></td><td>标准分数</td></tr><tr><td>艺术型</td><td>A</td><td colspan="3">-</td><td>71</td></tr><tr><td>探究型</td><td>1</td><td/><td>_____</td><td/><td>56</td></tr><tr><td>社会型</td><td>S</td><td>_____</td><td/><td/><td>51</td></tr><tr><td>进取型</td><td>E</td><td>_____</td><td/><td/><td>48</td></tr><tr><td>传统型</td><td>C</td><td>_____</td><td/><td/><td>43</td></tr><tr><td>现卖型</td><td>R</td><td>the Reference Programma .</td><td/><td/><td>37</td></tr></table>



上述表格按照降序说明你的一般职业主题 (GOTs) 结果, 兴趣水平从高到低排列。参照主题描述, 判断你的测试结果适合你的程度。你得分最高的主题真实可靠吗? 参看你得分排第二的兴趣类型, 问自己同样的问题。你可以突出划出本页中最适合你的主题描述。

斯特朗兴趣量表档案 简的样例/第 3 页

基本兴趣量表 第 2 部分

图 14-2 斯特朗兴趣量表中的档案样本

资料来源: 经出版社许可后修改转载。美国心理学家出版社, 加利福尼亚帕洛阿尔托, 94303, 选自斯特朗量表。1994 年及 2004 年版权归小利兰斯坦福大学董事会所有。保留所有权利。未经出版商书面同意禁止再次出版。斯特朗兴趣量表是斯坦福大学出版社的一个注册商标。

基本兴趣量表能够说明工作活动、项目、课程作业及休闲活动相关的具体方面对个人有激励作用和成就感的兴趣领域。类似于一般职业主题, 你的兴趣水平 (极低、低、中等、高、极高) 取决于你所在性别组平均分与你的分数的比较。

当回顾下列图表中你的测试结果时, 请注意你最感兴趣的领域和最不感兴趣的领域, 思考这两个领域跟工作活动、教育活动和休闲活动有何相关性。抽出时间来思考一下, 哪些你最感兴趣的领域不存在你目前工作或生活方式中, 思考你如何将其融合到你的计划中。 你最感兴趣的五个方面 你最不感兴趣的五个方面

1. 写作与大众传媒 (A) 管理 (E) 2. 表演艺术 (A) 计算机硬件和电子产品 (R)

3. 视觉艺术和设计 (A) 军事 (R)

4. 烹饪艺术 (A)

5. 法律 (E)

艺术型一极高



<table><tr><td>基本兴趣量表</td><td>标准分数和兴趣水平</td><td>标准 分数</td></tr><tr><td>写作与大众传媒</td><td/><td>71</td></tr><tr><td>表演艺术</td><td/><td>71</td></tr><tr><td>视觉艺术与设计</td><td/><td>70</td></tr><tr><td>烹饪艺术</td><td/><td>67</td></tr></table>



探究型一中等



<table><tr><td>基本兴趣量表</td><td>标准分数和兴趣水平 405060</td><td>70></td><td>标准 分数</td></tr><tr><td>研究</td><td/><td/><td>57</td></tr><tr><td>科学</td><td/><td/><td>56</td></tr><tr><td>医学</td><td/><td/><td>52</td></tr><tr><td>数学</td><td/><td/><td>40</td></tr></table>



社会型一中等



<table><tr><td>基本兴趣量表</td><td colspan="3">标准分数和兴趣水平 5070></td><td>标准 分数</td></tr><tr><td>社会科学</td><td/><td/><td/><td>59</td></tr><tr><td>咨询与帮助</td><td/><td/><td>M</td><td>58</td></tr><tr><td>宗教与灵性</td><td>_____</td><td/><td/><td>53</td></tr><tr><td>人力资源与培训</td><td/><td/><td/><td>48</td></tr><tr><td>医疗服务</td><td/><td/><td/><td>48</td></tr><tr><td>教学与教育</td><td/><td/><td/><td>45</td></tr></table>



进取型一中等



<table><tr><td>基本兴趣量表</td><td/><td>标准分数和兴趣水平</td><td>标准 分数</td></tr><tr><td>法律</td><td/><td/><td>66</td></tr><tr><td>營銷与广告</td><td/><td/><td>65</td></tr><tr><td>政治与公众演讲</td><td/><td/><td>58</td></tr><tr><td>创业</td><td/><td/><td>48</td></tr><tr><td>销售</td><td/><td/><td>41</td></tr><tr><td>管理</td><td>_____VL</td><td/><td>33</td></tr></table>

图 14-2 (续)

传统型一适中

<table><tr><td>基本兴趣量表</td><td colspan="6">标准分数和兴趣水平</td><td>标准</td></tr><tr><td/><td/><td>40</td><td>50</td><td/><td>60</td><td>70></td><td>分数</td></tr><tr><td>金融和投资</td><td/><td/><td/><td/><td/><td/><td>55</td></tr><tr><td>办公室管理</td><td/><td/><td/><td/><td/><td/><td>50</td></tr><tr><td>税务和会计</td><td/><td/><td/><td/><td/><td/><td>43</td></tr><tr><td>编程和信息系统</td><td/><td/><td/><td/><td/><td/><td>39</td></tr></table>

现实型一低

<table><tr><td>基本兴趣量表</td><td>标准分数和兴趣水平 4050</td><td>60</td><td>70></td><td>标准 分数</td></tr><tr><td>自然和农业</td><td/><td>M</td><td/><td>50</td></tr><tr><td>保护服务</td><td/><td/><td/><td>47</td></tr><tr><td>体育运动</td><td/><td/><td/><td>45</td></tr><tr><td>机械和建筑</td><td/><td/><td/><td>40</td></tr><tr><td>军事</td><td/><td/><td/><td>38</td></tr><tr><td>计算机硬件和电子产品</td><td/><td/><td/><td>33</td></tr></table>

兴趣水平: VL -极低, L -低, M -中等, H -高, VH -极高

图 14-2 (续)



两种报告的完整样本都可以从美国心理学家出版社网站 http://www.cpp.com/ samplereports/reports. asp#strong 获得。希望客户接受斯特朗兴趣量表 (SII) 测评的咨询师可以在网站上使用与美国心理学家出版社评分网站链接的外部链接 http://www.Skillsone.com 进行量表实施和评分。

我们现在来看斯特朗兴趣量表评分的信度和效度。表明其信度的证据主要包含在一定时间间隔后的测试一再测试之间的相关性。1985 年斯特朗量表指南说明了三种分数的平均值, 如下表所示:



<table><tr><td rowspan="2">量 表</td><td colspan="3">测试-再测试时间间隔</td></tr><tr><td>2 周</td><td>30 天</td><td>3 年</td></tr><tr><td>一般职业主题</td><td>0.91</td><td>0.86</td><td>0.81</td></tr><tr><td>基本兴趣量表</td><td>0.91</td><td>0.86</td><td>0.81</td></tr><tr><td>职业量表</td><td>0.91</td><td>0.89</td><td>0.87</td></tr></table>



上述三种量表都有合理的稳定性, 尽管长期来看, 具体职业的量表 (OS) 比其他量表的表现更好。目前已有的 1994 年斯特朗量表测试-再测试的信度信息表明, 该量表保持着较高的信度, 且跟其他某些量表相比信度甚至稍微提高了一点。对原斯特朗职业兴趣量表 (SVIB) 的研究提供了职业量表长期稳定性相关信息, 同时某种程度上说明量表稳定性与应试者最初接受测试时的年龄之间的关系。表 14-3 中的数476据表明, 兴趣在青春期和成年早期变得越来越稳定, 正如所预料的那样, 时间间隔越长, 兴趣转变就越常见, 但对于最长的时间间隔来说, 兴趣转变仍存在实质的一致性核心。



表 14-3 斯特朗兴趣量表的长期稳定性

<table><tr><td rowspan="2">初次测试时的年龄</td><td colspan="6">测试-再测试时间间隔</td></tr><tr><td>两周</td><td>1 年</td><td>2-5 年</td><td>6----10 年</td><td>11-20 年</td><td>20 +</td></tr><tr><td>17 ……18</td><td/><td>0.80</td><td>0.70</td><td>0.65</td><td>0.64</td><td/></tr><tr><td>19—21</td><td>0.91</td><td>0.80</td><td>0.73</td><td>0.67</td><td>0.67</td><td>0.64</td></tr><tr><td>22-25</td><td/><td/><td>0.78</td><td>0.69</td><td>0.75</td><td>0.72</td></tr><tr><td>\( {25} + \)</td><td/><td/><td>0.77</td><td>0.81</td><td>0.80</td><td/></tr></table>

注: 空格表示时间间隔一年龄关系方面不存在相关数据。



未来使用者应该寻求哪些证据证明兴趣量表的效度仍然不是特别清晰。首先, 他或她可以探究量表构建基础的意义。对于职业量表, 问题大部分集中在从一般人组成的广泛参照群体 (共同效度) 中区分某个特定职业从业人员时量表的效度。由于某些职业群体相比其他更为特殊, 所以不同职业之间情况多多少少存在差异, 但还是能够得出一个大致但非常精确的整体概述,即相较于实际从事某种职业的 \( {65}\% \) 到 \( {70}\% \) 的人相比,大约 \( {10}\% \) 的人一般在该职业量表中评分“高”或“极高”。

霍兰德的六个一般职业主题中隐含的结构意义在于, 每种主题与若干职业量表之间, 与基本兴趣量表中展示的项目内容领域之间, 以及与每种主题上评分较高的人的特性描述之间产生联系的方式。评估兴趣测试效度过程中, 应该特别注意这些测试方法能够作为随后职业发展历史 (预测性信度) 的预测指标的有效性。对于职业量表中显示的兴趣水平为高或者极高的那些职业, 有多大比例的人最终进入了该职业? 在估计实际进入的职业与兴趣量表分数之间的一致性时, 会产生严重问题, 因为具体职业成千上万,但斯特朗职业兴趣量表 (SVIB) 和斯特朗兴趣量表 (SII) 数量有限。 除了上述问题, 不同研究者的研究还发现了一个相当不错的结果, 即年龄在 20 岁左右的测试者中,约 \( {50}\% \) 的人最终进入了与自己兴趣一致的职业。这明显说明了上述关系, 而且从许多其他方面来看, 上述关系能够影响个人职业选择, 能视其为量表预则效度的有力证据。

## 2. 职业评估量表

斯特朗兴趣量表的一个重要局限在于, 量表主要侧重于专业性职业, 因此对某些人不是很有用, 比如那些对某些不要求完成大学学业的职业感兴趣的人。职业评估量表 (CAI) 是查尔斯・约翰森 (Charles Johansson, 1991) 为了弥补上述空缺设计的。 很明显以斯特朗量表为基础模板, 职业评估量表 (CAI) 的职业版对霍兰德的 6 个一般职业主题进行评分, 共 2 个基本兴趣量表和 91 个职业量表, 类别与级别都不同 (卡车司机、教师、工具/模具制造商、护士, 等等)。也可运用加强版, 能够为 111 种职业提供信息, 这 111 种职业的教育要求分布更为广泛。职业评估量表 (CAI) 的特别之处在于, 其得分不分男性和女性。在量表构建时只涵盖对男性和女性同时有效的项日, 以此来鼓励男性和女性更加自由地进入理想的职业, 同时也考虑到测试结果在更广泛范围内的解释说明。虽然这种不分性别公平对待的观点值得肯定, 但许多职业样本较小, 而评分标准必须建立在职业样本基础上。这个问题关系到评估量表效度, 尤其是当对比斯特朗量表或者更大的样本时。但是, 已经证明职业评估量表 (尤其是职业版) 是一种评估职业兴趣的有用手段, 对于想要快速找到新工作的未升人大学的高中生或成年人尤其如此。职业评估量表自 1991 年出版以来还没有更新过, 但经过几十年发展的斯特朗量表证据表明, 职业兴趣和职业偏好之间存在极大的稳定性。职业评估量表的详细信息可以在培生评估网站上 http://www.pearsonassessments.com/assessments/index.htm 获得。从这个页面选择链接, 链接到您希望查看的评估量表。

## 3. 自我探索量表

约翰・霍兰德 (John Holland, 1985, 1997) 设计了自我探索量表 (SDS), 该量表是一种自评分工具, 可以根据六种性格类型或职业主题对自己进行分类 (现实型、艺术型、探究型、传统型、社会型和进取型)。霍兰德在自己的研究中确定了斯特朗量表中的上述 6 种性格类型或职业主题, 以此帮助个人进行职业探索和职业选择。最近一次修订是在 1994 年, 量表本身包括两个小册子, 即评估册和职业索引, 可以在 40-50 分钟内完成 (Holland, Powell, & Fritzsche, 1997)。评估册使个人有机会列出梦想职业, 思考该职业首选的活动和能力, 获得六种职业主题评分, 分数最高的三个主题形成一个总代码。例如,一个人在社会型主题得分最高, 其次是探究型和进取型, 那么他获得的总代码就是 SIE。然后此人可以参考职业索引, 用特定代码确定相关职业。在 SIE (社会、调查、进取) 总代码中, 职业列表中包括医疗记录管理员、保险理赔审查员、学校护士和理疗师。职业索引包括 1000 多种职业, 每种都根据霍兰德代码进行分类, 鼓励个人更多地了解相关职业与三个字母总代码之间的相关性。获取各种职业信息的一个重要来源是《职业名称词典》(1992)。该词典美国劳工部出版, 提供了 1.2 万多个职业的描述。

自我探索量表的独到之处, 顾名思义, 就是它可以用于在没有职业顾问帮助的情况下进行职业生涯探索。两个小册子都是自我探索性的, 个人可以完成测试, 进行评分, 并自己理解量表结果。尽管自我探索量表通常是独立完成, 但也可以在小组中使用。例如,一位高中老师或辅导员可能在班级中使用自我探索量表,使其成为职业探索课程的一部分。该量表还可以提供职业咨询面试方面的有用信息, 许多职业顾问将其融合到职业咨询过程中。在解读分数结果时的顾问协助对青少年来说尤为重要, 因为经常需要鼓励他们更广泛地思考职业选择和机遇。自我探索量表紧跟互联网潮流, 也可以在 http://www.self-directed-search.com 网站上获得。进入这个网站, 可以参加测试, 获得个性化报告, 或查看示例报告, 获取该测试大致信息 (在撰写本书时, 测试及一份 8-16 页报告的相关费用是 9.95 美元)。

## 14.3 性格和调整能力评估

如果能预料对我们很重要的人的感情、思想和行动, 那么生活会容易得多。心理学家和教育工作者同样也想理解和预测其客户和学生, 从而更有效地完成工作。如果我们能预先了解如何根据每个学生的个人特点有效地进行激励、教育或干预就好了。但是在形成对他人的印象时, 专业人士相对公众只存在微弱优势 (Garb, 1994)。 目前已开发出许多个性和调整能力测试, 弥补主观判断所固有的严重缺陷。这些测试在近几十年来经过了不断调整和改进, 但我们还未发展到较高的境界, 从专业或者文化角度对人类性格本质或人类调整能力的构成达成一致。

有四种理论方法主导人格测试。动态理论描述人格的组成部分, 如弗洛伊德的本我、自我和超我。大部分动态评估强调隐蔽的或无意识的需求和冲突的重要性, 这些需求和冲突必须用规避意识的方式测量。这种方法在很大程度上依赖于评价者了解和解释应试者回答的能力, 从而将应试者的整体个性概念化。特征理论假定存在稳定的内部特征或倾向, 通常用卷面测试测评。可能要求某位应试者判断一系列陈述的真假, 从应试者对题目的反应推断出被测试特征的出现或水平 (如对怀疑别人或别人目的的许多题目表示赞成)。测试成绩通过比较应试者和测试建立的标准来进行计算和说明, 这些标准是通过大量群体测试建立起来的。斯特朗兴趣量表和自我探索量表衡量的职业兴趣可以算是人格特质。人本主义理论关注个人如何想象和评价自己。早期的人本主义测试技术要求应试者通过自我观察和分析作自己的评估者或分析师。当代人本评估仍然关注自我认知, 但更依赖卷面测试。最后, 行为主义理论通过质疑传统人格结构的重要性——甚至质疑其存在——来挑战我们的基本假设, 行为主义理论认为, 环境或情境因素是行为的主要决定因素。个体差异是由于每个人出于先前的经历习得不同的行为模式。行为评估主要收集某人行为模式和与相关行为相联系的具体情况等方面信息。

## 1. 动态评估法

动态人格评估方法依赖于投射假说, 假设我们的核心关注点和冲突影响我们的认知和行为。精神分析学家开发了投射技术来说明上述过程, 整个过程中使用模糊的刺激因素进行测试, 假定潜意识需要和冲突, 而不是刺激因素本身的内容, 决定了测试者的认知和反应。

## (1)罗夏墨迹测试

最著名的投射技术是赫尔曼 - 罗夏 (Hermann Rorschach) 的墨迹测试。据称, 罗夏经常观察云的变化, 把云想象成物体、人或者某个景象, 在此基础上设计了墨迹测试。他想知道, 这个童年游戏是否能够例证人的潜意识投射到模糊的刺激因素上的过程。让病人看云似乎是不可行的。相反, 罗夏通过在纸上滴墨水, 然后对折形成对称形状 (参见图 14-3), 创造了 10 种墨迹。





图 14-3 罗夏测试中使用的一个图像



墨迹测试的实施是通过两个阶段完成的。在自由联想阶段, 给病人展示一张卡片, 要求其说出墨点可能是什么或可能代表什么, 并将每个反应记录下来。剩下的 9 张卡片重复上述过程。可能还需要一点自由联想。参看图 14-3, 你看到了什么? 污点看起来像某种物体? 还是可以以其他不同方式来解释? 它是正面朝上还是颠倒过来的?

在第二阶段即调查阶段, 检查每张卡片, 判断刺激某种反应的卡片的物理形态, 测试者记录下卡片的哪部分 (全部或特定的某部分) 或者哪些特征 (形状、颜色、材质等) 决定了病人的反应。参看图 14-3, 你从卡片的哪部分看出来是个物体? 卡片的哪些方面暗示了该物体?

测试实施相当直接, 可能只需要 10 分钟, 尽管 45 分钟更为常见。但测试评分和解析则比较费时费力, 需要广泛的培训和大量时间。每一个反应的内容、位置和决定因素都要经过仔细分析, 才能计算大量得分及分数间的比率。可以通过将分数和比率与现行标准进行比较来指导评分和说明, 但最终结果说明的主要因素在于临床医生。480临床医学传说中充满了熟练的测试者的故事。他们诊断出了医学测试未检测出来的大脑病变或者有见地地解决了某复杂病例的疑难杂症。但是, 临床医生没有传说那么神乎其神。在 20 世纪 70 年代之前, 罗夏测试非常受欢迎, 但是其信度和效度评估结果较差, 因此对罗夏测试的关注度也逐渐下降。评估同一组病人反应的临床医生通常会得出不一致甚至相互矛盾的解释。约翰・埃克斯纳和他的同事们 (Exner & Eaner, 1972) 通过努力改善该测试的心理测量学性质来推动了对该测试的新关注。至少部分问题是有许多不同的评分和说明测试系统。埃克斯纳的结论是, 该测试评分系统过于混乱, 临床医生通常简单地用其主观印象来解释病人的原始反应。埃克斯纳试图通过集成现有系统的最佳特性来标准化实施流程及格式化评分系统。埃克斯纳剔除了现有分数和比率造成的混乱, 只保留那些评价者间信度达到 ). 85 以上的测试 (Exner, 1974)。埃克斯那的研究结果是一种新的测试系统, 被罗夏则试使用者广泛应用 (Exner, 1993)。

除埃克斯纳的贡献之外, 罗夏测试仍是心理测试领域的一个噩梦。罗夏测试没有总分来总结获得的分数和比率阵列。保留的某些成绩评分者间信度还可以接受 (Acklin, McDowell, Verschell, & Chan, 2000)。但许多评分者间信度低的分数仍然在使用, 且不同评分的复测信度要么不清楚要么非常低 (Lilienfeld, Wood, & Garb, 2000)。

罗夏测试的效度问题更大。罗夏测试没有体现出良好的预测效度。例如, 该测式并非治疗预后及治疗反应的良好指标 (Groth-Marnat, 1999)。仍未证明该测试是只别多数类型心理问题的良好诊断工具。但该测试可能适用于诊断极度错乱的精神芮患者。帕克 (Parker, 1983) 进行了一项已有相关研究的元分析, 得出结论认为, 罗夏测试可以用于识别测试中的一组反应是来自于一个正常人还是一个心理极度错乱的人。心理极度错乱的病人, 特别是患有精神分裂症和其他精神病问题的人, 通常会付罗夏测试卡片产生极为不同寻常的反应 (Vincent & Harmon,1991)。但他们的测式反应是其整体反常行为模式的一部分, 这种奇怪的行为甚至在一个简短的采访中上可能是显而易见的。因此, 罗夏测试对严重精神疾病可能是一个很好的指标, 但没必要为了诊断病人情况进行该测试。罗夏测试的心理测试证据极为薄弱, 因此利恩作尔德等人 (Lilienfeld et al., 2000) 呼吁限制该测试的使用, 包括使用效度较高的分汝, 以及在临床培训项目中不予强调。

这场争论中的持相反立场的是人格评估协会(SPA,2005)。他们引用了迈耶和可彻的结论 (Meyer & Archer, 2001), “将罗夏测试挑出来加以批判或赞美毫无道理, 罗夏测试能够产生合理效度, 大致和其他常用测试在同一个水平 " (人格评估协会, 第 220 页)。该协会还指定了一个“蓝丝带委员会”, 进一步对罗夏测试和明尼苏达多相人格调查表 (明尼苏达多项人格调查量表, 见下文) 进行元分析, 得出的结论是, “罗夏测试和明尼苏达多相人格调查表明尼苏达多项人格调查量表/明尼苏达多项人格调查量表-2 在人格测试方面的效果如预期一样理想” (第 220 页)。这些测试系数达到的最大值只有 0.35 , 表明评估个性是多么难以进行。 (2)主题统觉测试

主题统觉测试 (TAT) 是另一个常用的投射测试。20 世纪 40 年代, 亨利・默里 (Henry Murray) 根据人类 28 种需求建立了人格心理动力理论, 这 28 种需求主要包括亲和性、成就、攻击性、权力、性等。他选择了一组黑白素描和照片, 作为刺激卡片去评估人格。给应试者展示一系列卡片, 每次展示一张卡片, 并要求其根据卡片编故事, 包括目前情况、一个开头、一个结尾以及故事中的人物可能体验的思想和感情方面的描述。

默里 (Murray, 1943) 认为人们所讲述的故事充满了心理投射。例如, 应试者“讲述的关于虚构人物的某些事情可以用到他自己身上, 这些事可能是他面对直接质疑很难承认的事情。测试规则是, 被测试者高兴地完成测试, 完全意识不到自己已经给心理学家坦露了自己的内心,主要通过 \( \mathrm{X} \) 光片来解释”。(第 1 页) 也许默里过于热衷他的技术了, 但是人们确实会对同样的卡片讲述不同的故事, 故事通常包括自己生活的主题和关注, 因此临床医生往往会有这样的印象, 人们讲述的故事确实涵盖了重要信息。问题是“能以讲故事人提供有效信息的方式来解读这些故事吗”?

总的来说, 主题统觉测试心理评估是令人失望的。部分问题在于, 标准化的测试程序非常烦琐, 2 个阶段中需要出示 20 张卡片, 可能要连续多天的时间。标准化的指令在测试中呈现为想象与欺骗的任务, 很多心理学家常以职业道德为由拒绝上述任务。测试者会简化测试流程, 例如提供少量卡片, 经过一个简单的阶段后草草完成测试。针对某个特定实施程序, 会根据测试者的偏好使用的卡片也会有不同。大多数测试者也会改变测试指令, 在测试目的方面可能会误导客户。测试程序上的不一致在评估该测试的研究中也较为明显。凯泽和普莱瑟 (Keiser & Prather, 1990) 发现, 已出版的测试评估通常使用了不同的测试程序, 且在测试过程中仅仅使用了 20 张卡片中的几张。即使是指令和程序上发生极小的变化, 也会对被测试者创作的故事产生戏剧性的影响 (Lundy, 1988)。另外一个问题就是, 两位心理学家可能关注同一个故事的不同方面, 相同的材料可能会提出大不相同的解释。甚至我们可以说, 说482明故事在本质上就是一个投射任务, 但是对某个故事的说明在多大程度上揭示出解释者与客户相反呢?

以前后一致的方式实施整个测试, 使用明确界定的标准, 从而获得某个特定特征或者特点方面的分数, 这能够大量提高测试可信度及效度。已经开发了若干系统来评估某些最初由默里描述的 28 种需求。例如, 斯潘格勒 (Spangler, 1992) 进行了元分析, 认为建立一套界定清晰的评分标准来评估成就需求才能产生较高的评分者间信度及测试-复试信度。成就需求分数能够预测 “真实世界”的某些结果, 比如成绩、 收入、工作绩效以及领导力等, 效果优于同样目的而设计的问卷调查。通过使用上述评分系统来评估亲和力需求和权力需求能够获得可喜的结果 (Winter, John, Stewart, Klohnen, & Duncan, 1998)。同样地, 也可评估防御机制 (例如, 否认、拒绝、 识别)、人际理解和联系的成熟程度等 (Cramer,1999)。但是上述评分系统每个只能评估人格的某个方面, 不能够单个或集体地产生人格的全面描述。

## 2. 特质研究法

描述个性的特质研究法由我们平常使用的对人们的特性描述发展而来。高尔顿。奥尔波特 (Gordon Allport,1937) 是特质研究法的先驱, 认为日常描述符号泛滥的背后, 是若干真正的神经心理学结构或者特征, 它们能够用来解释行为的一致性。 奥尔波特和霍德贝特 (Allport & Odbert, 1936) 用字典来发现了描述人格的 18000 多个单词, 通过整合同义词, 仅保留能够表明一致且稳定的调节模式的描述符号后, 单词数量减少到约 4500 个。奥尔波特 (Allport, 1955) 认为集中而长期的个案研究是调查上述结构的最佳方式。除奥尔波特的个人偏好外, 人格特征研究很快成为高技术含量的任务。20 世纪 50 年代以来, 研究者通常在大样本群体中进行卷面测试, 使用某些复杂的统计程序来分析海量数据结果。

毫不夸张地说, 上述努力产生了数百种不同的测试, 每种测试都旨在评估某个或多个特征。

(1)特质的因素分析探究

16 型人格因素问卷 (16 PF)。雷蒙德・卡特尔 (Raymond Cattell,1950) 认为评估人格不需要数百种不同的特征。他修订了奥尔波特和奥德贝特的 4500 种特征列表, 精选了 200 个描述字, 称之为表面特征。接着选择了一个大样本群体, 收集了自我评估、统计评估及行为评估, 旨在衡量 200 种人格的表面特性。之后他使用因素分析方法分析了 200 种人格表面特性之间的关系。因素分析是分析不同评估方法之间相关性模式的一种方法, 从而确定较少数量的潜在成分或因素。例如, 各种各样的体育活动的因素分析 (如所有田径项目) 可能会确定一系列单独的运动能力组成部分 (如加速度、上肢力量、耐力等), 某项特定活动可能主要依赖于某个组成部分或者因素 (如百米短跑: 加速度) 或者不同因素的组合 (如掷标枪: 加速度和上肢力量)。卡特尔认为, 可以将这 200 个表面特征视为 16 个基本因素或根源特质的变形或者组合, 这 16 种基本因素分别是: 情绪稳定、自信、放松、信任、自律克制、认真、外向、依靠集体、无忧无虑、冒险、坚定、自然朴实、激进、富有想象力、温和、聪明。

卡特尔设计了十六型人格因素问卷来评估确定根源特质。每个测试问题只衡量一种根源特质, 且每个根源特质应该相对独立于其他根源特质。卡特尔成功地选取了类似题目来评估每个根源特质, 但根源特质并不完全独立于其他特质。根源特质之间的重叠部分说明上述列表能够进一步缩减, 但前提是不能丧失其区分不同群体种类的能力。

还有许多研究者也使用了因素分析方法, 针对样本群体给出大量不同的测试问题, 不同问题之间的关系经过数据分析, 从而用来确定基本人格因素。使用多种多样的题目以及多样的样本群体, 已经进行了大量人格特质因素分析研究, 通常都会产生 10 到 20 种相互联系的因素, 类似于卡特尔的根源特质。研究者逐渐开始注意到各研究中得到的因素内容上的相似性。进一步分析旨在消除各种因素之间的重叠部分, 表明各种因素列表可以减少到 5 个几乎没有重叠的高阶因素 (Digman, 1990)。 这五种因素通常称之为五大因素, 分别是神经质、外向性、开放性、随和性和责任心。

人格量表修订版 (NEO PI-R)。科斯塔和麦克雷 (Costa & McCrae,1992 b) 从头开始研究测试构建任务, 从五种高阶因素开始, 或如他们所称的五种领域。为了评估所有五种高阶领域挑选并编写了不同题目, 他们在大量人群中进行测试, 仅留下那些只关系到一种领域的题目, 然后对每种领域中的题目进行因素分析, 从而确定组成该领域的子特征或者方面。他们最新的成果是人格量表修订版。该测试名称的 NEO 部分指的是, 五大因素中的前三个: 神经质、外向性、开放性 (PI 指个人量表)。该测试的早期版本只能评估五大因素中的三个, 目前的版本能够评估所有的五大因素, 但原缩略词得以保留下来。

人格量表修订版共有 240 道题目, 旨在测评正常成人个性。测试有两种形式, 一是自我报告 (表 S),另一种是观察者评定表 (表 R)。表 \( \mathrm{R} \) 与表 \( \mathrm{S} \) 的题目类似,但以第三人称陈述。可以将自我评定和观察者评定绘制在同一个档案表上, 从而对某个人在上述两方面进行比较 (见图 14-4)。

人格特质层次结构的假设在计算分数时很明显。该测试为五种领域中的每个领





图 14-4 人格量表修订版

资料来源: 经出版社许可后修改转载。心理学评估资源出版社, 佛罗里达州鲁兹市北佛罗里达大道。 选自人格量表修订版 (NEO PI-R), 作者保罗 T. 科斯塔和罗伯特 R. 麦克雷。1978 年、1985 年、1992 年版权归心理学评估资源出版社, 未经出版商书面许可禁止复制。



域各产生一个得分, 五种领域分别为神经质、外向性、开放性、随和性和责任心。每种领域都有六个独特的方面, 该领域得分是六个方面的得分相加计算得来的。而每个方面由八个测试题目来测评 (5 种领域 \( \times  6 \) 个方面/每种领域 \( \times  8 \) 项 \( = {240} \) 个测试题目)。参见表 14-4, 各个领域及其方面列表如下: 续表



表 14-4 相关形容词检查表

<table><tr><td>NEO PI-R 各方面</td><td>形容词检查表项目</td></tr><tr><td>神经质方面</td><td/></tr><tr><td>焦虑</td><td>焦虑的、恐惧的、担心的、紧张的、不安的、一自信的、一乐观的</td></tr><tr><td>愤怒敌对</td><td>焦虑的、急躁的、不耐烦的、容易激动的、喜怒无常的、一温柔的、紧张的</td></tr><tr><td>压抑</td><td>担忧的、一满足的、一有信心的、一自信的、悲观的、喜怒无常的、焦虑的</td></tr><tr><td>自我意识</td><td>害羞的、一自信的、胆小的、一有信心的、防备的、羞怯的、焦虑的</td></tr><tr><td>冲动</td><td>喜怒无常的、烦躁的、讽刺的、以自我为中心的、大声的、轻率的、易激动的</td></tr><tr><td>脆弱</td><td>一清晰思维的、一自信的、一有信心的、焦虑的、一高效的、一警觉的、粗心大 意的</td></tr><tr><td>外向性方面</td><td/></tr><tr><td>温暖</td><td>友好的、热情的、善于交际的、开朗的、一冷漠的, 深情的、外向的</td></tr><tr><td>合群性</td><td>善于交际的、外向的、享乐的、一冷漠的、健谈的、自发的、一孤僻的</td></tr><tr><td>坚定</td><td>积极进取的、一害羞的、坚定的、自信的、坚强的、热情的、有信心的</td></tr><tr><td>主动性</td><td>充满活力的、匆忙的、敏捷的、坚决的、热情的、积极进取的、活跃的</td></tr><tr><td>寻求刺激</td><td>享乐的、大胆的、富有冒险精神的、迷人的、英俊的、充满勇气的、聪明白</td></tr></table>

<table><tr><td>NEO PI-R 各方面</td><td>形容词检查表项目</td></tr><tr><td>积极情绪</td><td>热情的、幽默的、赞扬的、自发的、享乐的、乐观的、快乐的</td></tr><tr><td>开放性方面</td><td/></tr><tr><td>幻象</td><td>梦幻的、富有想象力的、幽默的、调皮的、理想主义的、艺术的、复杂的</td></tr><tr><td>审美</td><td>有想象力的、艺术的、原始的、热情的、有创造力的、理想主义的、多才多艺</td></tr><tr><td>感情</td><td>自发的、深刻的、富有想象力的、深情的、健谈的、开朗的</td></tr><tr><td>行为</td><td>兴趣广泛的、富有想象力的、富有冒险精神的、乐观的、一温和的、健谈的、多 才多艺的</td></tr><tr><td>想法</td><td>理想主义的、兴趣广泛的、有创造力的、好奇的, 原始的、富有想象力、富有洞 察力的</td></tr><tr><td>价值观</td><td>一保守的、非传统的、一谨慎的、轻浮的</td></tr><tr><td colspan="2">随和性方面</td></tr><tr><td>信任</td><td>宽容的、信任的、一怀疑的、一小心翼翼的、一悲观的、和平的、一硬心肠的</td></tr><tr><td>坦率</td><td>一复杂的、一苛刻的、一聪明的、一轻浮的、一迷人的、一精明的、一专制的</td></tr><tr><td>利他主义</td><td>温暖宽厚的、温柔的、大方的、善良的、宽容的、一自私的</td></tr><tr><td>顺从</td><td>一固执的、一要求多的、一刚愎自用的、一不耐烦的、一狭隘的、一直言不详 的、一硬心肠的</td></tr><tr><td>谦逊</td><td>一炫耀的、一聪明的、一坚定的、一好辩的、一自信的、一积极进取的、一理想 主义的</td></tr><tr><td>温和</td><td>友好的、热情的、同情的、心地善良的、性格温和的、一不稳定的、善良的</td></tr><tr><td colspan="2">责任心方面</td></tr><tr><td>能力</td><td>高效的、自信的、全面的、应变能力强的、自信的、一困惑的、聪明的</td></tr><tr><td>秩序</td><td>组织的、全面的、高效的、精确的、有条理的、一健忘的、一粗心大意的</td></tr><tr><td>责任心</td><td>一防守的、一不专心的、一粗心的、一懒惰的、全面的、一健忘的、一挑剔的</td></tr><tr><td>追求成就</td><td>全面的、野心勃勃的、勤奋的、进取的、坚定的、自信的、持续的</td></tr><tr><td>自律</td><td>有组织的、一懒惰的、高效的、一健忘的、精力充沛的、全面的、勤奋的</td></tr><tr><td>审慎</td><td>一草率的、一冲动的、一粗心的、一没有耐心的、一不成熟的, 全面的、一喜 无常的</td></tr></table>

注: 按绝对大小降序排列相关形容词; 所有形容词都有显著性, \( P < {0.001},N = {305} \) 。形容词前的负号表示与人格量表修订版 (NEO PI-R) 有关方面呈负相关性。改编自 McCrae 8. Costa, 1992。

资料来源: 经出版社许可后修改转载。心理学评估资源出版社, 佛罗里达州鲁兹市北佛罗里达大道。选自人格量表修订版 (NEO PI-R), 作者保罗 - 科斯塔和罗伯特 - 麦克雷。1978 年、1985 年、1992 年版权归心理学评估资源出版社,未经出版商书面同意禁止复制。



人格量表修订版表 \( \mathrm{S} \) (自我报告) 的设计使用了三个研究项目的数据,其中包括约 2200 人。从更大群体中筛选出规范样本 1000 人 (500 名男性和 500 名女性), 控制筛选过程, 使得规范样本的年龄、性别和种族情况与最新人口普查工程中的人口数据一致。但是规范样本的受教育水平有问题, 几乎所有参与者都获得了高中以上教育水平。受教育水平问题实际上可能已经与测试编写者的意图相结合来弥补这个问486。为了保持样本均值接近实际人口情况, 他们删除了受教育水平较高的人。人格表修订版表 \( \mathrm{R} \) (观察者评定) 样本要小得多,针对表 \( \mathrm{S} \) 样本中的 142 人使用配偶评表和同行评定表。

人格量表修订版的心理测量特质是相当令人瞩目的。自我报告各领域分数的内一致性分析得出不同的 \( \alpha \) 系数,范围在随和性 \( \alpha \) 系数的 0.86 和神经质 \( \alpha \) 系数的 92 之间。观察者评定表的一致性更高, \( \alpha \) 系数的变化范围是: 开放性的 0.89 到随性的 0.95 。自我报告的分数信度变化范围是 0.56 到 0.81 , 观察者评定分数信度范围是 0.60 到 0.90 。考虑到每个方面得分仅根据 8 个项目合计, 某些方面的信尤其高。

计划评估稳定的人格特征的测试会得到较高的再测效度。但是大多数人格测试法在时间稳定性的长期评估方面做得不是很好。人格量表修订版 (NEO PI-R) 自评定和观察者评定的相对优势在于其长时间间隔中的再测稳定性。例如, 六年时间隔的自我评定和观察者评定量表研究发现, 各领域分数的时间稳定性系数在 68 到 0.83 之间。

科斯塔和麦克雷 (Costa & McCrae, 1992 b) 积累了大量证据, 证明某些类型测试效度。人格量表修订版的因素分析能够持续复制出作者打算创造出的层次结构, 已经说明各领域和各方面分数存在较高的同证效度 (与其他意在测量相同特征或特征的测试关联性高) 和区分效度 (与测评无关特征或子特征的测试关联性极低或零)。自我 (表 S) 和其他 (表 R) 评级之间的相关系数说明, 自我评定和观察者评定各领域及各方面之间的相关性为中等水平至较高水平。配偶和自我评定之间的相性系数明显高于同行和自我评定之间的相关性系数, 表明评价者越了解被评价者, 系越亲密, 提供的评定结果与自我认知就越一致。

麦克雷和科斯塔 (McCrae & Costa, 1997) 认为, 测试评估的五种领域是人类普的明显特征, 跨越了时间和文化的界限。事实上, 该测试已经成功地翻译成不同的言。翻译版本的因素分析通常会在不同文化和年龄群体中产生五种称谓不同的因 : (De Fruyt, Mervielde, Hoekstra, Hans, & Rolland, 2000; Heuchert, Parker, :umpf, & Myburgh, 2000; Piedmont & Chae, 1997)。然而, 人格量表修订版和本土化中发展出来的其他措施相结合分析说明, 人格量表修订版可能遗漏了某些文化素, 人格量表修订版中各因素可能在特定文化中有不同的含义 (Cheung, Leung, hang, & Sun, 2001)。

针对人格量表修订版的主要批评是, 除了其心理测量方面的优势, 它还没有广泛的实际应用。因素分析得出的维度是从相关模式中提取的统计抽象化概念。这类抽象化概念的名字如 “开放性” 或 “神经质” 等, 只是一种语言标签, 用于象征潜在的统计关系。有时候将统计产生的因素和其他抽象化概念加以比较要更为容易, 比如利其他测试中的分数或因素进行比较, 而将其应用到现实世界的预测及决策制定则会较为困难。例如, 科斯塔和麦克雷 (Costa & McCrae, 1992) 认为, 该测试可能在确定人格障碍患者时很有用。但布切尔和劳斯 (Butcher & Rouse, 1996) 得出结论, 人格量表修订版得分过于抽象和肤浅, 无法用于临床评估。虽然人格量表修订版有望得到实际应用, 仍未充分研究或证实这些应用程序。效度证据仍然很大程度上依赖于与其他测试的相关性, 其中许多测试用于发展最初的五因素人格模型。

第二个问题是, 类似于所有的自我报告测评, 人格量表修订版依靠人的诚实和坦诚来提供评分。要求受访者报告他们是否诚实地回答, 是否回答了所有的问题, 是否在正确的位置上做出回答。作者对受访者完成测试的坦率和能力的信心主要来自于测试开发样本群体的评估。上述信心可能在评估环境中经过了严格测试, 在相关评估环境中, 应试者可能存在某些动机使其最小化或者夸大个人困难 (如残疾评估或人员筛选)。研究员要求样本人群回答测试题目, 从而得出或消极或积极的印象。参与者似乎有能力完成上述任务, 提供的答案与预期一致 (Caldwell-Andrews, Baer, & Berry, 2000; Topping & O'Gorman, 1997)。人格量表修订版也设计了效度量表, 效度量表似乎能够用来确定得到指示的人展现的是积极印象还是消极印象 (Scandell, 2000; Schinka, Kinder, & Kremer, 1997), 以及确定否认自身情况的精神病患者 (Yang, Bagby, & Ryder, 2000)。然而, 对于正常情况下的正常人可能没必要使用效度量表 (Piedmont, McCrae, Riemann, & Angleitner, 2000)。

在本节前面的内容中, 我们提到卡特尔的 16 种因素是否可以减少到更少种类的特征。戈宾和图雷 (Gerbing & Tuley,1991) 研究了 16 种人格因素 (PF) 和科斯塔- 麦克雷早期测试版本即人格量表最新版之间的关系, 表明人格量表最新版与 16 种人格因素量表测评的人格特质基本相同。尽管量表名称可能不同, 但卡特尔 16 种人格因素与人格量表最新版中所对应的方面得分有较强的相关性。此外, 卡特尔 16 种人格因素本身就可以通过因素分析产生数量较少的高阶因素, 与人格量表最新版中的领域得分形成了很好的一致性。 (2)使用实证量表构建识别特征

使用实证量表构建方法已经开发出大量人格和调整能力测试。同样的方法也适用于斯特朗职业兴趣量表/斯特朗兴趣量表的设计。在此量表使用过程中, 选出明显带有某种特征的一群人, 给出大量题目, 而同样的题目也会给代表一般人群的样本群体。题目筛选仅根据其区分所选群体和代表群体的能力。

明尼苏达多项人格调查量表 (MMPI)。明尼苏达多项人格调查量表主要用于提供客观量表, 诊断特定的心理障碍患者。明尼苏达多项人格调查表初始版本的作者 (Hathaway & Mckinley, 1940) 用实证量表方式去研究病理学评估, 已有测试、研究和病理学相关特征说明文本都被用来构建大量能够用是或否来回答的题目。海瑟薇和麦金利确定并测试了几组有特定心理障碍的样本, 他们对哪些特征能够区别正常组和诊断组没有先验理念, 相反, 他们对整个序列的题目进行了测试, 使用统计程序来选择能够用来分类的题目。海瑟薇和麦金利首先从一群体细胞出现问题但医生找不到任何机体原因的神经质患者开始。测试题目针对这些病人进行测试, 同时也针对参照组进行测试, 参照组主要是到医院的正常人。最终保留能够区分开这两组人的那些题目, 用来构建明尼苏达多项人格调查疑病症量表。该量表同样针对第二组患疑病症的病人进行测试, 确定这些题目能够将该组病人与正常参照组区分开。海瑟薇和麦金利以类似的方式进行测试, 开发出了 9 种其他群体的临床量表。

明尼苏达多项人格调查量表的一个主要问题在于用于设计量表的“正常”组。医院的访客不管是在人口变量基础上还是在人格变量基础上并不能代表一般人群。即使他们能够代表一般人群, 他们正在医疗机构里看望病人这一事实也表明, 这群人中的许多人在完成测试题目时, 承受着心理压力。在实证测试构建过程中, 选择良好的目标群体和参照群体极为重要, 因为抽样误差会影响量表题目的选择。

明尼苏达多项人格量表的临床量表。建立在实证基础上的 10 个基本分数代表如下标签。标签后是测试组的特性描述, 该测试组是量表的基础。

1. 疑病症(Hs): 过分担心健康,报告无名病痛及不适,但其症状并没有机体原因 (32 项)。

2. 抑郁症(D): 慢性抑郁症,感觉自己无用,无法面对未来 (57 项)。

3. 转换性癔症(Hy); 通过出现身体症状如瘫痪、痉挛、胃痛或心脏症状对个人问题做出反应。否认心理问题 (60 项)。

4. 精神病态(Pd): 不负责任,无视社会规范或对他人的关心,缺乏深刻的情绪反应 (50 项)。

5. 男性一女性(Mf): 高分表明偏离文化规定的性别角色倾向。低分表明持有性别角色偏见 (56 项)。

6. 偏执(Pa): 过度地怀疑别人及其动机,人际关系敏感,相信某人正遭受迫害 (40 项)。

7. 精神衰弱(Pt): 过度的担心 (恐惧) 和强迫性重复某些行为,崇高的道德标准, 自责, 僵化的冲动控制 (48 项)。

8. 精神分裂症(Sc): 奇怪和不寻常的想法或行为,脱离现实的主观体验 (78 项)。

9. 轻度躁狂(Ma): 身体和精神过度活跃,思想或行为的快速转移 (46 项)。

10. 社交内向(SI): 倾向于保守秘密,避免社交聚会。低分表明外向 (69 项)。

明尼苏达多项人格调查量表中既包含明显的病理题目, 也包含了似乎中立或者无关痛痒的题目, 是这两者有些不寻常的结合。这两种类型的陈述称为明显题目和隐蔽题目。同一种量表中的明显题目和隐蔽题目之间是完全不相关的。交叉验证研究表明, 区分病理组的是明显题目, 而非隐蔽题目 (Duff, 1965)。由于该量表的优势在于明显题目, 所以明尼苏达多项人格调查量表会出现扭曲事实的回答, 这主要来自于那些出于某种理由夸大或缩小其困难的人。测试设计者很快就发现了上述问题, 因为某些病人属于严重失常样本, 但竟然得出了正常测试分数。他们及时开发了效度量表, 来确定并纠正受访者的虚假陈述。常用的效度量表有四种:

? 测试者没有作答的题目数量。大量的空白题目被视为防御性和退出任务的表现。

L 同意选项为 “好” 但极不可能的题目数量 (如 “我从来没有说谎”)。可能表明神经防御或试图去展示自己的出色 (15 项)。

\( \mathrm{F} \) 同意非常罕见和极不寻常的题目数量 (如“有一个全球大阴谋在读取我的思想”)。高分可能表明应试者没有理解和遵循题目说明或应试者可能假装或夸大症状 (60 项)。

\( \mathrm{K} \) 测试中经常被严重错乱的病人选择但测试分数与正常人无异的赞同题目数量 (如 “我喜欢几乎所有我见到的人”。) 高分被视为老练世故的防御型风格的标志, 以及用 “社会认可” 的方式来形容自己的倾向 (30 项)。

最有趣最有争议的效度量表是 \( \mathrm{K} \) 量表。目前尚不清楚该量表到底能在多大程度上评估防御性,即与真实合理的积极的自我形象截然相反的形象。 \( \mathrm{K} \) 量表中等偏上的分数在生活美好的成功人士以及某些临床病人中较为常见。 \( \mathrm{K} \) 量表评分主要是根据病人防御性的相对敏感性来调整 10 种临床量表中的 5 种。

对明尼苏达多项人格调查量表前 50 年的使用研究, 产生了大量的数据。在 20 世纪 80 年代, 该量表在研究的基础上进行了修订 (Hathaway & McKinley, 1989), 修订主要是为了纠正某些原始量表中出现的缺陷。例如, 根据由 1138 名男性和 1462 名女性组成的全国样本群体设计了新的标准。样本群体包括合理的少数民族群体的代表。但是新样本群体的受教育水平远远高于全国平均水平, 导致对受教育水平较低的个体使用测试时会出现问题。尽管重新调整标准有助于调整分数来适应当前的人口特征, 但并没有改进题目选择时使用无代表性样本群体产生的最基本问题。最初的题目经过剔除改编来改进内容落后或冒犯他人的题目, 也尝试了 154 道新题目。 修订版 (明尼苏达多项人格调查量表第二版 MMPI-2) 包括 567 道题目, 而“基本量表根据前 370 道题评分” (Hathaway & McKinley, 1989, 第 15 页)。

4 类似于许多其他使用实证量表构建的测试, 明尼苏达多项人格调查量表第二版的不同量表之间有很多重叠题目。某道题回答是可能在某两个量表中会提高分数, 但在第三个量表中可能会降低分数。因此量表之间并非相互独立的。尽管说这是一个较为严重的评估问题, 但也说明了测试构建背后的事实: 两个有不同心理障碍的患者可能会有一些共同的症状, 表现出特定病情的其他症状。例如心理缺陷感对许多疾病, 包括抑郁症和饮食失调是很常见的。但每一种障碍症也包括其他症状, 需要进行不同的诊断。

测试设计者最初的设想是, 这个测试可以根据某项分数的提高来诊断临床情况。 相反, 明尼苏达多项人格调查量表第二版的档案表以若干量表形成的分数规律为基础。从理论上来说,抑郁症患者的疑病症(Hs)量表和转换性癔症(Hy)量表分数较高,而轻度躁狂(Ma)量表分数较低,因为抑郁情绪通常伴随着对身体症状的担忧和活跃度较低。说明测试结果通常需要比较应试者得分最高的两到三个量表和几百份经过验证的临床档案 (Hathaway & McKinley,1989)。大多经过验证的临床档案主要通过明尼苏达多项人格调查量表第一版获得。研究者对第一版量表进行了修订, 设计了尼苏达多项人格调查量表第二版, 这些研究者仅进行了保守修订, 仍然使用第一版档案来解释第二版量表 (Butcher & Williams, 1992a)。但是若对第一版量表和第二版量表中得到的同一批应试者的档案进行直接对比, 可能会发现一些重大差异, 能够改变对量表的解释和分类 (Dahlstrom,1992)。这个问题可能在临床应用中不是特别重要, 因为明尼苏达多项人格调查量表第一版与第二版之间的档案差异主要存在于正常的应试者中。患病的人更可能在两种测试类型中产生一致的档案 (Butcher &. Rouse, 1996)。

明尼苏达多项人格调查量表第二版临床量表提供了再测信度和内部一致性信息。在 82 名男性样本中, 平均时间间隔超过 1 周的再测信度介于 0.67 和 0.92 之间,而在 111 名女性样本中则介于 0.58 和 0.9 之间。男性样本中的 \( \alpha \) 系数信度介于 0.33 和 0.85 之间, 女性样本则介于 0.36 和 0.87 之间。明尼苏达多项人格调查量表第二版 MMPI-2 大多数题目内容与第一版相比没有太多变化。因此, 对五十多年以来初版明尼苏达多项人格调查量表的使用研究所收集的效度证据, 以及作为心理测量工具所保留的某些品质仍然可以使用。

据称, 明尼苏达多项人格调查量表是在临床实践中使用范围最广泛的自我描述量表, 已经广泛应用于其他情景中。例如, 第二版明尼苏达多项人格调查量表通常用于诊断心理疾病, 并为患有心理疾病的人制订治疗计划。也经常用于某些工作岗位的人员选拔, 涉及较强责任及较高压力的职位, 比如警察。在某些敏感甚至改变生活的情况中广泛使用该测试使人们对其公平性产生担忧。设计最初的明尼苏达多项人格调查量表及制定标准时, 没有考虑到文化和种族的多样性。第二版明尼苏达多项人格调查量表的规范样本更加多样化, 能够代表全国人口。但是使用更新版的更加多样化的规范样本并不能减少人们对该测试的担忧, 由于测试题目筛选时只使用白人样本, 因此测试内容可能有失偏颇。事实上, 在若干第二版明尼苏达多项人格调查量表中, 美国非洲裔样本平均得分更高。目前尚不清楚这些较高的分数是否反映了测试偏差或非裔美国人群体中某些类型的症状更为明显 (McNulty, Graham, Ben-Porath, & Stein, 1997)。

该测试除了在心理测量方面的缺陷之外, 明尼苏达多项人格调查量表已经被广泛地接受和使用, 尤其是临床心理学家。除了使用分数和整个档案, 临床医生可能还会考察某些特殊问题或者某些问题组的回答, 从而获悉或者理解病人情况。但是只能由具备广泛临床经验的人来使用该项测试, 且只能作为整个诊断过程的起点。该测试设计者认为, 完成心理测试和精神病理学研究生课程是使用明尼苏达多项人格调查量表的最低教育标准, 但我们建议需要更高标准, 除非在训练有素的医生直接监督下进行测试。对于第二版明尼苏达多项人格调查量表的详细信息, 例如各类专业量表和报告等, 可以通过出版商网站 http://www.pearsonassessments.com/ assessments/index. htm 获取。

还有一个青少年版的明尼苏达多项人格调查量表, 即明尼苏达多项人格量表一青少年版 (MMPI-A; Butcher & Williams, 1992b)。明尼苏达多项人格调查量表青少年版提供一系列临床量表和效度量表, 与成人版本一样。量表使用标准是通过适当年龄的样本来建立的。

## 3. 人本主义研究法: 性格与自我认知

卡尔・罗杰斯 (Carl Rogers) 在心理学中倡导人本主义方法, 并将自我意识视为流行文化的一部分。罗杰斯 (Rogers, 1951) 认为, 人类存在一种自我完善趋向的基本驱动力。他认为, 我们会形成自己想要成为谁或者成为什么的观念, 而且会不断缩小理想状态和现实的自我意识或自我评价之间的差距。罗杰斯认为, 这些自我评估是人格的核心。他提出了一种新理念, 即个性测试应该只是自我评价过程形式中的一部分。个人本身应该进行评价并说明测试结果, 而不是心理学家或分析师。

罗杰斯最早的自我意识正式测评方法是 \( \mathrm{Q} \) 分类技术,是一种自我评定的方法。 该方法利用一组简短自我描述的陈述卡片, 首先应试者按照最不能描述自己现状到最能描述自身现状的顺序对卡片进行排序, 接着对同样的卡片进行排序来描述自己的理想状态, 这种自我评定是一种自我意识测评方法, 自我现状和理想自我评定之间的差异能够产生自我满意度评估。而人本主义心理学家则充当了顾问和教练的角色, 不是解读测试过程中的外部评估者。罗杰斯鼓励应试者自己去解释说明测试结果, 去探索评分的意义。

(1)其他自我意识评估方法

其他学者很快也设计了大量白我意识评估方法。卷面测试形式逐渐取代了 \( \mathrm{Q} \) 分类技术, 现代测试技术也应用到随后的测试开发和分析中, 早期的定性自我诠释测评被测试分数的规范对比所取代。当代自我意识评估格式已经与特征测试基本无异, 能够区分自我意识测试的特征主要在于, 自我意识测试对自我认知进行评估, 或者是在一系列正常范围内的人类行为中评估个人的自我满意度。自我意识测试得到的分数, 不管是叫做白我意识得分还是自尊得分, 往往与调整能力的自我评估有较高的相关性 (Bracken, 1991)。

近年来对自我意识评估的关注日益增加, 尤其是关于儿童和青少年。已经证明自我意识得分与多种发展指标和社会适应能力相关联。自我意识和调整能力之间的因果关系还不清楚, 例如, 对自身的积极看法究竟是良好调整能力的原因还是结果。 然而, 许多教育家提倡教育孩子更积极地看待自己, 希望此举带来良好的调整能力及更高的成就。

多维度自我意识量表。多维度自我意识量表 (MSCS) 由布拉肯 (Bracken,1992) 殳计, 其中包含 150 道测试题目, 主要用于评估 9-19 岁儿童和青少年的自我意识。 10 年来使用不同自我意识评估方法的因素分析研究表明, 自我意识不是单一维度的。根据我们进行自我评价的各个方面以及进行自我描述的社会背景, 自我评定可走会不同。例如, 有人可能在与家人关系中的自我形象较为积极, 但在社交场合中可能会不自在。也有人可能会认为自己很能干, 但对她自己的身体感到尴尬。多维自我意识量表通过提供总分和六种领域的分项得分来展现自我意识的复杂性质。如图 14-5 所示, 这六种领域分别是: 社交、能力、影响、学业、家庭和身体。





图 14-5 布拉肯自我意识模型

资料来源: B. A. 布拉肯, 多维度自我意识量表手册。得克萨斯州奥斯汀市: PRO-ED, 1992, 第 5 页。经许可后重印。



布拉肯将上述六种领域视为一般自我意识中高度关联的六个部分。测试标准根据 5-12 年级学龄期青少年样本建立, 筛选该样本来代表不同年龄段的美国人口。 罗塔托里 (Rotatori, 1994) 指出, 尽管该样本能够代表不同性别和种族情况, 但某些地区的代表人数超出相应比例, 且缺乏社会经济地位数据。有证据表明, 若干美国少数民族中, 自我意识各领域是一致的 (Tansy & Miller, 1997; Wilson, 1998), 并且某些领域在三年级水平就可以进行评估 (Wilson, 1998)。

多维度自我意识测试有较高的内部一致性,每个年龄段的总分 \( \alpha \) 系数能够高达 0.90 以上。各领域分项得分的 \( \alpha \) 系数略微低于总分,变化范围介于九年级学生能力量表的 0.85 和若干年级学生家庭量表的 0.97 之间。该测试的时间稳定性也较强,4 周时间间隔的总分再测系数为 0.90 。各领域分项得分的再测系数变化范围介于影响量表的 0.73 和学业与身体量表的 0.81 之间。布拉肯认为, 测试的内容效度应该基于测试所评估的各领域和先前研究中确定的自我意识各方面之间的匹配程度。

比较多维度自我意识量表分数和其他自我意识测试分数可以发现, 两者之间存在较高的相关性, 从而证明多维度自我意识量表的同时效度。测试手册还提到了相关研究, 表明该测试能够较好地区分自尊评定较低的儿童及情绪困扰测试中得分较低的儿童。

## 4. 行为研究法

传统行为主义是传统人格观念的对立面。约翰・沃森 (John B. Watson) 以及后来的 B. F. 斯金纳 (B. F. Skinner) 坚决反对使用那些不能进行直接观察的测试。动态枢动力、特质和自我意识都是传统行为主义者希望废除的测试类型。认知心理学的安展对行为主义产生了深远影响, 尤为重要的是阿尔伯特 - 班杜拉 (Albert 3 andura) 等理论家的贡献, 阿尔伯特 - 班杜拉逐渐意识到, 习得的社会行为关系到小显行为和 “内部行为”, 例如通过图像和文字来描述某些事情, 做出判断或者体验情求等。一旦内部行为尤其是认知被认为是合理的研究中心, 行为主义研究范围将会大大扩展。

传统的行为学家认为, 没有必要推测人的内心结构, 以此来解释不同时间情境中的行为一致性。相反, 不同情境中的类似行为主要解释为不同环境中的相似性所控训的习得反应。个体之间的差异主要是因为个体先前的学习经历。人们寻求不同的青境或在同样情境中有不同表现, 是因为他们已经习得如何将不同的刺激因素或者有不同后果的不同行为联系起来。

最初, 人们主要通过直接观察对行为模式进行评估。观察者会记录某个特定的子为, 行为产生前的环境刺激, 以及随之而来的后果。还利用情境测试, 将某人置于 ξ际情况中, 预测其表现, 从而评估行为模式。例如, 可以将求职者放在紧张的环境可, 评估其管理工作压力的能力。后来该过程经过删减, 使用自我报告形式, 受访者老够回忆或评估重要的刺激因素、行为模式及其后果。后来, 自我报告卷面测试逐渐的盖认知、判断及情感原因。现代测试技术也应用到上述自我报告测试中, 自我报告 \( {f}_{2} \) 式与传统特征量表非常相似。但是,上述测试开发者声称,自己是在直接测评行为 【行为模式, 而不是控制或引导行为的内心结构 (如自我、特质或自我意识)。

(1)米隆临床多向问卷第三版

西奥多・米隆 (Millon, Millon, & Dalis 1994) 设计了一种非常创新的以行为为 5 础的测试, 该项测试已经在临床医生中获得了相当高的知名度。该测试与第二版 1 尼苏达多项人格量表 (MMPI-2) 直接竞争, 因为该测试也用于鉴别具有严重心理 ] 题的人并对其加以分类。但是米隆开发测试所使用的理论方法与海瑟薇和麦金利用的实证量表构建完全相反。米隆临床多向问卷第三版 (MCMI-III) 是根据米隆 J人格和精神病理学理论 (Millon, 1990) 设计的测试最新版本, 共有 175 道题目, 提 \( \$ {24} \) 种临床量表分数,这 24 种临床量表主要分为四组: 临床人格障碍 (11 个量表), \( {}^{z} \) 重人格障碍 (3 个量表),临床综合征 (7 个量表),以及严重临床综合征 (3 个量表)。

临床人格障碍量表。米隆认为, 具有临床人格障碍的人能够用两种行为类型来行分类: 强化过程和行为应对方式。米隆最初根据五种强化过程和两种应对方式 \( \left( {2 \times  5 = {10}}\right) \) 确定了 10 种临床人格障碍。表 14-5 列举了这 10 种基本障碍,称为临床人格模式。与每种人格模式相关联的行为特征在表 14-6 中进行了总结。该工具增添了第十一种个人量表, 即抑郁量表来解释那些以放弃来应对的人。他们会有出失去希望和对未来绝望的表现。因此在整个临床人格障碍测试中共有 11 个临床人格模式量表。



表 14-5 米隆临床人格类型

<table><tr><td rowspan="2">强化模式</td><td colspan="2">应对方式</td></tr><tr><td>消极的</td><td>积极的</td></tr><tr><td>孤立的</td><td>精神分裂的</td><td>避免性的</td></tr><tr><td>依赖性的</td><td>依赖性的</td><td>夸张的</td></tr><tr><td>独立的</td><td>自恋的</td><td>反社会的</td></tr><tr><td>不和谐的</td><td>自我挫败的</td><td>好胜的</td></tr><tr><td>矛盾的</td><td>强迫性的</td><td>抗拒的</td></tr></table>

表 14-6 米隆临床人格障碍的行为特征

<table><tr><td>临床人格障碍</td><td>强化模式</td><td>处理方式</td></tr><tr><td>精神分裂</td><td>孤立的: 很少有来自生活乐趣的回报</td><td>被动的: 冷漠, 放弃的</td></tr><tr><td>回避型</td><td>孤立的</td><td>主动的: 积极避免痛苦</td></tr><tr><td>依赖型</td><td>依赖的: 快乐和痛苦来自于他人对自己 的感觉</td><td>被动的: 等待他人来指导或联系他们</td></tr><tr><td>夸张型</td><td>依赖的</td><td>主动的: 为了得到别人的目光或赞同 去控制某些东西</td></tr><tr><td>自恋型</td><td>独立的: 自私地满足自己的需求和希望</td><td>被动: 沉浸在自我肯定中</td></tr><tr><td>反社会型</td><td>独立的</td><td>主动的: 剥削和利用他人</td></tr><tr><td>自我挫败型</td><td>不和谐的: 用痛苦替代快乐</td><td>被动的: 允许自己被利用和被虐待</td></tr><tr><td>好斗型</td><td>不和谐的</td><td>主动的: 从虐待他人中获得快乐</td></tr><tr><td>强迫型</td><td>矛盾的: 寻求赞同与表达愤怒 (独立与依 赖) 之间的冲突</td><td>被动的: 抑制怨恨和过度服从的</td></tr><tr><td>抗拒型</td><td>矛盾的</td><td>主动的: 表达怨恨, 感到内疚</td></tr></table>



严重人格障碍量表。严重人格障碍量表评估的人格错乱特点是, 极端失调的应对方式和偶然脱离现实。上述障碍的三个量表如下:

分裂型: 孤立、自闭、迷茫的人, 在别人看来行为怪异。他们极端失调的应对方式可能包括主动及被动特征, 如过度敏感和缺乏情感。

边缘型: 依赖型人, 经常被感知到的来自其他人的接受或拒绝引发激烈的情绪波动。该极端失调的应对方式通常包括对被感知到的拒绝做出自杀行为和/或自残496行为。

偏执型: 独立的个人, 由于其他人的不信任、欺骗的及防御性风格引起对他人的愤怒恼火, 表现为诿过于人。这种失调的应对方式主要表现为极力抵制他人的建议或指导。

临床综合征量表。临床综合征量表描述相对独特的症状模式, 可以形成某人个性风格的延伸。例如, 强迫型容易发展为焦虑性综合征。临床综合征量表包括以下量表:

焦虑: 担心、忧虑或恐惧症状。

躯体型障碍: 与健康和身体机能相关的症状, 包括疼痛、健康担忧、疲劳、头晕等。

双相狂躁: 阶段性欣快、白尊心膨胀、多动、注意力分散、不切实际的乐观情绪。

情绪障碍: 长期的低度到中度抑郁, 非人格核心部分的时期, 尚未造成无力正常持续发挥机能的时期。

酒精依赖: 酗酒, 妨碍社会调整能力和机能正常运作。

药物依赖: 滥用药物, 妨碍社会调整能力和机能正常运作。

创伤后应激障碍: 非自主的侵入性记忆或再次经历创伤事件, 伴随着对创伤的高度敏感及对引起创伤回忆之物的回避。

严重临床综合征量表。严重临床综合征量表主要描述极端症状模式足以引起严重的定向障碍和/或失去身体机能和应对的能力。这些量表包括:

思维障碍: 精神病思维模式, 包括混乱思维、定向障碍、幻觉、妄想或片段奇怪的想法。通常伴随着怪异的行为。

抑郁症: 抑郁症状严重, 个人不能良好运转。

妄想障碍: 极端怀疑和错觉, 脱离现实。

所有上述 24 个临床量表都是在操作上评估米隆理论所描述的人格类型或者症状类型 (Millon et al., 1994)。这些量表后来与美国精神病学协会开发的诊断手册列举的目前已知的精神疾病及其症状相比较, 上述量表的题目做出了相应的添加或修改, 以同时满足米隆理论和诊断手册的要求。最终有 325 项题库在 600 名精神病患者中进行测试。不同的量表题目组合通过数据分析评估来选择最能够描述每种诊断类型的题目, 同时也减少确定具有某种特定障碍的病人所必需的题目数量。值得注意的是, 筛选量表题目主要是根据题目在区分不同诊断组的效力, 而不是像明尼苏达多项人格调查量表 (MMPI)一样区分诊断组与正常组。两种测试之间还存在一个显著差异, 即米隆临床多向问卷第三版的最初题目筛选以理论为指导, 且使用数据分析方法随后进行检验, 而明尼苏达多项人格调查量表仅仅依靠实证基础。

除了这 24 个临床量表, 米隆还开发了类似于明尼苏达多项人格量表效度量表的四个量表。主要包括:

真实: 描述极不可能的经历的题目。

公开: 倾向于公开的和敞开的, 与不公开的或秘密的相对。

合意: 希望把自己表现得有道德的或有社会吸引力的。

贬低: 倾向于自贬或自谦。

公开、合意和贬低量表可以用来调整临床量表得分, 就像是完成了明尼苏达多项人格调查量表中的 \( \mathrm{K} \) 量表。

图 14-6 是从假定病人测试中获得的分数总结档案示例。该档案的修改指标部分包含病人进行测试的信息。公开、合意和贬低量表的分数分别编码为 \( \mathrm{X}\text{、}\mathrm{X} \) 和 \( \mathrm{Z} \) 。 档案中的临床人格模式部分使用编码 1 到 \( 8\mathrm{\;B} \) 来记录分数,即精神分裂 (1)、回避型 (2A)、抑郁型(2B)、依赖型(3)、夸张型(4)、自恋型(5)、反社会型(6A)、好斗型(6b)、 强迫型 (7)、抗拒型(8A)和自我挫败型(8B)临床人格障碍量表。严重人格障碍量表部分得出三种严重人格障碍的分数: 分裂型 (S)、边缘型 (C) 和偏执型 (P)。临床症状部分记录焦虑(A)、躯体型障碍(H)、双相狂躁(N)、情绪障碍(D)、酒精依赖(B)、药物依赖 (T)、创伤后应激障碍 (R) 分数。最后, 严重临床症状部分记录思维障碍 (SS)、抑郁症 (CC)、妄想障碍 (PP) 分数。

米隆临床多向问卷第三版的另一个创新之处在于分数记录的方式。米隆认为, 使用正态分布的分数是不恰当的, 因为量表旨在评估病理, 不应该得出分数的钟形分布。相反, 该测试根据规范样本中每种障碍的普遍程度记录了基准分数 (BR)。基准分数变化范围在 0-115 分之间, 75-85 分之间的基准分数表明存在某种特定疾病或某种综合征特点, 85 分以上表明特征非常明显。

米隆临床多向问卷第三版具有较高的内部一致性。 \( \alpha \) 系数的范围介于强迫症的 0.66 和重度抑郁症的 0.90 之间, 大多数系数在 0.80-0.85 之间。5-14 天时间间隔的再测系数变化范围介于焦虑的 0.84 和躯体型障碍的 0.96 之间, 大多数都在 0.89-0.93 之间。

米隆通过联系比较自己的量表分数和大量旁系测试以及临床医生评定, 研究了米隆临床多向问卷第三版的同时效度。与其他旨在评估类似精神病理类型的测试相比, 米隆临床多向问卷第三版具有中高等聚合效度。例如, 明尼苏达多项人格调查量表第二版的抑郁量表与米隆临床多向问卷第三版的情绪障碍量表 (相关系数在 0.68498以上), 重度抑郁症量表 (0.71 以上) 和抑郁量表 (0.59 以上) 相关性较强。但是, 米隆临床多向问卷第三版与其他临床测试相比, 不会总是具备良好的区分效度。



AGE 48 RACE NHITE DATE TESTED 6 /25 /94 Hand-Scoring Profile



图 14-6 米隆临床多向问卷第三版档案表

资料来源: 经国家计算机系统许可使用, 明尼苏达州明尼阿波利斯市。2006 年培生教育出版集团版权所有。



例如, 明尼苏达多项人格调查量表第二版抑郁量表也与米隆临床多向问卷第三饭许多量表存在相关性 (精神分裂 0.46、回避型 0.46、依赖型 0.53、夸张型 0.52 、自峦型 0.52 、自我挫败型 0.49 、分裂型 0.45 、边缘型 0.47 、焦虑型 0.52 、躯体型障碍 ). 65 、创伤后应激障碍 0.50 、思想障碍 0.58 )。这种情况并不令人惊讶, 因为米隆临末多向问卷第三版量表之间紧密相关。独立临床样本中已经记录了量表重叠问题 Davis & Hays, 1997)。量表重叠部分会降低测试的诊断能力, 因为某个患有某种章碍的病人可能在评估其他疾病的量表中获得高分。

测试手册不会记录分项得分的因素分析, 但量表的相关矩阵检查表明, 量表没有则试开发者想象的那么有区分性。许多量表之间的高度相关性 (相关性系数在 0.70 以上非常普遍) 表明, 24 种不同临床测试分数的使用可能会不太合理, 因为不同量表之间存在重叠部分。尽管缺乏量表纯度, 该测试在匹配临床医生做出的诊断方面还是相当有效的。但是部分效力源于对两组病人使用相同的临床评定及相同的基准分数评估。

该测试的优势似乎在于人格障碍的评估, 它一直与刑事司法领域关系极为紧密, 且人格障碍的评估在决定受审资格、刑事责任、量刑及未来不正当行为预测等方面非常重要。虽然米隆临床多向问卷第三版量表可能在司法系统许多阶段都很有用, 但关于该测试是否足以在刑事审判程序中用作证据也争议颇大 (Dyer & McCann, 2000; Rogers, Salekin, & Sewell, 1999; Schutte, 2000)。额外信息可以在 http:// www. pearsonassessments. com/tests/mcmi-3. htm. 上获得, 包括可出版商的相关报告和服务。

## 14.4 性格和兴趣测量存在的问题

兴趣和性格卷面测试中存在许多问题, 遭到许多批评。其中一个误差来源是反应定势, 即应试者作答题目得到的测试结果可能会受到歪曲。例如, 某个人可能有一种默许或者“点头就好”的倾向。这个反应定势是接受或同意陈述的一种简单习性。 在斯特朗兴趣量表中, 某个有默许反应定势的人可能会在大量题目中选择 “喜欢”。 那么性格或调整能力测试评分可能会被歪曲, 因为应试者可能会得出如下结论, “是的, 在某些方面或某些时间, 这可能是真实的我”。例如, 某个学生拿到形容词检查表, 将 300 个词中的 297 个标记为表现了真实的自己, 被质疑时, 他会说除了三个形容词, 其余形容词有时候描述了真实的自己。相关的反应定势包括, 要求回答题目中陈述的赞成或反对程度时喜欢中点位置或端点位置。

第二种反应定势涉及以某种心境或者以创造某种印象为目的接受测试。例如, 一些应试者将自己的反应基于社会赞许, 倾向于选择他们认为有更多的社会认可度或接受度的反应。兴趣陈述在价值观上相对中立, 因此社会赞许不太可能成为一个严重的问题, 但可能在性格和调整能力评估中成为问题, 这些测试中的许多题目都有或高或低的社会赞许性, 或者应试者企图从消极角度展现自己。在解释测试结果时必须注意应试者可能会通过表面的问题获得利益。假设你在某场诉讼中提出了心理伤害, 或者控诉与刑事诉讼相关的心理障碍, 进行残疾评估时接受能够产生赡养费的测试, 那么你要如何以不同的方式进行测试呢? 这显然不同于在研究中或者在招聘筛选中进行同样测试的情况。

自我报告的性格和调整能力评估相关结果也会由于其他几个问题产生歪曲。应试者可能无法或不愿阅读或理解大量题目。有些人可能不会置身事外去看待自己的行为, 决定某个特定陈述是否适合自己。有些人可能过于严于律己或太勇于承认个人弱点。明尼苏达多项人格调查量表第二版和米隆临床多向问卷第三版中的效度指标有助于识别并改善上述问题, 但是上述效度量表并不完美。例如, 通常很难判断一个人是真的自信还是试图以这种形象展现自己。

还有一些伦理问题值得关注, 因为测试环境可能涉及隐私侵犯, 要求个人提供可能会违背自己利益的信息, 或者某些 “不当” 性格或调整能力分数可能会限制某个人的机遇。因此, 性格和兴趣评估方法应该只有当测试结果有益于应试者时使用, 且只能由经过充分临床培训经验丰富的人进行解释。

兴趣和性格评估明显不同于认知能力测试。认知能力测试量表之间通常会有较强的正相关性, 因此测试结果能够总结为一个分数。因此, 预测学业及职业成就的大多数能力中通常存在普遍的一般能力因素。这种因素结构的简单性使得测试相对容易理解和解释。但兴趣和性格截然不同。本章回顾的若干测试包括许多不同的分数或量表, 不能简单概括在一个分数里。因此, 每个分数都应该在某个人兴趣或性格方面提供独特的新信息。上述较为复杂的测试使得效度评估和分数解释非常具有挑战性, 只是由于测试的多面性。人格量表修订版这类几乎能够完全实现量表独立的测试呈现出较大的挑战性。其他的测试, 包括尼苏达多项人格调查量表第二版和米隆临床多向问卷第三版, 应该相对独立, 但实际上相关性很高, 这进一步将解释和校验测试分数复杂化。

也许沃尔特・米歇尔 (Walter Mischel, 1968) 提出的批评是迄今为止对客观性格测试批判最为强烈的, 且尚未得到相关回应。米歇尔所熟悉的大量研究, 主要是从社会心理学研究中积累产生的。研究表明, 实验者可以同时创建实验室情境和现实情境, 两种不同情境很大程度上能够决定行为表现, 不考虑 “性格差异”。人们可以控制社会环境, 从而大体上准确判断测试者的行为是诚实还是不诚实, 是利他的还是冷漠的, 是整体的还是独立的, 是攻击性的还是被动的等等。米歇尔最初认为, 人格理念是一种错觉。随着时间的推移和情况的变化, 人们的行为不一致, 主要是由他们所处的社会环境决定的。他指出, 性格测试通常与其自身或其他测试一致, 但在预测实际行为方面却效果很差。他回顾已有研究得出的结论是, 性格测试与行为外在评估之间的相关系数总是在 \( {0.20} - {0.30} \) 之间。

许多研究者从逻辑和方法论角度批评米歇尔的结论。他们认为, 某种行为或情境不足以衡量个体差异。假设你认为自己是一个慷慨的人, 你是否在所有情况中的所有时间内都是慷慨的? 你会认为随机选择的某天中一个随机事件是表示你慷慨的良好指标吗? 批评者认为, 性格方面的恰当行为测试应该包括很多性格特征相关的行为, 由不同观察者在不同的情境中经过合理的时间段进行收集。爱普斯坦 (Epstein, 1983) 表明, 当积累多种观测结果产生更好的行为样本时, 性格测试和行为之间的相关性能够大大提升。米歇尔 (Mischel,1993) 承认他最初结论的局限性, 原因在于行为样本不足。他现在认为, 测试和行为种类之间存在的一致性要远高于他最初的看法。但他认为个人之间的一致性并没有我们想象的那么高。米歇尔认为, 行为最好解释为个体特征和社会环境之间的互动, 但环境变量往往拥有更大的影响力。

## 14.5 计算机评分与解析

通常情况下, 兴趣和性格测试的评分和说明极为复杂且耗时, 原因在于各种量表的复杂性质。例如, 在某些情况下不同题目得分需要加权, 这使得手动打分非常费劲。此类测试的计算机评分算是临床医生的福音, 计算机软件开发有利于通过计算机进行测试, 且得分几乎是即时的。另一个重要的发展是计算机分析报告在各个组织机构中的迅速扩展。临床医生可以获取大量评分服务和计算机分析报告, 包括提供特定量表分数, 提供详细的叙述报告, 甚至可能包括行为表现的预测性陈述, 如斯特朗量表生成的多页报告等。计算机技术无疑大大改进了兴趣和性格测试过程, 但是需要注意的是, 使用上述自动化系统有利也有弊。

## 优点

1. 省时、便利, 可以更及时地提供得分和反馈, 特别是在电脑上进行的测试。

2. 提高临床医生效率。使用电脑计分系统可以解放临床医生, 使他们可以有更多时间来直接服务病人。此外, 生成报告的新软件系统中会有许多选择菜单, 临床医生能够选择最适合病人, 或最适合评估问题的文本。

3. 标准化。上述报告高度标准化的特点有助于消除由个人解释说明带来的偏差和潜在偏见。同样分数总是产生同样叙述性评论。

4. 实证预测。计算机生成的报告更有可能直接地与精算数据相关联, 因为可以在系统里内置大型数据库中的案例和病人病史。

## 缺点

1. 缺乏个性化。计算机生成的报告可能不具有充分的个性化, 因而不能够搜集高度私人化的病人情况。通用的描述往往可能适用于许多人, 且语气较为机械化, 可能会缺乏精准细微的描述。

2. 存档。评分服务机构不一定会提供报告中不同叙述性陈述的文件, 因此很难评估报告或评分服务的质量。

3. 效度问题。虽然计算机生成的报告可能是基于很多病人案例, 但与所评估的具体病人相似的病人数量实际上可能会非常小, 这可以明显影响预测效度。尽管一些评分服务机构正在努力扩大和加强数据库, 从而以此为基础产生有效预测, 但不一定能够获取上述信息。若没有足够证据证明预测的效度, 那么也就没有理由说电脑生成的预测比临床医生的预测更有效。

## 14.6 总 结

旨在评估兴趣、人格和调整能力的测试通常用于三种目的: 研究、自我了解、临床评估和诊断。虽然这些测试主要是由临床医生或心理学专家使用, 但对其他人也有更广泛的用途。尤其是兴趣测试能够应用于各种不同的情境。因为个人兴趣模式对职业选择和工作满意度有很大影响, 职业咨询师会经常使用上述测试。此外, 咨询师可以使用兴趣测试及某些个性量表, 帮助客户实现更好地自我了解, 做出更好的工作和人际关系选择等。教育工作者越来越关注自我意识量表的应用, 以此研究不同学习情境和儿童及青少年的学业成绩。个性和调整能力测试能够为临床诊断和制订治疗计划提供有效信息。

## 14.7 习 题

1. 思考以下量表: (1) 斯特朗兴趣量表, (2) 职业评估量表, (3) 职业自我探索量表。你会在以下情况中推荐哪一个? 并给出原因。

a. 大学二年级学生寻求有关其专业和职业选择的咨询。

b. 为即将进入某所开设不同销售管理专业的职业高中的学生设立咨询项目。

c. 需要为 10 年级学生探索事业和职业选择过程的相关课程设计量表。

2. 如何解释在成年之前进行的兴趣量表评分缺乏稳定性?

3. 假设你将要去学校就业中心完成一个或多个兴趣量表, 请某个咨询师与你面谈测试工具及其说明解释。

4. 反应定势的含义是什么? 有哪些重要反应定势? 它们如何影响兴趣、人格和调整能力量表的结果?

5. 如果要准确填写自我报告量表并产生有意义的结果, 必须满足什么条件?

6. 五大因素是什么, 它们如何与人格测量相联系?

7. 你注意到明尼苏达多项人格调查量表第二版和米隆临床多向问卷第三版之间的重要差异是什么? 这两种测试的相对优势和劣势是什么?

8. 为什么性格、调整能力和兴趣测试通常比认知能力的测试更难理解和解释?

9. 对个性量表进行计算机评分说明有什么好处? 这些自动化系统的缺点是什么?

## 推荐阅读

Cramer, P. (1999). Future directions for the Thematic Apperception Test. Journal of Personality Assessment, 72, 74-92.

Exner, J. E. (1993). The Rorschach: A comprehensive system, Vol. 1: Basic foundations (3rd ed.). New York: Wiley.

Gottfredson, G. D., & Holland, J. L. (1996). Dictionary of Holland occupational codes (3rd ed.). Odessa, FL: Psychological Assessment Resources.

Groth-Marnat, G. (1999). Handbook of psychological assessment (3rd ed.). New York: Wiley.

Harmon, L. W., Hansen, J. C., Borgen, F. H., & Hammer, A. L. (1994). Strong interest inventory, applications and technical guide. Stanford, CA: Stanford University Press.

Holland, J. L. (1997). Making vocational choices. Odessa, FL: Psychological Assessment Resources.

Lilienfeld, S. O., Wood, J. M., & Garb, H. N. (2000). The scientific status of projective techniques. Psychological Science in the Public Interest, 1(2), 1-66.

Meyer, G. J., & Archer, R. P. (2001). The hard science of Rorschach research: What do we know and where do we go? Psychological Assessment, 13, 486-502.

Millon, T. (1990). Toward a new personology. New York: Wiley.

Piedmont, R. L., McCrae, R. R., Riemann, R., & Angleitner, A. (2000). On the invalidity of validity scales: Evidence from self-reports and observer ratings in volunteer samples. Journal of Personality and Social Psychology, 78, 582-593.

Society for Personality Assessment. (2005). The status of the Rorschach in clinical and forensic practice: An official statement by the Board of Trustees of the Society for Personality Assessment. Journal of Personality Assessment, 85, 219-237.

U. S. Department of Labor. (1992). Dictionary of occupational titles ( 4th rev. ed.)

Washington, DC: U. S. Government Printing Office.

J. S. Department of Labor (2000-2001). Occupational outlook handbook. Washington, DC: U. S. Government Printing Office.

Nilson, P. L. (1998). Multidimensional self-concept scale; An examination of grade, race and gender differences in third through sixth grade students' self-concepts. Psychology in the Schools, 35, 317-326.

## 第15章 附录 正态曲线中低于设定值的 测试对象所占比例



<table><tr><td>以标准差单位 表示的偏差值</td><td>低于设定值 的测试对象 点比 \( \left( \% \right) \)</td><td>以标准差单位 表示的偏差值</td><td>低于设定值 的测试对象 占比(%)</td><td>以标准差单位 表示的偏差值</td><td>低于设定值 的测试对象 占比 (%)</td></tr><tr><td>+3.50</td><td>99.98</td><td>2.05</td><td>97.98</td><td>0.85</td><td>80.23</td></tr><tr><td>3.40</td><td>99.97</td><td>2.00</td><td>97.72</td><td>0.80</td><td>78. 81</td></tr><tr><td>3. 30</td><td>99.95</td><td>1.95</td><td>97.44</td><td>0.75</td><td>77.34</td></tr><tr><td>3. 20</td><td>99.93</td><td>1.90</td><td>97.13</td><td>0.70</td><td>75. 80</td></tr><tr><td>3.10</td><td>99.90</td><td>1.85</td><td>96.78</td><td>0.65</td><td>74.22</td></tr><tr><td>3.00</td><td>99.87</td><td>1. 80</td><td>96.41</td><td>0.60</td><td>72.57</td></tr><tr><td>2. 95</td><td>99.84</td><td>1.75</td><td>95.99</td><td>0.55</td><td>70.88</td></tr><tr><td>2. 90</td><td>99. 81</td><td>1.70</td><td>95.54</td><td>0.50</td><td>69. 15</td></tr><tr><td>2.85</td><td>99.78</td><td>1.65</td><td>95.05</td><td>0.45</td><td>67.36</td></tr><tr><td>2. 80</td><td>99.74</td><td>1.60</td><td>94.52</td><td>0.40</td><td>65.54</td></tr><tr><td>2,75</td><td>99.70</td><td>1.55</td><td>93.94</td><td>0.35</td><td>63.68</td></tr><tr><td>2.70</td><td>99.65</td><td>1.50</td><td>93.32</td><td>0.30</td><td>61.79</td></tr><tr><td>2. 65</td><td>99.60</td><td>1.45</td><td>92.65</td><td>0.25</td><td>59.87</td></tr><tr><td>2. 60</td><td>99.53</td><td>1.40</td><td>91.92</td><td>0.20</td><td>57.93</td></tr><tr><td>2.55</td><td>99.46</td><td>1. 35</td><td>91.15</td><td>0.15</td><td>55.96</td></tr><tr><td>2.50</td><td>99.38</td><td>1. 30</td><td>90.30</td><td>0.10</td><td>53.98</td></tr><tr><td>2.45</td><td>99.29</td><td>1.25</td><td>89.44</td><td>0.05</td><td>51.99</td></tr><tr><td>2.40</td><td>99.18</td><td>1. 20</td><td>88.49</td><td>0.00</td><td>50.00</td></tr><tr><td>2. 35</td><td>99.06</td><td>1. 15</td><td>87.49</td><td>-0.05</td><td>48.01</td></tr><tr><td>2. 30</td><td>98.93</td><td>1.10</td><td>86.43</td><td>-0.10</td><td>46.02</td></tr><tr><td>2. 25</td><td>98.78</td><td>1.05</td><td>85. 31</td><td>-0.15</td><td>44.04</td></tr><tr><td>2. 20</td><td>98.61</td><td>1.00</td><td>84. 13</td><td>-0.20</td><td>42.07</td></tr><tr><td>2. 15</td><td>98.42</td><td>0.95</td><td>82,89</td><td>-0.25</td><td>40. 13</td></tr><tr><td>2. 10</td><td>98. 21</td><td>0.90</td><td>81.59</td><td>-0.30</td><td>38. 21</td></tr><tr><td>-0.35</td><td>36. 32</td><td>-1.65</td><td>4. 95</td><td>-2.85</td><td>0.22</td></tr><tr><td>-0.40</td><td>34.46</td><td>-1.70</td><td>4.46</td><td>-2.90</td><td>0.19</td></tr><tr><td>-0.45</td><td>32.64</td><td>-1.75</td><td>4.01</td><td>-2.95</td><td>0.16</td></tr><tr><td>-0.50</td><td>30.85</td><td>-1.80</td><td>3.59</td><td>-3.00</td><td>0.13</td></tr></table>

续表

<table><tr><td>以标准差单位 表示的偏差值</td><td>低于设定值 的测试对象 占比(%)</td><td>以标准差单位 表示的偏差值</td><td>低于设定值 的测试对象 占比(%)</td><td>以标准差单位 表示的偏差值</td><td>低于设定值 的测试对象 占比(%)</td></tr><tr><td>-0.55</td><td>29. 12</td><td>-1.85</td><td>3.22</td><td>-3.10</td><td>0.10</td></tr><tr><td>-0.60</td><td>27.43</td><td>-1.90</td><td>2. 87</td><td>-3.20</td><td>0.07</td></tr><tr><td>-0.65</td><td>25.78</td><td>-1.95</td><td>2.56</td><td>-3.20</td><td>0.05</td></tr><tr><td>-0.70</td><td>24. 20</td><td>-2.00</td><td>2. 88</td><td>-3.40</td><td>0.03</td></tr><tr><td>-0.75</td><td>22. 66</td><td>-2.05</td><td>2.02</td><td>-3.50</td><td>0.02</td></tr><tr><td>--- 0.80</td><td>21.19</td><td>-2.10</td><td>1.79</td><td/><td/></tr><tr><td>-0.85</td><td>19.77</td><td>-2.15</td><td>1.58</td><td/><td/></tr><tr><td>-0.90</td><td>18.41</td><td>-2.20</td><td>1. 39</td><td/><td/></tr><tr><td>-0.95</td><td>17. 11</td><td>-2.25</td><td>1.22</td><td/><td/></tr><tr><td>-1.00</td><td>15. 87</td><td>-2.30</td><td>1.07</td><td/><td/></tr><tr><td>-1.05</td><td>14.69</td><td>-2.35</td><td>0.94</td><td/><td/></tr><tr><td>-1.10</td><td>13. 57</td><td>-2.40</td><td>0.82</td><td/><td/></tr><tr><td>-1.15</td><td>12. 51</td><td>-2.45</td><td>0.71</td><td/><td/></tr><tr><td>-1.20</td><td>11. 51</td><td>-2.50</td><td>0.62</td><td/><td/></tr><tr><td>1.25</td><td>10. 56</td><td>-2.55</td><td>0.54</td><td/><td/></tr><tr><td>-1.30</td><td>9.68</td><td>-2.60</td><td>0.47</td><td/><td/></tr><tr><td>-1.35</td><td>8. 85</td><td>-2.65</td><td>0.40</td><td/><td/></tr><tr><td>-1.40</td><td>8.08</td><td>-2.70</td><td>0.35</td><td/><td/></tr><tr><td>-1.45</td><td>7. 35</td><td>-2.80</td><td>0.26</td><td/><td/></tr><tr><td>-1.50</td><td>6.68</td><td/><td/><td/><td/></tr><tr><td>-1.55</td><td>6.06</td><td/><td/><td/><td/></tr><tr><td>-1.60</td><td>5.48</td><td/><td/><td/><td/></tr></table>



## 参考文献

Aamodt, M. G., Bryan, D. A., 8. Whitcomb, A. J. (1993). Predicting performance with letters of recommendation. Public Personnel Management, 22, 81-100.

Achenback, T. M. (1991). Manual for the Child Behavior Checklist and 1991 Profile. Burlington, VT: University Associates in Psychiatry.

Acklin, M. W., McDowell, C. J., II, Verschell, M. S., 8. Chan, D. (2000). Inter-observer agreement, server reliability, and the Rorschach comprehensive system. Journal of Personality Assessment, 74, 15-47.

Adjutant General's Office, Personnel Research Section. (1952). A study of officer rating methodology, validity and reliability of ratings by single raters and multiple raters (PRS Report No. 904). Washington, DC: Author.

Adjutant General's Office, Personnel Research Section. (1953). Survey of the aptitude for service rating system at the U. S. Military Academy, West Point, New York. Washington, DC: Author.

Albanese, M. A. (1988). The projected impact of the correction for guessing on individual scores. Journal of Educational Measurement, 25, 149-157.

Albanese, M. A., & Sabers, D. L. (1988). Multiple true-false items: A study of interitem correlations, scoring alternatives, and reliability estimation. Journal of Educational Measurement, 25, 111-123.

Alexander, L., & James, H. T. (1987). The nation's report card: Improving the assessment of student achievement. Washington, DC: National Academy of Education.

Allen, W. B. (1988). Rhodes handicapping, or slowing the pace of integration. Journal of Vocational Behavior, 33, 365-378.

Allport, G. W. (1937). Personality: A psychological interpretation. New York: Holt, Rinehart and Winston.

Allport, G. W. (1955). Becoming. New Haven, CT: Yale University Press.

Allport, G. W., & Odbert, H. S. (1936). Trait-names, a psycholexical study. Psychological Monographs, 47 (Whole No. 211).

American Association on Mental Retardation. (1992). Mental retardation: Definition, classification, and systems of supports (9th ed.). Washington, DC: Author.

American Counseling Association. (1995). Code of ethics and standards of practice. Alexandria, VA: Author.

American Educational Research Association, American Psychological Association, & National Council on Measurement in Education. (1985). Standards for educational and psychological testing. Washington, DC: American Psychological Association.

American Educational Research Association, American Psychological Association, & National Council on Measurement in Education. (1999). Standards for educational and psychological testing. Washington, DC: American Psychological Association.

American Psychological Association. (1954). Technical recommendations for psychological tests and diagnostic techniques. Washington, DC: Author.

American Psychological Association. (1992). Ethical principles of psychologists and code of conduct. Washington, DC: Author.

American Psychological Association. (2001). Appropriate use of high-stakes testing in our nation's schools. Washington, DC: Author.

Americans with Disabilities Act, 42 U. S. C. 12101 (1990). Ames, C., & Archer, J. (1988). Achievement goals in the classroom: Students' learning strategies and motivation processes. Journal of Educational Psychology, 80, 260-267.

Anastasi, A. (1986). Evolving concepts of test validation. Annual Review of Psychology, 37, 1-15.

Anastasi, A., & Urbina, S. (1997). Psychological testing (7th cd.). Upper Saddle River, NJ: Prentice Hall.

Angoff, W. H. (1971). Scales, norms, and equivalent scores. In R. L. Thorndike (Ed.), Educational measurement (2nd ed., pp. 508-600). Washington, DC: American Council on Education.

Angoff, W. H. (1988). Validity: An evolving concept. In H. Wainer & H. Braun (Eds.), Test validity (pp. 19-32). Mahwah, NJ: Erlbaum.

Banaji, M. R. (2001). Implicit attitudes can be measured. In H. L. Roediger, III, & J. S. Nairne (Eds.), The nature of remembering : Essays in honor of Robert G. Crowder (pp. 117- 150). Washington, DC: American Psychological Association.

3arak, A. (1999). Psychological applications on the Internet: A discipline on the threshold of a newmillennium. Applied and Preventive Psychology, 8, 231-246.

3arak, A., & English, N. (2002). Prospects and limitations of psychological testing on the Internet. Journal of Technology in Human Services, 19(2/3), 65-89.

3arrios, B. A. (1988). On the changing nature of behavioral assessment. In A. S. Bellack & M. Hershon (Eds.), Behavioral assessment: A practical handbook (pp. 3-41). New York: Pergamon.

3axter, J. C., Brock, B., Hill, P. C., & Rozelle, R. M. (1981). Letters of recommendation: A question of value. Journal of Applied Psychology, 66, 296-301.

3elk, M. S., LoBello, S. G., Ray, G. E., & Zachar, P. (2002). WISC-III administration, clerical, and scoring errors made by student examiners. Journal of Psychoeducational Assessment, 20, 290-300.

3ennett, R. E., & Ward, W. C. (1993). Construction versus choice in cognitive measurement: Issues in constructed response, performance testing, and portfolio assessment. Mahwah, NJ: Erlbaum.

Berk, R. A. (1980). A consumer's guide to criterionreferenced test reliability. Journal of Educational Measurement, 17, 323-349.

Berk, R. A. (Ed.). (1984). A guide to criterion-referenced test construction. Baltimore: Johns Hopkins University Press.

Berk, R. A. (Ed.). (1986). Performance assessment: Methods and applications. Baltimore: Johns Hopkins University Press.

Bersoff, D. N. (1981). Testing and the law. American Psychologist, 36, 1047-1056.

Birns, B. (1965). Individual differences in human neonates' responses to stimulation. Child Development, 36, 249-256.

Blanton, H., & Jaccard, J. (2006). Arbitrary metrics in psychology. American Psychologist, 61, 27-41.

Blatchford, C. H. (1970). Experimental steps to ascertain reliability of diagnostic tests in English as a second language. Unpublished doctoral dissertation, Teachers College, Columbia University, New York.

Blixt, S. L., & Shama, D. B. (1986). An empirical investigation of the standard error of measurement at different ability levels. Educational and Psychological Measurement, 45, 545-550.

Bloom, B. S. (Ed.). (1956). Taxonomy of educational objectives, Handbook I : Cognitive domain. New York: Longman, Green and Company.

Bloom, B. S., Hastings, J. T., & Madaus, C. F. (1971). Handbook on formative and summative evaluation of student learning. New York: McGraw-Hill.

Boake, C. (2002). From the Binet-Simon to the Wechsler-Bellevue: Tracing the history of intelligence testing. Journal of Clinical and Experimental Neuropsychology, 24, 383-405.

Bond, L. (1989). The effects of special preparation on measures of scholastic ability. In R. L. Linn (Ed.), Educational measurement (3rd ed., pp. 429-444). New York: Macmillan.

Borsboom, D., & Mellenbergh, G. H. (2002). True scores, latent variables and constructs: A comment on Schmidt and Hunter. Intelligence, 30, 505-514.

Boswell, J. (1988). The kindness of strangers: The abandonment of children in western Europe from late antiquity to the Renaissance. New York: Pantheon.

Boyle, G. J. (1989). Confirmation of the structural dimensionality of the Stanford-Binet Intelligence Scale (4th ed.). Personality and Individual Differences, 10, 709-715.

Bracken, B. A. (1991). Multidimensional self concept validation; A three instrument investigation. Journal of Psychoeducational Assessment, 9, 319-328.

Bracken, B. A., & McCallum, R. S. (1998). The universal nonverbal intelligence test. Itasca, IL: Riverside.

Brennan, R. L. (1984). Estimating the dependability of the scores. In R. A. Berk (Ed.), A guide to criterion-referenced test construction (pp. 292-334). Baltimore: Johns Hopkins University Press.

Brennan, R. L. (2006). Perspectives on the evolution and future of measurement. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 1-16). Westport, CT: Praeger.

Brodsky, S. L. (1991). Testifying in court; Guidelines and maxims for the expert witness. Washington, DC: American Psychological Association.

Brody, N. (2003). Construct validation of the Sternberg Triarchic Abilities Test: Comment and reanalysis. Intelligence, 31, 319-329.

Browder, D. M. (2001). Curriculum and assessment for students with moderate and severe disabilities. New York: Guilford. Brown v. Board of Education of Topeka, Kansas, 347

J. S. 483 (1954).

1, L., Sherbenou, R. J., & Johnson, S. K. (1997). Test of non-verbal intelligence (3rd d.). Austin, TX: PRO-ED.

1, V. L., Cronin, M. E., 8. McEntire, E. (1994). Test of mathematical abilities (2nd d.). Austin, TX: PRO-ED.

nks, R. H., Thurlow, M. L., & Gillman, C. J. (1987). Adaptive behavior and mental etardation. Journal of Special Education, 21, 69-88.

nks, R. H., Woodcock, R., Weatherman, R., & Hill, B. (1996). Scales of independent ehavior- revised. Chicago: Riverside.

', R. A. (1953). Flicker fusion threshold and anxiety level. Unpublished doctoral dissertation, Jolumbia University, New York.

, H. F. (1977). Burks behavioral rating scales: Preschool and Kindergarten edition. Los Ingeles: Western Psychological Services.

er, J., & Williams, C. L. (1992). The Minnesota multiphasic personality inventory-dolescent. Minneapolis: University of Minnesota Press.

er, J. N., & Rouse, S. V. (1996). Personality: Individual differences and clinical assessment. Innual Review of Psychology, 47, 87-111.

er, J. N., & Williams, C. L. (1992). Essentials of MMPI-2 and MMPI-A interpretation. linneapolis: University of Minnesota Press.

'ell-Andrews, A., Baer, R. A., & Berry, D. T. (2000). Effects of response sets on NEO 'I-R scores and their relations to external criteria. Journal of Personality Assessment, 7, 72-478.

li, G. (2006). Test fairness. In R. L. Brennan (Ed.), Educational measurement (4th ed., p. 221-256). Westport, CT: Greenwood.

bell, D. T., 8. Fiske, D. W. (1959). Convergent and discriminant validation by the multitrait-ultimethod matrix. Psychological Bulletin, 56, 81-105.

bell, J. P., Dunnette, M. D., Arvey, R. D., & Hellervik, L. V. (1973). The evelopment and evaluation of behaviorally based rating scales. Journal of Applied 'sychology, 57, 15-22.

II, J. J. (1988). Nationally normed elementary achievement testing in America's public chools: How all 50 states are above the national average. Educational Measurement: Issues nd Practice, 7(2), 5-9.

II, J. B. (1993). Human cognitive abilities: A survey of factor-analytic studies. ambridge, MA: Cambridge University Press.

1, R. B. (1950). Personality: A systematic, theoretical, and factual study. New York: 4cGraw-Hill.

ig, F. M., Leung, K., Zhang, J., & Sun, H. (2001). Indigenous Chinese personality onstructs: Is the five factor model complete? Journal of Cross Cultural Psychology, 32, 07-433.

Rights Act, 42 U. S. C. 2000 et seq. (1964).

, G. J., & Bunch, M. B. (2006). Standard setting: A guide to establishing and evaluating erformance standards on tests. Thousand Oaks, CA: Sage.

Cohen, A. S., & Wollack, J. A. (2006). Test administration, security, scoring and reporting. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 355-386). Westport, CT: Praeger.

Cohen, J., & Cohen, P. (1983). Applied multiple regression for the behavioral sciences (2nd ed.). Hillsdale, NJ: Erlbaum.

Cohen, R. J., 8. Swerdlik, M. E. (1999). Psychological testing and assessment: An introduction to tests and measurements (4th ed.). Mountain View, CA: Mayfield.

Cole, N. S., & Moss, P. A. (1989). Bias in test use. In R. L. Linn (Ed.), Educational measurement (3rd ed., pp. 201-220). New York: Macmillan.

Comprehensive Test of Basic Skills technical bulletin. (1990). Monterey, CA: McGraw-Hill.

Comrey, A. L., & Lee, H. B. (1992). A first course in factor analysis. Hillsdale, NJ: Erlbaum.

Connolly, A. J. (1988). KeyMath-Revised: A diagnostic inventory of essential mathematics. Circle Pines, MN: American Guidance Service.

Connolly, A. J. (1997). Manual for KeyMath--Revised. Circle Pines, MN: American Guidance Service.

Conoley, J. C., & Impara, J. C. (Eds.). (1995). The twelfth mental measurements yearbook. Lincoln, NB: Buros Institute of Mental Measurements.

Conoley, J. C., & Kramer, J. J. (1989). The tenth mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Conoley, J. C., Kramer, J. J., & Mitchell, J. V., Jr. (Eds.). (1988). Supplement to the ninth mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Cook, T. D., & Campbell, D. T. (1979). Quasiexperimentation: Design and analysis issues for field settings. Chicago: Rand McNally.

Costa, P. T., & McCrae, R. R. (1992a). The five factor model and its relevance to personality disorders. Journal of Personality Disorders, 6, 343-359.

Costa, P. T., & McCrae, R. R. (1992b). Professional manual: Revised NEO Personality Inventory (NEO PI-R) and NEO Five-Factor Inventory (NEO-FFI). Odessa FL: Psychological Assessment Resources.

Cramer, P. (1999). Future directions for the Thematic Apperception Test. Journal of Personality Assessment, 72, 74-92.

Cronbach, L. J. (1971). Test validation. In R. L. Thorndike (Ed.), Educational measurement (2nd ed., pp. 443-507). Washington, DC: American Council on Education.

Cronbach, L. J. (1975). Five decades of public controversy over mental testing. American Psychologist, 30, 1-14.

Cronbach, L. J. (1988). Five perspectives on validation argument. In H. Wainer & H. Braun (Eds.), Test validity (pp. 3-17). Mahwah, NJ: Erlbaum.

Cronbach, L. J., & Gleser, G. C. (1965). Psychological tests and personnel decisions. Champaign: University of Illinois Press.

Cunningham, W. A., Preacher, K. J., & Banaji, M. R. (2001). Implicit attitude measures: Consistency, stability, and convergent validity. Psychological Science, 12, 163-170.

Dahlstrom, W. G. (1992). Comparability of two-point high-point code patterns from original

MMPI norms to MMPI-2 norms for the restandardization sample. Journal of Personality Assessment, 59, 153-164.

Jana, R. H. (1990). Cross-cultural and multi-ethnic assessment. In J. N. Butcher & C. D. Spielberger (Eds.), Recent advances in personality assessment (Vol. 8, pp. 1-26). Hillsdale, \( \mathrm{{NJ}} \) : Erlbaum.

Jarlington, R. B. (1990). Regression and linear models. New York: McGraw-Hill.

Jas, J. P., & Naglieri, J. A. (2001). The Das-Naglieri Cognitive Assessment System in theory and practice. In J. J. C. Andrews, D. H. Saklofske, & H. L. Janzen (Eds.), Handbook of psychoeducational assessment (pp. 33-63). San Diego, CA: Academic Press.

Jas, J. P., Naglieri, J. A., & Kirby, J. R. (1994). Assessment of cognitive processes: The PASS theory of intelligence. Boston: Allyn & Bacon.

Javis, D. E., & Hays, L. W. (1997). An examination of the clinical validity of the MCMI-III Depressive Personality Scale. Journal of Clinical Psychology, 53, 15-23.

Jawes, R. M., Faust, D., & Meehl, P. E. (1989). Clinical versus actuarial judgement. Science, 243, 1668-1674.

bebra P. v. Turlington, 78-892 Civ. T-C (M. D. Fla. July 12, 1979) at 2380.

JeFruyt, R., Mervielde, I., Hoekstra, H. A., Hans, A., & Rolland, J. P. (2000). Assessing adolescents' personality with the NEO PI-R. Assessment 7, 329-345.

Jeutsch, M. (1975). Equity, equality and need: What determines which value will be used as the basis of distributive justice. Journal of Social Issues, 31, 137-149.

jigman, J. M. (1990). Personality structure: Emergence of the five-factor model. Annual Review of Psychology, 41, 417-440.

iStafano, C., & Dombrowski, S. C. (2006). Investigating the theoretical structure of the Stanford-Binet-Fifth Edition. Journal of Psychoeducational Assessment, 24, 123-136.

Petzke, B. J., & Heilman, K. A. (1998). Statistics with Microsoft Excel. Upper Saddle River, NJ: Prentice Hall.

'uBois, P. H. (1970). A history of psychological testing. Boston: Allyn & Bacon.

Juff, F. L. (1965). Item subtlety in personality inventory scales. Journal of Consulting Psychology, 29, 565-570.

Junn, L. M., & Dunn, L. M. (1981). Peabody picture vocabulary test-revised: Manual for forms L and M. Circle Pines, MN: American Guidance Service.

'wyer, K. P. (1997). IDEA amendments become law. Communique, 25(2), 1-4.

yer, F. J., & McCann, J. T. (2000). The Millon clinical inventories: Research critical of their forensic application and Daubert criteria. Law and Human Behavior, 24, 487-497.

bel, R. L. (1979). Essentials of educational measurement (3rd ed.). Englewood Cliffs, NJ: Prentice Hall.

bel, R. L. (1983). The practical validation of tests of ability. Educational Measurement: Issues and Practices, 2(2), 7-10.

ducation of the Handicapped Act Amendments, 20 U. S. C. 1400 (1900).

ducational Testing Service, Test Collection. (1975-1995). Tests in microfiche annotated bibliography (Set A-Set U). Princeton, NJ: Author.

ducational Testing Service, Test Collection. (1987). Directory of selected national testing

programs. Phoenix, AZ: Oryx Press.

Edwards, A. L. (1957). Techniques of attitude scale construction. New York: Appleton.

Egan, O., & Archer, P. (1985). The accuracy of teachers' ratings of ability: A regression model. American Educational Research Journal, 22, 25-34.

Embretson (Whitely), S. (1983). Construct validity: Construct representation versus nomothetic span. Psychological Bulletin, 93,179-197.

Enright, B. E. (1983). Enright diagnostic inventory of basic arithmetic skills. North Billerica, MA: Curriculum Associates.

Epstein, S. (1983). Aggregation and beyond: Some basic issues on the prediction of behavior. Journal of Personality, 51, 360-392.

Equal Employment Opportunity Commission, U. S. Civil Service Commission, U. S. Department of Labor, & U. S. Department of Justice. (August, 1978). Uniform guidelines on employee selection procedures (p. 43).

Evertson, C. M. (1986). Observation as inquiry and method. In M. C. Witrock (Ed.), Handbook of research on teaching (pp. 162-213). New York: Macmillan.

Exner, J. E. (1986). The Rorschach : A comprehensive system: Volume 1. Basic foundations (2nd ed.). New York: Wiley.

Exner, J. E. (1993). The Rorschach : A comprehensive system: Volume 1. Basic foundations (3rd ed.). New York: Wiley.

Exner, J. E., & Exner, D. E. (1972). How clinicians use the Rorschach. Journal of Personality Assessment, 36, 403-408.

Eysenck, H. J. (1936). Inspection time and intelligence: A historical perspective. Personality and Individual Differences, 7, 603-607.

Eysenck, H. J. (1988). The concept of "intelligence": Useful or useless? Intelligence, 12, 1-16.

Eysenck, H. J., & Rachman, S. (1965). The causes and cures of neurosis : An introduction to the modern behavior therapy based on learning theory and principles of conditioning. San Diego, CA: Knapp.

Fabiano, E. (1939). Index to tests used in educational dissertations. Phoenix, AZ: Oryx Press. Family Educational Rights and Privacy Act, 20 U. S. C. 241 (1974).

Federal Policy for the Protection of Human Subjects: Notices and Rules, 45 C. F. R. 46 (1991) Fed. Reg. 166, 38290-38309. Washington, DC: U.S. Government Printing Office.

Fehrmann, P. G., & O' Brien, N. P. (2001). Directory of test collections in academic, professional, and research libraries. Chicago: Association of College and Research Libraries.

Feifer, S. G., & DeFina, P. A. (2000). The neuropsychology of reading disorders: Diagnosis and intervention workbook. Middleton, MD: School Neuropsychology.

Feldt, L. S., & Brennan, R. L. (1989). Reliability. In R. L. Linn (Ed.), Educational measurement (3rd ed., pp. 105-146). New York: Macmillan.

Feldt, L. S., Forsyth, R. A., Ansley, T. N., & Alnot, S. D. (1993). Iowa tests of educational development,forms \( \mathrm{K} \) and \( \mathrm{L} \) . Chicago: Riverside.

Ferrara, S., & DeMauro, G. E. (2006). Standardized assessment of individual achievement. In R. L. Brennan (Ed.), Educational measurement (4th ed.). Westport, CT: Praeger.

Finch, F. L. (Ed.). (1991). Educational performance assessment. Chicago: Riverside.

fitzpatrick, R., & Morrison E. J. (1971). Performance and product evaluation. In R. L. Thorndike (Ed.), Educational measurement (pp. 237-270). Washington, DC: American Council on Education.

Planagan, D. P., Andrews, T. J., & Genshaft, J. L. (1997). The functional utility of intelligence tests with special education populations. In D. P. Flanagan, J. L. Genshaft, & P. L. Harrison (Eds.), Contemporary intellectual assessment: Theories, tests, and issues. New York: Guilford.

'landers, N. (1970). Analyzing teacher behavior. Menlo Park, CA: Addison-Wesley.

Jlynn, J. R. (1984). The mean IQ of Americans: Massive gains 1932 to 1978. Psychological Bulletin, 95, 29-51.

Jlynn, J. R. (1998). WAIS-III and WISC-III gains in the United States from 1972 to 1995: How to compensate for obsolete norms. Perceptual & Motor Skills, 86, 1231-1239.

Poster, S. L., Bell-Dolan, D. J., & Burge, D. A. (1988), Behavioral observation. In A. S. Bellack & M. Hershon (Eds.), Behavioral assessment: A practical handbook (pp. 119-160). New York: Pergamon.

'redericksen, J. R., & Collins, A. (1989). A systems approach to educational testing. Educational Researcher, 18(9), 27-32.

'redericksen, N. (1986). Construct validity and construct similarity: Methods for use in test development and test validation. Journal of Multivariate Behavioral Research, 21, 3-28.

'redericksen, N., Mislevy, R. J., & Bejar, I. I. (1993). Test theory for a new generation of tests. Hillsdale, NJ: Erlbaum.

Sallatin, J. (1982). Abnormal psychology: Concepts, issues, trends. New York: Macmillan.

Sarb, H. N. (1994). Social and clinical judgment: Fraught with error? American Psychologist, 49,758-759.

Sarber, H. L. (1988). The Milwaukee Project: Preventing mental retardation in children at risk. Washington, DC: American Association on Mental Retardation.

Jardner, E. F. (1983). Intrinsic rational validity: Necessarybut not sufficient. Educational Measurement: Issues and Practices, 2(2), 13.

Serbing, D. W., & Tuley, M. R. (1991). The 16PF related to the five-factor model of personality: Multiple-indicator measurement versus the a priori scales. Multivariate Behavioral Research, 26, 271-289.

blass, G. V. (1977). Integrating findings: The meta-analysis of research. Review of Research in Education, 5, 351-379.

Slutting, J., Adams, W., & Sheslow, D. (2000). WRIT: Wide Range Intelligence Test manual. Wilmington, DE: Wide Range.

Soldman, B. A., & Busch, J. C. (1978). Directory of unpublished experimental mental measures: Vol. 2. New York: Human Sciences Press.

Joldman, B. A., & Busch, J. C. (1982). Directory of unpublished experimental mental measures: Vol. 3. New York: Human Sciences Press.

Joldman, B. A., & Mitchell, D. F. (1990). Directory of unpublished experimental mental measures: Vol. 5. Dubuque, IA: Wm. C. Brown.

Soldman, B. A., & Osborne, W. L. (1985). Directory of unpublished experimental mental

measures: Vol. 4. New York: Human Sciences Press.

Goldman, B. A., & Sanders, J. L. (1974). Directory of unpublished experimental mental measures: Vol. 1. New York: Behavioral Publications.

Gorsuch, R., & Harlow, L. (1997). Factor analysis (3rd ed.). Hillsdale, NJ: Erlbaum.

Gottfredson, G. D., & Holland, J. L. (1989). Dictionary of Holland occupational codes (2nd ed.). Odessa, FL: Psychological Assessment Resources.

Gottfredson, G. D., & Holland, J. L. (1996). Dictionary of Holland occupational codes (3rd ed.). Odessa, FL: Psychological Assessment Resourccs.

Gottfredson, L. S. (1997). Why g matters: The complexity of everyday life. Intelligence, 24, 79-132.

Gottfredson, L. S. (2003). Dissecting practical intelligence theory: Its claims and evidence. Intelligence, 31, 343-397.

Gottfredson, L. S., & Sharf, J. C. (1988). Fairness in employment testing [Special issuc]. Journal of Vocational Behavior, 33(3), 225-477.

Greenspan, S. R., & Granfield, J. M. (1992). Reconsidering the construct of mental retardation: Implications of a model of social competence. American Journal of Mental Retardation, 96, 442-453.

Greenwald, A. G., McGhee, D. E., & Schwartz, J. L. K. (1998). Measuring individual differences in cognition: The Implicit Association Test. Journal of Personality and Social Psychology, 74, 1464-1480.

Greenwald, A. G., & Nosek, B. A. (2001). Health of the Implicit Association Test at age 3. Zeitschrift fur Experimentelle Psychologie, 48, 85-93.

Gregory, R. J. (1987). Adult intellectual assessment. Boston: Allyn & Bacon.

Gregory, R. J. (1996). Psychological testing: History, principles, and applications (2nd ed.) Boston: Allyn & Bacon. Griggs v. Duke Power Company, 401 U. S. 424 (1971).

Gronlund, N. E. (1982). Constructing achievement tests. Upper Saddle River, NJ: Prentice Hall. Groth-Marnat, G. (1999). Handbook of psychological assessment (3rd ed.). New York: Wiley. Guadalupe Organization v. Tempe Elementary School District, E. D. Ariz. (1972).

Guilford, J. P. (1985). The structure-of-intellect model. In B. B. Wolman (Ed.), Handbook of intelligence (pp. 225-266). New York: Wiley.

Gullickson, A. R., & Hopkins, K. D. (1987). The context of educational measurement instruction for preservice teachers: Professor perspectives. Issues and Practices, 6 (3), 12-16.

Haertel, E. (1985). Construct validity and criterionreferenced testing. Review of Educational Research, 55, 23-46.

Haertel, E. H. (2006). Reliability. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 65-110). Westport, CT: Praeger.

Hall, B. W. (1985). Survey of the technical characteristics of published educational achievement tests. Educational Measurement: Issues and Practice, 4(1), 6-14.

Hambleton, R. K. (1984). Validating the test scores. In R. A. Berk (Ed.), A guide to criterion-referenced test construction (pp. 199-230). Baltimore: Johns Hopkins University Press.

516

Hambleton, R. K., & Pitoniak, M. J. (2006). Setting performance standards. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 433-470). Westport, CT: Praeger.

Hammill, D. D., Brown, L., & Bryant, B. R. (1992). A consumer's guide to tests in print (2nd ed.). Austin, TX: PRO-ED.

Hammill, D. D., & Larsen, S. C. (1996). Test of written language-third edition. Austin, TX: PRO-ED.

Haney, W. (1981). Validity, vaudeville, and values: A short history of social concerns over standardized testing. American Psychologist, 36, 1021-1034.

-lansen, J. C., & Campbell, D. P. (1985). The Strong manual (4th ed.). Palo Alto, CA: Consulting Psychologists Press.

Harari, O., & Zedeck, S. (1973). Development of behaviorally anchored scales for the evaluation of faculty teaching. Journal of Applied Psychology, 58, 261-265.

Harmon, L. W., Hansen, J. C., Borgen, F. H., & Hammer, A. L. (1994). Strong interest inventory: Applications and technical guide. Stanford, CA: Stanford University Press.

Harper, A. E., Jr., & Harper, E. S. (1990). Preparing objective examinations. New Delhi: Prentice Hall of India.

Hartigan, J. A., & Wigdor, A. K. (Eds.). (1989). Fairness in employment testing: Validity generalization, minority issues, and the General Aptitude Test Battery. Washington, DC: National Academy Press.

Iathaway, S. R., & McKinley, J. C. (1940). A multiphasic personality schedule (Minnesota); I. Construction of the schedule. Journal of Psychology, 10, 249-254.

Iathaway, S. R., & McKinley, J. C. (1989). The Minnesota Multiphasic Personality Inventory II. Minneapolis: University of Minnesota Press.

Ieiman, G. W. (2000). Basic statistics for the behavioral sciences (3rd ed.). Boston: Houghton Mifflin.

Iepner, J. C. (1988). ETS test collection cumulative index to tests in microfiche, 1975-1987. Princeton, NJ: Educational Testing Service.

lerman, K., & Samuels, R. (1985). Computers: An extension of the clinician's mind-A sourcebook. Norwood, NJ: ABLEX.

lerrnstein, R. J., & Murray, C. (1994). The bell curve: Intelligence and class structure in American life. New York: The Free Press.

[ersen, M., & Bellack, A. S. (Eds.). (1988). Dictionary of behavioral assessment techniques. New York: Pergamon.

less, F. M., & Petrilli, M. J. (2007). No Child Left Behind. New York: Peter Lang.

leuchert, J. W., Parker, W. D., Stumpf, H., & Myburgh, C. P. (2000). The five factor model of personality in South African college students. The American Behavioral Scientist, 44, 112-125.

ildebrand, D. K., & Ledbetter, M. F. (2001). Assessing children's intelligence and memory: The Wechsler Intelligence Scale for Children-Third Edition and the Children's Memory Scale.

In J. J. C. Andrews, D. H. Saklofske, & H. L. Janzen (Eds.), Handbook of psychoeducational assessment (pp. 13-32). San Diego, CA: Academic Press.

'obson v. Hansen, \( {269}\mathrm{\;F} \) . Supp. 401 (D. D. C. 1967) aff’d sub nom. Smuck v. Hobson, \( {408}\mathrm{\;F} \) .

2d 175 (D. C. Cir. 1969).

Holland, J. L. (1985). Making vocational choices: A theory of vocational personalities and work environments (2nd ed.). Englewood Cliffs, NJ: Prentice Hall.

Holland, J. L. (1997). Making vocational choices: A theory of vocational personalities and work environments (3rd ed.). Odessa, FL: Psychological Assessment Resources.

Holland, P. W., & Dorans, N. J. (2006). Linking and equating. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 187-220). Westport, CT: Praeger.

Holland, J. L., Powell, A. B., & Fritzsche, B. A. (1997). Self-directed search (SDS) professional user's guide. Odessa, FL: Psychological Assessment Resources.

Holland, P. W., & Rubin, D. B. (Eds.). (1982). Test equating. New York: Academic Press.

Hoover, H. D. (1984). The most appropriate scores for measuring educational development in the elementary schools: GE's. Educational Measurement: Issues and Practices, 3, 8-14.

Hopkins, K. D., Stanley, J. C., & Hopkins, B. R. (1990). Educational and psychological measurement and evaluation (7th ed). Englewood Cliffs, NJ: Prentice Hall.

Horn, J. L. (1985). Remodeling old models of intelligence. In B. B. Wolman (Ed.), Handbook of intelligence (pp. 267-300). New York: Wiley.

Howard, G. S. (1985). The role of values in the science of psychology. American Psychologist, 40,255-265.

Hunt, E. (1987). Science, technology, and intelligence. In R. R. Ronning, J. A. Glover, J. C. Conoley, & J. C. Witt (Eds.), The influence of cognitive psychology on testing and measurement : The Buros-Nebraska symposium on measurement and testing (Vol. 3, pp. 11- 40). Hillsdale, NJ: Erlbaum.

Hyman, I. E., Jr., & Kleinknecht, E. (1998). False childhood memories: Research, theory, and applications. In L. M. Williams & V. L. Banyard (Eds.), Trauma and memory (pp. 175-188). Thousand Oaks, CA: Sage.

Impara, J. C., & Plake, B. S. (1998). The thirteenth mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Iowa tests of basic skills. (1993). Chicago: Riverside.

Jacoby, R., & Glauberman, N. (Eds.). (1995). The bell curve debate. New York: Time Books.

Jaeger, R. M. (1989). Certification of student competence. In R. L. Linn (Ed.), Educational measurement (3rd ed., pp. 545-572). New York: Macmillan.

Jarjoura, D. (1985). Tolerance intervals for true scores. Journal of Educational Measurement, 10,1-17.

Jensen, A. R. (1982). The chronometry of intelligence. In H. J. Eysenck (Ed.), A model for intelligence. New York: Springer.

Jensen, A. R. (1991). General mental ability: From psychometrics to biology. Diagnostique, 16, 134-144.

Jensen, A. R. (1993). Spearman's hypothesis tested with chronometric information-processing tasks. Intelligence, 17, 47-77.

Jensen, A. R. (1998). The g factor. Westport, CT: Praeger.

Johansson, C. B. (1991). Career assessment inventory: Vocational version. Minneapolis, MN: National Computer Systems.

Johnson, O. G. (1976). Tests and measurements in child development: Handbook II. San Francisco: Jossey-Bass.

Johnson, O. G., & Bommarity, J. W. (1971). Tests and measurements in child development; A handbook. San Francisco: Jossey-Bass.

lones, L. V. (1971). The nature of measurement. In R. L. Thorndike (Ed.), Educational measurement (2nd ed., pp. 335-355). Washington, DC: American Council on Education.

luarez, M. (1933). Assessment and treatment of minoritylanguage- handicapped children: The role of the monolingual speech-language pathologist. Topics in Language Disorders, 3(3), 57-66.

Kaiser, H. F. (1958). The varimax criterion for analytic rotation in factor analysis. Psychometrika, 23, 187-200.

Kane, M. T., S. Wilson, J. (1984). Errors of measurement and standard setting in mastery testing. Applied Psychological Measurement, 4, 107-115.

Saufman, A. S. (1990). Assessing adolescent and adult intelligence (p. 73). Boston: Allyn & Bacon.

Caufman, A. S., & Kaufman, N. L. (1983). Kaufman Assessment Battery for Children: Interpretive manual. Circle Pines, MN: American Guidance Service.

Caufman, A. S., & Kaufman, N. L. (1985). Kaufman Test of Educational Achievement (K-TEA). Circle Pines, MN: American Guidance Service.

Caufman, A. S., & Kaufman, N. L. (1990). Kaufman Brief Intelligence Test. Circle Pines, MN: American Guidance Service.

Jaufman, A. S., & Kaufman, N. L. (1998). Manual for the Kaufman test of educational achievement-comprehensive form. Circle Pines, MN: American Guidance Service.

Jaufman, J. C., & Kaufman, A. S. (2001). Time for the changing of the guard: A farewell to short forms of intelligence tests. Journal of Psychoeducational Assessment, 19, 245-267.

leiser, R. E., & Prather, E. N. (1990). What is the TAT? A review of ten years of research. Journal of Personality Assessment, 52, 309-32).

elly, J. G. (1966). Ecological constraints on mental health services. American Psychologist, 21,535-539.

elly, J. G. (1986). Context and process: An ecological view of the interdependence of practice and research. American Journal of Community Psychology, 14, 531-590.

lennard, B. D., Stewart, S. M., Silver, C. H., & Emslie, G. J. (2000). Neuropsychological abilities and academic gains in learning disabled children: A follow-up study over an academic school year. School Psychology International, 21, 172-175.

entucky Department of Education, Office of Education for Exceptional Children. (1990). The manual of local education requirements related to exceptional children. Frankfort, KY: Author.

eyser, D. J., 8. Sweetland, R. C. (1984). Test critiques. Kansas City, MO: Test Corporation of America.

irk, R. E. (1999). Statistics: An introduction. (4th ed.). Fort Worth, TX: Harcourt Brace.

nouse, S. B. (1989). Impression management and the letter of recommendation. In R. C. Giacalone & P. Rosenfeld (Eds.), Impression management in the organization. Hillsdale,

\( \mathrm{{NJ}} : \) Erlbaum.

Kolen, M. J. (1988). Defining score scales in relation to measurement error. Journal of Educational Measurement, 25, 97-110.

Kolen, M. J. (2006). Scaling and norming. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 155-186). Westport, CT: Praeger.

Koretz, D. M., 8. Hamilton, L. S. (2006). Testing for accountability in K-12. In R. I. Brennan (Ed.), Educational measurement (4th ed., pp. 471-516). Westport, CT: Praeger.

Kramer, J. J., & Conoley, J. C. (Eds.). (1992). The eleventh mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Kubiszyn, T., & Borich, G. (1987). Educational testing and measurement. Glenview, IL: Scott, Foresman.

Lambert, N., Leland, H., & Nihira, K. (1993). AAMR adaptive behavior scale-school edition (revised). Austin, TX: PRO-ED.

Landy, F. J., Shankster, L. J., 8. Kohler, S. S. (1994). Personnel selection and placement. In L. W. Porter & M. R. Rosenzweig (Eds.), Annual Review of Psychology, 45, 261-269.

Lane, S., & Stone, C. A. (2006). Performance assessment. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 387-431). Westport, CT: Praeger.

Larry P. v. Wilson Riles. 343 F. Supp. 1306 (N. D. Cal. 1972), affirmed 502 F. 2d 963 (9th Cir. 1979).

Larry P. et al. v. Wilson Riles et al. No. C 71-2270. United States District Court for the Northern District of California, San Francisco, October 1979, slip opinion.

Levy, P., & Goldstein, H. (1984). Tests in education: A book of critical reviews. London: Academic Press.

Lilienfeld, S. O., Wood, J. M., & Garb, H. N. (2000). The scientific status of projective techniques. Psychological Science in the Public Interest, 1(2), 1-66.

Linn, R. L. (1989). Current perspectives and future directions. In R. L. Linn (Ed.), Educational measurement (3rd ed., pp. 1-12). New York: Macmillan.

Linn, R. L., & Gronlund, N. E. (2000). Measurement and assessment in teaching (8th ed.). Upper Saddle River, NJ: Merrill/Prentice Hall.

Livingston, S. A., & Zieky, M. J. (1982). Passing scores: A manual for setting standards of performance on educational and occupational tests. Princeton, NJ: Educational Testing Service.

Loehlin, J. C. (1992). Latent variable analysis. Hillsdale, NJ: Erlbaum.

Lonner, W. J. (1985). Issues in testing and assessment in cross-cultural counseling. The Counseling Psychologist, 13, 599-614.

Lord, F. M. (1984). Standard errors of measurement at different score levels. Journal of Educational Measurement, 21, 239-243.

Lord, F. M., & Novick, M. R. (1968). Statistical theories of mental test scores. Reading, MA: Addison-Wesley.

Lundy, A. (1988). Instructional set and thematic apperception test validity. Journal of Personality Assessment, 52, 309-320.

Mager, R. F. (1975). Preparing instructional objectives (2nd ed.). Belmont, CA: Fearon. 520

Markwardt, F. C. (1989). Peabody individual achievement test-revised. Circle Pines, MN: American Guidance Service.

Markwardt, F. C. (1997). Peabody individual achievement test-revised. Circle Pines, MN: American Guidance Service.

Marston, D. B. (1989). A curriculum-based measurement approach to assessing academic performance: What it is and why do it. In M. R. Shinn (Ed.), Curriculumbased measurement: Assessing special children (pp. 18-78). New York: Guilford.

Matarazzo, J. D. (1990). Psychological assessment versus psychological testing. American Psychologist, 45, 999-1017.

Mather, N., & Gregg, N. (2001). Assessment with the Woodcock-Johnson-III. In J. J. C. Andrews, D. H. Saklofske, & H. L. Janzen (Eds.), Handbook of psychoeducational assessment (pp. 133-165). San Diego, CA: Academic Press.

McCarney, S. B., & Leigh, J. (1990). Behavioral evaluation scale- II (BES- II ). Columbia, MO: Hawthorne Educational Services.

McClelland, D. C., Atkinson, J. W., Clark, R. A., & Lowell, E. L. (1953). The achievement motive. New York: Appleton- Century-Crofts.

McClendon, M. J. (1994), Multiple regression and causal analysis. Itasca, IL: Peacock.

McClung, M. S. (1979). Competency testing programs: Legal and educational issues. Fordham Law Review, 47, 652.

McCrae, R. R., & Costa, P. T. (1997). Personality trait structure as a human universal. American Psychologist, 52, 509-516.

McGrew, K. S., & Flanagan, D. P. (1998). The intelligence test desk reference. Boston: Allyn &. Bacon.

McGrew, K. S., Ittenbach, R. F., Bruininks, R. H., & Hill, B. K. (1991). Factor structure of maladaptive behavior across the lifespan of persons with mental retardation. Research in Developmental Disabilities, 12, 181-199.

McLoughlin, J. A., & Lewis, R. B. (2008). Assessing students with special needs (7th ed.). Upper Saddle River, NJ: Pearson.

McNulty, J. L., Graham, J. R., Ben-Porath, Y. S., & Stein, L. (1997). Comparative validity of MMPI-2 scores of African American and Caucasian mental health center clients. Psychological Assessment, 9, 463-470.

Aeehl, P. E. (1986). Causes and effects of my disturbing little book. Journal of Personality Assessment, 50, 370-375.

Aehrens, W. A. (1987). Using standardized tests in education. New York: Longman.

Aeier, D., & Wood, G. (2004). Many children left behind. Boston: Beacon Press.

herrell, K. W. (1999). Behavioral, social, and emotional assessment of children and adolescents. Mahwah, NJ: Erlbaum.

Aessick, S. (1980). Test validity and the ethics of assessment. American Psychologist, 35, 1012-1027.

Aessick, S. (1988). The once and future issues of validity: Assessing the meaning and consequences of measurement. In H. Wainer & H. Braun (Eds.), Test validity (pp. 33-45). Mahwah, NJ: Erlbaum.

Messick, S. (1989). Validity. In R. L. Linn (Ed.), Educational measurement (3rd ed., pp. 13- 103). New York: Macmillan.

Messick, S. (1993). Foundations of validity: Meaning and consequences in psychological assessment. Princeton, NJ: Educational Testing Service.

Messick, S. (1995). Validity of psychological assessment: Validation of inferences from persons' responses and performances as scientific inquiry into score meaning. American Psychologist, 50,741-749.

Metropolitan achievement tests (7th ed.). (1992). Orlando, FL: Harcourt Brace.

Meyer, G. J., & Archer, R. P. (2001). The hard science of Rorschach research: What do we know and where do we go? Psychological Assessment, 13, 486-502.

Michell, J. (1986). Measurement scales and statistics: A clash of paradigms. Psychological Bulletin, 103, 398-407.

Miller, G. A. (1984). The test. Science 84 : Fifth Anniversary Issue, 5(9), 55-60.

Miller, M. D. (1992). Review of comprehensive test of basic skills. In J. J. Kramer & J. C. Conoley (Eds.), The eleventh mental measurements yearbook (pp. 217-220). Lincoln, NE: Buros Institute of Mental Measurements.

Millon, T. (1990). Toward a new personology. New York: Wiley.

Millon, T., Millon, C., & Davis, R. (1994). Millon Clinical Multiaxial Inventory- III manual. Minneapolis, MN: National Computer Systems.

Mischel, W. (1968). Personality and assessment. New York: Wiley.

Mischel, W. (1993). Introduction to personality (5th ed.). New York: Harcourt Brace Jovanovich.

Mitchell, J. V., Jr. (Ed.). (1985). The ninth mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Moreland, K. L., Eyde, L. D., Robertson, G. J., Primoff, E. S., & Most, R. B. (1995). Assessment of test user qualifications: A research-based measurement procedure. American Psychologist, 50, 14-23.

Morreau, L. E., & Bruininks, R. H. (1991). Checklist of adaptive learning skills. Chicago: Riverside.

Morrison, R. L. (1983). Structured interviews and rating scales. In A. S. Bellack & M. Hershon (Eds.), Behavioral assessment: A practical handbook (pp. 252-278). New York: Pergamon.

Murphy, K. R., & Davidshofer, C. O. (2001). Psychological testing: Principles and applications. (5th ed.). Upper Saddle River, NJ: Prentice Hall.

Murphy, L. L., Plake, B. S., Impara, J. C., & Spies, R. A. (2002). Tests in print (6th ed.). Lincoln, NE: Buros Institute of Mental Measurements.

Murray, H. A. (1943). Thematic apperception test manual. Cambridge, MA: Harvard University Press.

National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research. (1979). The Belmont report : Ethical principles and guidelines for the protection of human subjects of research. Washington, DC: National Institutes of Health.

Newmark, C. S. (Ed.). (1996). Major psychological assessment instruments (2nd ed.). Boston:

Allyn & Bacon.

Nickerson, R. S. (1989). New directions in educational assessment. Educational Researcher, 18 (9), 3-7.

Nihira, K., Leland, H., & Lambert, N. (1993). AAMR Adaptive behavior scales- residential and community (2nd ed.). Austin, TX: PRO-ED.

Nitko, A. J. (1984). Defining "criterion-referenced test." In R. A. Berk (Ed.), A guide to criterion-referenced test construction (pp. 8-28). Baltimore: Johns Hopkins University Press.

Nitko, A. J. (2003). Educational assessment of students (4th ed.). Upper Saddle River, NJ: Merrill/Prentice Hall.

Nunnally, J. C., & Bernstein, I. H. (1994). Psychometric theory. New York: McGraw-Hill.

Nyborg, H., & Jensen, A. R. (2001). Occupation and income related to psychometric g. Intelligence, 29, 45-56.

O'Brien, N. P. (1988). Test construction: A bibliography of selected resources. New York: Greenwood.

Osgood, C. E., Suci, G. J., & Tannenbaum, P. H. (1957). The measurement of meaning. Urbana: University of Illinois Press.

Osterlind, S. J. (1989). Constructing test items. Boston: Kluwer.

Page, E. B. (1994). Computer grading of student prose, using modern concepts and software. Journal of Experimental Education, 62, 127-142.

Paris, S. G. (2000). Trojan horse in the schoolyard: The hidden threats in high-stakes testing. Issues in Education, \( 6\left( {1,2}\right) ,1 - {16} \) .

Parker, K. (1983). A meta-analysis of the reliability and validity of the Rorschach. Journal of Personality Assessment, 47, 227-231.

PASE v. Hannon,506 F. Supp. 831 (N. D. Ill., 1980).

Peres, S. H., & Garcia, J. R. (1962). Validity and dimensions of descriptive adjectives used in reference letters for engineering applicants. Personnel Psychology, 15, 279-286.

Perlmutter, B. F., Touliatos, J., & Holden, G. W. (Eds.). (2001). Handbook of family measurement techniques: Vol. 3. Instruments & index. Thousand Oaks, CA: Sage.

Petersen, N. S., Kolen, M. J., & Hoover, H. D. (1989), Scaling, norming, and equating. In R. L. Linn (Ed.), Educational measurement (3rd ed., pp. 221-262). New York: Macmillan.

Petrill, S. A., Rempell, J., Oliver, B., & Plomin, R. (2002). Testing cognitive abilities by telephone in a sample of 6- to 8-year-olds. Intelligence, 30, 353-360.

Piedmont, R. L., & Chae, J. (1997). Cross-cultural generalizability of the five factor model of personality: Development and validation of the NEO PI-R for Koreans. Journal of Cross-Cultural Psychology, 28, 131-155.

Piedmont, R. L., McCrae, R. R., Riemann, R., & Angleitner, A. (2000). On the invalidity of validity scales: Evidence from self-reports and observer ratings in volunteer samples. Journal of Personality and Social Psychology, 78, 582-593.

Plake, B. S., & Impara, J. C. (1999). Supplement to the thirteenth mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Plake, B. S., & Impara, J. C. (2001). The fourteenth mental measurements yearbook. Lincoln,

NE: Buros Institute of Mental Measurements.

Plake, B. S., Impara, J. C., & Spies, R. A. (2003). The fifteenth mental measurements yearbook. Lincoln, NE: Buros Institute of Mental Measurements.

Popham, W. J. (1990). Modern educational measurement: A practitioner's perspective. Upper Saddle River, NJ: Prentice Hall.

Porter, T. B. (1995). Basic considerations in informed consent in research. Clinical Research and Regulatory Affairs, 12, 95-109.

The Psychological Corporation, (2003). Stanford diagnostic reading test (4th ed.). San Antonio, TX: Author.

The Psychological Corporation. (1999). Wechsler abbreviated scale of intelligence (WASI). San Antonio, TX: Author.

Ree, M. J., & Earles, J. A. (1992). Intelligence is the best predictor of job performance. Current Directions in Psychological Science, 1, 86-89.

Reynolds, C. R., & Kamphaus, R. W. (1992). Behavior assessment system for children. Circle Pines, MN: American Guidance Service.

Robinson, J. P., Athanasion, R., & Head, K. B. (1969). Measures of occupational attitudes and occupational characteristics. Ann Arbor: University of Michigan.

Robinson, J. P., Rusk, J. G., & Head, K. B. (1968). Measures of political attitudes. Ann Arbor: University of Michigan.

Robinson, J. P., & Shaver, P. R. (1973). Measures of social psychological attitudes (rev. ed.). Ann Arbor: University of Michigan.

Rogers, C. R. (1951). Client centered therapy: Its current practice, implications and theory. Boston: Houghton Mifflin.

Rogers, R., Salekin, R. T., & Sewell, K. W. (1999). Validation of the Millon Clinical Multiaxial Inventory for Axis II disorders: Does it meet the Daubert standard? Law & Human Behavior, 23, 425-443.

Rogers, T. B. (1995). The psychological testing enterprise : An introduction. Pacific Grove, CA: Brooks/Cole.

Rogosa, D. R., & Willett, J. B. (1983). Demonstrating the reliability of the difference score in the measurement of change. Journal of Educational Measurement, 20, 335-343.

Roid, G. H. (2003). Stanford-Binet intelligence scales (5th ed.). Itasca, IL: Riverside.

Rosenbaum, B. L. (1971). An empirical study of attitude toward invasion of privacy as it relates to personnel selection. Unpublished doctoral dissertation, Columbia University, Teachers College, New York.

Rotatori, A. F. (1994). Test review: Multidimensional Self Concept Scale. Measurement and Evaluation in Counseling and Development, 26, 265-267.

Rubin, D. B. (1988). Discussion. In H. Wainer & H. Braun (Eds.), Test validity (pp. 241- 256). Mahwah, NJ: Erlbaum.

Runyon, R. P., Coleman, K. A., & Pittenger, D. J. (2000). Fundamentals of behavioral statistics (9th ed.). New York: McGraw-Hill.

Ryanen, I. A. (1988). Commentary of a minor bureaucrat. Journal of Vocational Behavior, 33, 379-387.

1, F. E., Downey, R. G., & Lahey, M. A. (1980). Rating the ratings: Assessing the psychometric quality of rating data. Psychological Bulletin, 88, 413-428.

kett, P. R., Schmitt, N., Ellingson, J. E., and Kabin, M. B. (2001). High-stakes testing in employment, credentialing, and higher education. American Psychologist, 56, 302-318.

ord, P. L., & Safford, E. J. (1996). A history of childhood and disability. New York: Teachers College Press.

via, J., & Ysseldyke, J. E. (2000). Assessment (8th ed.). Boston: Houghton Mifflin.

:ler, J. M. (1982). Assessment of children's intelligence and special abilities (2nd ed.). Boston: Allyn & Bacon.

ler, J. M. (2001). Assessment of children: Cognitive applications (4th ed.). San Diego, CA: Author.

ler, J. M. (2002). Assessment of children: Behavioral and clinical applications (4th ed.). San Diego, CA: Author.

ndell, D. J. (2000). Development and initial validation of validity scales for the NEO-Five Factor Inventory. Personality and Individual Differences, 29(6), 1153-1162.

inell, D. P., Haugh, O. M., Loyd, B. H., & Risinger, C. F. (1993). Tests of achievement and proficiency,Forms \( K \) and \( L \) . Chicago: Riverside.

inka, J. A., Kinder, B. N., & Kremer, T. (1997). Research validity scales for the NEO PI-R: Development and initial validation. Journal of Personality Assessment, 68, 127-138.

meiser, C. B., & Welch, C. J. (2006). Test development. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 307-354). Westport, CT: Praeger.

midt, F. L. (1988a). The problem of group differences in ability test scores in employment selection. Journal of Vocational Behavior, 33, 272-292.

midt,F. L. (1988b). Validity generalization and the future of criterion-related validity. In H. Wainer & H. Braun (Eds.), Test validity (pp. 173-189). Hillsdale, NJ: Erlbaum.

midt, F. L., & Hunter, J. E. (1981). Employment testing: Old theories and new research findings. American Psychologist, 36, 1128-1137.

nidt, F. L., & Hunter, J. E. (1992). Development of a causal model of processes determining job performance. Current Directions in Psychological Science, 1, 89-92.

midt, F. L., Hunter, J. E., Pearlman, K., & Hirsh, H. R. (1985). Forty questions about validity generalization and meta-analysis. Personnel Psychology, 32, 697-798.

neider, A. (2000, June 30). Why you can't trust letters of recommendation. The Chronicle of Higher Education, pp. A14-A18.

Jltz, D., & Schultz, S. E. (1996). A history of modern psychology (6th ed.), Fort Worth, TX: Harcourt Brace Jovanovich.

Itte, J. W. (2000). Using the MCMI-II in forensic evaluations. American Journal of Forensic Psychology, 19, 5-20.

iin, E. O. (1966). Idiocy and its treatment by the physiological method. New York: Wood.

dish, W. R., Cook, T. D. & Campbell, D. T. (2002). Experimental and quasi-experimental designs for generalized causal inference. Boston: Houghton Mifflin.

ifer, T. W., Erdberg, P., & Haroian, J. (1999). Current nonpatient data for the Rorschach, WAIS-R, and MMPI-2. Journal of Personality Assessment, 73, 305-316.

Sharf, J. C. (1988). Litigating personnel management policy. Journal of Vocational Behavior, 33, 235-271.

Shaw, M. E., & Wright, J. W. (1967). Scales for the measurement of attitudes. New York: McGraw-Hill.

Shepard, L. A. (1984). Setting performance standards. In R. A. Berk (Ed.), A guide to criterion-referenced test construction (pp. 169-198). Baltimore: Johns Hopkins University Press.

Shepard, L. A. (1989). Identification of mild handicaps. In R. L. Linn (Ed.), Educational measurement (3rd ed., pp. 545-572). New York: Macmillan.

Shepard, L. A. (1993). Evaluating test validity. In L. Darling- Hammond (Ed.), Review of research in education (Vol. 19, pp. 405-450). Washington, DC: American Educational Research Association. Shepard, L. A. (2006). Classroom assessment. In R. L. Brennan (Ed.), Educational measurement (4th ed.). Westport, CT: Praeger.

Simpson, R. L. (1990). Conferencing parents of exceptional children (2nd ed.), Austin, TX: PRO-ED.

Siskind, G. (1966), "Mine eyes have seen a host of angels." American Psychologist, 21, 804-806.

Slavin, R. E. (1987). Mastery learning reconsidered. Review of Educational Research, 57, 175-213.

Slavin, R. E. (1988). Educational psychology: Theory into practice. Upper Saddle River, NJ: Prentice Hall.

Snow, R. E., & Lohman, D. F. (1989). Implications of cognitive psychology for educational measurement. In R. L. Linn (Ed.), Educational measurement (3rd ed. , pp. 263-331). New York: Macmillan.

Society for Personality Assessment. (2005). The status of the Rorschach in clinical and forensic practice: An official statement by the Board of Trustees of the Society for Personality Assessment. Journal of Personality Assessment, 85, 219-237.

Spangler, W. D. (1992). Validity of questionnaire and TAT measures of need for achievement: Two meta-analyses. Psychological Bulletin, 112, 140-154.

Sparrow, S. S., Balla, D. A., & Cicchetti, D. V. (1984a). Vineland adaptive behavior scales. Circle Pines, MN: American Guidance Service.

Sparrow, S. S., Balla, D. A., & Cicchetti, D. V. (1984b). Vineland adaptive behavior scales: Interviewedition, expanded form. Circle Pines, MN: American Guidance Service.

Sparrow, S. S., Balla, D. A., & Cicchetti, D. V. (1984c). Vineland adaptive behavior scales: Survey form. Circle Pines, MN: American Guidance Service.

Sparrow, S. S., Balla, D. A., & Cicchetti, D. V. (1985). Vineland adaptive behavior scales: Classroom edition form. Circle Pines, MN: American Guidance Service.

Stanford achievement test series (9th ed.). (1996). Orlando FL: Harcourt Brace.

Stanford diagnostic mathematics test (3rd ed.), (1984). San Antonio, TX: Psychological Corporation.

Sternberg, R. J. (1985). Beyond IQ: A triarchic theory of intelligence. Cambridge, England: Cambridge University Press.

nberg, R. J. (2003). Issues in the theory and measurement of successful intelligence: A reply to Brody. Intelligence, 31, 331-337.

gins, R. J., & Bridgeford, N. J. (1985). The ecology of classroom assessment. Journal of Educational Measurement, 22, 271-286.

gins, R. J., Frisbie, D. A., 8. Griswold, P. A. (1989). Inside high school grading practices: Building a research agenda. Educational Measurement : Issues and Practices, 8(2), 5-14.

npf, S. E. (1994). Philosophy: History & problems (5th ed.). New York: McGraw-Hill. koviak, M. J. (1984). Estimating the reliability of mastery-non-mastery classifications. In R.

A. Berk (Ed.), A guide to criterion-referenced test construction (pp. 267-291). Baltimore: Johns Hopkins University Press.

et, S. A. (1999). Data analysis with SPSS. Needham Heights, MA: Allyn & Bacon. etland, R. C., & Keyser, D. J. (Eds.). (1986). Tests: A comprehensive reference for assessments in psychology, education and business (2nd ed.). Kansas City, MO: Test Corporaton of America.

nson, L. C. (1993). Psychology and law for the helping professions. Pacific Grove, CA: Brooks/Cole.

sy, M., & Miller, J. A. (1997). The invariance of the self-concept construct across White and Hispanic student populations. Journal of Psychoeducational Assessment 15, 4-14.

lor, H. C., & Russell, J. T. (1939). The relationship of validity coefficients to the practical effectiveness of tests in selection: Discussion and tables. Journal of Applied Psychology, 23,565-578.

williger, J. S. (1989). Classroom standard setting and grading practices. Educational Measurement: Issues and Practices, 8(2), 15-19.

isen, D. (1990). Reliability and measurement precision. In H. Wainer (Ed.), Computer adaptive testing : A primer (pp. 161-186). Mahwah, NJ: Erlbaum.

isen, D., Steinberg, L., & Fitzpatrick, A. R. (1989). Multiple-choice models: The distractors are also part of the item. Journal of Educational Measurement, 26, 161-176.

rn, A. R., & Mulvenon, S. W. (2002). High-stakes testing: An examination of elementary counselors' views and their academic preparation to meet this challenge. Measurement & Evaluation in Counseling & Development, 35, 195-207.

rndike, R. L. (1982). Applied psychometrics. Boston: Houghton Mifflin.

rndike, R. L., Hagen, E. P., & Sattler, J. M. (1986a). Guide for administering and scoring the Stanford-Binet Intelligence Scale : Fourth Edition. Chicago : Riverside.

rndike, R. L., Hagen, E. P., & Sattler, J. M. (1986b). Stanford-Binet intelligence scale (4th ed.). Chicago: Riverside.

rndike, R. L., Hagen, E. P., 8. Sattler, J. M. (1986c). The Stanford-Binet intelligence scale: Fourth edition. Technical manual. Chicago: Riverside.

rndike, R. L., & Thorndike, R. M. (1994). Reliability in educational and psychological measurement. In T. Husen & N. Postlethwaite (Eds.), International encyclopedia of education (2nd ed., pp. 4981-4995). New York: Pergamon Press.

rndike, R. M. (1990a). A century of ability testing. Chicago: Riverside.

Thorndike, R. M. (1990b). Would the real factors of the Stanford-Binet (fourth edition) please come forward? Journal of Psychoeducational Assessment, 8, 412-435.

Thorndike, R. M. (1999a). IRT and intelligence testing: Past, present, and future. In S. E. Embretson and S. L. Hershberger (Eds.), The new rules of measurement: What every psychologist and educator should know (pp. 17-35). Mahwah, NJ: Erlbaum.

Thorndike, R. M. (1999b). Review of the Twelfth Mental Measurements Yearbook. Journal of Psychoeducational Assessment, 17, 50-56.

Thorndike, R. M. (2001). Reliability. In B. Bolton (Ed.), Handbook of measurement and evaluation in rehabilitation (3rd ed., pp. 29-48). Gaithersburg, MD: Aspen.

Thorndike, R. M., & Dinnel, D. L. (2001). Basic statistics for the behavioral sciences. Upper Saddle River, NJ: Merrill/Prentice Hall.

Thurstone, L. L. (1938). Primary mental abilities. Psychometric Monographs, No. 1.

Thurstone, L. L. (1947). Multiple factor analysis. Chicago: University of Chicago Press.

Topping, G. D., & O'Gorman, J. G. (1997). Effects of faking set on validity of the NEO-FFI. Personality and Individual Differences, 23, 117-124.

Torgerson, W. S. (1958). Theory and methods of scaling. New York: Wiley.

Touliatos, J., Perlmutter, B. F., & Holden, G. W. (Eds.). (2001). Handbook of family measurement techniques: Vol. 2. Abstracts. Thousand Oaks, CA: Sage.

Touliatos, J., Perlmutter, B. F., & Straus, M. A. (Eds.). (2001). Handbook of family measurement techniques: Vol. 1. Abstracts. Thousand Oaks, CA: Sage.

U. S. Department of Education. (1983). A nation at risk : The imperative for school reform. Washington, DC: Author.

U. S. Department of Health and Human Services. (1993). Protecting human research subjects: Institutional Review Board guidebook. Washington, DC: U. S. Government Printing Office.

U. S. Department of Labor. (1992). Dictionary of occupational titles, 4th rev. ed. Washington, DC: U. S. Government Printing Office.

U. S. Department of Labor. (2000-2001). Occupational outlook handbook. Washington, DC: U. S. Government Printing Office.

U. S. Employment Service. (1967). Manual for the General Aptitude Test Battery, Section III : Development. Washington, DC: U. S. Department of Labor.

Van Sack, J. (2004, June 14). Cheating keeps getting easier: Students using cell phones to cheat on exams. The Patriot Ledger. Retrieved July 20, 2007, from http:// ledger. southboston. com.

Vincent, K. R., & Harman, M. J. (1991). The Exner Rorschach: An analysis of its clinical validity. Journal of Clinical Psychology, 47, 596-599.

Vold, D. J. (1985). The roots of teacher testing in America. Educational Measurement: Issues and Practice, 4(3), 5-8.

Wainer, H. (1989). The future of item analysis. Journal of Educational Measurement, 26, 191-208.

Wainer, H. (1990). Computer adaptive testing: A primer. Mahwah, NJ: Erlbaum.

Wainer, H., & Mislevy, R. J. (1990). Item response theory, item calibration and proficiency estimation. In H. Wainer (Ed.) Computer adaptive testing: A primer (pp. 65-102). Mahwah, NJ: Erlbaum.

ld, A. (1950). Statistical decision function. New York: Wiley.

son, P. (1961). Response to affirmative and negative binary statements. British Journal of Psychology, 52, 133-142. Watson v. Fort Worth Bank and Trust, U. S. Sup. Ct., No. 86- 6139 (June, 1988).

chsler, D. (1944). The measurement of adult intelligence. Baltimore: Williams & Wilkens.

chsler, D. (1981a). Wechsler adult intelligence scale- revised. San Antonio, TX: Psychological Corporation.

chsler, D. (1981b).WAIS-R manual. San Antonio, TX: Psychological Corporation.

chsler, D. (1989a). Wechsler preschool and primary scale of intelligence-revised. San Antonio, TX: Psychological Corporation.

chsler, D. (1989b). WPPSI-R manual. San Antonio, TX: Psychological Corporation.

chsler, D. (1991a). Wechsler intelligence scale for children-third edition. San Antonio, TX: Psychological Corporation.

chsler, D. (1991b). WISC-III manual. San Antonio, TX: Psychological Corporation.

chsler, D. (1997). Wechsler adult intelligence scale-third edition. San Antonio, TX: The Psychological Corporation.

eks, Z. R., & Ewer-Jones, B. (1991). The psychoeducational assessment of children (2nd ed.). Boston: Allyn & Bacon.

ite House. (1991, February 4). The national education goals: A second report to the nation's governors. Washington, DC: Author.

derholt, J. L., & Bryant, B. R. (1992). Gray oral reading test (3rd ed.). Austin, TX: PRO-ED.

dor, A. K., & Garner, W. R. (Eds.). (1982). Ability testing: Uses, consequences, and controversies: Pt. 1. Report of the committee. Washington, DC: National Academy Press.

lett, J. B. (1988). Questions and answers in the measurement of change. In E. Z. Rothkopf (Ed.), Review of research in education (Vol. 15, pp. 345-422). Washington, DC: American Educational Research Association.

son, P. L. (1998). Multidimensional Self-Concept Scale: An examination of grade, race and gender differences in third through sixth grade student's self-concepts. Psychology in the Schools, 35, 317-326.

ter, D. G., John, P., Stewart, A. J., Klohnen, E. C., & Duncan, L. E. (1998). Traits and motives: Toward an integration of two traditions in personality research. Psychological Review, 105, 230-250.

t, J. C., Elliott, S. N., Kramer, J. J., & Gresham, F. M. (1994). Assessment of children: Fundamental methods and practices. Madison, WI: Brown & Benchmark.

d, J. M., Garb, H. N., Lilienfeld, S. O., & Nezworski, M. T. (2002). Clinical assessment. Annual Reviews of Psychology, 53, 519-543.

odcock, R. W. (1991). Woodcock language proficiency battery-revised, English form. Chicago: Riverside.

odcock, R. W. (1998). The Woodcock reading mastery tests-revised. Circle Pines, MN: American Guidance Service.

odcock, R. W., & Mather, N. (1989). Woodcock-Johnson tests of achievement: Standard

and supplemental batteries. Chicago: Riverside.

Woodcock, R. W., McGrew, K. S., & Mather, N. (2001). Woodcock-Johnson III. Itasca, IL: Riverside.

Yang, J., Bagby, R. M., & Ryder, A. G. (2000). Response style and the revised NEO Personality Inventory: Validity scales and spousal ratings in a Chinese psychiatric sample. Assessment, 7, 389-402.

Yell, M. L., 8. Drasgow, E. (2005). No Child Left Behind: A guide for professionals. Upper Saddle River, NJ: Prentice Hall.

Yen, W. M., & Fitzpatrick, A. R. (2006). Item response theory. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 111-154). Westport, CT: Praeger.

Ysseldyke, J. E., Algozzine, B., 8. Thurlow, M. L. (1992). Critical issues in special education. Boston: Houghton Mifflin.

Ysseldyke, J. E., 8. Christenson, S. L. (1993). The instructional environment system-II. Longmont, C(   ): Sopris West.

Ysseldyke, J. E., Christenson, S. L., & Kovaleski, J. F. (1994). Identifying students' instructional needs in the context of classroom and home environments. Teaching Exceptional Children, 26, 37-41.

Ysseldyke, M. E., Thurlow, M. L., & Erickson, R. N. (1994). Possible sources of data for post-school level indicators. Minneapolis: University of Minnesota, College of Education and Human Development, National Center on Educational Outcomes.

Zern, D. (1967). Effects of variations in question phrasing on true-false answers by grade-school children. Psychological Reports, 20, 527-533.

## 图书在版编目 (CIP) 数据

教育评价: 教育和心理学中的测量与评估: 第八版/ (美) 罗伯特 - M. 桑代克, (美) 特雷西 - 桑代克- 克莱斯特著; 方群, 吴瑞芬, 陈志新译. 一北京: 商务印书馆,2018

ISBN 978-7-100-15882-4

I. ①教... II. ①罗... ② 特... ③ 方... ④ 吴... ⑤陈... III. ①教育评估 IV. ①G40-058.1

中国版本图书馆 CIP 数据核字 (2018) 第 036296 号

权利保留, 侵权必究。

教育评价

一教育和心理学中的测量与评估

(第八版)

(美) 罗伯特 \( \cdot \) M. 桑代克

(美) 特雷西・桑代克一克莱斯特

方 群 吴瑞芬 陈志新 译

商务 印 书 馆 出 版

(北京王府井大街 36 号 邮政编码 100710)

商 务 印 书 馆 发 行

北京市艺辉印刷有限公司印刷

ISBN 978-7-100-15882-4

2018 年 10 月第 1 版 开本 \( {787} \times  {10921}/{16} \)

2018 年 10 月北京第 1 次印刷

定价: 88.00 元