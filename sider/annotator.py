import re
import json
import yaml
import multiprocessing as mp
import os
from typing import List, Dict, Union, Optional
from utils.api import single_conversation
from tqdm import tqdm 

class Annotator:
    def __init__(self, use_llm_for_structure: bool = True):
        """
        åˆå§‹åŒ–æ™ºèƒ½Markdownæ–‡æ¡£æ‰¹æ³¨å™¨
        :param use_llm_for_structure: æ˜¯å¦ä½¿ç”¨å¤§æ¨¡å‹å¤„ç†æ–‡æ¡£ç»“æ„
        """
        self.annotation_cache = {}
        self.section_cache = {} 
        self.use_llm_for_structure = use_llm_for_structure

    def parse_markdown(self, markdown_content: str) -> Dict:
        """
        è§£æMarkdownæ–‡æ¡£ä¸ºç»“æ„åŒ–æ•°æ®
        :param markdown_content: Markdownæ ¼å¼çš„æ–‡æœ¬
        :return: ç»“æ„åŒ–æ–‡æ¡£å­—å…¸
        """
        if self.use_llm_for_structure:
            # ä½¿ç”¨å¤§æ¨¡å‹è¾…åŠ©è§£ææ–‡æ¡£ç»“æ„
            return self._parse_with_llm(markdown_content)
        else:
            # ä½¿ç”¨æœ¬åœ°æ–¹æ³•è§£ææ–‡æ¡£ç»“æ„
            return self._parse_locally(markdown_content)
    
    def _parse_with_llm(self, markdown_content: str) -> Dict:
        """
        ä½¿ç”¨å¤§æ¨¡å‹è§£ææ–‡æ¡£ç»“æ„
        :param markdown_content: Markdownå†…å®¹
        :return: ç»“æ„åŒ–æ–‡æ¡£å­—å…¸
        """
        # ä½¿ç”¨å¤§æ¨¡å‹è¾…åŠ©è§£ææ–‡æ¡£ç»“æ„
        structure = self._get_document_structure(markdown_content)
        
        # åˆå§‹åŒ–æ–‡æ¡£ç»“æ„
        structured_doc = {
            'title': structure.get("title", "æœªå‘½åæ–‡æ¡£"),
            'metadata': structure.get("metadata", {}),
            'sections': []
        }

        # å¦‚æœæœ‰æ˜ç¡®çš„ç« èŠ‚ç»“æ„
        if structure.get("sections"):
            for section in structure["sections"]:
                # åˆ›å»ºç« èŠ‚å†…å®¹
                section_content = self._extract_section_content(
                    markdown_content, section["start"], section["end"])
                
                # æ·»åŠ åˆ°æ–‡æ¡£ç»“æ„
                structured_doc['sections'].append({
                    'title': section["title"],
                    'paragraphs': self._create_section_paragraphs(section_content),
                    'annotations': []
                })
        else:
            # å¦‚æœå¤§æ¨¡å‹æ²¡æœ‰è¯†åˆ«å‡ºç»“æ„ï¼Œåˆ™æŒ‰ä¼ ç»Ÿæ–¹å¼å¤„ç†
            structured_doc = self._fallback_parsing(markdown_content)
        
        return structured_doc
    
    def _parse_locally(self, markdown_content: str) -> Dict:
        """
        ä½¿ç”¨æœ¬åœ°æ–¹æ³•è§£ææ–‡æ¡£ç»“æ„
        :param markdown_content: Markdownå†…å®¹
        :return: ç»“æ„åŒ–æ–‡æ¡£å­—å…¸
        """
        return self._fallback_parsing(markdown_content)

    def _get_document_structure(self, markdown_content: str) -> Dict:
        """
        ä½¿ç”¨å¤§æ¨¡å‹åˆ†ææ–‡æ¡£ç»“æ„
        :param markdown_content: Markdownå†…å®¹
        :return: æ–‡æ¡£ç»“æ„åˆ†æç»“æœ
        """
        prompt = f"""
        åˆ†æä»¥ä¸‹Markdownæ–‡æ¡£çš„ç»“æ„ï¼Œè¯†åˆ«æ ‡é¢˜ã€ç« èŠ‚å’Œå…ƒæ•°æ®ï¼š
        {markdown_content[:2000]}  # åªå–å‰2000å­—ç¬¦é¿å…è¶…é•¿
        
        è¦æ±‚ï¼š
        1. è¯†åˆ«æ–‡æ¡£æ ‡é¢˜ï¼ˆå¦‚æœæœ‰ï¼‰
        2. è¯†åˆ«å…ƒæ•°æ®ï¼ˆYAML front matterï¼‰
        3. è¯†åˆ«æ‰€æœ‰ç« èŠ‚ï¼ŒåŒ…æ‹¬æ ‡é¢˜çº§åˆ«å’Œä½ç½®
        4. æŒ‰JSONæ ¼å¼è¿”å›ï¼š
        {{"title": "æ–‡æ¡£æ ‡é¢˜",
          "metadata": {{}},
          "sections": [
            {{"level": "æ ‡é¢˜çº§åˆ«ï¼ˆå¦‚h1ã€h2ï¼‰",
              "title": "ç« èŠ‚æ ‡é¢˜",
              "start": "èµ·å§‹ä½ç½®",
              "end": "ç»“æŸä½ç½®"
            }}
          ]}}
        """
        response = self.call_llm(prompt, need_json=True)
        try:
            # æ¸…ç†å“åº”å­—ç¬¦ä¸²
            cleaned_response = response.strip()
            cleaned_response = re.sub(r'(```json|json)', '', cleaned_response).strip()
            cleaned_response = re.sub(r'`', '', cleaned_response).strip()
            
            # åŠ è½½ä¸ºJSON
            structure = json.loads(cleaned_response)
            
            # éªŒè¯å’Œè½¬æ¢startå’Œendä¸ºæ•´æ•°
            if structure.get("sections"):
                for section in structure["sections"]:
                    if "start" in section and isinstance(section["start"], (float, int)):
                        section["start"] = int(section["start"])
                    else:
                        section["start"] = 0  # é»˜è®¤å€¼
                    
                    if "end" in section and isinstance(section["end"], (float, int)):
                        section["end"] = int(section["end"])
                    else:
                        section["end"] = len(markdown_content)  # é»˜è®¤å€¼
            
            return structure
        except:
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›ç©ºç»“æ„
            return {
                "title": "",
                "metadata": {},
                "sections": []
            }

    def _extract_section_content(self, full_content: str, start: int, end: int) -> str:
        """
        æå–ç« èŠ‚å†…å®¹
        :param full_content: å®Œæ•´æ–‡æ¡£å†…å®¹
        :param start: ç« èŠ‚èµ·å§‹ä½ç½®
        :param end: ç« èŠ‚ç»“æŸä½ç½®
        :return: æå–çš„ç« èŠ‚å†…å®¹
        """
        # ç¡®ä¿startå’Œendæ˜¯æ•´æ•°
        start = max(0, min(start, len(full_content)))
        end = max(start, min(end, len(full_content)))
        return full_content[start:end].strip()

    def _fallback_parsing(self, markdown_content: str) -> Dict:
        """
        ä¼ ç»Ÿæ–¹å¼è§£æMarkdownæ–‡æ¡£ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        :param markdown_content: Markdownå†…å®¹
        :return: ç»“æ„åŒ–æ–‡æ¡£å­—å…¸
        """
        structured_doc = {
            'title': "æœªå‘½åæ–‡æ¡£",
            'metadata': {},
            'sections': []
        }

        # æå–æ–‡æ¡£å…ƒæ•°æ®ï¼ˆYAML front matterï¼‰
        front_matter_match = re.search(r'^---\s*\n(.+?)\n---', markdown_content, re.DOTALL)
        if front_matter_match:
            try:
                structured_doc['metadata'] = yaml.safe_load(front_matter_match.group(1))
            except:
                pass
        
        # åˆ†å‰²æ‰€æœ‰æ ‡é¢˜ï¼ˆæ”¯æŒh1-h6ï¼‰
        sections = re.split(r'\n(?=[#]{1,6}\s)', markdown_content)
        
        # å¤„ç†æ¯ä¸ªéƒ¨åˆ†
        for section in sections:
            # åŒ¹é…æ ‡é¢˜
            title_match = re.match(r'^[#]{1,6}\s+(.+)', section)
            if title_match:
                title = title_match.group(1).strip()
                content = section[len(title_match.group(0)):].strip()
                
                # ç¡®å®šæ ‡é¢˜çº§åˆ«
                level = len(title_match.group(0).split()[0])
                
                # åˆ›å»ºç« èŠ‚
                structured_doc['sections'].append({
                    'title': title,
                    'level': level,
                    'paragraphs': self._create_section_paragraphs(content),
                    'annotations': []
                })
            else:
                # æ— æ ‡é¢˜éƒ¨åˆ†ä½œä¸ºå†…å®¹
                if sections.index(section) == 0:
                    # ç¬¬ä¸€ä¸ªæ— æ ‡é¢˜éƒ¨åˆ†å¯èƒ½æ˜¯æ–‡æ¡£ä»‹ç»
                    structured_doc['sections'].append({
                        'title': "ä»‹ç»",
                        'level': 1,
                        'paragraphs': self._create_section_paragraphs(section),
                        'annotations': []
                    })
                else:
                    # åç»­æ— æ ‡é¢˜éƒ¨åˆ†ä½œä¸ºç‹¬ç«‹ç« èŠ‚
                    structured_doc['sections'].append({
                        'title': f"æœªå‘½åç« èŠ‚ {len(structured_doc['sections'])+1}",
                        'level': 2,
                        'paragraphs': self._create_section_paragraphs(section),
                        'annotations': []
                    })
        
        # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°ä»»ä½•ç« èŠ‚ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤ç« èŠ‚
        if not structured_doc['sections']:
            structured_doc['sections'].append({
                'title': "å†…å®¹",
                'level': 1,
                'paragraphs': self._create_section_paragraphs(markdown_content),
                'annotations': []
            })
        return structured_doc

    def _create_section_paragraphs(self, content: str) -> List[Dict]:
        """
        åˆ›å»ºç« èŠ‚æ®µè½åˆ—è¡¨ï¼ˆä½¿ç”¨å¤§æ¨¡å‹è¾…åŠ©ï¼‰
        :param content: ç« èŠ‚å†…å®¹
        :return: æ®µè½å¯¹è±¡åˆ—è¡¨
        """
        # ä½¿ç”¨å¤§æ¨¡å‹åˆ†ææ®µè½ç»“æ„
        paragraphs = self._get_paragraphs_from_llm(content)
        
        if paragraphs:
            # åˆ›å»ºæ®µè½å¯¹è±¡
            paragraph_objects = []
            for para in paragraphs:
                # æå–çº¯æ–‡æœ¬ç”¨äºåˆ†æï¼ˆå»é™¤Markdownæ ¼å¼ï¼‰
                plain_text = self._markdown_to_plaintext(para)
                paragraph_objects.append({
                    'raw': para,
                    'text': plain_text
                })
            
            return paragraph_objects
        else:
            # å¦‚æœå¤§æ¨¡å‹è§£æå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹å¼å¤„ç†
            return self._fallback_paragraph_parsing(content)

    def _get_paragraphs_from_llm(self, content: str) -> List[str]:
        """
        ä½¿ç”¨å¤§æ¨¡å‹æå–æ®µè½åˆ—è¡¨
        :param content: ç« èŠ‚å†…å®¹
        :return: æ®µè½åˆ—è¡¨
        """
        prompt = f"""
        åˆ†æä»¥ä¸‹Markdownç« èŠ‚å†…å®¹ï¼Œæå–æ®µè½åˆ—è¡¨ï¼š
        {content[:2000]}  # åªå–å‰2000å­—ç¬¦é¿å…è¶…é•¿
        
        è¦æ±‚ï¼š
        1. è¯†åˆ«å¹¶æå–æ‰€æœ‰æ®µè½å†…å®¹
        2. æ’é™¤æ ‡é¢˜ã€åˆ—è¡¨æ ‡è®°ã€ä»£ç å—ç­‰éæ®µè½å†…å®¹
        3. æŒ‰é¡ºåºè¿”å›æ®µè½åˆ—è¡¨
        4. æŒ‰JSONæ ¼å¼è¿”å›ï¼š{{"paragraphs": ["æ®µè½1", "æ®µè½2", ...]}}
        """
        response = self.call_llm(prompt, need_json=True)
        try:
            # æ¸…ç†å“åº”å­—ç¬¦ä¸²
            cleaned_response = response.strip()
            cleaned_response = re.sub(r'(```json|json)', '', cleaned_response).strip()
            cleaned_response = re.sub(r'`', '', cleaned_response).strip()
            
            # åŠ è½½ä¸ºJSON
            result = json.loads(cleaned_response)
            if "paragraphs" in result:
                return result["paragraphs"]
            else:
                return []
        except:
            return []

    def _fallback_paragraph_parsing(self, content: str) -> List[Dict]:
        """
        ä¼ ç»Ÿæ–¹å¼æå–æ®µè½ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        :param content: ç« èŠ‚å†…å®¹
        :return: æ®µè½å¯¹è±¡åˆ—è¡¨
        """
        paragraphs = []
        current_paragraph = []
        in_code_block = False
        in_list = False
        in_header = False  # æ·»åŠ æ ‡é¢˜çŠ¶æ€æ ‡è®°

        for line in content.split('\n'):
            # å¤„ç†ä»£ç å—
            if line.startswith('```'):
                in_code_block = not in_code_block
            
            # å¤„ç†åˆ—è¡¨
            list_item = re.match(r'^(\s*[-*+]\s+|\s*\d+\.\s+)', line)
            if list_item and not in_code_block:
                if not in_list:
                    # åˆ—è¡¨å¼€å§‹
                    if current_paragraph:
                        paragraphs.append('\n'.join(current_paragraph))
                        current_paragraph = []
                    in_list = True
            elif in_list and not in_code_block:
                # åˆ—è¡¨ç»“æŸ
                in_list = False
            
            # æ£€æµ‹æ ‡é¢˜è¡Œ
            header_match = re.match(r'^#+\s+', line)
            if header_match and not in_code_block:
                if current_paragraph:
                    paragraphs.append('\n'.join(current_paragraph))
                    current_paragraph = []
                in_header = True
            elif in_header:
                # æ ‡é¢˜ç»“æŸ
                in_header = False
            
            # ç©ºè¡Œåˆ†å‰²æ®µè½ï¼ˆä¸åœ¨ä»£ç å—ã€åˆ—è¡¨æˆ–æ ‡é¢˜ä¸­ï¼‰
            if not line.strip() and not in_code_block and not in_list and not in_header:
                if current_paragraph:
                    paragraphs.append('\n'.join(current_paragraph))
                    current_paragraph = []
            else:
                current_paragraph.append(line)
        
        # æ·»åŠ æœ€åä¸€ä¸ªæ®µè½
        if current_paragraph:
            paragraphs.append('\n'.join(current_paragraph))
        
        # åˆ›å»ºæ®µè½å¯¹è±¡
        paragraph_objects = []
        for para in paragraphs:
            # æå–çº¯æ–‡æœ¬ç”¨äºåˆ†æï¼ˆå»é™¤Markdownæ ¼å¼ï¼‰
            plain_text = self._markdown_to_plaintext(para)
            paragraph_objects.append({
                'raw': para,
                'text': plain_text
            })
        
        return paragraph_objects

    def _markdown_to_plaintext(self, markdown: str) -> str:
        """
        å°†Markdownè½¬æ¢ä¸ºçº¯æ–‡æœ¬ï¼ˆç”¨äºåˆ†æï¼‰
        :param markdown: Markdownæ–‡æœ¬
        :return: çº¯æ–‡æœ¬
        """
        # ç§»é™¤ä»£ç å—
        text = re.sub(r'```.*?```', '', markdown, flags=re.DOTALL)
        # ç§»é™¤å†…è”ä»£ç 
        text = re.sub(r'`([^`]+)`', r'\1', text)
        # ç§»é™¤å›¾ç‰‡
        text = re.sub(r'!\[.*?\]\(.*?\)', '', text)
        # ç§»é™¤é“¾æ¥
        text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text)
        # ç§»é™¤ç²—ä½“å’Œæ–œä½“
        text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)
        text = re.sub(r'\*([^*]+)\*', r'\1', text)
        # ç§»é™¤å¼•ç”¨
        text = re.sub(r'^>\s*', '', text, flags=re.MULTILINE)
        # ç§»é™¤HTMLæ ‡ç­¾
        text = re.sub(r'<[^>]+>', '', text)
        # ç§»é™¤å¤šä½™çš„ç©ºç™½
        text = re.sub(r'\s+', ' ', text).strip()
        return text

    def call_llm(self, prompt: str, need_json: bool = False) -> Union[str, Dict]:
        """
        è°ƒç”¨å¤§æ¨¡å‹API
        :param prompt: æç¤ºè¯
        :param need_json: æ˜¯å¦è¿”å›JSONæ ¼å¼
        :return: æ¨¡å‹å“åº”å†…å®¹
        """
        # ä½¿ç”¨ç»Ÿä¸€çš„ç³»ç»Ÿæç¤º
        system_prompt = "ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£æ™ºèƒ½æ‰¹æ³¨åŠ©æ‰‹ï¼Œè´Ÿè´£åˆ†ææ–‡æ¡£å†…å®¹å¹¶æä¾›æ‰¹æ³¨å’Œè§£é‡Šã€‚"
        
        try:
            response = single_conversation(
                system_prompt=system_prompt,
                user_input=prompt,
                need_json=need_json,
                show_progress=False
            )
            return response
        except Exception as e:
            print(f"APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def assess_difficulty(self, text: str) -> float:
        """è¯„ä¼°æ–‡æœ¬éš¾åº¦ (0-1åˆ†)"""
        if not text.strip():
            return 0.0
            
        prompt = f"""
        è¯·è¯„ä¼°ä»¥ä¸‹æ–‡æœ¬çš„é˜…è¯»éš¾åº¦ï¼Œç»™å‡º0-1ä¹‹é—´çš„åˆ†æ•°ï¼ˆ1ä¸ºæœ€éš¾ï¼‰ï¼š
        {text[:1000]}
        
        è¯„åˆ†æ ‡å‡†ï¼š
        1. 0.0-0.3: å°å­¦ç”Ÿæ°´å¹³
        2. 0.4-0.6: ä¸­å­¦ç”Ÿæ°´å¹³
        3. 0.7-0.9: å¤§å­¦ç”Ÿæ°´å¹³
        4. 1.0: ä¸“ä¸šç ”ç©¶äººå‘˜æ°´å¹³
        
        åªéœ€è¿”å›åˆ†æ•°æ•°å­—ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚ä¾‹å¦‚ï¼š0.75
        """
        response = self.call_llm(prompt)
        try:
            return min(max(float(response.strip()), 0.0), 1.0)
        except:
            return 0.5  # é»˜è®¤å€¼

    def identify_concepts(self, text: str) -> List[str]:
        """è¯†åˆ«å…³é”®æ¦‚å¿µå’Œä¸“ä¸šæœ¯è¯­"""
        if not text.strip():
            return []
            
        # ä½¿ç”¨ç¼“å­˜
        cache_key = hash(text[:500])
        if cache_key in self.section_cache:
            return self.section_cache[cache_key]
        
        prompt = f"""
        ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å…³é”®æ¦‚å¿µå’Œä¸“ä¸šæœ¯è¯­ï¼ˆæœ€å¤š5ä¸ªï¼‰ï¼š
        {text[:1000]}
        
        è¦æ±‚ï¼š
        1. åªæå–æ ¸å¿ƒæ¦‚å¿µï¼Œæ’é™¤å¸¸è§è¯æ±‡
        2. æŒ‰é‡è¦æ€§æ’åº
        3. æŒ‰JSONæ ¼å¼è¿”å›ï¼š{{"concepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2", ...]}}
        """
        response = self.call_llm(prompt, need_json=True)
        # print("åŸå§‹è¿”å›å€¼ï¼š", response)
        
        try:
            # æ¸…ç†å“åº”å­—ç¬¦ä¸²ï¼ˆç§»é™¤å¤šä½™çš„æ ‡è®°ï¼‰
            cleaned_response = response.strip()
            # ç§»é™¤å¤šä½™çš„ ```json å’Œ json å•è¯
            cleaned_response = re.sub(r'(```json|json)', '', cleaned_response).strip()
            # ç§»é™¤å¤šä½™çš„åå¼•å·
            cleaned_response = re.sub(r'`', '', cleaned_response).strip()
            # print("æ¸…ç†åçš„æ ¼å¼ä¸ºï¼š", cleaned_response)
            
            # å°è¯•åŠ è½½ä¸ºJSON
            concepts = []
            if isinstance(cleaned_response, dict):
                concepts = cleaned_response.get("concepts", [])
            else:
                concepts = json.loads(cleaned_response).get("concepts", [])
            
            # è¿‡æ»¤æ— æ•ˆæ¦‚å¿µ
            concepts = [c for c in concepts if len(c) > 2 and not c.isdigit() and not c.isspace()]
            
            self.section_cache[cache_key] = concepts
            return concepts
        except json.JSONDecodeError as e:
            print("é”™è¯¯ï¼šè¿”å›å€¼ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼")
            print(f"JSON è§£ç é”™è¯¯ï¼š{e}")
            return []
        except Exception as e:
            print(f"å¤„ç†è¿”å›å€¼æ—¶å‡ºé”™: {e}")
            return []

    def generate_annotation(self, concept: str, context: str, difficulty: float) -> Dict:
        """ç”Ÿæˆæ¦‚å¿µæ‰¹æ³¨ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{concept}-{difficulty:.1f}"
        if cache_key in self.annotation_cache:
            return self.annotation_cache[cache_key]
            
        prompt = f"""
        åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œä¸ºæ¦‚å¿µ'{concept}'åˆ›å»ºä¸­æ–‡çŸ¥è¯†å¡ç‰‡ï¼š
        {context[:500]}
        
        è¦æ±‚ï¼š
        1. ç”¨1-2å¥è¯è§£é‡Šï¼ˆæ ¹æ®éš¾åº¦{difficulty:.1f}è°ƒæ•´ä¸“ä¸šæ·±åº¦ï¼‰
        2. æä¾›1ä¸ªä¸ä¸Šä¸‹æ–‡ç›¸å…³çš„ç®€å•ç¤ºä¾‹
        3. æ·»åŠ 1ä¸ªæœ‰è¶£äº‹å®
        4. ä½¿ç”¨Markdownæ ¼å¼ï¼ˆç²—ä½“ã€åˆ—è¡¨ç­‰ï¼‰
        
        æŒ‰JSONæ ¼å¼è¿”å›ï¼š
        {{"concept": "æ¦‚å¿µåç§°",
          "explanation": "è§£é‡Šå†…å®¹",
          "example": "ç¤ºä¾‹å†…å®¹",
          "fact": "æœ‰è¶£äº‹å®"}}
        """
        response = self.call_llm(prompt, need_json=True)
        # print("çŸ¥è¯†å¡ç‰‡è¿”å›",response)
        try:
            # æ¸…ç†å“åº”å­—ç¬¦ä¸²ï¼ˆç§»é™¤å¤šä½™çš„æ ‡è®°ï¼‰
            cleaned_response = response.strip()
            # ç§»é™¤å¤šä½™çš„ ```json å’Œ json å•è¯
            cleaned_response = re.sub(r'(```json|json)', '', cleaned_response).strip()
            # ç§»é™¤å¤šä½™çš„åå¼•å·
            cleaned_response = re.sub(r'`', '', cleaned_response).strip()

            # print("æ¸…ç†åçš„æ ¼å¼ä¸ºï¼š", cleaned_response)
            if isinstance(cleaned_response, dict):
                annotation = cleaned_response
            else:
                annotation = json.loads(cleaned_response)
            # éªŒè¯ç»“æ„
            if all(key in annotation for key in ['concept', 'explanation', 'example', 'fact']):
                self.annotation_cache[cache_key] = annotation
                return annotation
        except:
            pass
            
        # é»˜è®¤è¿”å›æ ¼å¼
        return {
            "concept": concept,
            "explanation": f"æœªå–å¾—è§£é‡Š",
            "example": f"æœªå–å¾—ç¤ºä¾‹",
            "fact": f"ğŸ’¡ æœªå–å¾—æœ‰è¶£äº‹å®"
        }

    def analyze_content(self, structured_doc: Dict, difficulty_threshold: float = 0.7) -> Dict:
        """
        åˆ†æMarkdownæ–‡æ¡£å†…å®¹å¹¶ç”Ÿæˆæ‰¹æ³¨ï¼ˆé¡ºåºå¤„ç†æ®µè½ï¼‰
        :param structured_doc: ç»“æ„åŒ–æ–‡æ¡£
        :param difficulty_threshold: è§¦å‘ç®€åŒ–çš„éš¾åº¦é˜ˆå€¼
        :return: å¸¦æ‰¹æ³¨çš„æ–‡æ¡£
        """
        annotated_doc = json.loads(json.dumps(structured_doc))  # æ·±æ‹·è´
        
        # å¤„ç†ç« èŠ‚çº§åˆ«çš„åˆ†æ
        for section in annotated_doc['sections']:
            # ç« èŠ‚çº§åˆ†æ
            section_text = ' '.join(p['text'] for p in section['paragraphs'])
            section_diff = self.assess_difficulty(section_text)
            
            # æ‰“å°ç« èŠ‚åˆ†æä¿¡æ¯
            print(f"ğŸ“¦ ç« èŠ‚: {section['title']}")
            print(f"   - æ®µè½æ•°é‡: {len(section['paragraphs'])}")
            print(f"   - éš¾åº¦è¯„ä¼°: {section_diff:.2f}")
            print(f"   - ç« èŠ‚å†…å®¹: {section_text[:100]}...")  # æ‰“å°æ¯æ®µå†…å®¹çš„å‰100ä¸ªå­—ç¬¦
            
            # è¯†åˆ«ç« èŠ‚çº§æ¦‚å¿µ
            concepts = self.identify_concepts(section_text)
            print(f"   - è¯†åˆ«å…³é”®æ¦‚å¿µ: {concepts}")
            
            for concept in concepts:
                # ä½¿ç”¨ç« èŠ‚ä¸Šä¸‹æ–‡ç”Ÿæˆæ‰¹æ³¨
                annotation = self.generate_annotation(concept, section_text, section_diff)
                if annotation:
                    section['annotations'].append(annotation)
        
        # æ‰¹é‡å¤„ç†æ‰€æœ‰æ®µè½
        all_paragraphs = []
        for section in annotated_doc['sections']:
            for para in section['paragraphs']:
                all_paragraphs.append(para)
        
        # æ‰¹é‡è¯„ä¼°æ®µè½éš¾åº¦
        difficulties = self.batch_assess_difficulty([p['text'] for p in all_paragraphs])
        
        # æ›´æ–°éš¾åº¦è¯„åˆ†
        for i, para in enumerate(all_paragraphs):
            para['difficulty'] = difficulties[i]
        
        # æ‰¹é‡å¤„ç†é«˜éš¾åº¦æ®µè½
        high_difficulty_paragraphs = []
        for para in all_paragraphs:
            if para['difficulty'] > difficulty_threshold:
                high_difficulty_paragraphs.append(para)
        
        # æ‰¹é‡ç”Ÿæˆæ‰©å±•å†…å®¹
        expanded_contents = self.batch_expand_content(
            [p['raw'] for p in high_difficulty_paragraphs],
            [p['difficulty'] for p in high_difficulty_paragraphs]
        )
        
        # æ‰¹é‡ç”Ÿæˆæ˜“åŒ–å†…å®¹
        explained_contents = self.batch_explain_content(
            [p['raw'] for p in high_difficulty_paragraphs],
            [p['difficulty'] for p in high_difficulty_paragraphs]
        )
        
        # æ›´æ–°é«˜éš¾åº¦æ®µè½
        for i, para in enumerate(high_difficulty_paragraphs):
            para['expanded'] = expanded_contents[i]
            para['explained'] = explained_contents[i]
            para['high_difficulty'] = True
        
        return annotated_doc

    def batch_assess_difficulty(self, texts: List[str]) -> List[float]:
        """æ‰¹é‡è¯„ä¼°æ–‡æœ¬éš¾åº¦ï¼ˆé¡ºåºå¤„ç†ï¼‰"""
        if not texts:
            return []
        
        difficulties = []
        print("è¯„ä¼°æ®µè½éš¾åº¦â€¦â€¦")
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = tqdm(total=len(texts), desc="è¯„ä¼°éš¾åº¦")
        
        for text in texts:
            if not text.strip():
                difficulties.append(0.0)
            else:
                prompt = f"""
                è¯·è¯„ä¼°ä»¥ä¸‹æ–‡æœ¬çš„é˜…è¯»éš¾åº¦ï¼Œç»™å‡º0-1ä¹‹é—´çš„åˆ†æ•°ï¼ˆ1ä¸ºæœ€éš¾ï¼‰ï¼š
                {text[:1000]}
                
                è¯„åˆ†æ ‡å‡†ï¼š
                1. 0.0-0.3: å°å­¦ç”Ÿæ°´å¹³
                2. 0.4-0.6: ä¸­å­¦ç”Ÿæ°´å¹³
                3. 0.7-0.9: å¤§å­¦ç”Ÿæ°´å¹³
                4. 1.0: ä¸“ä¸šç ”ç©¶äººå‘˜æ°´å¹³
                
                åªéœ€è¿”å›åˆ†æ•°æ•°å­—ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚ä¾‹å¦‚ï¼š0.75
                """
                
                response = self.call_llm(prompt)
                
                try:
                    score = min(max(float(response.strip()), 0.0), 1.0)
                    difficulties.append(score)
                except:
                    difficulties.append(0.5)  # é»˜è®¤å€¼
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.update(1)
        
        progress_bar.close()
        return difficulties

    def batch_expand_content(self, markdowns: List[str], difficulties: List[float]) -> List[str]:
        """æ‰¹é‡ç”Ÿæˆæ‰©å±•å†…å®¹ï¼ˆé¡ºåºå¤„ç†ï¼‰"""
        if not markdowns:
            return []
        
        expanded_contents = []
        print("é’ˆå¯¹é«˜éš¾åº¦æ®µè½è¿›è¡ŒçŸ¥è¯†æ‰©å±•â€¦â€¦")
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = tqdm(total=len(markdowns), desc="çŸ¥è¯†æ‰©å±•")
        
        for md, diff in zip(markdowns, difficulties):
            prompt = f"""
            åŸºäºä»¥ä¸‹å†…å®¹è¿›è¡Œè”æƒ³æ‰©å±•ï¼Œæœç´¢ç›¸å…³ä¿¡æ¯å¹¶è¡¥é½çŸ¥è¯†ï¼š
            {md[:1500]}
            
            è¦æ±‚ï¼š
            1. åŸºäºå·²æœ‰ä¿¡æ¯è¿›è¡Œè”æƒ³ï¼Œæ‰©å±•æœç´¢ç›¸å…³ä¿¡æ¯ï¼ˆå¦‚èƒŒæ™¯çŸ¥è¯†ã€ç›¸å…³æ¦‚å¿µã€åº”ç”¨åœºæ™¯ç­‰ï¼‰
            2. æ ¹æ®éš¾åº¦{diff:.1f}è°ƒæ•´æ‰©å±•æ·±åº¦å’Œå¹¿åº¦
            3. ç”Ÿæˆçº¯æ–‡æœ¬ï¼Œä¸è¦markdownæ ¼å¼
            """
            
            response = self.call_llm(prompt)
            
            expanded_contents.append(response or "æœªè·å–åˆ°æ‰©å±•å†…å®¹")
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.update(1)
        
        progress_bar.close()
        return expanded_contents

    def batch_explain_content(self, markdowns: List[str], difficulties: List[float]) -> List[str]:
        """æ‰¹é‡ç”Ÿæˆæ˜“åŒ–å†…å®¹ï¼ˆé¡ºåºå¤„ç†ï¼‰"""
        if not markdowns:
            return []
        
        explained_contents = []
        print("é’ˆå¯¹é«˜éš¾åº¦æ®µè½è¿›è¡Œæ˜“åŒ–å­¦ä¹ â€¦â€¦")
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = tqdm(total=len(markdowns), desc="æ˜“åŒ–å­¦ä¹ ")
        
        for md, diff in zip(markdowns, difficulties):
            prompt = f"""
            å¯¹ä»¥ä¸‹å¤æ‚å†…å®¹è¿›è¡Œæ˜“åŒ–å­¦ä¹ å¤„ç†ï¼š
            {md[:1500]}
            
            è¦æ±‚ï¼š
            1. å°†ä¸“ä¸šæ¦‚å¿µè½¬åŒ–ä¸ºæ˜“äºç†è§£çš„è¡¨è¿°
            2. æ·»åŠ å¿…è¦çš„èƒŒæ™¯çŸ¥è¯†å’Œè§£é‡Š
            3. ä½¿ç”¨ç±»æ¯”ã€ç¤ºä¾‹ç­‰æ•™å­¦æŠ€å·§
            4. æ ¹æ®éš¾åº¦{diff:.1f}è°ƒæ•´è§£é‡Šæ·±åº¦
            5. ç”Ÿæˆçº¯æ–‡æœ¬ï¼Œä¸è¦markdownæ ¼å¼
            """
            
            response = self.call_llm(prompt)
            
            explained_contents.append(response or "æœªç”Ÿæˆæ˜“åŒ–å†…å®¹")
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.update(1)
        
        progress_bar.close()
        return explained_contents

    def generate_markdown(self, annotated_doc: Dict) -> str:
        """ç”Ÿæˆå¸¦æ‰¹æ³¨çš„Markdownæ–‡æ¡£"""
        # æ–‡æ¡£æ ‡é¢˜å’Œå…ƒæ•°æ®
        md_content = ""
        
        # å¦‚æœæœ‰æ˜ç¡®æ ‡é¢˜
        if annotated_doc['title'] != "æœªå‘½åæ–‡æ¡£":
            md_content += f"# {annotated_doc['title']}\n\n"
        
        # æ·»åŠ å…ƒæ•°æ®
        if annotated_doc.get('metadata'):
            md_content += "---\n"
            for key, value in annotated_doc['metadata'].items():
                md_content += f"{key}: {value}\n"
            md_content += "---\n\n"
        
        # æ·»åŠ æ–‡æ¡£æè¿°
        md_content += "> æœ¬æ–‡æ¡£å·²æ·»åŠ AIæ™ºèƒ½æ‰¹æ³¨ï¼Œå¸®åŠ©ç†è§£å…³é”®æ¦‚å¿µ\n\n"
        
        # ç”Ÿæˆå„ç« èŠ‚å†…å®¹
        for section in annotated_doc['sections']:
            # æ ¹æ®æ ‡é¢˜çº§åˆ«ç”Ÿæˆç›¸åº”çš„æ ‡é¢˜æ ‡è®°
            heading_level = section.get('level', 2)
            heading_marker = '#' * heading_level
            md_content += f"{heading_marker} {section['title']}\n\n"
            
            # æ·»åŠ ç« èŠ‚æ¦‚å¿µæ ‡ç­¾
            if section['annotations']:
                concepts = ", ".join(f"**{ann['concept']}**" for ann in section['annotations'])
                md_content += f"**å…³é”®æ¦‚å¿µ:** {concepts}\n\n"
            
            # æ·»åŠ çŸ¥è¯†å¡ç‰‡
            if section['annotations']:
                md_content += "### ğŸ”– çŸ¥è¯†å¡ç‰‡\n\n"
                for annotation in section['annotations']:
                    md_content += f"#### {annotation['concept']}\n"
                    md_content += f"**è§£é‡Š**: {annotation['explanation']}\n\n"
                    md_content += f"**ç¤ºä¾‹**: {annotation['example']}\n\n"
                    md_content += f"**æœ‰è¶£äº‹å®**: {annotation['fact']}\n\n"
                    md_content += "---\n"
                md_content += "\n"
            
            # æ·»åŠ æ®µè½
            for para in section['paragraphs']:
                # æ·»åŠ åŸæ®µè½æ ‡è¯†
                md_content += "#### ğŸ“„ åŸå§‹æ®µè½\n\n"
                
                # è¾“å‡ºåŸå§‹æ®µè½ï¼ˆä½¿ç”¨ç¼©è¿›å—ï¼‰
                md_content += "```markdown\n"
                md_content += f"{para['raw']}\n"
                md_content += "```\n\n"
                
                # æ·»åŠ éš¾åº¦ä¿¡æ¯
                md_content += f"**éš¾åº¦è¯„ä¼°:** {para.get('difficulty', 0.5):.2f}\n\n"
                
                # å¦‚æœæ˜¯é«˜éš¾åº¦æ®µè½ï¼Œæ·»åŠ æ‰©å±•å†…å®¹å’Œæ˜“åŒ–å­¦ä¹ 
                if para.get('high_difficulty'):
                    # çŸ¥è¯†æ‰©å±•éƒ¨åˆ†ï¼ˆå¯å±•å¼€å—ï¼‰
                    md_content += "<details>\n"
                    md_content += "<summary>ğŸ“š çŸ¥è¯†æ‰©å±•ï¼ˆç‚¹å‡»å±•å¼€ï¼‰</summary>\n\n"
                    # ä½¿ç”¨çº¯æ–‡æœ¬æ®µè½å½¢å¼å±•ç¤º
                    md_content += f"{para.get('expanded', '')}\n\n"
                    md_content += "</details>\n\n"
                    
                    # æ˜“åŒ–å­¦ä¹ éƒ¨åˆ†ï¼ˆå¯å±•å¼€å—ï¼‰
                    md_content += "<details>\n"
                    md_content += "<summary>ğŸ“ æ˜“åŒ–å­¦ä¹ ï¼ˆç‚¹å‡»å±•å¼€ï¼‰</summary>\n\n"
                    # ä½¿ç”¨çº¯æ–‡æœ¬æ®µè½å½¢å¼å±•ç¤º
                    md_content += f"{para.get('explained', '')}\n\n"
                    md_content += "</details>\n\n"
                    
                    md_content += "---\n\n"
                else:
                    # ä½éš¾åº¦æ®µè½æ·»åŠ åˆ†éš”çº¿
                    md_content += "---\n\n"
    
        # æ·»åŠ é¡µè„š
        md_content += "---\n"
        md_content += "*æ™ºèƒ½æ‰¹æ³¨ç”±AIç”Ÿæˆï¼Œæ—¨åœ¨è¾…åŠ©ç†è§£æ ¸å¿ƒæ¦‚å¿µ*\n"
        md_content += "*æ–°å¢å†…å®¹æ ‡è®°ä¸ºã€ŒçŸ¥è¯†å¡ç‰‡ã€ã€ã€ŒçŸ¥è¯†æ‰©å±•ã€å’Œã€Œæ˜“åŒ–å­¦ä¹ ã€éƒ¨åˆ†*"
        
        return md_content

    def process(self, markdown_content: str, output_file: str = "annotated_document.md") -> str:
        """
        å¤„ç†Markdownæ–‡æ¡£å¹¶ç”Ÿæˆå¸¦æ‰¹æ³¨çš„ç‰ˆæœ¬
        :param markdown_content: Markdownæ ¼å¼çš„æ–‡æœ¬
        :param output_file: è¾“å‡ºMarkdownæ–‡ä»¶è·¯å¾„
        :return: ç”Ÿæˆçš„Markdownå†…å®¹
        """
        print("ğŸ“‘ æ­£åœ¨è§£æMarkdownç»“æ„...")
        structured_doc = self.parse_markdown(markdown_content)
        print(f"âœ… æ–‡æ¡£è§£æå®Œæˆ: å…± {len(structured_doc['sections'])} ä¸ªç« èŠ‚")
        
        print("ğŸ§  æ­£åœ¨åˆ†æå†…å®¹å¹¶ç”Ÿæˆæ‰¹æ³¨...")
        annotated_doc = self.analyze_content(structured_doc)
        concept_count = sum(len(s['annotations']) for s in annotated_doc['sections'])
        print(f"âœ¨ ç”Ÿæˆ {concept_count} ä¸ªçŸ¥è¯†å¡ç‰‡æ‰¹æ³¨")
        
        print("ğŸ“ æ­£åœ¨ç”ŸæˆMarkdownæ–‡æ¡£...")
        markdown_content = self.generate_markdown(annotated_doc)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_file)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
        
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(markdown_content)
        
        print(f"ğŸ‰ æ™ºèƒ½æ‰¹æ³¨æ–‡æ¡£å·²ç”Ÿæˆ: {output_file}")
        return markdown_content

