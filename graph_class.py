import networkx as nx
from typing import Dict, List, Tuple
import json
import websocket
from websocket import WebSocketApp
import _thread as thread
import base64
import hashlib
import hmac
from urllib.parse import urlparse, urlencode
from datetime import datetime
from time import mktime
from wsgiref.handlers import format_date_time
import os
import ssl
from tqdm import tqdm
import time

# import sys
# from pathlib import Path

# # è·å–å½“å‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼Œç„¶åæ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼ˆå‡è®¾é¡¹ç›®æ ¹ç›®å½•æ˜¯ "EduSpark"ï¼‰
# current_dir = Path(__file__).parent
# project_root = current_dir.parent.parent  # æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´å±‚çº§

# # å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° Python è·¯å¾„
# sys.path.append(str(project_root))

from utils.api import (
    single_conversation,
    multi_conservation,
    single_embedding,
    multi_embedding,
    multiroundConversation,
)

import multiprocessing as mp
from concurrent.futures import ThreadPoolExecutor


class ConcurrentRequestHandler:
    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers

    def generate_questions_concurrently(self, prompts: List[str]) -> List[str]:
        """å¹¶å‘ç”Ÿæˆå¤šä¸ªé—®é¢˜"""
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            results = list(tqdm.tqdm(
                executor.map(self._generate_single_question, prompts),
                total=len(prompts),
                desc="å¹¶å‘ç”Ÿæˆé—®é¢˜"
            ))
        return results

    def _generate_single_question(self, prompt: str) -> str:
        """å•ä¸ªé—®é¢˜ç”Ÿæˆï¼ˆé€‚é…ä½ çš„APIï¼‰"""
        # è¿™é‡Œæ›¿æ¢ä¸ºä½ çš„å®é™…ç”Ÿæˆé€»è¾‘
        return single_conversation(
            system_prompt="ä½ æ˜¯ä¸€ä¸ªé—®é¢˜ç”ŸæˆåŠ©æ‰‹",
            user_input=prompt,
            need_json=False,
            show_progress=False
        )
    

class KnowledgeGraph:
    def __init__(self):
        """åˆå§‹åŒ–çŸ¥è¯†å›¾è°±ç»“æ„"""
        self.graph = nx.DiGraph()  # ä½¿ç”¨æœ‰å‘å›¾
        self.question_templates = {
            'definition': "è¯·è§£é‡Š{concept}çš„æ ¸å¿ƒæ¦‚å¿µ",
            'relation': "{source}å’Œ{target}ä¹‹é—´çš„å…³ç³»ä¸»è¦ä½“ç°åœ¨å“ªäº›æ–¹é¢ï¼Ÿ",
            'application': "å¦‚ä½•è¿ç”¨{concept}è§£å†³å®é™…é—®é¢˜ï¼Ÿ"
        }

    def load_knowledge_graph(self, graph_file_path: str = './demo_kg/graph'):
        """åŠ è½½çŸ¥è¯†å›¾è°±ï¼ˆå¸¦è¿›åº¦æ˜¾ç¤ºï¼‰"""
        print("ğŸ” å¼€å§‹åŠ è½½çŸ¥è¯†å›¾è°±...")
        start_time = time.time()
        
        nodes_path = graph_file_path + "/all_node.json"
        edges_path = graph_file_path + "/all_relations.json"
        
        # åŠ è½½èŠ‚ç‚¹
        print(f"ğŸ“‚ æ­£åœ¨åŠ è½½èŠ‚ç‚¹æ–‡ä»¶: {nodes_path}")
        with open(nodes_path, 'r', encoding='utf-8') as f:
            nodes = json.load(f)
        print(f"âœ… å·²åŠ è½½ {len(nodes)} ä¸ªèŠ‚ç‚¹")
        
        # åŠ è½½è¾¹
        print(f"ğŸ“‚ æ­£åœ¨åŠ è½½è¾¹æ–‡ä»¶: {edges_path}")
        with open(edges_path, 'r', encoding='utf-8') as f:
            edges = json.load(f)
        print(f"âœ… å·²åŠ è½½ {len(edges)} æ¡è¾¹")
        
        # å¤„ç†èŠ‚ç‚¹ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰
        print("\nğŸ› ï¸ æ­£åœ¨æ„å»ºçŸ¥è¯†èŠ‚ç‚¹...")
        id_to_name = {}
        for node in tqdm(nodes, desc="å¤„ç†èŠ‚ç‚¹"):
            id_to_name[node['id']] = node['title']
            description = node['summary'] if 'summary' in node else node['descriptions'][-1]
            self.graph.add_node(node['title'], description=description)
        
        # å¤„ç†è¾¹ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰
        print("\nğŸ› ï¸ æ­£åœ¨æ„å»ºçŸ¥è¯†å…³ç³»...")
        for edge in tqdm(edges, desc="å¤„ç†è¾¹"):
            source = id_to_name[edge['source_id']]
            target = id_to_name[edge['target_id']]
            rel_type = edge['type'] + edge['descriptions'][-1] if edge['descriptions'] else edge['type']
            self.graph.add_edge(source, target, type=rel_type, weight=edge.get('weight', 1.0))
        
        print(f"\nğŸ‰ çŸ¥è¯†å›¾è°±åŠ è½½å®Œæˆ! å…± {len(nodes)} èŠ‚ç‚¹, {len(edges)} è¾¹, è€—æ—¶ {time.time()-start_time:.2f} ç§’")


    def generate_questions(self) -> List[Dict[str, str]]:
        """ç”Ÿæˆä¸‰ç±»é—®é¢˜ï¼ˆé€‚é…å½“å‰æ•°æ®ç»“æ„ï¼‰"""
        questions = []
        
        # 1. æ¦‚å¿µå®šä¹‰é—®é¢˜ï¼ˆä½¿ç”¨èŠ‚ç‚¹æè¿°ï¼‰
        for concept in self.graph.nodes:
            desc = self.graph.nodes[concept]['descriptions']
            questions.append({
                'type': 'definition',
                'question': f"è¯·è§£é‡Š'{concept}'çš„æ¦‚å¿µ",
                'reference': f"{concept}æ˜¯æŒ‡ï¼š{desc}",
                'concept': concept
            })
        
        # 2. å…³ç³»é—®é¢˜ï¼ˆä½¿ç”¨è¾¹ä¿¡æ¯ï¼‰
        for src, dst, data in self.graph.edges(data=True):
            questions.append({
                'type': 'relation',
                'question': f"æè¿°'{src}'å’Œ'{dst}'ä¹‹é—´çš„{data['type']}å…³ç³»",
                'reference': f"å…³ç³»ç±»å‹ï¼š{data['type']}\nå…³ç³»å¼ºåº¦ï¼š{data['weight']}",
                'source': src,
                'target': dst
            })
        
        # 3. åº”ç”¨é—®é¢˜ï¼ˆåŸºäºè¿æ¥æ€§ï¼‰
        for concept in self.graph.nodes:
            neighbors = list(self.graph.neighbors(concept))
            if neighbors:
                questions.append({
                    'type': 'application',
                    'question': f"ä¸¾ä¾‹è¯´æ˜'{concept}'å¦‚ä½•å½±å“'{neighbors[0]}'",
                    'reference': f"é€šè¿‡{self.graph.edges[concept, neighbors[0]]['type']}å…³ç³»äº§ç”Ÿå½±å“",
                    'concept': concept,
                    'related': neighbors[0]
                })
        
        return questions

    def get_node_description(self, concept: str) -> str:
        """è·å–èŠ‚ç‚¹æè¿°"""
        return self.graph.nodes.get(concept, {}).get('description', 'æ— æè¿°')

    def get_relation_info(self, source: str, target: str) -> Dict:
        """è·å–å…³ç³»ä¿¡æ¯"""
        return self.graph.edges.get((source, target), {})
    
class SparkAPI:
    def __init__(self, appid, api_key, api_secret, spark_url="wss://spark-api.xf-yun.com/v1/x1"):
        """
        åˆå§‹åŒ–æ˜Ÿç«APIå‚æ•°
        :param appid: æ§åˆ¶å°è·å–çš„APPID
        :param api_key: æ§åˆ¶å°è·å–çš„APIKey
        :param api_secret: æ§åˆ¶å°è·å–çš„APISecret
        :param spark_url: æ˜Ÿç«APIçš„WebSocketåœ°å€
        """
        self.APPID = appid
        self.APIKey = api_key
        self.APISecret = api_secret
        self.Spark_url = spark_url
        self.host = urlparse(spark_url).netloc
        self.path = urlparse(spark_url).path
        self.answer = ""
        self.question = ""

    def create_url(self):
        """ç”Ÿæˆå¸¦é‰´æƒçš„WebSocketè¿æ¥URL"""
        now = datetime.now()
        date = format_date_time(mktime(now.timetuple()))
        
        signature_origin = f"host: {self.host}\ndate: {date}\nGET {self.path} HTTP/1.1"
        signature_sha = hmac.new(
            self.APISecret.encode('utf-8'), 
            signature_origin.encode('utf-8'),
            digestmod=hashlib.sha256
        ).digest()
        signature_sha_base64 = base64.b64encode(signature_sha).decode()
        
        authorization_origin = f'api_key="{self.APIKey}", algorithm="hmac-sha256", headers="host date request-line", signature="{signature_sha_base64}"'
        authorization = base64.b64encode(authorization_origin.encode('utf-8')).decode()
        
        v = {"authorization": authorization, "date": date, "host": self.host}
        return self.Spark_url + '?' + urlencode(v)

    def gen_params(self, question):
        """æ„é€ è¯·æ±‚å‚æ•°"""
        return {
            "header": {"app_id": self.APPID, "uid": "1234"},
            "parameter": {
                "chat": {
                    "domain": "x1",
                    "temperature": 0.7,  # æ§åˆ¶å›å¤éšæœºæ€§
                    "max_tokens": 2048   # æ§åˆ¶å›å¤é•¿åº¦
                }
            },
            "payload": {"message": {"text": [{"role": "user", "content": question}]}}
        }

    def on_message(self, ws, message):
        """å¤„ç†APIè¿”å›çš„æµå¼æ•°æ®"""
        data = json.loads(message)
        if data['header']['code'] != 0:
            print(f'è¯·æ±‚é”™è¯¯: {data}')
            ws.close()
            return
        
        choices = data["payload"]["choices"]
        status = choices["status"]
        
        # æå–å›å¤å†…å®¹
        content = choices['text'][0].get("content", "")
        self.answer += content
        
        if status == 2:  # å¯¹è¯ç»“æŸ
            ws.close()

    def on_error(self, ws, error):
        print("### è¿æ¥é”™è¯¯:", error)

    def on_close(self, ws, *args):
        pass

    def on_open(self, ws):
        """è¿æ¥å»ºç«‹åå‘é€é—®é¢˜"""
        def run(*args):
            data = json.dumps(self.gen_params(self.question))
            ws.send(data)
        thread.start_new_thread(run, ())

    def generate_questions(self, text):
        """ç”Ÿæˆé—®é¢˜çš„ä¸»æ–¹æ³•"""
        self.question = f"è¯·åŸºäºä»¥ä¸‹æ–‡æœ¬ç”Ÿæˆ3-5ä¸ªå•é¡¹é€‰æ‹©é¢˜ï¼š\n{text}"
        self.answer = ""  # é‡ç½®å›ç­”
        
        ws_url = self.create_url()
        ws = websocket.WebSocketApp(
            ws_url,
            on_message=self.on_message,
            on_error=self.on_error,
            on_close=self.on_close,
            on_open=self.on_open
        )
        ws.run_forever(sslopt={"cert_reqs": ssl.CERT_NONE})
        
        # æ ¼å¼åŒ–è¿”å›çš„é—®é¢˜åˆ—è¡¨
        questions = [q.strip() for q in self.answer.split("\n") if q.strip()]
        return questions
    
class KnowledgeQuestionGenerator(SparkAPI):
    def __init__(self, kg: KnowledgeGraph, **api_config):
        super().__init__(**api_config)
        self.kg = kg
        self.question_types = {
            'mcq': {
                'template': "è¯·ç”Ÿæˆå…³äº{concept}çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œè¦æ±‚ï¼š\n"
                          "- é¢˜å¹²æ¸…æ™°æ˜ç¡®\n"
                          "- é€‰é¡¹4ä¸ªï¼Œå…¶ä¸­1ä¸ªæ­£ç¡®\n"
                          "- éš¾åº¦{level}\n"
                          "- è€ƒå¯Ÿé‡ç‚¹ï¼š{focus}\n"
                          "- çŸ¥è¯†ç‚¹æè¿°ï¼š{description}",
                'focus_map': {
                    'definition': 'æ¦‚å¿µç†è§£',
                    'relation': 'å…³è”åˆ†æ'
                }
            },
            'short_answer': {
                'template': "è¯·ç”Ÿæˆå…³äº{concept}çš„ç®€ç­”é¢˜ï¼Œè¦æ±‚ï¼š\n"
                          "- é—®é¢˜èšç„¦{aspect}\n"
                          "- æœŸæœ›ç­”æ¡ˆé•¿åº¦{length}\n"
                          "- çŸ¥è¯†ç‚¹æè¿°ï¼š{description}"
            }
        }

    def generate_by_concept(self, concept: str, q_type: str = 'mcq') -> List[str]:
        """åŸºäºç‰¹å®šçŸ¥è¯†ç‚¹ç”Ÿæˆé—®é¢˜ï¼ˆé€‚é…å½“å‰æ•°æ®ç»“æ„ï¼‰"""
        if concept not in self.kg.graph:
            raise ValueError(f"æœªçŸ¥çŸ¥è¯†ç‚¹: {concept}")
        
        node_data = self.kg.graph.nodes[concept]
        print("-------before------")
        print("node_data: ",node_data)
        params = {
            'concept': concept,
            'level': self._infer_difficulty(concept),  # åŸºäºè¿æ¥æ•°æ¨æ–­éš¾åº¦
            'description': node_data['description']  # ä½¿ç”¨èŠ‚ç‚¹æè¿°
        }
        print("1111111111111111")
        if q_type == 'mcq':
            print("-----mcq----------")
            neighbors = list(self.kg.graph.neighbors(concept))
            focus = 'relation' if neighbors else 'definition'
            params.update({
                'focus': self.question_types['mcq']['focus_map'].get(focus, 'åŸºç¡€è®¤çŸ¥')
            })
            prompt = self.question_types['mcq']['template'].format(**params)
        else:
            print("-----short_answer----------")
            prompt = self.question_types['short_answer']['template'].format(
                concept=concept,  # æ·»åŠ ç¼ºå¤±çš„å…³é”®å‚æ•°
                aspect=self._infer_aspect(concept),  # è‡ªåŠ¨æ¨æ–­è€ƒå¯Ÿé‡ç‚¹
                length='3-5å¥è¯',
                description=node_data['description']
            )
        print("222222222222222222222")
        return self.generate_questions(prompt)

    def _infer_difficulty(self, concept: str) -> str:
        """åŸºäºè¿æ¥æ•°æ¨æ–­éš¾åº¦"""
        degree = len(list(self.kg.graph.neighbors(concept)))
        print(f"ğŸ” æ¨æ–­çŸ¥è¯†ç‚¹ '{concept}' çš„éš¾åº¦ï¼Œè¿æ¥æ•°: {degree}")
        if degree == 0:
            return "ç®€å•"
        elif degree <= 3:
            return "ä¸­ç­‰" 
        else:
            return "å›°éš¾"

    def _infer_aspect(self, concept: str) -> str:
        """ä»æè¿°ä¸­æå–å…³é”®è€ƒå¯Ÿæ–¹é¢"""
        desc = self.kg.graph.nodes[concept]['description']
        print("desc:",desc)
        if len(desc) < 20:
            return "æ ¸å¿ƒå®šä¹‰"
        elif "åº”ç”¨" in desc or "ä½¿ç”¨" in desc:
            return "å®é™…åº”ç”¨"
        else:
            return "å…³é”®ç‰¹å¾"
    
    def generate_and_save(self, output_path: str = "./questions", formats: List[str] = ["md", "txt"], 
                        concept: str = None, relation_type: str = None):
        """ç”Ÿæˆå¹¶ä¿å­˜é—®é¢˜ï¼ˆå¸¦è¿›åº¦æ˜¾ç¤ºï¼‰"""
        print("\n" + "="*50)
        print("ğŸš€ å¼€å§‹ç”Ÿæˆé—®é¢˜é›†")
        start_time = time.time()
        
        os.makedirs(output_path, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ç”Ÿæˆé—®é¢˜
        print("\nğŸ”§ æ­£åœ¨ç”Ÿæˆé—®é¢˜...")
        if concept:
            print(f"  ä¸“æ³¨ç”ŸæˆçŸ¥è¯†ç‚¹: {concept}")
            questions = {
                "concept_questions": [
                    ("é€‰æ‹©é¢˜", self._generate_with_progress(concept, 'mcq')),
                    ("ç®€ç­”é¢˜", self._generate_with_progress(concept, 'short_answer'))
                ]
            }
        elif relation_type:
            print(f"  ä¸“æ³¨ç”Ÿæˆå…³ç³»ç±»å‹: {relation_type}")
            questions = {"relation_questions": self.generate_relation_questions(relation_type)}
        else:
            print("  ç”Ÿæˆå…¨éƒ¨çŸ¥è¯†ç‚¹å’Œå…³ç³»çš„é—®é¢˜")
            questions = {
                "all_concepts": self._generate_all_concept_questions(),
                "all_relations": self.generate_relation_questions()
            }
        
        # ä¿å­˜æ–‡ä»¶
        print("\nğŸ’¾ æ­£åœ¨ä¿å­˜æ–‡ä»¶...")
        for fmt in formats:
            if fmt == "md":
                path = f"{output_path}/questions_{timestamp}.md"
                self._save_as_markdown(questions, path)
                print(f"  âœ… Markdownæ–‡ä»¶å·²ä¿å­˜: {path}")
            elif fmt == "txt":
                path = f"{output_path}/questions_{timestamp}.txt"
                self._save_as_text(questions, path)
                print(f"  âœ… æ–‡æœ¬æ–‡ä»¶å·²ä¿å­˜: {path}")
        
        # é¢„è§ˆ
        print("\nğŸ” ç”Ÿæˆç»“æœé¢„è§ˆ:")
        self._print_questions_preview(questions)
        
        print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆ! æ€»è€—æ—¶ {time.time()-start_time:.2f} ç§’")
        print("="*50)

    def _generate_with_progress(self, concept: str, q_type: str) -> List[str]:
        """å¸¦è¿›åº¦æ˜¾ç¤ºçš„é—®é¢˜ç”Ÿæˆ"""
        try:
            print(f"  æ­£åœ¨ç”Ÿæˆ {q_type} é—®é¢˜: {concept[:20]}...")
            start_time = time.time()
            result = self.generate_by_concept(concept, q_type)
            print(f"  âœ… ç”Ÿæˆå®Œæˆ ({len(result)} ä¸ªé—®é¢˜, è€—æ—¶ {time.time()-start_time:.2f} ç§’)")
            return result
        except Exception as e:
            print(f"  âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
            return []

    def _generate_all_concept_questions(self) -> Dict[str, List[str]]:
        """ç”Ÿæˆæ‰€æœ‰çŸ¥è¯†ç‚¹çš„é—®é¢˜ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰"""
        results = {}
        concepts = list(self.kg.graph.nodes)
        print(f"  éœ€è¦å¤„ç† {len(concepts)} ä¸ªçŸ¥è¯†ç‚¹")
        cnt=0
        for concept in tqdm(concepts, desc="ç”Ÿæˆæ¦‚å¿µé—®é¢˜"):
            cnt+=1
            if cnt<4:
                try:
                    results[concept] = {
                        "mcq": self.generate_by_concept(concept, 'mcq'),
                        "short_answer": self.generate_by_concept(concept, 'short_answer')
                    }
                except Exception as e:
                    print(f"\nâš ï¸ ç”Ÿæˆå¤±è´¥ [{concept}]: {str(e)}")
                    continue
                
        return results

    def generate_relation_questions(self, relation_type: str = None) -> Dict[str, List[str]]:
        """ç”Ÿæˆå…³ç³»ç±»é—®é¢˜ï¼ˆå¸¦è¿›åº¦æ˜¾ç¤ºï¼‰"""
        results = {}
        edges = [e for e in self.kg.graph.edges(data=True) 
                if relation_type is None or e[2]['type'] == relation_type]
        
        if not edges:
            print("âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„å…³ç³»ç±»å‹" if relation_type else "âš ï¸ çŸ¥è¯†å›¾è°±ä¸­æ²¡æœ‰å…³ç³»æ•°æ®")
            return {}
        
        print(f"  æ­£åœ¨å¤„ç† {len(edges)} æ¡å…³ç³»...")
        cnt=0
        for src, dst, data in tqdm(edges, desc="ç”Ÿæˆå…³ç³»é—®é¢˜"):
            cnt+=1
            if cnt<2:
                try:
                    prompt = (
                        f"è¯·ç”Ÿæˆè€ƒå¯Ÿä»¥ä¸‹å…³ç³»çš„é¢˜ç›®ï¼š\n"
                        f"- çŸ¥è¯†ç‚¹1ï¼š{src}\n"
                        f"- çŸ¥è¯†ç‚¹2ï¼š{dst}\n"
                        f"- å…³ç³»ç±»å‹ï¼š{data['type']}\n"
                        f"è¦æ±‚ï¼š\n"
                        f"- é€‰æ‹©é¢˜éœ€åŒ…å«åæ˜ è¯¥å…³ç³»ç‰¹å¾çš„é€‰é¡¹\n"
                        f"- ç®€ç­”é¢˜éœ€è¯„ä¼°å¯¹è¯¥å…³ç³»çš„ç†è§£æ·±åº¦\n"
                        f"- ä¸è¦åœ¨é¢˜å¹²å’Œé€‰é¡¹ä¸­å‡ºç°â€œç¬¬å‡ ç« â€ç­‰ä¸çŸ¥è¯†ç‚¹æ— å…³çš„å†—æ‚å­—æ ·"
                    )
                    questions = self.generate_questions(prompt)
                    print(questions)
                    results[f"{src}â†’{dst}({data['type']})"] = questions
                except Exception as e:
                    print(f"\nâš ï¸ ç”Ÿæˆå¤±è´¥ [{src}â†’{dst}]: {str(e)}")
                    continue
            else:
                break
                    
        return results
    
    def generate_by_concepts_batch(self, concepts: List[str], q_type: str = 'mcq') -> Dict[str, List[str]]:
        """æ‰¹é‡ç”Ÿæˆå¤šä¸ªçŸ¥è¯†ç‚¹çš„é—®é¢˜ï¼ˆå¹¶å‘ä¼˜åŒ–ï¼‰"""
        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡ç”Ÿæˆ {len(concepts)} ä¸ªçŸ¥è¯†ç‚¹çš„é—®é¢˜")
        results = {}
        
        # å‡†å¤‡æ‰€æœ‰prompt
        prompts = []
        for concept in concepts:
            if concept not in self.kg.graph:
                print(f"âš ï¸ è·³è¿‡æœªçŸ¥çŸ¥è¯†ç‚¹: {concept}")
                continue
                
            params = {
                'concept': concept,
                'level': self._infer_difficulty(concept),
                'description': self.kg.get_node_description(concept)
            }
            
            if q_type == 'mcq':
                prompt = self.question_types['mcq']['template'].format(**params)
            else:
                prompt = self.question_types['short_answer']['template'].format(
                    concept=concept,
                    aspect=self._infer_aspect(concept),
                    length='3-5å¥è¯',
                    description=params['description']
                )
            prompts.append(prompt)
        
        # å¹¶å‘æ‰§è¡Œ
        questions_list = self.concurrent_handler.generate_questions_concurrently(prompts)
        
        # æ•´ç†ç»“æœ
        for concept, questions in zip(concepts, questions_list):
            results[concept] = [q.strip() for q in questions.split("\n") if q.strip()]
        
        return results

    def generate_relation_questions_concurrent(self, relation_type: str = None) -> Dict[str, List[str]]:
        """å¹¶å‘ç”Ÿæˆå…³ç³»ç±»é—®é¢˜"""
        edges = [e for e in self.kg.graph.edges(data=True) 
                if relation_type is None or e[2]['type'] == relation_type]
        
        if not edges:
            print("âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„å…³ç³»")
            return {}
            
        print(f"\nğŸš€ å¼€å§‹å¹¶å‘ç”Ÿæˆ {len(edges)} æ¡å…³ç³»é—®é¢˜")
        results = {}
        
        # å‡†å¤‡æ‰€æœ‰prompt
        prompts = []
        relations = []
        for src, dst, data in edges:
            prompt = (
                f"è¯·ç”Ÿæˆè€ƒå¯Ÿä»¥ä¸‹å…³ç³»çš„é¢˜ç›®ï¼š\n"
                f"- çŸ¥è¯†ç‚¹1ï¼š{src}\n"
                f"- çŸ¥è¯†ç‚¹2ï¼š{dst}\n"
                f"- å…³ç³»ç±»å‹ï¼š{data['type']}\n"
                f"è¦æ±‚ï¼š\n"
                f"- é€‰æ‹©é¢˜éœ€åŒ…å«åæ˜ è¯¥å…³ç³»ç‰¹å¾çš„é€‰é¡¹\n"
                f"- ç®€ç­”é¢˜éœ€è¯„ä¼°å¯¹è¯¥å…³ç³»çš„ç†è§£æ·±åº¦"
            )
            prompts.append(prompt)
            relations.append(f"{src}â†’{dst}({data['type']})")
        
        # å¹¶å‘æ‰§è¡Œ
        questions_list = self.concurrent_handler.generate_questions_concurrently(prompts)
        
        # æ•´ç†ç»“æœ
        for rel, questions in zip(relations, questions_list):
            results[rel] = [q.strip() for q in questions.split("\n") if q.strip()]
        
        return results
    def _save_as_markdown(self, questions: Dict, filepath: str):
        """ä¿å­˜ä¸ºMarkdownæ ¼å¼"""
        with open(filepath, 'w', encoding='utf-8') as f:
            for category, content in questions.items():
                f.write(f"## {category.replace('_', ' ').title()}\n\n")
                if isinstance(content, dict):
                    for key, value in content.items():
                        f.write(f"### {key}\n")
                        if isinstance(value, list):
                            for q in value:
                                f.write(f"- {q}\n")
                        elif isinstance(value, dict):
                            for sub_key, sub_value in value.items():
                                f.write(f"#### {sub_key}\n")
                                for q in sub_value:
                                    f.write(f"- {q}\n")
                        f.write("\n")
                else:
                    for q in content:
                        f.write(f"- {q}\n")
                f.write("\n")

    def _save_as_text(self, questions: Dict, filepath: str):
        """ä¿å­˜ä¸ºçº¯æ–‡æœ¬æ ¼å¼"""
        with open(filepath, 'w', encoding='utf-8') as f:
            for category, content in questions.items():
                f.write(f"ã€{category.replace('_', ' ').upper()}ã€‘\n\n")
                if isinstance(content, dict):
                    for key, value in content.items():
                        f.write(f"*{key}*\n")
                        if isinstance(value, list):
                            for q in value:
                                f.write(f"  - {q}\n")
                        elif isinstance(value, dict):
                            for sub_key, sub_value in value.items():
                                f.write(f"  {sub_key}:\n")
                                for q in sub_value:
                                    f.write(f"    - {q}\n")
                        f.write("\n")
                else:
                    for q in content:
                        f.write(f"- {q}\n")
                f.write("\n")

    def _print_questions_preview(self, questions: Dict):
        """æ§åˆ¶å°æ‰“å°é¢„è§ˆ"""
        print("\n=== é—®é¢˜é¢„è§ˆ ===")
        for category, content in questions.items():
            print(f"\nã€{category.replace('_', ' ').title()}ã€‘")
            if isinstance(content, dict):
                for key, value in content.items():
                    print(f"\n* {key}:")
                    if isinstance(value, list):
                        for i, q in enumerate(value[:2], 1):  # æ¯ç±»åªæ˜¾ç¤ºå‰2ä¸ª
                            print(f"  {i}. {q[:60]}...")
                    elif isinstance(value, dict):
                        for sub_key, sub_value in value.items():
                            print(f"  - {sub_key}:")
                            for i, q in enumerate(sub_value[:1], 1):  # æ¯å­ç±»åªæ˜¾ç¤º1ä¸ª
                                print(f"    {i}. {q[:60]}...")
            else:
                for i, q in enumerate(content[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"{i}. {q[:60]}...")
        

if __name__ == "__main__":
    mp.freeze_support()

    # 1. æ„å»ºçŸ¥è¯†å›¾è°±
    kg = KnowledgeGraph()
    kg.load_knowledge_graph()

    # 2. åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = KnowledgeQuestionGenerator(
        kg,
        appid="2d1bc910",
        api_key="a1df9334fd048ded0c9304ccf12c20d1",
        api_secret="YzZjODMwNmNjNmRiMDVjOGI4MjcxZDVi"
    )

    # 3. å¹¶å‘ç”Ÿæˆæµ‹è¯•
    concepts = list(kg.graph.nodes)[:5]  # å–å‰5ä¸ªæ¦‚å¿µæµ‹è¯•
    batch_results = generator.generate_by_concepts_batch(concepts, 'mcq')
    
    # 4. å¹¶å‘å…³ç³»é—®é¢˜ç”Ÿæˆ
    rel_results = generator.generate_relation_questions_concurrent()
    
    # 5. ä¿å­˜ç»“æœ
    generator.generate_and_save(
        output_path="./output",
        formats=["md", "txt"],
        concept=None,
        relation_type=None
    )

    # # ç”Ÿæˆæ‰€æœ‰å…³ç³»é—®é¢˜
    # all_relation_questions = generator.generate_relation_questions()

    # # ç”Ÿæˆç‰¹å®šç±»å‹å…³ç³»é—®é¢˜
    # causal_questions = generator.generate_relation_questions("å› æœå…³ç³»")

    # generator.generate_and_save()
